{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning - Project 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class\n",
    "\n",
    "There are 2 ways to generate the forward pass:\n",
    "- either give a single sample as input (vector implies the use of mv), and apply the formula: \n",
    "$$\n",
    "\\begin{aligned}\n",
    "a^{(1)} = \\sigma(Wa^{(0)} + b)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "- or give all the training as input, i.e. a vector of (nb_samples, nb_features) using the formula \n",
    "$$\n",
    "\\begin{aligned}\n",
    "a^{(1)} = \\sigma(a^{(0)} * W + b)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where $a = [nb samples, nb features]$, $W = [nb features, nb hidden]$, $aW = [nb samples, nb hidden]$ and $b = [nb hidden]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Module(object):\n",
    "    def __init__(self, weights, bias, act_fct, d_act_fct):\n",
    "        self.W = weights\n",
    "        self.b = bias\n",
    "        self.act = act_fct\n",
    "        self.dact = d_act_fct\n",
    "    \n",
    "    def forward(self, input_data):\n",
    "        '''\n",
    "        Compute the output tensor  \n",
    "        '''\n",
    "        return # a * W\n",
    "\n",
    "    \n",
    "    def backward(self, *gradwrtoutput):\n",
    "        raise tobecontinued\n",
    "    \n",
    "    def param(self):\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activation functions\n",
    "\n",
    "$tanh(x) = \\frac{e^x - e^{-x}}{e^x + e^{-x}}$\n",
    "\n",
    "$\\frac{d}{dx}tanh(x) = \\frac{4}{(e^x + e^{-x})^2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(x):\n",
    "    output = torch.clone(x)\n",
    "    output[x <= 0] = 0\n",
    "    \n",
    "    return output\n",
    "    \n",
    "def dReLU(x):\n",
    "    output = torch.clone(x)\n",
    "    \n",
    "    output[x > 0] = 1\n",
    "    output[x <= 0] = 0\n",
    "    \n",
    "    return output\n",
    "\n",
    "def Tanh(x):\n",
    "    return (x.exp() - x.mul(-1).exp()) * ((x.exp() + x.mul(-1).exp()).pow(-1))\n",
    "\n",
    "def dTanh(x):\n",
    "    return 4 * (x.exp() + x.mul(-1).exp()).pow(-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other required functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_norm(x, y):\n",
    "    y_hat = Module.forward(x)\n",
    "    return ((y_hat - y).pow(2)).sum().item()\n",
    "\n",
    "def lossMSE(x, y):\n",
    "    '''\n",
    "    Compute the mean squared error (MSE) between the x and y input tensors\n",
    "    '''\n",
    "    return ((x - y).pow(2)).mean().item()\n",
    "\n",
    "def dlossMSE(x, y):\n",
    "    return (2 * (x - y)).mean().item()\n",
    "\n",
    "#def Linear()\n",
    "\n",
    "#def Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing_error(test_set):\n",
    "    nb_errors = 0\n",
    "    # ...\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1., -4.,  2.],\n",
      "        [ 0.,  6., -5.]])\n",
      "tensor([[1., 0., 2.],\n",
      "        [0., 6., 0.]])\n",
      "tensor([[ 0.7616, -0.9993,  0.9640],\n",
      "        [ 0.0000,  1.0000, -0.9999]])\n",
      "tensor([[ 0.7616, -0.9993,  0.9640],\n",
      "        [ 0.0000,  1.0000, -0.9999]])\n"
     ]
    }
   ],
   "source": [
    "# Check\n",
    "test_tensor = torch.Tensor([[1,-4,2], [0,6,-5]])\n",
    "print(test_tensor)\n",
    "print(ReLU(test_tensor))\n",
    "\n",
    "print(test_tensor.tanh()) #PyTorch function\n",
    "print(Tanh(test_tensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate train + test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training set\n",
    "def generate_sets(nb_train = 1000, nb_test = 1000):\n",
    "    # data\n",
    "    train_set = torch.Tensor(nb_train, 2).uniform_(0, 1)\n",
    "    test_set = torch.Tensor(nb_test, 2).uniform_(0, 1)\n",
    "    # labels\n",
    "    train_target = train_set.pow(2).sum(1).sub(1 / math.sqrt(2 * math.pi)).sign().long()\n",
    "    test_target = test_set.pow(2).sum(1).sub(1 / math.sqrt(2 * math.pi)).sign().long()\n",
    "    \n",
    "    return train_set, test_set, train_target, test_target\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 2])\n",
      "torch.Size([1000, 2])\n",
      "torch.Size([1000])\n",
      "torch.Size([1000])\n"
     ]
    }
   ],
   "source": [
    "train_, test_, train_labels, test_labels = generate_sets()\n",
    "print(train_.shape)\n",
    "print(test_.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
