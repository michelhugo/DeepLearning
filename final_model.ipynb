{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning - Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import dlc_practical_prologue as prologue\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_PAIRS = 1000\n",
    "NB_EPOCHS = 25\n",
    "MINI_BATCH_SIZE = 100 # seems to be quite optimal (see lesson 5.2)\n",
    "NB_RUN = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input,train_target,train_classes,test_input,test_target,test_classes \\\n",
    "= prologue.generate_pair_sets(NB_PAIRS)\n",
    "\n",
    "train_input = Variable(train_input.float(),requires_grad=True)\n",
    "test_input = Variable(test_input.float(),requires_grad=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_error_classification (input, class_target):\n",
    "    # input of size Nx2x10\n",
    "    # target of size Nx2\n",
    "    # max error N*2 = 2N\n",
    "    error = 0\n",
    "   \n",
    "    for k in range(input.size(0)):\n",
    "        for i in range(2):\n",
    "            _,n = t.max(input[k,i],0)\n",
    "            if n != class_target[k,i]:\n",
    "                error = error + 1\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_error_comparison (input,target):\n",
    "    # input of size Nx2\n",
    "    # target of size N\n",
    "   \n",
    "    error = 0\n",
    "    for k in range(input.size(0)):\n",
    "        _,n = t.max(input[k],0)\n",
    "        if n != target[k]:\n",
    "            error = error + 1\n",
    "    return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model_classification,model_comparison, lr):\n",
    "    ##### TO MODIFY ##############################################################################\n",
    "    #sera mieux de mettre train_input , train_classes , train target in the parameters of the function ? \n",
    "    lr_ = lr\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer_cl = t.optim.Adam(model_classification.parameters(),lr=lr_)\n",
    "    optimizer_co = t.optim.Adam(model_comparison.parameters(),lr=lr_)\n",
    "    input = train_input\n",
    "    target_cl = train_classes\n",
    "    target_co = train_target\n",
    "    \n",
    "    for e in range(NB_EPOCHS):\n",
    "        sum_loss_classification = 0\n",
    "        sum_loss_comparison = 0\n",
    "        model_comparison.zero_grad()\n",
    "        model_classification.zero_grad()\n",
    "        for b in range(0,input.size(0),MINI_BATCH_SIZE):\n",
    "            sum_loss = 0\n",
    "            input_co = t.empty(MINI_BATCH_SIZE,2,10)\n",
    "            #model_comparison.zero_grad()\n",
    "            #model_classification.zero_grad()\n",
    "            for i in range(2):\n",
    "                # using 100 samples to train our model (fast and accurate and enough i guess )\n",
    "                output_cl = model_classification(input[b:b+MINI_BATCH_SIZE,i].view(100,1,14,14)) \n",
    "                loss_cl = criterion (output_cl,target_cl[b:b+MINI_BATCH_SIZE,i].long())\n",
    "                input_co[:,i,:] = output_cl\n",
    "                sum_loss = sum_loss + loss_cl\n",
    "                # Update parameters after backward pass\n",
    "            sum_loss_classification = sum_loss_classification + sum_loss.item()\n",
    "            output_co = model_comparison(input_co)\n",
    "            loss_co = criterion(output_co,target_co[b:b+MINI_BATCH_SIZE].long())\n",
    "            sum_loss = sum_loss*0.8 + loss_co*0.2\n",
    "            #model_comparison.zero_grad()\n",
    "            #model_classification.zero_grad()\n",
    "            sum_loss_comparison = sum_loss_comparison + loss_co.item()\n",
    "            sum_loss.backward()\n",
    "            optimizer_co.step()\n",
    "            optimizer_cl.step()\n",
    "        ######### \\ MODIFY ############################################################################\n",
    "        print(\"Epoch no {} : \\nClassification loss = {:0.4f}\\nComparison loss = {:0.4f}\".format(e+1,sum_loss_classification,sum_loss_comparison))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_models(model_cl, model_co, input, classes, target, train=True):\n",
    "    output_cl = t.empty(NB_PAIRS,2,10)\n",
    "    for i in range(2):\n",
    "        output_cl[:,i,:] = model_cl(input[:,i].view(NB_PAIRS,1,14,14)) \n",
    "      \n",
    "    output_co = model_co(output_cl) #1000x2\n",
    "\n",
    "    if (train):\n",
    "        s = \"training\"\n",
    "    else:\n",
    "        s = \"testing\"\n",
    "    err1 = compute_error_classification(output_cl,classes)/2/NB_PAIRS\n",
    "    err2 = compute_error_comparison(output_co, target)/NB_PAIRS\n",
    "    print('\\x1b[3;37;41m'+\"Error in {}: \\nClassification = {:0.3f}% \\nComparison = {:0.3f}%\".format(\n",
    "          s,err1*100\n",
    "          ,err2*100)+'\\x1b[0m')\n",
    "    return err1, err2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classification, self).__init__()\n",
    "        #1x14x14\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(64, 128)\n",
    "        self.fc3 = nn.Linear(128,256)\n",
    "        self.fc2 = nn.Linear(256,10)\n",
    "        self.b1 = nn.BatchNorm1d(128)\n",
    "        self.m = nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), kernel_size=2, stride=2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), kernel_size=2, stride=2))\n",
    "        x = F.relu(self.fc1(x.view(-1, 64)))\n",
    "        x = self.b1(x)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        #batchnorm here does not change much\n",
    "        #dropout neither\n",
    "        x = self.fc2(x)\n",
    "        x = self.m(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classification_leaky_relu(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classification_leaky_relu, self).__init__()\n",
    "        #1x14x14\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(64, 128)\n",
    "        self.fc3 = nn.Linear(128,256)\n",
    "        self.fc2 = nn.Linear(256,10)\n",
    "        self.b1 = nn.BatchNorm1d(128)\n",
    "        self.m = nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(F.max_pool2d(self.conv1(x), kernel_size=2, stride=2))\n",
    "        x = F.leaky_relu(F.max_pool2d(self.conv2(x), kernel_size=2, stride=2))\n",
    "        x = F.leaky_relu(self.fc1(x.view(-1, 64)))\n",
    "        x = self.b1(x)\n",
    "        x = F.leaky_relu(self.fc3(x))\n",
    "        #batchnorm here does not change much\n",
    "        #dropout neither\n",
    "        x = self.fc2(x)\n",
    "        x = self.m(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classification_sigmoid(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classification_sigmoid, self).__init__()\n",
    "        #1x14x14\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(64, 128)\n",
    "        self.fc3 = nn.Linear(128,256)\n",
    "        self.fc2 = nn.Linear(256,10)\n",
    "        self.b1 = nn.BatchNorm1d(128)\n",
    "        self.m = nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.sigmoid(F.max_pool2d(self.conv1(x), kernel_size=2, stride=2))\n",
    "        x = F.sigmoid(F.max_pool2d(self.conv2(x), kernel_size=2, stride=2))\n",
    "        x = F.sigmoid(self.fc1(x.view(-1, 64)))\n",
    "        x = self.b1(x)\n",
    "        x = F.sigmoid(self.fc3(x))\n",
    "        #batchnorm here does not change much\n",
    "        #dropout neither\n",
    "        x = self.fc2(x)\n",
    "        x = self.m(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison - 2 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Comparison_2(nn.Module):\n",
    "    def __init__(self):\n",
    "        #1x10 I guess\n",
    "        super(Comparison_2,self).__init__()\n",
    "        self.fc1 = nn.Linear(20,32)\n",
    "        self.fc2 = nn.Linear(32,2)\n",
    "        self.m = nn.Softplus()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = x.view(-1,20)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.m(self.fc2(x))\n",
    "  \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Comparison_2_leaky_relu(nn.Module):\n",
    "    def __init__(self):\n",
    "        #1x10 I guess\n",
    "        super(Comparison_2_leaky_relu,self).__init__()\n",
    "        self.fc1 = nn.Linear(20,32)\n",
    "        self.fc2 = nn.Linear(32,2)\n",
    "        self.m = nn.Softplus()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = x.view(-1,20)\n",
    "        x = F.leaky_relu(self.fc1(x))\n",
    "        x = self.m(self.fc2(x))\n",
    "  \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Comparison_2_sigmoid(nn.Module):\n",
    "    def __init__(self):\n",
    "        #1x10 I guess\n",
    "        super(Comparison_2_sigmoid,self).__init__()\n",
    "        self.fc1 = nn.Linear(20,32)\n",
    "        self.fc2 = nn.Linear(32,2)\n",
    "        self.m = nn.Softplus()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = x.view(-1,20)\n",
    "        x = F.sigmoid(self.fc1(x))\n",
    "        x = self.m(self.fc2(x))\n",
    "  \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison - 3 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Comparison_3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Comparison_3,self).__init__()\n",
    "        self.fc1 = nn.Linear(20,40)\n",
    "        self.fc2 = nn.Linear(40,80)\n",
    "        self.fc3 = nn.Linear(80,2)\n",
    "        self.m = nn.Softplus()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.relu(x.view(-1,20))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.m(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Comparison_3_leaky_relu(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Comparison_3_leaky_relu,self).__init__()\n",
    "        self.fc1 = nn.Linear(20,40)\n",
    "        self.fc2 = nn.Linear(40,80)\n",
    "        self.fc3 = nn.Linear(80,2)\n",
    "        self.m = nn.Softplus()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.leaky_relu(x.view(-1,20))\n",
    "        x = F.leaky_relu(self.fc1(x))\n",
    "        x = F.leaky_relu(self.fc2(x))\n",
    "        x = self.m(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Comparison_3_sigmoid(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Comparison_3_sigmoid,self).__init__()\n",
    "        self.fc1 = nn.Linear(20,40)\n",
    "        self.fc2 = nn.Linear(40,80)\n",
    "        self.fc3 = nn.Linear(80,2)\n",
    "        self.m = nn.Softplus()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.sigmoid(x.view(-1,20))\n",
    "        x = F.sigmoid(self.fc1(x))\n",
    "        x = F.sigmoid(self.fc2(x))\n",
    "        x = self.m(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison - 4 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Comparison_4(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Comparison_4, self).__init__()\n",
    "        self.fc1 = nn.Linear(20, 40)\n",
    "        self.fc2 = nn.Linear(40, 80)\n",
    "        self.fc3 = nn.Linear(80, 40)\n",
    "        self.fc4 = nn.Linear(40, 2)\n",
    "        self.m = nn.Softplus()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(x.view(-1,20))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.m(self.fc4(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Comparison_4_leaky_relu(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Comparison_4_leaky_relu, self).__init__()\n",
    "        self.fc1 = nn.Linear(20, 40)\n",
    "        self.fc2 = nn.Linear(40, 80)\n",
    "        self.fc3 = nn.Linear(80, 40)\n",
    "        self.fc4 = nn.Linear(40, 2)\n",
    "        self.m = nn.Softplus()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(x.view(-1,20))\n",
    "        x = F.leaky_relu(self.fc1(x))\n",
    "        x = F.leaky_relu(self.fc2(x))\n",
    "        x = F.leaky_relu(self.fc3(x))\n",
    "        x = self.m(self.fc4(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Comparison_4_sigmoid(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Comparison_4_sigmoid, self).__init__()\n",
    "        self.fc1 = nn.Linear(20, 40)\n",
    "        self.fc2 = nn.Linear(40, 80)\n",
    "        self.fc3 = nn.Linear(80, 40)\n",
    "        self.fc4 = nn.Linear(40, 2)\n",
    "        self.m = nn.Softplus()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.sigmoid(x.view(-1,20))\n",
    "        x = F.sigmoid(self.fc1(x))\n",
    "        x = F.sigmoid(self.fc2(x))\n",
    "        x = F.sigmoid(self.fc3(x))\n",
    "        x = self.m(self.fc4(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison - 5 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Comparison_5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Comparison_5, self).__init__()\n",
    "        self.fc1 = nn.Linear(20, 40)\n",
    "        self.fc2 = nn.Linear(40, 80)\n",
    "        self.fc3 = nn.Linear(80, 160)\n",
    "        self.fc4 = nn.Linear(160, 80)\n",
    "        self.fc5 = nn.Linear(80, 2)\n",
    "        self.m = nn.Softplus()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(x.view(-1,20))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.m(self.fc5(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Comparison_5_leaky_relu(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Comparison_5_leaky_relu, self).__init__()\n",
    "        self.fc1 = nn.Linear(20, 40)\n",
    "        self.fc2 = nn.Linear(40, 80)\n",
    "        self.fc3 = nn.Linear(80, 160)\n",
    "        self.fc4 = nn.Linear(160, 80)\n",
    "        self.fc5 = nn.Linear(80, 2)\n",
    "        self.m = nn.Softplus()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(x.view(-1,20))\n",
    "        x = F.leaky_relu(self.fc1(x))\n",
    "        x = F.leaky_relu(self.fc2(x))\n",
    "        x = F.leaky_relu(self.fc3(x))\n",
    "        x = F.leaky_relu(self.fc4(x))\n",
    "        x = self.m(self.fc5(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Comparison_5_sigmoid(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Comparison_5_sigmoid, self).__init__()\n",
    "        self.fc1 = nn.Linear(20, 40)\n",
    "        self.fc2 = nn.Linear(40, 80)\n",
    "        self.fc3 = nn.Linear(80, 160)\n",
    "        self.fc4 = nn.Linear(160, 80)\n",
    "        self.fc5 = nn.Linear(80, 2)\n",
    "        self.m = nn.Softplus()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.sigmoid(x.view(-1,20))\n",
    "        x = F.sigmoid(self.fc1(x))\n",
    "        x = F.sigmoid(self.fc2(x))\n",
    "        x = F.sigmoid(self.fc3(x))\n",
    "        x = F.sigmoid(self.fc4(x))\n",
    "        x = self.m(self.fc5(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison - 6 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Comparison_6(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Comparison_6, self).__init__()\n",
    "        self.fc1 = nn.Linear(20, 40)\n",
    "        self.fc2 = nn.Linear(40, 80)\n",
    "        self.fc3 = nn.Linear(80, 160)\n",
    "        self.fc4 = nn.Linear(160, 80)\n",
    "        self.fc5 = nn.Linear(80, 40)\n",
    "        self.fc6 = nn.Linear(40, 2)\n",
    "        self.m = nn.Softplus()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(x.view(-1,20))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = F.relu(self.fc5(x))\n",
    "        x = self.m(self.fc6(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Comparison_6_leaky_relu(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Comparison_6_leaky_relu, self).__init__()\n",
    "        self.fc1 = nn.Linear(20, 40)\n",
    "        self.fc2 = nn.Linear(40, 80)\n",
    "        self.fc3 = nn.Linear(80, 160)\n",
    "        self.fc4 = nn.Linear(160, 80)\n",
    "        self.fc5 = nn.Linear(80, 40)\n",
    "        self.fc6 = nn.Linear(40, 2)\n",
    "        self.m = nn.Softplus()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(x.view(-1,20))\n",
    "        x = F.leaky_relu(self.fc1(x))\n",
    "        x = F.leaky_relu(self.fc2(x))\n",
    "        x = F.leaky_relu(self.fc3(x))\n",
    "        x = F.leaky_relu(self.fc4(x))\n",
    "        x = F.leaky_relu(self.fc5(x))\n",
    "        x = self.m(self.fc6(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Comparison_6_sigmoid(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Comparison_6_sigmoid, self).__init__()\n",
    "        self.fc1 = nn.Linear(20, 40)\n",
    "        self.fc2 = nn.Linear(40, 80)\n",
    "        self.fc3 = nn.Linear(80, 160)\n",
    "        self.fc4 = nn.Linear(160, 80)\n",
    "        self.fc5 = nn.Linear(80, 40)\n",
    "        self.fc6 = nn.Linear(40, 2)\n",
    "        self.m = nn.Softplus()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.sigmoid(x.view(-1,20))\n",
    "        x = F.sigmoid(self.fc1(x))\n",
    "        x = F.sigmoid(self.fc2(x))\n",
    "        x = F.sigmoid(self.fc3(x))\n",
    "        x = F.sigmoid(self.fc4(x))\n",
    "        x = F.sigmoid(self.fc5(x))\n",
    "        x = self.m(self.fc6(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison - 10 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Comparison_10(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Comparison_10, self).__init__()\n",
    "        self.fc1 = nn.Linear(20, 40)\n",
    "        self.fc2 = nn.Linear(40, 80)\n",
    "        self.fc3 = nn.Linear(80, 160)\n",
    "        self.fc4 = nn.Linear(160, 320)\n",
    "        self.fc5 = nn.Linear(320, 640)\n",
    "        self.fc6 = nn.Linear(640, 320)\n",
    "        self.fc7 = nn.Linear(320, 160)\n",
    "        self.fc8 = nn.Linear(160, 80)\n",
    "        self.fc9 = nn.Linear(80, 40)\n",
    "        self.fc10 = nn.Linear(40, 2)\n",
    "        self.m = nn.Softplus()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(x.view(-1,20))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = F.relu(self.fc5(x))\n",
    "        x = F.relu(self.fc6(x))\n",
    "        x = F.relu(self.fc7(x))\n",
    "        x = F.relu(self.fc8(x))\n",
    "        x = F.relu(self.fc9(x))\n",
    "        x = self.m(self.fc10(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison - 20 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid search (based on the one previously computed in the test.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "lrs = [1e-4, 1e-3, 1e-2, 1e-1]\n",
    "classification_models = [Classification(), Classification_leaky_relu(), Classification_sigmoid()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN NO 1\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.9561\n",
      "Comparison loss = 6.9224\n",
      "Epoch no 2 : \n",
      "Classification loss = 45.6728\n",
      "Comparison loss = 6.9168\n",
      "Epoch no 3 : \n",
      "Classification loss = 45.3634\n",
      "Comparison loss = 6.9117\n",
      "Epoch no 4 : \n",
      "Classification loss = 44.9660\n",
      "Comparison loss = 6.9073\n",
      "Epoch no 5 : \n",
      "Classification loss = 44.4771\n",
      "Comparison loss = 6.9031\n",
      "Epoch no 6 : \n",
      "Classification loss = 43.9487\n",
      "Comparison loss = 6.8990\n",
      "Epoch no 7 : \n",
      "Classification loss = 43.4091\n",
      "Comparison loss = 6.8949\n",
      "Epoch no 8 : \n",
      "Classification loss = 42.8936\n",
      "Comparison loss = 6.8910\n",
      "Epoch no 9 : \n",
      "Classification loss = 42.4207\n",
      "Comparison loss = 6.8870\n",
      "Epoch no 10 : \n",
      "Classification loss = 41.9286\n",
      "Comparison loss = 6.8826\n",
      "Epoch no 11 : \n",
      "Classification loss = 41.3959\n",
      "Comparison loss = 6.8777\n",
      "Epoch no 12 : \n",
      "Classification loss = 40.8463\n",
      "Comparison loss = 6.8720\n",
      "Epoch no 13 : \n",
      "Classification loss = 40.1979\n",
      "Comparison loss = 6.8655\n",
      "Epoch no 14 : \n",
      "Classification loss = 39.5186\n",
      "Comparison loss = 6.8565\n",
      "Epoch no 15 : \n",
      "Classification loss = 38.8587\n",
      "Comparison loss = 6.8441\n",
      "Epoch no 16 : \n",
      "Classification loss = 38.1590\n",
      "Comparison loss = 6.8312\n",
      "Epoch no 17 : \n",
      "Classification loss = 37.5512\n",
      "Comparison loss = 6.8116\n",
      "Epoch no 18 : \n",
      "Classification loss = 36.8844\n",
      "Comparison loss = 6.7857\n",
      "Epoch no 19 : \n",
      "Classification loss = 36.2692\n",
      "Comparison loss = 6.7525\n",
      "Epoch no 20 : \n",
      "Classification loss = 35.6364\n",
      "Comparison loss = 6.7062\n",
      "Epoch no 21 : \n",
      "Classification loss = 35.1289\n",
      "Comparison loss = 6.6429\n",
      "Epoch no 22 : \n",
      "Classification loss = 34.7042\n",
      "Comparison loss = 6.5555\n",
      "Epoch no 23 : \n",
      "Classification loss = 34.2209\n",
      "Comparison loss = 6.4336\n",
      "Epoch no 24 : \n",
      "Classification loss = 33.8303\n",
      "Comparison loss = 6.2936\n",
      "Epoch no 25 : \n",
      "Classification loss = 33.5059\n",
      "Comparison loss = 6.1106\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 13.500% \n",
      "Comparison = 39.800%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 15.900% \n",
      "Comparison = 42.800%\u001b[0m\n",
      "RUN NO 2\n",
      "Epoch no 1 : \n",
      "Classification loss = 33.1468\n",
      "Comparison loss = 6.9397\n",
      "Epoch no 2 : \n",
      "Classification loss = 32.8864\n",
      "Comparison loss = 6.9324\n",
      "Epoch no 3 : \n",
      "Classification loss = 32.6689\n",
      "Comparison loss = 6.9252\n",
      "Epoch no 4 : \n",
      "Classification loss = 32.4070\n",
      "Comparison loss = 6.9177\n",
      "Epoch no 5 : \n",
      "Classification loss = 32.2283\n",
      "Comparison loss = 6.9097\n",
      "Epoch no 6 : \n",
      "Classification loss = 32.0788\n",
      "Comparison loss = 6.9002\n",
      "Epoch no 7 : \n",
      "Classification loss = 31.9341\n",
      "Comparison loss = 6.8889\n",
      "Epoch no 8 : \n",
      "Classification loss = 31.8045\n",
      "Comparison loss = 6.8761\n",
      "Epoch no 9 : \n",
      "Classification loss = 31.6677\n",
      "Comparison loss = 6.8597\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.5422\n",
      "Comparison loss = 6.8389\n",
      "Epoch no 11 : \n",
      "Classification loss = 31.4120\n",
      "Comparison loss = 6.8151\n",
      "Epoch no 12 : \n",
      "Classification loss = 31.2340\n",
      "Comparison loss = 6.7811\n",
      "Epoch no 13 : \n",
      "Classification loss = 31.0301\n",
      "Comparison loss = 6.7346\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.8329\n",
      "Comparison loss = 6.6744\n",
      "Epoch no 15 : \n",
      "Classification loss = 30.5628\n",
      "Comparison loss = 6.5861\n",
      "Epoch no 16 : \n",
      "Classification loss = 30.3943\n",
      "Comparison loss = 6.4683\n",
      "Epoch no 17 : \n",
      "Classification loss = 30.2495\n",
      "Comparison loss = 6.3131\n",
      "Epoch no 18 : \n",
      "Classification loss = 30.1507\n",
      "Comparison loss = 6.1157\n",
      "Epoch no 19 : \n",
      "Classification loss = 30.0416\n",
      "Comparison loss = 5.8618\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.9625\n",
      "Comparison loss = 5.5881\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.8685\n",
      "Comparison loss = 5.2993\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.8315\n",
      "Comparison loss = 5.0119\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.7805\n",
      "Comparison loss = 4.7262\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.7317\n",
      "Comparison loss = 4.4441\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.6968\n",
      "Comparison loss = 4.1823\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 1.300% \n",
      "Comparison = 13.800%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 5.200% \n",
      "Comparison = 16.100%\u001b[0m\n",
      "RUN NO 3\n",
      "Epoch no 1 : \n",
      "Classification loss = 29.6885\n",
      "Comparison loss = 6.9398\n",
      "Epoch no 2 : \n",
      "Classification loss = 29.6374\n",
      "Comparison loss = 6.9344\n",
      "Epoch no 3 : \n",
      "Classification loss = 29.6484\n",
      "Comparison loss = 6.9285\n",
      "Epoch no 4 : \n",
      "Classification loss = 29.5887\n",
      "Comparison loss = 6.9225\n",
      "Epoch no 5 : \n",
      "Classification loss = 29.5387\n",
      "Comparison loss = 6.9166\n",
      "Epoch no 6 : \n",
      "Classification loss = 29.5377\n",
      "Comparison loss = 6.9085\n",
      "Epoch no 7 : \n",
      "Classification loss = 29.4895\n",
      "Comparison loss = 6.8986\n",
      "Epoch no 8 : \n",
      "Classification loss = 29.4660\n",
      "Comparison loss = 6.8870\n",
      "Epoch no 9 : \n",
      "Classification loss = 29.4491\n",
      "Comparison loss = 6.8716\n",
      "Epoch no 10 : \n",
      "Classification loss = 29.4376\n",
      "Comparison loss = 6.8509\n",
      "Epoch no 11 : \n",
      "Classification loss = 29.4271\n",
      "Comparison loss = 6.8227\n",
      "Epoch no 12 : \n",
      "Classification loss = 29.4182\n",
      "Comparison loss = 6.7847\n",
      "Epoch no 13 : \n",
      "Classification loss = 29.4084\n",
      "Comparison loss = 6.7326\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.3977\n",
      "Comparison loss = 6.6627\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.3886\n",
      "Comparison loss = 6.5692\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.3775\n",
      "Comparison loss = 6.4460\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.3701\n",
      "Comparison loss = 6.2867\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.3617\n",
      "Comparison loss = 6.0820\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.3576\n",
      "Comparison loss = 5.8236\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.3509\n",
      "Comparison loss = 5.4958\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.3477\n",
      "Comparison loss = 5.0938\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.3438\n",
      "Comparison loss = 4.6234\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.3364\n",
      "Comparison loss = 4.0959\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.3343\n",
      "Comparison loss = 3.5430\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3308\n",
      "Comparison loss = 2.9992\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.400% \n",
      "Comparison = 2.700%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 5.300% \n",
      "Comparison = 6.400%\u001b[0m\n",
      "RUN NO 4\n",
      "Epoch no 1 : \n",
      "Classification loss = 29.3237\n",
      "Comparison loss = 6.9686\n",
      "Epoch no 2 : \n",
      "Classification loss = 29.3029\n",
      "Comparison loss = 6.9630\n",
      "Epoch no 3 : \n",
      "Classification loss = 29.3114\n",
      "Comparison loss = 6.9577\n",
      "Epoch no 4 : \n",
      "Classification loss = 29.3234\n",
      "Comparison loss = 6.9525\n",
      "Epoch no 5 : \n",
      "Classification loss = 29.3067\n",
      "Comparison loss = 6.9481\n",
      "Epoch no 6 : \n",
      "Classification loss = 29.3146\n",
      "Comparison loss = 6.9424\n",
      "Epoch no 7 : \n",
      "Classification loss = 29.2978\n",
      "Comparison loss = 6.9371\n",
      "Epoch no 8 : \n",
      "Classification loss = 29.2912\n",
      "Comparison loss = 6.9308\n",
      "Epoch no 9 : \n",
      "Classification loss = 29.2809\n",
      "Comparison loss = 6.9235\n",
      "Epoch no 10 : \n",
      "Classification loss = 29.2772\n",
      "Comparison loss = 6.9132\n",
      "Epoch no 11 : \n",
      "Classification loss = 29.2763\n",
      "Comparison loss = 6.9000\n",
      "Epoch no 12 : \n",
      "Classification loss = 29.2756\n",
      "Comparison loss = 6.8829\n",
      "Epoch no 13 : \n",
      "Classification loss = 29.2752\n",
      "Comparison loss = 6.8598\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.2749\n",
      "Comparison loss = 6.8293\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.2746\n",
      "Comparison loss = 6.7876\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.2744\n",
      "Comparison loss = 6.7305\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.2743\n",
      "Comparison loss = 6.6527\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.2742\n",
      "Comparison loss = 6.5471\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.2741\n",
      "Comparison loss = 6.4068\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.2740\n",
      "Comparison loss = 6.2236\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.2739\n",
      "Comparison loss = 5.9908\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.2738\n",
      "Comparison loss = 5.7067\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.2736\n",
      "Comparison loss = 5.3704\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.2735\n",
      "Comparison loss = 4.9808\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.2734\n",
      "Comparison loss = 4.5497\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.250% \n",
      "Comparison = 12.000%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 5.350% \n",
      "Comparison = 14.300%\u001b[0m\n",
      "RUN NO 5\n",
      "Epoch no 1 : \n",
      "Classification loss = 29.2749\n",
      "Comparison loss = 6.8942\n",
      "Epoch no 2 : \n",
      "Classification loss = 29.2750\n",
      "Comparison loss = 6.8914\n",
      "Epoch no 3 : \n",
      "Classification loss = 29.2806\n",
      "Comparison loss = 6.8887\n",
      "Epoch no 4 : \n",
      "Classification loss = 29.2792\n",
      "Comparison loss = 6.8856\n",
      "Epoch no 5 : \n",
      "Classification loss = 29.2758\n",
      "Comparison loss = 6.8822\n",
      "Epoch no 6 : \n",
      "Classification loss = 29.2747\n",
      "Comparison loss = 6.8781\n",
      "Epoch no 7 : \n",
      "Classification loss = 29.2740\n",
      "Comparison loss = 6.8727\n",
      "Epoch no 8 : \n",
      "Classification loss = 29.2735\n",
      "Comparison loss = 6.8657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch no 9 : \n",
      "Classification loss = 29.2726\n",
      "Comparison loss = 6.8559\n",
      "Epoch no 10 : \n",
      "Classification loss = 29.2694\n",
      "Comparison loss = 6.8427\n",
      "Epoch no 11 : \n",
      "Classification loss = 29.2637\n",
      "Comparison loss = 6.8248\n",
      "Epoch no 12 : \n",
      "Classification loss = 29.2636\n",
      "Comparison loss = 6.7997\n",
      "Epoch no 13 : \n",
      "Classification loss = 29.2635\n",
      "Comparison loss = 6.7656\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.2633\n",
      "Comparison loss = 6.7199\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.2635\n",
      "Comparison loss = 6.6584\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.2635\n",
      "Comparison loss = 6.5761\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.2634\n",
      "Comparison loss = 6.4658\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.2634\n",
      "Comparison loss = 6.3198\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.2633\n",
      "Comparison loss = 6.1320\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.2633\n",
      "Comparison loss = 5.8931\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.2633\n",
      "Comparison loss = 5.5921\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.2633\n",
      "Comparison loss = 5.2332\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.2633\n",
      "Comparison loss = 4.8289\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.2633\n",
      "Comparison loss = 4.3795\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.2633\n",
      "Comparison loss = 3.9187\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.200% \n",
      "Comparison = 8.600%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 5.000% \n",
      "Comparison = 11.700%\u001b[0m\n",
      "RUN NO 6\n",
      "Epoch no 1 : \n",
      "Classification loss = 29.2636\n",
      "Comparison loss = 6.9924\n",
      "Epoch no 2 : \n",
      "Classification loss = 29.2633\n",
      "Comparison loss = 6.9838\n",
      "Epoch no 3 : \n",
      "Classification loss = 29.2641\n",
      "Comparison loss = 6.9755\n",
      "Epoch no 4 : \n",
      "Classification loss = 29.2632\n",
      "Comparison loss = 6.9666\n",
      "Epoch no 5 : \n",
      "Classification loss = 29.2632\n",
      "Comparison loss = 6.9568\n",
      "Epoch no 6 : \n",
      "Classification loss = 29.2631\n",
      "Comparison loss = 6.9464\n",
      "Epoch no 7 : \n",
      "Classification loss = 29.2631\n",
      "Comparison loss = 6.9339\n",
      "Epoch no 8 : \n",
      "Classification loss = 29.2631\n",
      "Comparison loss = 6.9183\n",
      "Epoch no 9 : \n",
      "Classification loss = 29.2631\n",
      "Comparison loss = 6.8993\n",
      "Epoch no 10 : \n",
      "Classification loss = 29.2631\n",
      "Comparison loss = 6.8745\n",
      "Epoch no 11 : \n",
      "Classification loss = 29.2631\n",
      "Comparison loss = 6.8429\n",
      "Epoch no 12 : \n",
      "Classification loss = 29.2631\n",
      "Comparison loss = 6.8013\n",
      "Epoch no 13 : \n",
      "Classification loss = 29.2631\n",
      "Comparison loss = 6.7470\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.2630\n",
      "Comparison loss = 6.6752\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.2630\n",
      "Comparison loss = 6.5793\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.2630\n",
      "Comparison loss = 6.4495\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.2630\n",
      "Comparison loss = 6.2779\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.2630\n",
      "Comparison loss = 6.0578\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.2630\n",
      "Comparison loss = 5.7889\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.2630\n",
      "Comparison loss = 5.4734\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.2630\n",
      "Comparison loss = 5.1207\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.2630\n",
      "Comparison loss = 4.7537\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.2630\n",
      "Comparison loss = 4.3644\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.2630\n",
      "Comparison loss = 3.9818\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.2630\n",
      "Comparison loss = 3.6088\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.200% \n",
      "Comparison = 8.000%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.900% \n",
      "Comparison = 10.700%\u001b[0m\n",
      "RUN NO 7\n",
      "Epoch no 1 : \n",
      "Classification loss = 29.2631\n",
      "Comparison loss = 6.9191\n",
      "Epoch no 2 : \n",
      "Classification loss = 29.2630\n",
      "Comparison loss = 6.9138\n",
      "Epoch no 3 : \n",
      "Classification loss = 29.2589\n",
      "Comparison loss = 6.9081\n",
      "Epoch no 4 : \n",
      "Classification loss = 29.2830\n",
      "Comparison loss = 6.9008\n",
      "Epoch no 5 : \n",
      "Classification loss = 29.2717\n",
      "Comparison loss = 6.8925\n",
      "Epoch no 6 : \n",
      "Classification loss = 29.2772\n",
      "Comparison loss = 6.8825\n",
      "Epoch no 7 : \n",
      "Classification loss = 29.2623\n",
      "Comparison loss = 6.8700\n",
      "Epoch no 8 : \n",
      "Classification loss = 29.2561\n",
      "Comparison loss = 6.8551\n",
      "Epoch no 9 : \n",
      "Classification loss = 29.2546\n",
      "Comparison loss = 6.8357\n",
      "Epoch no 10 : \n",
      "Classification loss = 29.2537\n",
      "Comparison loss = 6.8097\n",
      "Epoch no 11 : \n",
      "Classification loss = 29.2536\n",
      "Comparison loss = 6.7760\n",
      "Epoch no 12 : \n",
      "Classification loss = 29.2533\n",
      "Comparison loss = 6.7314\n",
      "Epoch no 13 : \n",
      "Classification loss = 29.2529\n",
      "Comparison loss = 6.6716\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.2532\n",
      "Comparison loss = 6.5910\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.2532\n",
      "Comparison loss = 6.4783\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.2532\n",
      "Comparison loss = 6.3372\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.2532\n",
      "Comparison loss = 6.1674\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.2532\n",
      "Comparison loss = 5.9609\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.2531\n",
      "Comparison loss = 5.7175\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.2531\n",
      "Comparison loss = 5.4326\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.2531\n",
      "Comparison loss = 5.1080\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.2531\n",
      "Comparison loss = 4.7561\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.2531\n",
      "Comparison loss = 4.3831\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.2531\n",
      "Comparison loss = 3.9880\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.2531\n",
      "Comparison loss = 3.5802\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.150% \n",
      "Comparison = 8.200%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 5.250% \n",
      "Comparison = 10.400%\u001b[0m\n",
      "RUN NO 8\n",
      "Epoch no 1 : \n",
      "Classification loss = 29.2542\n",
      "Comparison loss = 6.8953\n",
      "Epoch no 2 : \n",
      "Classification loss = 29.2531\n",
      "Comparison loss = 6.8911\n",
      "Epoch no 3 : \n",
      "Classification loss = 29.2531\n",
      "Comparison loss = 6.8871\n",
      "Epoch no 4 : \n",
      "Classification loss = 29.2530\n",
      "Comparison loss = 6.8831\n",
      "Epoch no 5 : \n",
      "Classification loss = 29.2530\n",
      "Comparison loss = 6.8792\n",
      "Epoch no 6 : \n",
      "Classification loss = 29.2530\n",
      "Comparison loss = 6.8740\n",
      "Epoch no 7 : \n",
      "Classification loss = 29.2529\n",
      "Comparison loss = 6.8675\n",
      "Epoch no 8 : \n",
      "Classification loss = 29.2547\n",
      "Comparison loss = 6.8586\n",
      "Epoch no 9 : \n",
      "Classification loss = 29.2532\n",
      "Comparison loss = 6.8464\n",
      "Epoch no 10 : \n",
      "Classification loss = 29.2532\n",
      "Comparison loss = 6.8305\n",
      "Epoch no 11 : \n",
      "Classification loss = 29.2531\n",
      "Comparison loss = 6.8075\n",
      "Epoch no 12 : \n",
      "Classification loss = 29.2531\n",
      "Comparison loss = 6.7768\n",
      "Epoch no 13 : \n",
      "Classification loss = 29.2530\n",
      "Comparison loss = 6.7357\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.2530\n",
      "Comparison loss = 6.6784\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.2530\n",
      "Comparison loss = 6.6052\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.2530\n",
      "Comparison loss = 6.5081\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.2530\n",
      "Comparison loss = 6.3776\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.2530\n",
      "Comparison loss = 6.2154\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.2530\n",
      "Comparison loss = 6.0067\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.2530\n",
      "Comparison loss = 5.7483\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.2530\n",
      "Comparison loss = 5.4378\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.2530\n",
      "Comparison loss = 5.0578\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.2530\n",
      "Comparison loss = 4.6265\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.2530\n",
      "Comparison loss = 4.1546\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.2530\n",
      "Comparison loss = 3.6492\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.150% \n",
      "Comparison = 4.000%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 5.150% \n",
      "Comparison = 6.800%\u001b[0m\n",
      "RUN NO 9\n",
      "Epoch no 1 : \n",
      "Classification loss = 29.2530\n",
      "Comparison loss = 6.9422\n",
      "Epoch no 2 : \n",
      "Classification loss = 29.2530\n",
      "Comparison loss = 6.9364\n",
      "Epoch no 3 : \n",
      "Classification loss = 29.2530\n",
      "Comparison loss = 6.9308\n",
      "Epoch no 4 : \n",
      "Classification loss = 29.2531\n",
      "Comparison loss = 6.9249\n",
      "Epoch no 5 : \n",
      "Classification loss = 29.2535\n",
      "Comparison loss = 6.9183\n",
      "Epoch no 6 : \n",
      "Classification loss = 29.2619\n",
      "Comparison loss = 6.9106\n",
      "Epoch no 7 : \n",
      "Classification loss = 29.2784\n",
      "Comparison loss = 6.9014\n",
      "Epoch no 8 : \n",
      "Classification loss = 29.4096\n",
      "Comparison loss = 6.8902\n",
      "Epoch no 9 : \n",
      "Classification loss = 29.3605\n",
      "Comparison loss = 6.8751\n",
      "Epoch no 10 : \n",
      "Classification loss = 29.3236\n",
      "Comparison loss = 6.8564\n",
      "Epoch no 11 : \n",
      "Classification loss = 29.3079\n",
      "Comparison loss = 6.8318\n",
      "Epoch no 12 : \n",
      "Classification loss = 29.2682\n",
      "Comparison loss = 6.7978\n",
      "Epoch no 13 : \n",
      "Classification loss = 29.2603\n",
      "Comparison loss = 6.7504\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.2580\n",
      "Comparison loss = 6.6839\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.2562\n",
      "Comparison loss = 6.5908\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.2555\n",
      "Comparison loss = 6.4615\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.2551\n",
      "Comparison loss = 6.2899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch no 18 : \n",
      "Classification loss = 29.2548\n",
      "Comparison loss = 6.0699\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.2546\n",
      "Comparison loss = 5.7996\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.2545\n",
      "Comparison loss = 5.4836\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.2544\n",
      "Comparison loss = 5.1405\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.2543\n",
      "Comparison loss = 4.7921\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.2542\n",
      "Comparison loss = 4.4450\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.2541\n",
      "Comparison loss = 4.1118\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.2540\n",
      "Comparison loss = 3.7971\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.150% \n",
      "Comparison = 8.700%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 5.600% \n",
      "Comparison = 10.800%\u001b[0m\n",
      "RUN NO 10\n",
      "Epoch no 1 : \n",
      "Classification loss = 29.2539\n",
      "Comparison loss = 6.9348\n",
      "Epoch no 2 : \n",
      "Classification loss = 29.2552\n",
      "Comparison loss = 6.9286\n",
      "Epoch no 3 : \n",
      "Classification loss = 29.2587\n",
      "Comparison loss = 6.9222\n",
      "Epoch no 4 : \n",
      "Classification loss = 29.2552\n",
      "Comparison loss = 6.9156\n",
      "Epoch no 5 : \n",
      "Classification loss = 29.2808\n",
      "Comparison loss = 6.9090\n",
      "Epoch no 6 : \n",
      "Classification loss = 29.2580\n",
      "Comparison loss = 6.9011\n",
      "Epoch no 7 : \n",
      "Classification loss = 29.2696\n",
      "Comparison loss = 6.8911\n",
      "Epoch no 8 : \n",
      "Classification loss = 29.2684\n",
      "Comparison loss = 6.8773\n",
      "Epoch no 9 : \n",
      "Classification loss = 29.2724\n",
      "Comparison loss = 6.8597\n",
      "Epoch no 10 : \n",
      "Classification loss = 29.2588\n",
      "Comparison loss = 6.8368\n",
      "Epoch no 11 : \n",
      "Classification loss = 29.2698\n",
      "Comparison loss = 6.8065\n",
      "Epoch no 12 : \n",
      "Classification loss = 29.2551\n",
      "Comparison loss = 6.7657\n",
      "Epoch no 13 : \n",
      "Classification loss = 29.2539\n",
      "Comparison loss = 6.7112\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.2537\n",
      "Comparison loss = 6.6399\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.2535\n",
      "Comparison loss = 6.5463\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.2534\n",
      "Comparison loss = 6.4251\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.2533\n",
      "Comparison loss = 6.2729\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.2533\n",
      "Comparison loss = 6.0862\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.2533\n",
      "Comparison loss = 5.8630\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.2532\n",
      "Comparison loss = 5.6049\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.2532\n",
      "Comparison loss = 5.3147\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.2532\n",
      "Comparison loss = 4.9978\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.2532\n",
      "Comparison loss = 4.6628\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.2532\n",
      "Comparison loss = 4.3215\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.2532\n",
      "Comparison loss = 3.9813\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.150% \n",
      "Comparison = 8.400%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.900% \n",
      "Comparison = 11.700%\u001b[0m\n",
      "Final error for train batch : 11.42±10.4831\n",
      "Final error for test batch : 14.17±10.4771\n",
      "RUN NO 1\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.9149\n",
      "Comparison loss = 6.9598\n",
      "Epoch no 2 : \n",
      "Classification loss = 45.6084\n",
      "Comparison loss = 6.9555\n",
      "Epoch no 3 : \n",
      "Classification loss = 45.2540\n",
      "Comparison loss = 6.9525\n",
      "Epoch no 4 : \n",
      "Classification loss = 44.8184\n",
      "Comparison loss = 6.9498\n",
      "Epoch no 5 : \n",
      "Classification loss = 44.2738\n",
      "Comparison loss = 6.9473\n",
      "Epoch no 6 : \n",
      "Classification loss = 43.5975\n",
      "Comparison loss = 6.9452\n",
      "Epoch no 7 : \n",
      "Classification loss = 42.8309\n",
      "Comparison loss = 6.9429\n",
      "Epoch no 8 : \n",
      "Classification loss = 42.0357\n",
      "Comparison loss = 6.9405\n",
      "Epoch no 9 : \n",
      "Classification loss = 41.2484\n",
      "Comparison loss = 6.9374\n",
      "Epoch no 10 : \n",
      "Classification loss = 40.3538\n",
      "Comparison loss = 6.9337\n",
      "Epoch no 11 : \n",
      "Classification loss = 39.5026\n",
      "Comparison loss = 6.9293\n",
      "Epoch no 12 : \n",
      "Classification loss = 38.7401\n",
      "Comparison loss = 6.9239\n",
      "Epoch no 13 : \n",
      "Classification loss = 37.9621\n",
      "Comparison loss = 6.9172\n",
      "Epoch no 14 : \n",
      "Classification loss = 37.2984\n",
      "Comparison loss = 6.9089\n",
      "Epoch no 15 : \n",
      "Classification loss = 36.6980\n",
      "Comparison loss = 6.8981\n",
      "Epoch no 16 : \n",
      "Classification loss = 36.1845\n",
      "Comparison loss = 6.8843\n",
      "Epoch no 17 : \n",
      "Classification loss = 35.7074\n",
      "Comparison loss = 6.8659\n",
      "Epoch no 18 : \n",
      "Classification loss = 35.3088\n",
      "Comparison loss = 6.8414\n",
      "Epoch no 19 : \n",
      "Classification loss = 34.9816\n",
      "Comparison loss = 6.8068\n",
      "Epoch no 20 : \n",
      "Classification loss = 34.6520\n",
      "Comparison loss = 6.7614\n",
      "Epoch no 21 : \n",
      "Classification loss = 34.4005\n",
      "Comparison loss = 6.7001\n",
      "Epoch no 22 : \n",
      "Classification loss = 34.1724\n",
      "Comparison loss = 6.6156\n",
      "Epoch no 23 : \n",
      "Classification loss = 34.0016\n",
      "Comparison loss = 6.5079\n",
      "Epoch no 24 : \n",
      "Classification loss = 33.7902\n",
      "Comparison loss = 6.3559\n",
      "Epoch no 25 : \n",
      "Classification loss = 33.6353\n",
      "Comparison loss = 6.1618\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 14.450% \n",
      "Comparison = 40.600%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 18.500% \n",
      "Comparison = 42.700%\u001b[0m\n",
      "RUN NO 2\n",
      "Epoch no 1 : \n",
      "Classification loss = 33.4191\n",
      "Comparison loss = 7.0370\n",
      "Epoch no 2 : \n",
      "Classification loss = 33.1440\n",
      "Comparison loss = 7.0277\n",
      "Epoch no 3 : \n",
      "Classification loss = 32.9489\n",
      "Comparison loss = 7.0189\n",
      "Epoch no 4 : \n",
      "Classification loss = 32.6182\n",
      "Comparison loss = 7.0101\n",
      "Epoch no 5 : \n",
      "Classification loss = 32.2991\n",
      "Comparison loss = 7.0005\n",
      "Epoch no 6 : \n",
      "Classification loss = 31.9819\n",
      "Comparison loss = 6.9906\n",
      "Epoch no 7 : \n",
      "Classification loss = 31.5997\n",
      "Comparison loss = 6.9800\n",
      "Epoch no 8 : \n",
      "Classification loss = 31.3298\n",
      "Comparison loss = 6.9685\n",
      "Epoch no 9 : \n",
      "Classification loss = 31.0222\n",
      "Comparison loss = 6.9563\n",
      "Epoch no 10 : \n",
      "Classification loss = 30.7685\n",
      "Comparison loss = 6.9417\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.5783\n",
      "Comparison loss = 6.9239\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.3763\n",
      "Comparison loss = 6.9010\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.2667\n",
      "Comparison loss = 6.8715\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.1368\n",
      "Comparison loss = 6.8330\n",
      "Epoch no 15 : \n",
      "Classification loss = 30.0465\n",
      "Comparison loss = 6.7825\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.9518\n",
      "Comparison loss = 6.7138\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.8868\n",
      "Comparison loss = 6.6217\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.8134\n",
      "Comparison loss = 6.5020\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.7593\n",
      "Comparison loss = 6.3470\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.7124\n",
      "Comparison loss = 6.1517\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.6717\n",
      "Comparison loss = 5.9117\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.6288\n",
      "Comparison loss = 5.6285\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.5925\n",
      "Comparison loss = 5.3117\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.5666\n",
      "Comparison loss = 4.9621\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.5321\n",
      "Comparison loss = 4.5802\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.550% \n",
      "Comparison = 15.000%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.400% \n",
      "Comparison = 15.900%\u001b[0m\n",
      "RUN NO 3\n",
      "Epoch no 1 : \n",
      "Classification loss = 29.5421\n",
      "Comparison loss = 6.9066\n",
      "Epoch no 2 : \n",
      "Classification loss = 29.4879\n",
      "Comparison loss = 6.9025\n",
      "Epoch no 3 : \n",
      "Classification loss = 29.4832\n",
      "Comparison loss = 6.8979\n",
      "Epoch no 4 : \n",
      "Classification loss = 29.4083\n",
      "Comparison loss = 6.8927\n",
      "Epoch no 5 : \n",
      "Classification loss = 29.3801\n",
      "Comparison loss = 6.8862\n",
      "Epoch no 6 : \n",
      "Classification loss = 29.3532\n",
      "Comparison loss = 6.8781\n",
      "Epoch no 7 : \n",
      "Classification loss = 29.3284\n",
      "Comparison loss = 6.8671\n",
      "Epoch no 8 : \n",
      "Classification loss = 29.3060\n",
      "Comparison loss = 6.8520\n",
      "Epoch no 9 : \n",
      "Classification loss = 29.2922\n",
      "Comparison loss = 6.8303\n",
      "Epoch no 10 : \n",
      "Classification loss = 29.2820\n",
      "Comparison loss = 6.8028\n",
      "Epoch no 11 : \n",
      "Classification loss = 29.2740\n",
      "Comparison loss = 6.7661\n",
      "Epoch no 12 : \n",
      "Classification loss = 29.2686\n",
      "Comparison loss = 6.7161\n",
      "Epoch no 13 : \n",
      "Classification loss = 29.2645\n",
      "Comparison loss = 6.6484\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.2614\n",
      "Comparison loss = 6.5566\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.2566\n",
      "Comparison loss = 6.4379\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.2510\n",
      "Comparison loss = 6.2848\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.2489\n",
      "Comparison loss = 6.0887\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.2475\n",
      "Comparison loss = 5.8374\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.2464\n",
      "Comparison loss = 5.5334\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.2453\n",
      "Comparison loss = 5.1745\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.2444\n",
      "Comparison loss = 4.7694\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.2436\n",
      "Comparison loss = 4.3356\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.2429\n",
      "Comparison loss = 3.8783\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.2423\n",
      "Comparison loss = 3.4250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch no 25 : \n",
      "Classification loss = 29.2417\n",
      "Comparison loss = 2.9713\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.050% \n",
      "Comparison = 7.400%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.450% \n",
      "Comparison = 10.400%\u001b[0m\n",
      "RUN NO 4\n",
      "Epoch no 1 : \n",
      "Classification loss = 29.2475\n",
      "Comparison loss = 7.0373\n",
      "Epoch no 2 : \n",
      "Classification loss = 29.2404\n",
      "Comparison loss = 7.0272\n",
      "Epoch no 3 : \n",
      "Classification loss = 29.2407\n",
      "Comparison loss = 7.0176\n",
      "Epoch no 4 : \n",
      "Classification loss = 29.2387\n",
      "Comparison loss = 7.0075\n",
      "Epoch no 5 : \n",
      "Classification loss = 29.2370\n",
      "Comparison loss = 6.9966\n",
      "Epoch no 6 : \n",
      "Classification loss = 29.2360\n",
      "Comparison loss = 6.9854\n",
      "Epoch no 7 : \n",
      "Classification loss = 29.2354\n",
      "Comparison loss = 6.9740\n",
      "Epoch no 8 : \n",
      "Classification loss = 29.2347\n",
      "Comparison loss = 6.9609\n",
      "Epoch no 9 : \n",
      "Classification loss = 29.2344\n",
      "Comparison loss = 6.9453\n",
      "Epoch no 10 : \n",
      "Classification loss = 29.2342\n",
      "Comparison loss = 6.9273\n",
      "Epoch no 11 : \n",
      "Classification loss = 29.2341\n",
      "Comparison loss = 6.9057\n",
      "Epoch no 12 : \n",
      "Classification loss = 29.2340\n",
      "Comparison loss = 6.8785\n",
      "Epoch no 13 : \n",
      "Classification loss = 29.2339\n",
      "Comparison loss = 6.8448\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.2338\n",
      "Comparison loss = 6.8007\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.2338\n",
      "Comparison loss = 6.7415\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.2337\n",
      "Comparison loss = 6.6648\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.2337\n",
      "Comparison loss = 6.5672\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.2336\n",
      "Comparison loss = 6.4407\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.2336\n",
      "Comparison loss = 6.2746\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.2335\n",
      "Comparison loss = 6.0641\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.2335\n",
      "Comparison loss = 5.8052\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.2335\n",
      "Comparison loss = 5.4999\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.2335\n",
      "Comparison loss = 5.1655\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.2334\n",
      "Comparison loss = 4.8133\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.2334\n",
      "Comparison loss = 4.4540\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.050% \n",
      "Comparison = 12.400%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.000% \n",
      "Comparison = 15.000%\u001b[0m\n",
      "RUN NO 5\n",
      "Epoch no 1 : \n",
      "Classification loss = 29.2336\n",
      "Comparison loss = 6.9705\n",
      "Epoch no 2 : \n",
      "Classification loss = 29.2335\n",
      "Comparison loss = 6.9614\n",
      "Epoch no 3 : \n",
      "Classification loss = 29.2337\n",
      "Comparison loss = 6.9533\n",
      "Epoch no 4 : \n",
      "Classification loss = 29.2485\n",
      "Comparison loss = 6.9454\n",
      "Epoch no 5 : \n",
      "Classification loss = 29.2999\n",
      "Comparison loss = 6.9371\n",
      "Epoch no 6 : \n",
      "Classification loss = 29.4526\n",
      "Comparison loss = 6.9276\n",
      "Epoch no 7 : \n",
      "Classification loss = 29.2912\n",
      "Comparison loss = 6.9170\n",
      "Epoch no 8 : \n",
      "Classification loss = 29.2728\n",
      "Comparison loss = 6.9037\n",
      "Epoch no 9 : \n",
      "Classification loss = 29.2428\n",
      "Comparison loss = 6.8884\n",
      "Epoch no 10 : \n",
      "Classification loss = 29.2377\n",
      "Comparison loss = 6.8700\n",
      "Epoch no 11 : \n",
      "Classification loss = 29.2362\n",
      "Comparison loss = 6.8462\n",
      "Epoch no 12 : \n",
      "Classification loss = 29.2355\n",
      "Comparison loss = 6.8144\n",
      "Epoch no 13 : \n",
      "Classification loss = 29.2351\n",
      "Comparison loss = 6.7722\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.2348\n",
      "Comparison loss = 6.7163\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.2347\n",
      "Comparison loss = 6.6422\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.2345\n",
      "Comparison loss = 6.5423\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.2344\n",
      "Comparison loss = 6.4116\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.2343\n",
      "Comparison loss = 6.2441\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.2342\n",
      "Comparison loss = 6.0319\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.2342\n",
      "Comparison loss = 5.7729\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.2341\n",
      "Comparison loss = 5.4649\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.2340\n",
      "Comparison loss = 5.1080\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.2340\n",
      "Comparison loss = 4.7057\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.2339\n",
      "Comparison loss = 4.2676\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.2339\n",
      "Comparison loss = 3.8089\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.050% \n",
      "Comparison = 6.500%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.050% \n",
      "Comparison = 10.200%\u001b[0m\n",
      "RUN NO 6\n",
      "Epoch no 1 : \n",
      "Classification loss = 29.2339\n",
      "Comparison loss = 6.9057\n",
      "Epoch no 2 : \n",
      "Classification loss = 29.2336\n",
      "Comparison loss = 6.8998\n",
      "Epoch no 3 : \n",
      "Classification loss = 29.2333\n",
      "Comparison loss = 6.8940\n",
      "Epoch no 4 : \n",
      "Classification loss = 29.2331\n",
      "Comparison loss = 6.8876\n",
      "Epoch no 5 : \n",
      "Classification loss = 29.2331\n",
      "Comparison loss = 6.8804\n",
      "Epoch no 6 : \n",
      "Classification loss = 29.2331\n",
      "Comparison loss = 6.8715\n",
      "Epoch no 7 : \n",
      "Classification loss = 29.2331\n",
      "Comparison loss = 6.8600\n",
      "Epoch no 8 : \n",
      "Classification loss = 29.2331\n",
      "Comparison loss = 6.8442\n",
      "Epoch no 9 : \n",
      "Classification loss = 29.2330\n",
      "Comparison loss = 6.8243\n",
      "Epoch no 10 : \n",
      "Classification loss = 29.2330\n",
      "Comparison loss = 6.7979\n",
      "Epoch no 11 : \n",
      "Classification loss = 29.2330\n",
      "Comparison loss = 6.7616\n",
      "Epoch no 12 : \n",
      "Classification loss = 29.2330\n",
      "Comparison loss = 6.7151\n",
      "Epoch no 13 : \n",
      "Classification loss = 29.2331\n",
      "Comparison loss = 6.6533\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.2330\n",
      "Comparison loss = 6.5711\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.2330\n",
      "Comparison loss = 6.4644\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.2330\n",
      "Comparison loss = 6.3274\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.2330\n",
      "Comparison loss = 6.1553\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.2331\n",
      "Comparison loss = 5.9449\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.2330\n",
      "Comparison loss = 5.6888\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.2330\n",
      "Comparison loss = 5.3819\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.2330\n",
      "Comparison loss = 5.0249\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.2330\n",
      "Comparison loss = 4.6178\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.2330\n",
      "Comparison loss = 4.1719\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.2330\n",
      "Comparison loss = 3.6986\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.2330\n",
      "Comparison loss = 3.2111\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.050% \n",
      "Comparison = 4.900%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.250% \n",
      "Comparison = 7.600%\u001b[0m\n",
      "RUN NO 7\n",
      "Epoch no 1 : \n",
      "Classification loss = 29.2330\n",
      "Comparison loss = 6.9285\n",
      "Epoch no 2 : \n",
      "Classification loss = 29.2330\n",
      "Comparison loss = 6.9243\n",
      "Epoch no 3 : \n",
      "Classification loss = 29.2331\n",
      "Comparison loss = 6.9202\n",
      "Epoch no 4 : \n",
      "Classification loss = 29.2334\n",
      "Comparison loss = 6.9159\n",
      "Epoch no 5 : \n",
      "Classification loss = 29.2336\n",
      "Comparison loss = 6.9112\n",
      "Epoch no 6 : \n",
      "Classification loss = 29.2332\n",
      "Comparison loss = 6.9056\n",
      "Epoch no 7 : \n",
      "Classification loss = 29.2341\n",
      "Comparison loss = 6.8989\n",
      "Epoch no 8 : \n",
      "Classification loss = 29.2403\n",
      "Comparison loss = 6.8908\n",
      "Epoch no 9 : \n",
      "Classification loss = 29.2636\n",
      "Comparison loss = 6.8810\n",
      "Epoch no 10 : \n",
      "Classification loss = 29.2729\n",
      "Comparison loss = 6.8682\n",
      "Epoch no 11 : \n",
      "Classification loss = 29.2798\n",
      "Comparison loss = 6.8517\n",
      "Epoch no 12 : \n",
      "Classification loss = 29.2777\n",
      "Comparison loss = 6.8293\n",
      "Epoch no 13 : \n",
      "Classification loss = 29.2605\n",
      "Comparison loss = 6.7979\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.2479\n",
      "Comparison loss = 6.7554\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.2441\n",
      "Comparison loss = 6.6995\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.2426\n",
      "Comparison loss = 6.6256\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.2349\n",
      "Comparison loss = 6.5262\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.2333\n",
      "Comparison loss = 6.3929\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.2332\n",
      "Comparison loss = 6.2211\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.2331\n",
      "Comparison loss = 6.0032\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.2330\n",
      "Comparison loss = 5.7363\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.2329\n",
      "Comparison loss = 5.4192\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.2329\n",
      "Comparison loss = 5.0569\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.2329\n",
      "Comparison loss = 4.6633\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.2329\n",
      "Comparison loss = 4.2536\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.050% \n",
      "Comparison = 13.900%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.650% \n",
      "Comparison = 15.000%\u001b[0m\n",
      "RUN NO 8\n",
      "Epoch no 1 : \n",
      "Classification loss = 29.2329\n",
      "Comparison loss = 6.8857\n",
      "Epoch no 2 : \n",
      "Classification loss = 29.2331\n",
      "Comparison loss = 6.8821\n",
      "Epoch no 3 : \n",
      "Classification loss = 29.2331\n",
      "Comparison loss = 6.8786\n",
      "Epoch no 4 : \n",
      "Classification loss = 29.2330\n",
      "Comparison loss = 6.8746\n",
      "Epoch no 5 : \n",
      "Classification loss = 29.2330\n",
      "Comparison loss = 6.8699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch no 6 : \n",
      "Classification loss = 29.2330\n",
      "Comparison loss = 6.8639\n",
      "Epoch no 7 : \n",
      "Classification loss = 29.2330\n",
      "Comparison loss = 6.8559\n",
      "Epoch no 8 : \n",
      "Classification loss = 29.2330\n",
      "Comparison loss = 6.8448\n",
      "Epoch no 9 : \n",
      "Classification loss = 29.2330\n",
      "Comparison loss = 6.8293\n",
      "Epoch no 10 : \n",
      "Classification loss = 29.2330\n",
      "Comparison loss = 6.8059\n",
      "Epoch no 11 : \n",
      "Classification loss = 29.2329\n",
      "Comparison loss = 6.7740\n",
      "Epoch no 12 : \n",
      "Classification loss = 29.2330\n",
      "Comparison loss = 6.7293\n",
      "Epoch no 13 : \n",
      "Classification loss = 29.2437\n",
      "Comparison loss = 6.6701\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.2548\n",
      "Comparison loss = 6.5930\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.2687\n",
      "Comparison loss = 6.4964\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.3387\n",
      "Comparison loss = 6.3760\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.2793\n",
      "Comparison loss = 6.2139\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.3257\n",
      "Comparison loss = 6.0240\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.2650\n",
      "Comparison loss = 5.7800\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.2438\n",
      "Comparison loss = 5.4884\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.2364\n",
      "Comparison loss = 5.1389\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.2347\n",
      "Comparison loss = 4.7337\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.2336\n",
      "Comparison loss = 4.2853\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.2335\n",
      "Comparison loss = 3.8057\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.2334\n",
      "Comparison loss = 3.3143\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.050% \n",
      "Comparison = 4.700%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.700% \n",
      "Comparison = 8.700%\u001b[0m\n",
      "RUN NO 9\n",
      "Epoch no 1 : \n",
      "Classification loss = 29.2333\n",
      "Comparison loss = 6.8986\n",
      "Epoch no 2 : \n",
      "Classification loss = 29.2337\n",
      "Comparison loss = 6.8912\n",
      "Epoch no 3 : \n",
      "Classification loss = 29.2387\n",
      "Comparison loss = 6.8836\n",
      "Epoch no 4 : \n",
      "Classification loss = 29.2333\n",
      "Comparison loss = 6.8755\n",
      "Epoch no 5 : \n",
      "Classification loss = 29.2331\n",
      "Comparison loss = 6.8648\n",
      "Epoch no 6 : \n",
      "Classification loss = 29.2331\n",
      "Comparison loss = 6.8508\n",
      "Epoch no 7 : \n",
      "Classification loss = 29.2330\n",
      "Comparison loss = 6.8332\n",
      "Epoch no 8 : \n",
      "Classification loss = 29.2329\n",
      "Comparison loss = 6.8105\n",
      "Epoch no 9 : \n",
      "Classification loss = 29.2322\n",
      "Comparison loss = 6.7791\n",
      "Epoch no 10 : \n",
      "Classification loss = 29.2236\n",
      "Comparison loss = 6.7371\n",
      "Epoch no 11 : \n",
      "Classification loss = 29.2261\n",
      "Comparison loss = 6.6817\n",
      "Epoch no 12 : \n",
      "Classification loss = 29.2241\n",
      "Comparison loss = 6.6068\n",
      "Epoch no 13 : \n",
      "Classification loss = 29.2232\n",
      "Comparison loss = 6.5079\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.2232\n",
      "Comparison loss = 6.3800\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.2231\n",
      "Comparison loss = 6.2172\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.2231\n",
      "Comparison loss = 6.0184\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.2231\n",
      "Comparison loss = 5.7773\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.2231\n",
      "Comparison loss = 5.4934\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.2230\n",
      "Comparison loss = 5.1703\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.2230\n",
      "Comparison loss = 4.8111\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.2230\n",
      "Comparison loss = 4.4386\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.2230\n",
      "Comparison loss = 4.0569\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.2230\n",
      "Comparison loss = 3.6778\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.2230\n",
      "Comparison loss = 3.3212\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.2230\n",
      "Comparison loss = 2.9598\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.000% \n",
      "Comparison = 1.400%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.450% \n",
      "Comparison = 4.800%\u001b[0m\n",
      "RUN NO 10\n",
      "Epoch no 1 : \n",
      "Classification loss = 29.2230\n",
      "Comparison loss = 6.9806\n",
      "Epoch no 2 : \n",
      "Classification loss = 29.2230\n",
      "Comparison loss = 6.9717\n",
      "Epoch no 3 : \n",
      "Classification loss = 29.2230\n",
      "Comparison loss = 6.9636\n",
      "Epoch no 4 : \n",
      "Classification loss = 29.2230\n",
      "Comparison loss = 6.9551\n",
      "Epoch no 5 : \n",
      "Classification loss = 29.2230\n",
      "Comparison loss = 6.9461\n",
      "Epoch no 6 : \n",
      "Classification loss = 29.2230\n",
      "Comparison loss = 6.9361\n",
      "Epoch no 7 : \n",
      "Classification loss = 29.2230\n",
      "Comparison loss = 6.9243\n",
      "Epoch no 8 : \n",
      "Classification loss = 29.2230\n",
      "Comparison loss = 6.9100\n",
      "Epoch no 9 : \n",
      "Classification loss = 29.2230\n",
      "Comparison loss = 6.8917\n",
      "Epoch no 10 : \n",
      "Classification loss = 29.2230\n",
      "Comparison loss = 6.8676\n",
      "Epoch no 11 : \n",
      "Classification loss = 29.2230\n",
      "Comparison loss = 6.8362\n",
      "Epoch no 12 : \n",
      "Classification loss = 29.2230\n",
      "Comparison loss = 6.7952\n",
      "Epoch no 13 : \n",
      "Classification loss = 29.2230\n",
      "Comparison loss = 6.7402\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.2230\n",
      "Comparison loss = 6.6671\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.2230\n",
      "Comparison loss = 6.5701\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.2230\n",
      "Comparison loss = 6.4428\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.2230\n",
      "Comparison loss = 6.2815\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.2230\n",
      "Comparison loss = 6.0895\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.2230\n",
      "Comparison loss = 5.8582\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.2230\n",
      "Comparison loss = 5.5813\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.2230\n",
      "Comparison loss = 5.2592\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.2230\n",
      "Comparison loss = 4.8906\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.2230\n",
      "Comparison loss = 4.4741\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.2230\n",
      "Comparison loss = 4.0135\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.2230\n",
      "Comparison loss = 3.5188\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.000% \n",
      "Comparison = 7.200%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.100% \n",
      "Comparison = 10.100%\u001b[0m\n",
      "Final error for train batch : 11.40±11.1437\n",
      "Final error for test batch : 14.04±10.6749\n",
      "RUN NO 1\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.9874\n",
      "Comparison loss = 6.9547\n",
      "Epoch no 2 : \n",
      "Classification loss = 45.8325\n",
      "Comparison loss = 6.9501\n",
      "Epoch no 3 : \n",
      "Classification loss = 45.6643\n",
      "Comparison loss = 6.9459\n",
      "Epoch no 4 : \n",
      "Classification loss = 45.4611\n",
      "Comparison loss = 6.9418\n",
      "Epoch no 5 : \n",
      "Classification loss = 45.2047\n",
      "Comparison loss = 6.9376\n",
      "Epoch no 6 : \n",
      "Classification loss = 44.8836\n",
      "Comparison loss = 6.9332\n",
      "Epoch no 7 : \n",
      "Classification loss = 44.5051\n",
      "Comparison loss = 6.9292\n",
      "Epoch no 8 : \n",
      "Classification loss = 44.1010\n",
      "Comparison loss = 6.9251\n",
      "Epoch no 9 : \n",
      "Classification loss = 43.7092\n",
      "Comparison loss = 6.9207\n",
      "Epoch no 10 : \n",
      "Classification loss = 43.3556\n",
      "Comparison loss = 6.9162\n",
      "Epoch no 11 : \n",
      "Classification loss = 43.0497\n",
      "Comparison loss = 6.9114\n",
      "Epoch no 12 : \n",
      "Classification loss = 42.7869\n",
      "Comparison loss = 6.9063\n",
      "Epoch no 13 : \n",
      "Classification loss = 42.5561\n",
      "Comparison loss = 6.9007\n",
      "Epoch no 14 : \n",
      "Classification loss = 42.3446\n",
      "Comparison loss = 6.8944\n",
      "Epoch no 15 : \n",
      "Classification loss = 42.1397\n",
      "Comparison loss = 6.8870\n",
      "Epoch no 16 : \n",
      "Classification loss = 41.9335\n",
      "Comparison loss = 6.8776\n",
      "Epoch no 17 : \n",
      "Classification loss = 41.7236\n",
      "Comparison loss = 6.8663\n",
      "Epoch no 18 : \n",
      "Classification loss = 41.5098\n",
      "Comparison loss = 6.8532\n",
      "Epoch no 19 : \n",
      "Classification loss = 41.2913\n",
      "Comparison loss = 6.8378\n",
      "Epoch no 20 : \n",
      "Classification loss = 41.0657\n",
      "Comparison loss = 6.8199\n",
      "Epoch no 21 : \n",
      "Classification loss = 40.8320\n",
      "Comparison loss = 6.7989\n",
      "Epoch no 22 : \n",
      "Classification loss = 40.5910\n",
      "Comparison loss = 6.7727\n",
      "Epoch no 23 : \n",
      "Classification loss = 40.3476\n",
      "Comparison loss = 6.7386\n",
      "Epoch no 24 : \n",
      "Classification loss = 40.1102\n",
      "Comparison loss = 6.6951\n",
      "Epoch no 25 : \n",
      "Classification loss = 39.8868\n",
      "Comparison loss = 6.6360\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 47.600% \n",
      "Comparison = 44.900%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 50.700% \n",
      "Comparison = 47.400%\u001b[0m\n",
      "RUN NO 2\n",
      "Epoch no 1 : \n",
      "Classification loss = 39.7097\n",
      "Comparison loss = 6.9624\n",
      "Epoch no 2 : \n",
      "Classification loss = 39.5330\n",
      "Comparison loss = 6.9558\n",
      "Epoch no 3 : \n",
      "Classification loss = 39.3878\n",
      "Comparison loss = 6.9491\n",
      "Epoch no 4 : \n",
      "Classification loss = 39.2577\n",
      "Comparison loss = 6.9424\n",
      "Epoch no 5 : \n",
      "Classification loss = 39.1392\n",
      "Comparison loss = 6.9359\n",
      "Epoch no 6 : \n",
      "Classification loss = 39.0388\n",
      "Comparison loss = 6.9290\n",
      "Epoch no 7 : \n",
      "Classification loss = 38.9454\n",
      "Comparison loss = 6.9212\n",
      "Epoch no 8 : \n",
      "Classification loss = 38.8600\n",
      "Comparison loss = 6.9117\n",
      "Epoch no 9 : \n",
      "Classification loss = 38.7834\n",
      "Comparison loss = 6.9013\n",
      "Epoch no 10 : \n",
      "Classification loss = 38.7039\n",
      "Comparison loss = 6.8894\n",
      "Epoch no 11 : \n",
      "Classification loss = 38.6325\n",
      "Comparison loss = 6.8761\n",
      "Epoch no 12 : \n",
      "Classification loss = 38.5591\n",
      "Comparison loss = 6.8610\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch no 13 : \n",
      "Classification loss = 38.4733\n",
      "Comparison loss = 6.8422\n",
      "Epoch no 14 : \n",
      "Classification loss = 38.3964\n",
      "Comparison loss = 6.8187\n",
      "Epoch no 15 : \n",
      "Classification loss = 38.3089\n",
      "Comparison loss = 6.7907\n",
      "Epoch no 16 : \n",
      "Classification loss = 38.2068\n",
      "Comparison loss = 6.7565\n",
      "Epoch no 17 : \n",
      "Classification loss = 38.1176\n",
      "Comparison loss = 6.7158\n",
      "Epoch no 18 : \n",
      "Classification loss = 38.0182\n",
      "Comparison loss = 6.6504\n",
      "Epoch no 19 : \n",
      "Classification loss = 37.8926\n",
      "Comparison loss = 6.5820\n",
      "Epoch no 20 : \n",
      "Classification loss = 37.7776\n",
      "Comparison loss = 6.4897\n",
      "Epoch no 21 : \n",
      "Classification loss = 37.6455\n",
      "Comparison loss = 6.3472\n",
      "Epoch no 22 : \n",
      "Classification loss = 37.4406\n",
      "Comparison loss = 6.2433\n",
      "Epoch no 23 : \n",
      "Classification loss = 37.2544\n",
      "Comparison loss = 6.0812\n",
      "Epoch no 24 : \n",
      "Classification loss = 37.0832\n",
      "Comparison loss = 5.8835\n",
      "Epoch no 25 : \n",
      "Classification loss = 36.8423\n",
      "Comparison loss = 5.7075\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 29.200% \n",
      "Comparison = 23.500%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 37.300% \n",
      "Comparison = 28.600%\u001b[0m\n",
      "RUN NO 3\n",
      "Epoch no 1 : \n",
      "Classification loss = 36.6521\n",
      "Comparison loss = 6.9741\n",
      "Epoch no 2 : \n",
      "Classification loss = 36.5018\n",
      "Comparison loss = 6.9677\n",
      "Epoch no 3 : \n",
      "Classification loss = 36.3457\n",
      "Comparison loss = 6.9620\n",
      "Epoch no 4 : \n",
      "Classification loss = 36.1962\n",
      "Comparison loss = 6.9564\n",
      "Epoch no 5 : \n",
      "Classification loss = 36.0656\n",
      "Comparison loss = 6.9513\n",
      "Epoch no 6 : \n",
      "Classification loss = 35.9311\n",
      "Comparison loss = 6.9460\n",
      "Epoch no 7 : \n",
      "Classification loss = 35.7988\n",
      "Comparison loss = 6.9405\n",
      "Epoch no 8 : \n",
      "Classification loss = 35.6925\n",
      "Comparison loss = 6.9345\n",
      "Epoch no 9 : \n",
      "Classification loss = 35.5767\n",
      "Comparison loss = 6.9274\n",
      "Epoch no 10 : \n",
      "Classification loss = 35.4676\n",
      "Comparison loss = 6.9195\n",
      "Epoch no 11 : \n",
      "Classification loss = 35.3718\n",
      "Comparison loss = 6.9097\n",
      "Epoch no 12 : \n",
      "Classification loss = 35.2746\n",
      "Comparison loss = 6.8977\n",
      "Epoch no 13 : \n",
      "Classification loss = 35.1793\n",
      "Comparison loss = 6.8834\n",
      "Epoch no 14 : \n",
      "Classification loss = 35.0838\n",
      "Comparison loss = 6.8656\n",
      "Epoch no 15 : \n",
      "Classification loss = 34.9919\n",
      "Comparison loss = 6.8416\n",
      "Epoch no 16 : \n",
      "Classification loss = 34.8873\n",
      "Comparison loss = 6.8109\n",
      "Epoch no 17 : \n",
      "Classification loss = 34.7862\n",
      "Comparison loss = 6.7707\n",
      "Epoch no 18 : \n",
      "Classification loss = 34.6811\n",
      "Comparison loss = 6.7127\n",
      "Epoch no 19 : \n",
      "Classification loss = 34.5659\n",
      "Comparison loss = 6.6388\n",
      "Epoch no 20 : \n",
      "Classification loss = 34.4445\n",
      "Comparison loss = 6.5399\n",
      "Epoch no 21 : \n",
      "Classification loss = 34.3280\n",
      "Comparison loss = 6.4072\n",
      "Epoch no 22 : \n",
      "Classification loss = 34.2054\n",
      "Comparison loss = 6.2542\n",
      "Epoch no 23 : \n",
      "Classification loss = 34.0595\n",
      "Comparison loss = 6.0264\n",
      "Epoch no 24 : \n",
      "Classification loss = 33.9062\n",
      "Comparison loss = 5.7962\n",
      "Epoch no 25 : \n",
      "Classification loss = 33.7659\n",
      "Comparison loss = 5.5222\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 16.750% \n",
      "Comparison = 18.500%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 26.400% \n",
      "Comparison = 25.600%\u001b[0m\n",
      "RUN NO 4\n",
      "Epoch no 1 : \n",
      "Classification loss = 33.5905\n",
      "Comparison loss = 6.9073\n",
      "Epoch no 2 : \n",
      "Classification loss = 33.4416\n",
      "Comparison loss = 6.9042\n",
      "Epoch no 3 : \n",
      "Classification loss = 33.3067\n",
      "Comparison loss = 6.9017\n",
      "Epoch no 4 : \n",
      "Classification loss = 33.1235\n",
      "Comparison loss = 6.8990\n",
      "Epoch no 5 : \n",
      "Classification loss = 32.9470\n",
      "Comparison loss = 6.8962\n",
      "Epoch no 6 : \n",
      "Classification loss = 32.7500\n",
      "Comparison loss = 6.8930\n",
      "Epoch no 7 : \n",
      "Classification loss = 32.5830\n",
      "Comparison loss = 6.8889\n",
      "Epoch no 8 : \n",
      "Classification loss = 32.3817\n",
      "Comparison loss = 6.8837\n",
      "Epoch no 9 : \n",
      "Classification loss = 32.1814\n",
      "Comparison loss = 6.8773\n",
      "Epoch no 10 : \n",
      "Classification loss = 32.0077\n",
      "Comparison loss = 6.8681\n",
      "Epoch no 11 : \n",
      "Classification loss = 31.8426\n",
      "Comparison loss = 6.8548\n",
      "Epoch no 12 : \n",
      "Classification loss = 31.6514\n",
      "Comparison loss = 6.8345\n",
      "Epoch no 13 : \n",
      "Classification loss = 31.5113\n",
      "Comparison loss = 6.8062\n",
      "Epoch no 14 : \n",
      "Classification loss = 31.3678\n",
      "Comparison loss = 6.7671\n",
      "Epoch no 15 : \n",
      "Classification loss = 31.2192\n",
      "Comparison loss = 6.7118\n",
      "Epoch no 16 : \n",
      "Classification loss = 31.1048\n",
      "Comparison loss = 6.6381\n",
      "Epoch no 17 : \n",
      "Classification loss = 30.9875\n",
      "Comparison loss = 6.5387\n",
      "Epoch no 18 : \n",
      "Classification loss = 30.8742\n",
      "Comparison loss = 6.4020\n",
      "Epoch no 19 : \n",
      "Classification loss = 30.7846\n",
      "Comparison loss = 6.2207\n",
      "Epoch no 20 : \n",
      "Classification loss = 30.6902\n",
      "Comparison loss = 5.9914\n",
      "Epoch no 21 : \n",
      "Classification loss = 30.6018\n",
      "Comparison loss = 5.6955\n",
      "Epoch no 22 : \n",
      "Classification loss = 30.5302\n",
      "Comparison loss = 5.3298\n",
      "Epoch no 23 : \n",
      "Classification loss = 30.4527\n",
      "Comparison loss = 4.9030\n",
      "Epoch no 24 : \n",
      "Classification loss = 30.3859\n",
      "Comparison loss = 4.4138\n",
      "Epoch no 25 : \n",
      "Classification loss = 30.3258\n",
      "Comparison loss = 3.8717\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.750% \n",
      "Comparison = 5.900%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 8.650% \n",
      "Comparison = 11.600%\u001b[0m\n",
      "RUN NO 5\n",
      "Epoch no 1 : \n",
      "Classification loss = 30.2881\n",
      "Comparison loss = 7.0091\n",
      "Epoch no 2 : \n",
      "Classification loss = 30.1862\n",
      "Comparison loss = 7.0006\n",
      "Epoch no 3 : \n",
      "Classification loss = 30.1139\n",
      "Comparison loss = 6.9935\n",
      "Epoch no 4 : \n",
      "Classification loss = 30.0347\n",
      "Comparison loss = 6.9867\n",
      "Epoch no 5 : \n",
      "Classification loss = 29.9832\n",
      "Comparison loss = 6.9811\n",
      "Epoch no 6 : \n",
      "Classification loss = 29.9344\n",
      "Comparison loss = 6.9750\n",
      "Epoch no 7 : \n",
      "Classification loss = 29.8768\n",
      "Comparison loss = 6.9682\n",
      "Epoch no 8 : \n",
      "Classification loss = 29.8340\n",
      "Comparison loss = 6.9611\n",
      "Epoch no 9 : \n",
      "Classification loss = 29.8029\n",
      "Comparison loss = 6.9523\n",
      "Epoch no 10 : \n",
      "Classification loss = 29.7632\n",
      "Comparison loss = 6.9401\n",
      "Epoch no 11 : \n",
      "Classification loss = 29.7281\n",
      "Comparison loss = 6.9216\n",
      "Epoch no 12 : \n",
      "Classification loss = 29.7035\n",
      "Comparison loss = 6.8977\n",
      "Epoch no 13 : \n",
      "Classification loss = 29.6739\n",
      "Comparison loss = 6.8649\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.6484\n",
      "Comparison loss = 6.8191\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.6270\n",
      "Comparison loss = 6.7587\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.6045\n",
      "Comparison loss = 6.6726\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.5871\n",
      "Comparison loss = 6.5511\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.5669\n",
      "Comparison loss = 6.3864\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.5504\n",
      "Comparison loss = 6.1664\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.5356\n",
      "Comparison loss = 5.8811\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.5178\n",
      "Comparison loss = 5.5240\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.5040\n",
      "Comparison loss = 5.0859\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4914\n",
      "Comparison loss = 4.5922\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4795\n",
      "Comparison loss = 4.0646\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.4695\n",
      "Comparison loss = 3.5381\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.300% \n",
      "Comparison = 8.600%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 8.500% \n",
      "Comparison = 12.500%\u001b[0m\n",
      "RUN NO 6\n",
      "Epoch no 1 : \n",
      "Classification loss = 29.4735\n",
      "Comparison loss = 6.9725\n",
      "Epoch no 2 : \n",
      "Classification loss = 29.4464\n",
      "Comparison loss = 6.9662\n",
      "Epoch no 3 : \n",
      "Classification loss = 29.4330\n",
      "Comparison loss = 6.9606\n",
      "Epoch no 4 : \n",
      "Classification loss = 29.4152\n",
      "Comparison loss = 6.9555\n",
      "Epoch no 5 : \n",
      "Classification loss = 29.4030\n",
      "Comparison loss = 6.9498\n",
      "Epoch no 6 : \n",
      "Classification loss = 29.3934\n",
      "Comparison loss = 6.9434\n",
      "Epoch no 7 : \n",
      "Classification loss = 29.3773\n",
      "Comparison loss = 6.9360\n",
      "Epoch no 8 : \n",
      "Classification loss = 29.3679\n",
      "Comparison loss = 6.9274\n",
      "Epoch no 9 : \n",
      "Classification loss = 29.3581\n",
      "Comparison loss = 6.9167\n",
      "Epoch no 10 : \n",
      "Classification loss = 29.3505\n",
      "Comparison loss = 6.9033\n",
      "Epoch no 11 : \n",
      "Classification loss = 29.3419\n",
      "Comparison loss = 6.8858\n",
      "Epoch no 12 : \n",
      "Classification loss = 29.3338\n",
      "Comparison loss = 6.8639\n",
      "Epoch no 13 : \n",
      "Classification loss = 29.3292\n",
      "Comparison loss = 6.8362\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.3240\n",
      "Comparison loss = 6.8003\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.3201\n",
      "Comparison loss = 6.7528\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.3165\n",
      "Comparison loss = 6.6916\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.3132\n",
      "Comparison loss = 6.6102\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.3100\n",
      "Comparison loss = 6.5037\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.3072\n",
      "Comparison loss = 6.3630\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.3044\n",
      "Comparison loss = 6.1785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch no 21 : \n",
      "Classification loss = 29.3010\n",
      "Comparison loss = 5.9476\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.2945\n",
      "Comparison loss = 5.6676\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.2909\n",
      "Comparison loss = 5.3492\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.2884\n",
      "Comparison loss = 5.0064\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.2867\n",
      "Comparison loss = 4.6520\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.150% \n",
      "Comparison = 17.300%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 8.450% \n",
      "Comparison = 20.400%\u001b[0m\n",
      "RUN NO 7\n",
      "Epoch no 1 : \n",
      "Classification loss = 29.2886\n",
      "Comparison loss = 6.8941\n",
      "Epoch no 2 : \n",
      "Classification loss = 29.2833\n",
      "Comparison loss = 6.8900\n",
      "Epoch no 3 : \n",
      "Classification loss = 29.2817\n",
      "Comparison loss = 6.8861\n",
      "Epoch no 4 : \n",
      "Classification loss = 29.2798\n",
      "Comparison loss = 6.8825\n",
      "Epoch no 5 : \n",
      "Classification loss = 29.2765\n",
      "Comparison loss = 6.8779\n",
      "Epoch no 6 : \n",
      "Classification loss = 29.2737\n",
      "Comparison loss = 6.8727\n",
      "Epoch no 7 : \n",
      "Classification loss = 29.2708\n",
      "Comparison loss = 6.8665\n",
      "Epoch no 8 : \n",
      "Classification loss = 29.2692\n",
      "Comparison loss = 6.8574\n",
      "Epoch no 9 : \n",
      "Classification loss = 29.2678\n",
      "Comparison loss = 6.8466\n",
      "Epoch no 10 : \n",
      "Classification loss = 29.2664\n",
      "Comparison loss = 6.8323\n",
      "Epoch no 11 : \n",
      "Classification loss = 29.2652\n",
      "Comparison loss = 6.8115\n",
      "Epoch no 12 : \n",
      "Classification loss = 29.2644\n",
      "Comparison loss = 6.7853\n",
      "Epoch no 13 : \n",
      "Classification loss = 29.2636\n",
      "Comparison loss = 6.7515\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.2628\n",
      "Comparison loss = 6.7042\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.2621\n",
      "Comparison loss = 6.6445\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.2615\n",
      "Comparison loss = 6.5680\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.2610\n",
      "Comparison loss = 6.4667\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.2605\n",
      "Comparison loss = 6.3373\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.2601\n",
      "Comparison loss = 6.1713\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.2596\n",
      "Comparison loss = 5.9530\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.2593\n",
      "Comparison loss = 5.6744\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.2589\n",
      "Comparison loss = 5.3222\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.2586\n",
      "Comparison loss = 4.8792\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.2584\n",
      "Comparison loss = 4.3565\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.2582\n",
      "Comparison loss = 3.7737\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.150% \n",
      "Comparison = 5.000%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 8.300% \n",
      "Comparison = 9.500%\u001b[0m\n",
      "RUN NO 8\n",
      "Epoch no 1 : \n",
      "Classification loss = 29.2586\n",
      "Comparison loss = 6.9731\n",
      "Epoch no 2 : \n",
      "Classification loss = 29.2577\n",
      "Comparison loss = 6.9665\n",
      "Epoch no 3 : \n",
      "Classification loss = 29.2573\n",
      "Comparison loss = 6.9603\n",
      "Epoch no 4 : \n",
      "Classification loss = 29.2567\n",
      "Comparison loss = 6.9538\n",
      "Epoch no 5 : \n",
      "Classification loss = 29.2566\n",
      "Comparison loss = 6.9472\n",
      "Epoch no 6 : \n",
      "Classification loss = 29.2559\n",
      "Comparison loss = 6.9399\n",
      "Epoch no 7 : \n",
      "Classification loss = 29.2554\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 8 : \n",
      "Classification loss = 29.2549\n",
      "Comparison loss = 6.9221\n",
      "Epoch no 9 : \n",
      "Classification loss = 29.2547\n",
      "Comparison loss = 6.9107\n",
      "Epoch no 10 : \n",
      "Classification loss = 29.2546\n",
      "Comparison loss = 6.8969\n",
      "Epoch no 11 : \n",
      "Classification loss = 29.2542\n",
      "Comparison loss = 6.8798\n",
      "Epoch no 12 : \n",
      "Classification loss = 29.2540\n",
      "Comparison loss = 6.8582\n",
      "Epoch no 13 : \n",
      "Classification loss = 29.2538\n",
      "Comparison loss = 6.8318\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.2538\n",
      "Comparison loss = 6.7982\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.2536\n",
      "Comparison loss = 6.7549\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.2536\n",
      "Comparison loss = 6.6985\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.2534\n",
      "Comparison loss = 6.6255\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.2533\n",
      "Comparison loss = 6.5339\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.2531\n",
      "Comparison loss = 6.4195\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.2532\n",
      "Comparison loss = 6.2719\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.2532\n",
      "Comparison loss = 6.0893\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.2534\n",
      "Comparison loss = 5.8636\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.2531\n",
      "Comparison loss = 5.5958\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.2531\n",
      "Comparison loss = 5.2917\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.2529\n",
      "Comparison loss = 4.9596\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.150% \n",
      "Comparison = 10.700%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 8.150% \n",
      "Comparison = 15.000%\u001b[0m\n",
      "RUN NO 9\n",
      "Epoch no 1 : \n",
      "Classification loss = 29.2530\n",
      "Comparison loss = 6.9409\n",
      "Epoch no 2 : \n",
      "Classification loss = 29.2534\n",
      "Comparison loss = 6.9346\n",
      "Epoch no 3 : \n",
      "Classification loss = 29.2532\n",
      "Comparison loss = 6.9286\n",
      "Epoch no 4 : \n",
      "Classification loss = 29.2532\n",
      "Comparison loss = 6.9219\n",
      "Epoch no 5 : \n",
      "Classification loss = 29.2529\n",
      "Comparison loss = 6.9141\n",
      "Epoch no 6 : \n",
      "Classification loss = 29.2533\n",
      "Comparison loss = 6.9050\n",
      "Epoch no 7 : \n",
      "Classification loss = 29.2527\n",
      "Comparison loss = 6.8947\n",
      "Epoch no 8 : \n",
      "Classification loss = 29.2528\n",
      "Comparison loss = 6.8825\n",
      "Epoch no 9 : \n",
      "Classification loss = 29.2526\n",
      "Comparison loss = 6.8687\n",
      "Epoch no 10 : \n",
      "Classification loss = 29.2523\n",
      "Comparison loss = 6.8504\n",
      "Epoch no 11 : \n",
      "Classification loss = 29.2522\n",
      "Comparison loss = 6.8267\n",
      "Epoch no 12 : \n",
      "Classification loss = 29.2523\n",
      "Comparison loss = 6.7954\n",
      "Epoch no 13 : \n",
      "Classification loss = 29.2524\n",
      "Comparison loss = 6.7527\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.2529\n",
      "Comparison loss = 6.6942\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.2527\n",
      "Comparison loss = 6.6144\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.2525\n",
      "Comparison loss = 6.5081\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.2523\n",
      "Comparison loss = 6.3702\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.2521\n",
      "Comparison loss = 6.1929\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.2522\n",
      "Comparison loss = 5.9693\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.2524\n",
      "Comparison loss = 5.7007\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.2525\n",
      "Comparison loss = 5.3861\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.2526\n",
      "Comparison loss = 5.0351\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.2522\n",
      "Comparison loss = 4.6619\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.2526\n",
      "Comparison loss = 4.2674\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.2530\n",
      "Comparison loss = 3.8637\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.150% \n",
      "Comparison = 7.600%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 7.900% \n",
      "Comparison = 11.600%\u001b[0m\n",
      "RUN NO 10\n",
      "Epoch no 1 : \n",
      "Classification loss = 29.2528\n",
      "Comparison loss = 6.9159\n",
      "Epoch no 2 : \n",
      "Classification loss = 29.2525\n",
      "Comparison loss = 6.9109\n",
      "Epoch no 3 : \n",
      "Classification loss = 29.2522\n",
      "Comparison loss = 6.9059\n",
      "Epoch no 4 : \n",
      "Classification loss = 29.2526\n",
      "Comparison loss = 6.9005\n",
      "Epoch no 5 : \n",
      "Classification loss = 29.2523\n",
      "Comparison loss = 6.8943\n",
      "Epoch no 6 : \n",
      "Classification loss = 29.2524\n",
      "Comparison loss = 6.8870\n",
      "Epoch no 7 : \n",
      "Classification loss = 29.2520\n",
      "Comparison loss = 6.8777\n",
      "Epoch no 8 : \n",
      "Classification loss = 29.2522\n",
      "Comparison loss = 6.8655\n",
      "Epoch no 9 : \n",
      "Classification loss = 29.2523\n",
      "Comparison loss = 6.8488\n",
      "Epoch no 10 : \n",
      "Classification loss = 29.2525\n",
      "Comparison loss = 6.8252\n",
      "Epoch no 11 : \n",
      "Classification loss = 29.2526\n",
      "Comparison loss = 6.7930\n",
      "Epoch no 12 : \n",
      "Classification loss = 29.2523\n",
      "Comparison loss = 6.7487\n",
      "Epoch no 13 : \n",
      "Classification loss = 29.2520\n",
      "Comparison loss = 6.6875\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.2522\n",
      "Comparison loss = 6.6045\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.2522\n",
      "Comparison loss = 6.4962\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.2524\n",
      "Comparison loss = 6.3537\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.2522\n",
      "Comparison loss = 6.1819\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.2519\n",
      "Comparison loss = 5.9766\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.2524\n",
      "Comparison loss = 5.7370\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.2519\n",
      "Comparison loss = 5.4680\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.2523\n",
      "Comparison loss = 5.1675\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.2523\n",
      "Comparison loss = 4.8468\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.2523\n",
      "Comparison loss = 4.5079\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.2523\n",
      "Comparison loss = 4.1621\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.2523\n",
      "Comparison loss = 3.8201\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.150% \n",
      "Comparison = 6.700%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 8.000% \n",
      "Comparison = 11.700%\u001b[0m\n",
      "Final error for train batch : 14.87±12.2454\n",
      "Final error for test batch : 19.39±11.8041\n",
      "RUN NO 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch no 1 : \n",
      "Classification loss = 29.5261\n",
      "Comparison loss = 6.8793\n",
      "Epoch no 2 : \n",
      "Classification loss = 30.4347\n",
      "Comparison loss = 6.8103\n",
      "Epoch no 3 : \n",
      "Classification loss = 31.3206\n",
      "Comparison loss = 6.5526\n",
      "Epoch no 4 : \n",
      "Classification loss = 31.1975\n",
      "Comparison loss = 5.6290\n",
      "Epoch no 5 : \n",
      "Classification loss = 30.4462\n",
      "Comparison loss = 4.5012\n",
      "Epoch no 6 : \n",
      "Classification loss = 30.2143\n",
      "Comparison loss = 3.2523\n",
      "Epoch no 7 : \n",
      "Classification loss = 29.9729\n",
      "Comparison loss = 3.8023\n",
      "Epoch no 8 : \n",
      "Classification loss = 29.6929\n",
      "Comparison loss = 2.6440\n",
      "Epoch no 9 : \n",
      "Classification loss = 29.5537\n",
      "Comparison loss = 7.5293\n",
      "Epoch no 10 : \n",
      "Classification loss = 29.5215\n",
      "Comparison loss = 1.6952\n",
      "Epoch no 11 : \n",
      "Classification loss = 29.4466\n",
      "Comparison loss = 3.0403\n",
      "Epoch no 12 : \n",
      "Classification loss = 29.4349\n",
      "Comparison loss = 1.5785\n",
      "Epoch no 13 : \n",
      "Classification loss = 29.3790\n",
      "Comparison loss = 1.1659\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.3657\n",
      "Comparison loss = 0.8103\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.3341\n",
      "Comparison loss = 0.3886\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.3209\n",
      "Comparison loss = 0.2402\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.3110\n",
      "Comparison loss = 0.1522\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.3095\n",
      "Comparison loss = 0.1094\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.3074\n",
      "Comparison loss = 0.0938\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.3061\n",
      "Comparison loss = 0.0852\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.3054\n",
      "Comparison loss = 0.0348\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.3154\n",
      "Comparison loss = 0.0098\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.3410\n",
      "Comparison loss = 0.1565\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.3391\n",
      "Comparison loss = 0.0840\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3400\n",
      "Comparison loss = 0.1660\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.550% \n",
      "Comparison = 0.100%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.550% \n",
      "Comparison = 3.100%\u001b[0m\n",
      "RUN NO 2\n",
      "Epoch no 1 : \n",
      "Classification loss = 29.4906\n",
      "Comparison loss = 6.9282\n",
      "Epoch no 2 : \n",
      "Classification loss = 29.4466\n",
      "Comparison loss = 6.8760\n",
      "Epoch no 3 : \n",
      "Classification loss = 29.5555\n",
      "Comparison loss = 6.7238\n",
      "Epoch no 4 : \n",
      "Classification loss = 29.7955\n",
      "Comparison loss = 6.1166\n",
      "Epoch no 5 : \n",
      "Classification loss = 29.6676\n",
      "Comparison loss = 5.2326\n",
      "Epoch no 6 : \n",
      "Classification loss = 29.5367\n",
      "Comparison loss = 4.1850\n",
      "Epoch no 7 : \n",
      "Classification loss = 29.5822\n",
      "Comparison loss = 4.4130\n",
      "Epoch no 8 : \n",
      "Classification loss = 29.5788\n",
      "Comparison loss = 4.0058\n",
      "Epoch no 9 : \n",
      "Classification loss = 29.5944\n",
      "Comparison loss = 2.1634\n",
      "Epoch no 10 : \n",
      "Classification loss = 29.4586\n",
      "Comparison loss = 1.7064\n",
      "Epoch no 11 : \n",
      "Classification loss = 29.4506\n",
      "Comparison loss = 2.0679\n",
      "Epoch no 12 : \n",
      "Classification loss = 29.4629\n",
      "Comparison loss = 0.6428\n",
      "Epoch no 13 : \n",
      "Classification loss = 29.5774\n",
      "Comparison loss = 0.9478\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.4880\n",
      "Comparison loss = 0.7189\n",
      "Epoch no 15 : \n",
      "Classification loss = 30.8941\n",
      "Comparison loss = 3.2178\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.9985\n",
      "Comparison loss = 0.9760\n",
      "Epoch no 17 : \n",
      "Classification loss = 30.0775\n",
      "Comparison loss = 1.1837\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.9180\n",
      "Comparison loss = 1.0539\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.9243\n",
      "Comparison loss = 1.2347\n",
      "Epoch no 20 : \n",
      "Classification loss = 30.1059\n",
      "Comparison loss = 1.3718\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.5775\n",
      "Comparison loss = 0.6064\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.3909\n",
      "Comparison loss = 0.2929\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.3456\n",
      "Comparison loss = 0.1647\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.3192\n",
      "Comparison loss = 0.0444\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3100\n",
      "Comparison loss = 0.0212\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.500% \n",
      "Comparison = 0.000%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 5.050% \n",
      "Comparison = 2.900%\u001b[0m\n",
      "RUN NO 3\n",
      "Epoch no 1 : \n",
      "Classification loss = 29.3386\n",
      "Comparison loss = 6.9425\n",
      "Epoch no 2 : \n",
      "Classification loss = 29.3815\n",
      "Comparison loss = 6.8489\n",
      "Epoch no 3 : \n",
      "Classification loss = 29.3124\n",
      "Comparison loss = 6.5907\n",
      "Epoch no 4 : \n",
      "Classification loss = 29.3517\n",
      "Comparison loss = 5.6834\n",
      "Epoch no 5 : \n",
      "Classification loss = 29.3523\n",
      "Comparison loss = 4.4646\n",
      "Epoch no 6 : \n",
      "Classification loss = 29.3749\n",
      "Comparison loss = 3.3217\n",
      "Epoch no 7 : \n",
      "Classification loss = 29.4378\n",
      "Comparison loss = 2.5932\n",
      "Epoch no 8 : \n",
      "Classification loss = 29.4916\n",
      "Comparison loss = 2.0588\n",
      "Epoch no 9 : \n",
      "Classification loss = 29.5212\n",
      "Comparison loss = 2.5021\n",
      "Epoch no 10 : \n",
      "Classification loss = 30.4127\n",
      "Comparison loss = 8.0591\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.2292\n",
      "Comparison loss = 4.3568\n",
      "Epoch no 12 : \n",
      "Classification loss = 29.8715\n",
      "Comparison loss = 3.0365\n",
      "Epoch no 13 : \n",
      "Classification loss = 29.8029\n",
      "Comparison loss = 2.2256\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.6676\n",
      "Comparison loss = 2.1727\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.6542\n",
      "Comparison loss = 1.5044\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.5429\n",
      "Comparison loss = 0.9838\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.5552\n",
      "Comparison loss = 0.7919\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.3766\n",
      "Comparison loss = 0.3809\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.4556\n",
      "Comparison loss = 0.5198\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.4146\n",
      "Comparison loss = 0.3412\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4096\n",
      "Comparison loss = 0.1322\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.3252\n",
      "Comparison loss = 0.1133\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.3283\n",
      "Comparison loss = 0.1644\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4192\n",
      "Comparison loss = 0.2364\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3787\n",
      "Comparison loss = 0.1562\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.800% \n",
      "Comparison = 0.100%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.400% \n",
      "Comparison = 3.300%\u001b[0m\n",
      "RUN NO 4\n",
      "Epoch no 1 : \n",
      "Classification loss = 29.3421\n",
      "Comparison loss = 6.9535\n",
      "Epoch no 2 : \n",
      "Classification loss = 29.3252\n",
      "Comparison loss = 6.8470\n",
      "Epoch no 3 : \n",
      "Classification loss = 29.3483\n",
      "Comparison loss = 6.5283\n",
      "Epoch no 4 : \n",
      "Classification loss = 29.3982\n",
      "Comparison loss = 5.4829\n",
      "Epoch no 5 : \n",
      "Classification loss = 29.3802\n",
      "Comparison loss = 4.1785\n",
      "Epoch no 6 : \n",
      "Classification loss = 29.3501\n",
      "Comparison loss = 3.2892\n",
      "Epoch no 7 : \n",
      "Classification loss = 29.3338\n",
      "Comparison loss = 4.3700\n",
      "Epoch no 8 : \n",
      "Classification loss = 29.4495\n",
      "Comparison loss = 2.7532\n",
      "Epoch no 9 : \n",
      "Classification loss = 29.6230\n",
      "Comparison loss = 2.6937\n",
      "Epoch no 10 : \n",
      "Classification loss = 29.5699\n",
      "Comparison loss = 3.4823\n",
      "Epoch no 11 : \n",
      "Classification loss = 29.7981\n",
      "Comparison loss = 1.8974\n",
      "Epoch no 12 : \n",
      "Classification loss = 29.8645\n",
      "Comparison loss = 1.7412\n",
      "Epoch no 13 : \n",
      "Classification loss = 29.5421\n",
      "Comparison loss = 1.0283\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.4933\n",
      "Comparison loss = 0.5823\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.4264\n",
      "Comparison loss = 0.4947\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.3883\n",
      "Comparison loss = 0.3046\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.3783\n",
      "Comparison loss = 0.1934\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.3212\n",
      "Comparison loss = 0.0931\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.3164\n",
      "Comparison loss = 0.1648\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.3257\n",
      "Comparison loss = 0.1542\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.2936\n",
      "Comparison loss = 0.0732\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.2933\n",
      "Comparison loss = 0.0696\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.2933\n",
      "Comparison loss = 0.0669\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.2932\n",
      "Comparison loss = 0.0647\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.2932\n",
      "Comparison loss = 0.0628\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.350% \n",
      "Comparison = 0.100%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.750% \n",
      "Comparison = 3.700%\u001b[0m\n",
      "RUN NO 5\n",
      "Epoch no 1 : \n",
      "Classification loss = 29.2942\n",
      "Comparison loss = 6.9685\n",
      "Epoch no 2 : \n",
      "Classification loss = 29.2984\n",
      "Comparison loss = 6.8974\n",
      "Epoch no 3 : \n",
      "Classification loss = 29.2953\n",
      "Comparison loss = 6.7768\n",
      "Epoch no 4 : \n",
      "Classification loss = 29.3272\n",
      "Comparison loss = 6.4404\n",
      "Epoch no 5 : \n",
      "Classification loss = 29.3579\n",
      "Comparison loss = 5.6920\n",
      "Epoch no 6 : \n",
      "Classification loss = 29.3036\n",
      "Comparison loss = 4.5596\n",
      "Epoch no 7 : \n",
      "Classification loss = 29.3772\n",
      "Comparison loss = 3.8696\n",
      "Epoch no 8 : \n",
      "Classification loss = 29.3430\n",
      "Comparison loss = 3.6236\n",
      "Epoch no 9 : \n",
      "Classification loss = 29.3313\n",
      "Comparison loss = 3.1922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch no 10 : \n",
      "Classification loss = 29.4212\n",
      "Comparison loss = 2.8545\n",
      "Epoch no 11 : \n",
      "Classification loss = 29.3202\n",
      "Comparison loss = 2.5512\n",
      "Epoch no 12 : \n",
      "Classification loss = 29.3936\n",
      "Comparison loss = 1.9104\n",
      "Epoch no 13 : \n",
      "Classification loss = 29.4012\n",
      "Comparison loss = 1.3449\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.5400\n",
      "Comparison loss = 0.9980\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.7011\n",
      "Comparison loss = 1.3110\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.8873\n",
      "Comparison loss = 1.9357\n",
      "Epoch no 17 : \n",
      "Classification loss = 30.0687\n",
      "Comparison loss = 1.7025\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.9413\n",
      "Comparison loss = 1.2979\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.8427\n",
      "Comparison loss = 1.1854\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.5583\n",
      "Comparison loss = 0.7656\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.5672\n",
      "Comparison loss = 0.5301\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4405\n",
      "Comparison loss = 0.3129\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.3938\n",
      "Comparison loss = 0.2282\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.3858\n",
      "Comparison loss = 0.2465\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3898\n",
      "Comparison loss = 0.2130\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.750% \n",
      "Comparison = 0.400%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.450% \n",
      "Comparison = 3.800%\u001b[0m\n",
      "RUN NO 6\n",
      "Epoch no 1 : \n",
      "Classification loss = 29.3728\n",
      "Comparison loss = 6.9732\n",
      "Epoch no 2 : \n",
      "Classification loss = 29.4037\n",
      "Comparison loss = 6.8676\n",
      "Epoch no 3 : \n",
      "Classification loss = 29.4013\n",
      "Comparison loss = 6.6443\n",
      "Epoch no 4 : \n",
      "Classification loss = 29.3799\n",
      "Comparison loss = 5.8283\n",
      "Epoch no 5 : \n",
      "Classification loss = 29.3147\n",
      "Comparison loss = 4.5337\n",
      "Epoch no 6 : \n",
      "Classification loss = 29.3630\n",
      "Comparison loss = 3.6590\n",
      "Epoch no 7 : \n",
      "Classification loss = 29.4934\n",
      "Comparison loss = 4.7664\n",
      "Epoch no 8 : \n",
      "Classification loss = 29.5199\n",
      "Comparison loss = 3.4029\n",
      "Epoch no 9 : \n",
      "Classification loss = 29.5127\n",
      "Comparison loss = 3.0264\n",
      "Epoch no 10 : \n",
      "Classification loss = 29.4654\n",
      "Comparison loss = 2.5208\n",
      "Epoch no 11 : \n",
      "Classification loss = 29.3966\n",
      "Comparison loss = 1.8126\n",
      "Epoch no 12 : \n",
      "Classification loss = 29.3500\n",
      "Comparison loss = 1.1326\n",
      "Epoch no 13 : \n",
      "Classification loss = 29.3430\n",
      "Comparison loss = 0.5403\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.3331\n",
      "Comparison loss = 0.3977\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.3337\n",
      "Comparison loss = 0.1358\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.3327\n",
      "Comparison loss = 0.1195\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.3327\n",
      "Comparison loss = 0.1107\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.3326\n",
      "Comparison loss = 0.1005\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.3316\n",
      "Comparison loss = 0.0950\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.3216\n",
      "Comparison loss = 0.0911\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.3071\n",
      "Comparison loss = 0.0880\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.3592\n",
      "Comparison loss = 0.1455\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.3072\n",
      "Comparison loss = 0.0817\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.3633\n",
      "Comparison loss = 0.2940\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3129\n",
      "Comparison loss = 0.0989\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.700% \n",
      "Comparison = 0.600%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.550% \n",
      "Comparison = 3.100%\u001b[0m\n",
      "RUN NO 7\n",
      "Epoch no 1 : \n",
      "Classification loss = 29.3297\n",
      "Comparison loss = 6.8969\n",
      "Epoch no 2 : \n",
      "Classification loss = 29.3696\n",
      "Comparison loss = 6.8425\n",
      "Epoch no 3 : \n",
      "Classification loss = 29.2978\n",
      "Comparison loss = 6.6138\n",
      "Epoch no 4 : \n",
      "Classification loss = 29.3058\n",
      "Comparison loss = 5.8309\n",
      "Epoch no 5 : \n",
      "Classification loss = 29.2968\n",
      "Comparison loss = 3.7385\n",
      "Epoch no 6 : \n",
      "Classification loss = 29.3033\n",
      "Comparison loss = 1.3945\n",
      "Epoch no 7 : \n",
      "Classification loss = 29.2867\n",
      "Comparison loss = 0.4816\n",
      "Epoch no 8 : \n",
      "Classification loss = 29.2832\n",
      "Comparison loss = 0.4035\n",
      "Epoch no 9 : \n",
      "Classification loss = 29.2833\n",
      "Comparison loss = 5.1943\n",
      "Epoch no 10 : \n",
      "Classification loss = 29.2831\n",
      "Comparison loss = 13.9787\n",
      "Epoch no 11 : \n",
      "Classification loss = 29.2828\n",
      "Comparison loss = 0.5963\n",
      "Epoch no 12 : \n",
      "Classification loss = 29.2775\n",
      "Comparison loss = 2.3637\n",
      "Epoch no 13 : \n",
      "Classification loss = 29.2731\n",
      "Comparison loss = 1.9582\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.2831\n",
      "Comparison loss = 1.0914\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.2831\n",
      "Comparison loss = 0.5293\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.2831\n",
      "Comparison loss = 0.2936\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.2830\n",
      "Comparison loss = 0.1409\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.2830\n",
      "Comparison loss = 0.0521\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.2830\n",
      "Comparison loss = 0.0159\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.2830\n",
      "Comparison loss = 0.0047\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.2830\n",
      "Comparison loss = 0.0017\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.2830\n",
      "Comparison loss = 0.0008\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.2830\n",
      "Comparison loss = 0.0005\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.2830\n",
      "Comparison loss = 0.0003\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3263\n",
      "Comparison loss = 0.3431\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.600% \n",
      "Comparison = 0.300%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.350% \n",
      "Comparison = 2.900%\u001b[0m\n",
      "RUN NO 8\n",
      "Epoch no 1 : \n",
      "Classification loss = 29.3067\n",
      "Comparison loss = 6.9229\n",
      "Epoch no 2 : \n",
      "Classification loss = 29.3036\n",
      "Comparison loss = 6.8768\n",
      "Epoch no 3 : \n",
      "Classification loss = 29.2866\n",
      "Comparison loss = 6.7373\n",
      "Epoch no 4 : \n",
      "Classification loss = 29.2775\n",
      "Comparison loss = 6.1665\n",
      "Epoch no 5 : \n",
      "Classification loss = 29.2903\n",
      "Comparison loss = 4.8778\n",
      "Epoch no 6 : \n",
      "Classification loss = 29.2832\n",
      "Comparison loss = 3.4377\n",
      "Epoch no 7 : \n",
      "Classification loss = 29.2821\n",
      "Comparison loss = 3.1297\n",
      "Epoch no 8 : \n",
      "Classification loss = 29.3601\n",
      "Comparison loss = 2.8670\n",
      "Epoch no 9 : \n",
      "Classification loss = 29.3766\n",
      "Comparison loss = 4.0835\n",
      "Epoch no 10 : \n",
      "Classification loss = 29.4762\n",
      "Comparison loss = 2.9231\n",
      "Epoch no 11 : \n",
      "Classification loss = 29.4189\n",
      "Comparison loss = 1.8953\n",
      "Epoch no 12 : \n",
      "Classification loss = 29.6054\n",
      "Comparison loss = 2.5514\n",
      "Epoch no 13 : \n",
      "Classification loss = 29.4665\n",
      "Comparison loss = 1.3526\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.4821\n",
      "Comparison loss = 0.8776\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.4220\n",
      "Comparison loss = 0.3873\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.3709\n",
      "Comparison loss = 0.3973\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.6343\n",
      "Comparison loss = 1.4685\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.5333\n",
      "Comparison loss = 0.8165\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.6708\n",
      "Comparison loss = 1.0031\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.5289\n",
      "Comparison loss = 0.5899\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.5509\n",
      "Comparison loss = 0.7341\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.5585\n",
      "Comparison loss = 0.7454\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.3129\n",
      "Comparison loss = 0.2491\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.3368\n",
      "Comparison loss = 0.2343\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3503\n",
      "Comparison loss = 0.1102\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.450% \n",
      "Comparison = 0.100%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 5.050% \n",
      "Comparison = 3.400%\u001b[0m\n",
      "RUN NO 9\n",
      "Epoch no 1 : \n",
      "Classification loss = 29.2950\n",
      "Comparison loss = 6.8974\n",
      "Epoch no 2 : \n",
      "Classification loss = 29.2675\n",
      "Comparison loss = 6.8344\n",
      "Epoch no 3 : \n",
      "Classification loss = 29.2628\n",
      "Comparison loss = 6.5737\n",
      "Epoch no 4 : \n",
      "Classification loss = 29.2729\n",
      "Comparison loss = 5.6105\n",
      "Epoch no 5 : \n",
      "Classification loss = 29.2808\n",
      "Comparison loss = 3.9757\n",
      "Epoch no 6 : \n",
      "Classification loss = 29.3095\n",
      "Comparison loss = 3.4977\n",
      "Epoch no 7 : \n",
      "Classification loss = 29.2831\n",
      "Comparison loss = 1.9950\n",
      "Epoch no 8 : \n",
      "Classification loss = 29.3132\n",
      "Comparison loss = 1.6654\n",
      "Epoch no 9 : \n",
      "Classification loss = 29.3145\n",
      "Comparison loss = 3.2007\n",
      "Epoch no 10 : \n",
      "Classification loss = 29.2790\n",
      "Comparison loss = 6.8262\n",
      "Epoch no 11 : \n",
      "Classification loss = 29.2531\n",
      "Comparison loss = 1.8329\n",
      "Epoch no 12 : \n",
      "Classification loss = 29.2531\n",
      "Comparison loss = 0.8951\n",
      "Epoch no 13 : \n",
      "Classification loss = 29.2532\n",
      "Comparison loss = 1.0575\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.2530\n",
      "Comparison loss = 0.7226\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.2530\n",
      "Comparison loss = 0.4315\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.2530\n",
      "Comparison loss = 0.2585\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.2530\n",
      "Comparison loss = 0.1833\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.2530\n",
      "Comparison loss = 0.1506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch no 19 : \n",
      "Classification loss = 29.2530\n",
      "Comparison loss = 0.1347\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.2530\n",
      "Comparison loss = 0.1257\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.2530\n",
      "Comparison loss = 0.1191\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.2530\n",
      "Comparison loss = 0.1128\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.2530\n",
      "Comparison loss = 0.1078\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.2530\n",
      "Comparison loss = 0.1036\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.2530\n",
      "Comparison loss = 0.0995\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.200% \n",
      "Comparison = 0.100%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.000% \n",
      "Comparison = 2.800%\u001b[0m\n",
      "RUN NO 10\n",
      "Epoch no 1 : \n",
      "Classification loss = 29.2530\n",
      "Comparison loss = 6.9309\n",
      "Epoch no 2 : \n",
      "Classification loss = 29.2578\n",
      "Comparison loss = 6.8295\n",
      "Epoch no 3 : \n",
      "Classification loss = 29.3497\n",
      "Comparison loss = 6.4748\n",
      "Epoch no 4 : \n",
      "Classification loss = 29.2534\n",
      "Comparison loss = 5.3813\n",
      "Epoch no 5 : \n",
      "Classification loss = 29.2633\n",
      "Comparison loss = 3.7385\n",
      "Epoch no 6 : \n",
      "Classification loss = 29.2634\n",
      "Comparison loss = 2.8649\n",
      "Epoch no 7 : \n",
      "Classification loss = 29.2682\n",
      "Comparison loss = 2.3495\n",
      "Epoch no 8 : \n",
      "Classification loss = 29.2659\n",
      "Comparison loss = 6.6263\n",
      "Epoch no 9 : \n",
      "Classification loss = 29.2542\n",
      "Comparison loss = 1.8597\n",
      "Epoch no 10 : \n",
      "Classification loss = 29.2672\n",
      "Comparison loss = 2.6752\n",
      "Epoch no 11 : \n",
      "Classification loss = 29.4411\n",
      "Comparison loss = 1.4723\n",
      "Epoch no 12 : \n",
      "Classification loss = 29.3146\n",
      "Comparison loss = 1.4546\n",
      "Epoch no 13 : \n",
      "Classification loss = 29.3256\n",
      "Comparison loss = 1.1389\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.3237\n",
      "Comparison loss = 0.6869\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.3421\n",
      "Comparison loss = 0.6427\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.6844\n",
      "Comparison loss = 1.3322\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.3658\n",
      "Comparison loss = 0.4886\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.5916\n",
      "Comparison loss = 0.8384\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.3970\n",
      "Comparison loss = 0.3598\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.4600\n",
      "Comparison loss = 0.5135\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4347\n",
      "Comparison loss = 0.2308\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.6496\n",
      "Comparison loss = 0.7355\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.5290\n",
      "Comparison loss = 0.6914\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.5073\n",
      "Comparison loss = 0.5114\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.7585\n",
      "Comparison loss = 0.8493\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 1.850% \n",
      "Comparison = 0.800%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 7.200% \n",
      "Comparison = 4.000%\u001b[0m\n",
      "Final error for train batch : 0.26±0.2633\n",
      "Final error for test batch : 3.30±0.4163\n",
      "RUN NO 1\n",
      "Epoch no 1 : \n",
      "Classification loss = 29.2230\n",
      "Comparison loss = 6.8870\n",
      "Epoch no 2 : \n",
      "Classification loss = 29.3397\n",
      "Comparison loss = 6.8191\n",
      "Epoch no 3 : \n",
      "Classification loss = 29.8528\n",
      "Comparison loss = 6.5525\n",
      "Epoch no 4 : \n",
      "Classification loss = 30.2886\n",
      "Comparison loss = 5.7850\n",
      "Epoch no 5 : \n",
      "Classification loss = 31.1589\n",
      "Comparison loss = 4.9377\n",
      "Epoch no 6 : \n",
      "Classification loss = 30.7624\n",
      "Comparison loss = 4.5698\n",
      "Epoch no 7 : \n",
      "Classification loss = 31.0204\n",
      "Comparison loss = 4.8688\n",
      "Epoch no 8 : \n",
      "Classification loss = 30.3785\n",
      "Comparison loss = 5.9771\n",
      "Epoch no 9 : \n",
      "Classification loss = 30.1083\n",
      "Comparison loss = 4.9657\n",
      "Epoch no 10 : \n",
      "Classification loss = 29.8655\n",
      "Comparison loss = 3.1525\n",
      "Epoch no 11 : \n",
      "Classification loss = 29.6246\n",
      "Comparison loss = 1.8267\n",
      "Epoch no 12 : \n",
      "Classification loss = 29.5738\n",
      "Comparison loss = 1.1070\n",
      "Epoch no 13 : \n",
      "Classification loss = 29.5644\n",
      "Comparison loss = 0.8732\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.5294\n",
      "Comparison loss = 0.5465\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.4665\n",
      "Comparison loss = 0.3289\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.4510\n",
      "Comparison loss = 0.2480\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.4190\n",
      "Comparison loss = 0.2270\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.4441\n",
      "Comparison loss = 0.2840\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.5182\n",
      "Comparison loss = 0.3771\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.4419\n",
      "Comparison loss = 0.3913\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4472\n",
      "Comparison loss = 0.3561\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4291\n",
      "Comparison loss = 0.2677\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4117\n",
      "Comparison loss = 0.2377\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4022\n",
      "Comparison loss = 0.2148\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3952\n",
      "Comparison loss = 0.2643\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.950% \n",
      "Comparison = 0.400%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.250% \n",
      "Comparison = 3.600%\u001b[0m\n",
      "RUN NO 2\n",
      "Epoch no 1 : \n",
      "Classification loss = 29.4205\n",
      "Comparison loss = 6.9014\n",
      "Epoch no 2 : \n",
      "Classification loss = 29.5141\n",
      "Comparison loss = 6.8492\n",
      "Epoch no 3 : \n",
      "Classification loss = 29.6812\n",
      "Comparison loss = 6.6444\n",
      "Epoch no 4 : \n",
      "Classification loss = 29.6738\n",
      "Comparison loss = 5.9027\n",
      "Epoch no 5 : \n",
      "Classification loss = 29.6297\n",
      "Comparison loss = 4.3219\n",
      "Epoch no 6 : \n",
      "Classification loss = 29.7902\n",
      "Comparison loss = 2.5221\n",
      "Epoch no 7 : \n",
      "Classification loss = 29.5992\n",
      "Comparison loss = 2.1879\n",
      "Epoch no 8 : \n",
      "Classification loss = 29.8264\n",
      "Comparison loss = 3.2938\n",
      "Epoch no 9 : \n",
      "Classification loss = 29.7190\n",
      "Comparison loss = 4.3081\n",
      "Epoch no 10 : \n",
      "Classification loss = 29.5604\n",
      "Comparison loss = 5.9068\n",
      "Epoch no 11 : \n",
      "Classification loss = 29.4605\n",
      "Comparison loss = 1.3727\n",
      "Epoch no 12 : \n",
      "Classification loss = 29.5026\n",
      "Comparison loss = 1.5161\n",
      "Epoch no 13 : \n",
      "Classification loss = 29.4811\n",
      "Comparison loss = 1.4702\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.3969\n",
      "Comparison loss = 0.7769\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.3855\n",
      "Comparison loss = 0.5339\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.3682\n",
      "Comparison loss = 0.4103\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.4187\n",
      "Comparison loss = 0.4019\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.3170\n",
      "Comparison loss = 0.2310\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.3132\n",
      "Comparison loss = 0.1745\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.2962\n",
      "Comparison loss = 0.1683\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.2938\n",
      "Comparison loss = 0.1652\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.2913\n",
      "Comparison loss = 0.1629\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.2854\n",
      "Comparison loss = 0.1605\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.2813\n",
      "Comparison loss = 0.1582\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.2745\n",
      "Comparison loss = 0.1557\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.250% \n",
      "Comparison = 0.200%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.350% \n",
      "Comparison = 3.300%\u001b[0m\n",
      "RUN NO 3\n",
      "Epoch no 1 : \n",
      "Classification loss = 29.3190\n",
      "Comparison loss = 6.8806\n",
      "Epoch no 2 : \n",
      "Classification loss = 29.2926\n",
      "Comparison loss = 6.8021\n",
      "Epoch no 3 : \n",
      "Classification loss = 29.4103\n",
      "Comparison loss = 6.4297\n",
      "Epoch no 4 : \n",
      "Classification loss = 29.4783\n",
      "Comparison loss = 5.3510\n",
      "Epoch no 5 : \n",
      "Classification loss = 29.5279\n",
      "Comparison loss = 4.0661\n",
      "Epoch no 6 : \n",
      "Classification loss = 29.7334\n",
      "Comparison loss = 3.4317\n",
      "Epoch no 7 : \n",
      "Classification loss = 29.6231\n",
      "Comparison loss = 2.1242\n",
      "Epoch no 8 : \n",
      "Classification loss = 29.7708\n",
      "Comparison loss = 2.6402\n",
      "Epoch no 9 : \n",
      "Classification loss = 29.6612\n",
      "Comparison loss = 2.7170\n",
      "Epoch no 10 : \n",
      "Classification loss = 29.4615\n",
      "Comparison loss = 4.8611\n",
      "Epoch no 11 : \n",
      "Classification loss = 29.4410\n",
      "Comparison loss = 1.2667\n",
      "Epoch no 12 : \n",
      "Classification loss = 29.4845\n",
      "Comparison loss = 2.7752\n",
      "Epoch no 13 : \n",
      "Classification loss = 29.4125\n",
      "Comparison loss = 1.1351\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.3112\n",
      "Comparison loss = 0.7430\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.3394\n",
      "Comparison loss = 0.8259\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.3627\n",
      "Comparison loss = 0.4129\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.6524\n",
      "Comparison loss = 0.9190\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.3515\n",
      "Comparison loss = 0.3722\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.4226\n",
      "Comparison loss = 0.5406\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.3517\n",
      "Comparison loss = 0.1438\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.3433\n",
      "Comparison loss = 0.1725\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.2979\n",
      "Comparison loss = 0.1589\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.2886\n",
      "Comparison loss = 0.1515\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.2686\n",
      "Comparison loss = 0.1459\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.2649\n",
      "Comparison loss = 0.1404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.150% \n",
      "Comparison = 0.100%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.700% \n",
      "Comparison = 3.500%\u001b[0m\n",
      "RUN NO 4\n",
      "Epoch no 1 : \n",
      "Classification loss = 29.2739\n",
      "Comparison loss = 6.8974\n",
      "Epoch no 2 : \n",
      "Classification loss = 29.3024\n",
      "Comparison loss = 6.8600\n",
      "Epoch no 3 : \n",
      "Classification loss = 29.3446\n",
      "Comparison loss = 6.7006\n",
      "Epoch no 4 : \n",
      "Classification loss = 29.3053\n",
      "Comparison loss = 6.0169\n",
      "Epoch no 5 : \n",
      "Classification loss = 29.3557\n",
      "Comparison loss = 4.5383\n",
      "Epoch no 6 : \n",
      "Classification loss = 29.3749\n",
      "Comparison loss = 3.6837\n",
      "Epoch no 7 : \n",
      "Classification loss = 29.3899\n",
      "Comparison loss = 2.8471\n",
      "Epoch no 8 : \n",
      "Classification loss = 29.3415\n",
      "Comparison loss = 5.4007\n",
      "Epoch no 9 : \n",
      "Classification loss = 29.3442\n",
      "Comparison loss = 3.3327\n",
      "Epoch no 10 : \n",
      "Classification loss = 29.5749\n",
      "Comparison loss = 2.1606\n",
      "Epoch no 11 : \n",
      "Classification loss = 29.3428\n",
      "Comparison loss = 1.4909\n",
      "Epoch no 12 : \n",
      "Classification loss = 29.4521\n",
      "Comparison loss = 1.0213\n",
      "Epoch no 13 : \n",
      "Classification loss = 29.5731\n",
      "Comparison loss = 0.6808\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.7598\n",
      "Comparison loss = 0.7890\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.7014\n",
      "Comparison loss = 0.5820\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.6761\n",
      "Comparison loss = 0.7426\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.5079\n",
      "Comparison loss = 0.4210\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.3819\n",
      "Comparison loss = 0.3093\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.3543\n",
      "Comparison loss = 0.2444\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.3297\n",
      "Comparison loss = 0.2149\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.3334\n",
      "Comparison loss = 0.1582\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.3189\n",
      "Comparison loss = 0.1860\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.2985\n",
      "Comparison loss = 0.1855\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.2923\n",
      "Comparison loss = 0.1309\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.2748\n",
      "Comparison loss = 0.1206\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.250% \n",
      "Comparison = 0.200%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 5.050% \n",
      "Comparison = 4.000%\u001b[0m\n",
      "RUN NO 5\n",
      "Epoch no 1 : \n",
      "Classification loss = 29.2734\n",
      "Comparison loss = 6.9273\n",
      "Epoch no 2 : \n",
      "Classification loss = 29.2825\n",
      "Comparison loss = 6.8305\n",
      "Epoch no 3 : \n",
      "Classification loss = 29.2711\n",
      "Comparison loss = 6.5364\n",
      "Epoch no 4 : \n",
      "Classification loss = 29.3017\n",
      "Comparison loss = 5.4409\n",
      "Epoch no 5 : \n",
      "Classification loss = 29.4115\n",
      "Comparison loss = 4.3659\n",
      "Epoch no 6 : \n",
      "Classification loss = 29.3870\n",
      "Comparison loss = 3.4232\n",
      "Epoch no 7 : \n",
      "Classification loss = 29.5603\n",
      "Comparison loss = 3.5872\n",
      "Epoch no 8 : \n",
      "Classification loss = 29.3887\n",
      "Comparison loss = 3.0710\n",
      "Epoch no 9 : \n",
      "Classification loss = 29.5013\n",
      "Comparison loss = 1.9160\n",
      "Epoch no 10 : \n",
      "Classification loss = 29.4391\n",
      "Comparison loss = 1.8042\n",
      "Epoch no 11 : \n",
      "Classification loss = 29.5026\n",
      "Comparison loss = 1.1649\n",
      "Epoch no 12 : \n",
      "Classification loss = 29.4118\n",
      "Comparison loss = 0.5236\n",
      "Epoch no 13 : \n",
      "Classification loss = 29.4908\n",
      "Comparison loss = 0.3325\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.5421\n",
      "Comparison loss = 0.9231\n",
      "Epoch no 15 : \n",
      "Classification loss = 30.5443\n",
      "Comparison loss = 3.6879\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.8292\n",
      "Comparison loss = 1.1246\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.6286\n",
      "Comparison loss = 1.1558\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.6526\n",
      "Comparison loss = 0.8323\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.5606\n",
      "Comparison loss = 0.6427\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.6415\n",
      "Comparison loss = 1.0283\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.5671\n",
      "Comparison loss = 0.6148\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.6835\n",
      "Comparison loss = 0.7085\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.7547\n",
      "Comparison loss = 0.5736\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.5627\n",
      "Comparison loss = 0.5688\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.4210\n",
      "Comparison loss = 0.3180\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.750% \n",
      "Comparison = 0.400%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 5.350% \n",
      "Comparison = 3.800%\u001b[0m\n",
      "RUN NO 6\n",
      "Epoch no 1 : \n",
      "Classification loss = 29.3341\n",
      "Comparison loss = 6.9290\n",
      "Epoch no 2 : \n",
      "Classification loss = 29.3007\n",
      "Comparison loss = 6.8629\n",
      "Epoch no 3 : \n",
      "Classification loss = 29.3394\n",
      "Comparison loss = 6.6581\n",
      "Epoch no 4 : \n",
      "Classification loss = 29.3520\n",
      "Comparison loss = 5.9175\n",
      "Epoch no 5 : \n",
      "Classification loss = 29.3383\n",
      "Comparison loss = 4.6516\n",
      "Epoch no 6 : \n",
      "Classification loss = 29.4228\n",
      "Comparison loss = 3.8537\n",
      "Epoch no 7 : \n",
      "Classification loss = 29.4764\n",
      "Comparison loss = 4.6559\n",
      "Epoch no 8 : \n",
      "Classification loss = 29.3268\n",
      "Comparison loss = 3.5014\n",
      "Epoch no 9 : \n",
      "Classification loss = 29.4524\n",
      "Comparison loss = 2.6311\n",
      "Epoch no 10 : \n",
      "Classification loss = 29.4081\n",
      "Comparison loss = 3.2923\n",
      "Epoch no 11 : \n",
      "Classification loss = 29.3953\n",
      "Comparison loss = 1.9766\n",
      "Epoch no 12 : \n",
      "Classification loss = 29.4609\n",
      "Comparison loss = 1.4368\n",
      "Epoch no 13 : \n",
      "Classification loss = 29.3634\n",
      "Comparison loss = 0.7224\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.4304\n",
      "Comparison loss = 0.5597\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.5143\n",
      "Comparison loss = 0.4310\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.5725\n",
      "Comparison loss = 0.4519\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.5236\n",
      "Comparison loss = 0.5239\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.4934\n",
      "Comparison loss = 0.4482\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.4715\n",
      "Comparison loss = 0.4709\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.4198\n",
      "Comparison loss = 0.3458\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4452\n",
      "Comparison loss = 0.3810\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4350\n",
      "Comparison loss = 0.4347\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.3768\n",
      "Comparison loss = 0.2155\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.3429\n",
      "Comparison loss = 0.1438\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3118\n",
      "Comparison loss = 0.1838\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.450% \n",
      "Comparison = 0.100%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.100% \n",
      "Comparison = 2.600%\u001b[0m\n",
      "RUN NO 7\n",
      "Epoch no 1 : \n",
      "Classification loss = 29.2951\n",
      "Comparison loss = 6.8941\n",
      "Epoch no 2 : \n",
      "Classification loss = 29.2942\n",
      "Comparison loss = 6.8241\n",
      "Epoch no 3 : \n",
      "Classification loss = 29.2932\n",
      "Comparison loss = 6.5328\n",
      "Epoch no 4 : \n",
      "Classification loss = 29.2740\n",
      "Comparison loss = 5.6291\n",
      "Epoch no 5 : \n",
      "Classification loss = 29.2748\n",
      "Comparison loss = 4.1999\n",
      "Epoch no 6 : \n",
      "Classification loss = 29.3111\n",
      "Comparison loss = 3.7521\n",
      "Epoch no 7 : \n",
      "Classification loss = 29.3015\n",
      "Comparison loss = 3.0153\n",
      "Epoch no 8 : \n",
      "Classification loss = 29.3658\n",
      "Comparison loss = 7.5941\n",
      "Epoch no 9 : \n",
      "Classification loss = 29.3522\n",
      "Comparison loss = 2.8502\n",
      "Epoch no 10 : \n",
      "Classification loss = 29.3851\n",
      "Comparison loss = 2.8413\n",
      "Epoch no 11 : \n",
      "Classification loss = 29.3505\n",
      "Comparison loss = 2.1876\n",
      "Epoch no 12 : \n",
      "Classification loss = 29.3072\n",
      "Comparison loss = 1.4163\n",
      "Epoch no 13 : \n",
      "Classification loss = 29.3752\n",
      "Comparison loss = 0.9875\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.3323\n",
      "Comparison loss = 0.5384\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.4805\n",
      "Comparison loss = 0.5170\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.3849\n",
      "Comparison loss = 0.2027\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.4899\n",
      "Comparison loss = 0.4727\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.4432\n",
      "Comparison loss = 0.2554\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.4534\n",
      "Comparison loss = 0.1841\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.5793\n",
      "Comparison loss = 0.6831\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.5847\n",
      "Comparison loss = 0.6319\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.7626\n",
      "Comparison loss = 1.2013\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.7222\n",
      "Comparison loss = 1.1545\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.9630\n",
      "Comparison loss = 1.4343\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.6728\n",
      "Comparison loss = 0.8196\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 1.850% \n",
      "Comparison = 1.100%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 5.550% \n",
      "Comparison = 4.500%\u001b[0m\n",
      "RUN NO 8\n",
      "Epoch no 1 : \n",
      "Classification loss = 29.5193\n",
      "Comparison loss = 6.8872\n",
      "Epoch no 2 : \n",
      "Classification loss = 29.4774\n",
      "Comparison loss = 6.8524\n",
      "Epoch no 3 : \n",
      "Classification loss = 29.4214\n",
      "Comparison loss = 6.7037\n",
      "Epoch no 4 : \n",
      "Classification loss = 29.3977\n",
      "Comparison loss = 6.0984\n",
      "Epoch no 5 : \n",
      "Classification loss = 29.3916\n",
      "Comparison loss = 4.9332\n",
      "Epoch no 6 : \n",
      "Classification loss = 29.4123\n",
      "Comparison loss = 3.5589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch no 7 : \n",
      "Classification loss = 29.4747\n",
      "Comparison loss = 2.7960\n",
      "Epoch no 8 : \n",
      "Classification loss = 29.4041\n",
      "Comparison loss = 1.4424\n",
      "Epoch no 9 : \n",
      "Classification loss = 29.4155\n",
      "Comparison loss = 1.2674\n",
      "Epoch no 10 : \n",
      "Classification loss = 29.4225\n",
      "Comparison loss = 0.4303\n",
      "Epoch no 11 : \n",
      "Classification loss = 29.3728\n",
      "Comparison loss = 0.4567\n",
      "Epoch no 12 : \n",
      "Classification loss = 29.3930\n",
      "Comparison loss = 1.4464\n",
      "Epoch no 13 : \n",
      "Classification loss = 29.4117\n",
      "Comparison loss = 2.7551\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.3776\n",
      "Comparison loss = 0.4481\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.3631\n",
      "Comparison loss = 0.9032\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.3639\n",
      "Comparison loss = 0.3828\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.3631\n",
      "Comparison loss = 0.1797\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.3630\n",
      "Comparison loss = 0.1139\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.3630\n",
      "Comparison loss = 0.0903\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.3630\n",
      "Comparison loss = 0.0795\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.3630\n",
      "Comparison loss = 0.0724\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.3630\n",
      "Comparison loss = 0.0672\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.3630\n",
      "Comparison loss = 0.0629\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.3630\n",
      "Comparison loss = 0.0588\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3630\n",
      "Comparison loss = 0.0550\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.700% \n",
      "Comparison = 0.100%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 3.700% \n",
      "Comparison = 2.700%\u001b[0m\n",
      "RUN NO 9\n",
      "Epoch no 1 : \n",
      "Classification loss = 29.3548\n",
      "Comparison loss = 6.9228\n",
      "Epoch no 2 : \n",
      "Classification loss = 29.3530\n",
      "Comparison loss = 6.8806\n",
      "Epoch no 3 : \n",
      "Classification loss = 29.3530\n",
      "Comparison loss = 6.7769\n",
      "Epoch no 4 : \n",
      "Classification loss = 29.3530\n",
      "Comparison loss = 6.4003\n",
      "Epoch no 5 : \n",
      "Classification loss = 29.3530\n",
      "Comparison loss = 5.4312\n",
      "Epoch no 6 : \n",
      "Classification loss = 29.3530\n",
      "Comparison loss = 4.1563\n",
      "Epoch no 7 : \n",
      "Classification loss = 29.3528\n",
      "Comparison loss = 3.2602\n",
      "Epoch no 8 : \n",
      "Classification loss = 29.3516\n",
      "Comparison loss = 2.3197\n",
      "Epoch no 9 : \n",
      "Classification loss = 29.3968\n",
      "Comparison loss = 4.6024\n",
      "Epoch no 10 : \n",
      "Classification loss = 29.5712\n",
      "Comparison loss = 2.7098\n",
      "Epoch no 11 : \n",
      "Classification loss = 29.5795\n",
      "Comparison loss = 2.1154\n",
      "Epoch no 12 : \n",
      "Classification loss = 29.4700\n",
      "Comparison loss = 1.5421\n",
      "Epoch no 13 : \n",
      "Classification loss = 29.5074\n",
      "Comparison loss = 1.1106\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.4960\n",
      "Comparison loss = 0.7049\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.3815\n",
      "Comparison loss = 0.3753\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.4049\n",
      "Comparison loss = 0.3978\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.3696\n",
      "Comparison loss = 0.4569\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.4287\n",
      "Comparison loss = 0.6973\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.4632\n",
      "Comparison loss = 0.7838\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.7359\n",
      "Comparison loss = 1.6819\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4355\n",
      "Comparison loss = 0.6152\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4300\n",
      "Comparison loss = 0.5059\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4401\n",
      "Comparison loss = 0.3993\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4230\n",
      "Comparison loss = 0.2442\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.4501\n",
      "Comparison loss = 0.4880\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.850% \n",
      "Comparison = 0.400%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 6.250% \n",
      "Comparison = 3.900%\u001b[0m\n",
      "RUN NO 10\n",
      "Epoch no 1 : \n",
      "Classification loss = 29.3899\n",
      "Comparison loss = 6.9271\n",
      "Epoch no 2 : \n",
      "Classification loss = 29.5225\n",
      "Comparison loss = 6.8514\n",
      "Epoch no 3 : \n",
      "Classification loss = 29.3999\n",
      "Comparison loss = 6.6327\n",
      "Epoch no 4 : \n",
      "Classification loss = 29.3557\n",
      "Comparison loss = 5.8582\n",
      "Epoch no 5 : \n",
      "Classification loss = 29.3471\n",
      "Comparison loss = 4.5976\n",
      "Epoch no 6 : \n",
      "Classification loss = 29.3066\n",
      "Comparison loss = 3.8077\n",
      "Epoch no 7 : \n",
      "Classification loss = 29.3387\n",
      "Comparison loss = 4.9901\n",
      "Epoch no 8 : \n",
      "Classification loss = 29.3708\n",
      "Comparison loss = 3.4922\n",
      "Epoch no 9 : \n",
      "Classification loss = 29.4899\n",
      "Comparison loss = 3.5035\n",
      "Epoch no 10 : \n",
      "Classification loss = 29.4588\n",
      "Comparison loss = 3.0006\n",
      "Epoch no 11 : \n",
      "Classification loss = 29.3826\n",
      "Comparison loss = 2.7613\n",
      "Epoch no 12 : \n",
      "Classification loss = 29.3675\n",
      "Comparison loss = 1.2787\n",
      "Epoch no 13 : \n",
      "Classification loss = 29.3412\n",
      "Comparison loss = 0.9979\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.3298\n",
      "Comparison loss = 0.4755\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.3231\n",
      "Comparison loss = 0.2576\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.3154\n",
      "Comparison loss = 0.1814\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.3357\n",
      "Comparison loss = 0.1650\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.3208\n",
      "Comparison loss = 0.1545\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.4515\n",
      "Comparison loss = 0.4307\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.4980\n",
      "Comparison loss = 0.5738\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.3824\n",
      "Comparison loss = 0.2156\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.5037\n",
      "Comparison loss = 0.6600\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4051\n",
      "Comparison loss = 0.2431\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4957\n",
      "Comparison loss = 0.3280\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.4516\n",
      "Comparison loss = 0.3594\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 1.200% \n",
      "Comparison = 0.700%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.500% \n",
      "Comparison = 3.700%\u001b[0m\n",
      "Final error for train batch : 0.37±0.3199\n",
      "Final error for test batch : 3.56±0.5777\n",
      "RUN NO 1\n",
      "Epoch no 1 : \n",
      "Classification loss = 29.2546\n",
      "Comparison loss = 6.9502\n",
      "Epoch no 2 : \n",
      "Classification loss = 29.3639\n",
      "Comparison loss = 6.8833\n",
      "Epoch no 3 : \n",
      "Classification loss = 30.0872\n",
      "Comparison loss = 6.7316\n",
      "Epoch no 4 : \n",
      "Classification loss = 30.8394\n",
      "Comparison loss = 6.3012\n",
      "Epoch no 5 : \n",
      "Classification loss = 30.7207\n",
      "Comparison loss = 5.2822\n",
      "Epoch no 6 : \n",
      "Classification loss = 30.4369\n",
      "Comparison loss = 4.2860\n",
      "Epoch no 7 : \n",
      "Classification loss = 30.2142\n",
      "Comparison loss = 4.1646\n",
      "Epoch no 8 : \n",
      "Classification loss = 30.2449\n",
      "Comparison loss = 5.2599\n",
      "Epoch no 9 : \n",
      "Classification loss = 30.3382\n",
      "Comparison loss = 4.0221\n",
      "Epoch no 10 : \n",
      "Classification loss = 29.9089\n",
      "Comparison loss = 3.8634\n",
      "Epoch no 11 : \n",
      "Classification loss = 29.7778\n",
      "Comparison loss = 2.2133\n",
      "Epoch no 12 : \n",
      "Classification loss = 29.8936\n",
      "Comparison loss = 2.1972\n",
      "Epoch no 13 : \n",
      "Classification loss = 29.8773\n",
      "Comparison loss = 0.9473\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.8947\n",
      "Comparison loss = 0.9459\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.9180\n",
      "Comparison loss = 0.7028\n",
      "Epoch no 16 : \n",
      "Classification loss = 30.5194\n",
      "Comparison loss = 1.3878\n",
      "Epoch no 17 : \n",
      "Classification loss = 30.6871\n",
      "Comparison loss = 1.8672\n",
      "Epoch no 18 : \n",
      "Classification loss = 30.7935\n",
      "Comparison loss = 1.9226\n",
      "Epoch no 19 : \n",
      "Classification loss = 30.8624\n",
      "Comparison loss = 2.3724\n",
      "Epoch no 20 : \n",
      "Classification loss = 30.7105\n",
      "Comparison loss = 1.4949\n",
      "Epoch no 21 : \n",
      "Classification loss = 30.9750\n",
      "Comparison loss = 1.9215\n",
      "Epoch no 22 : \n",
      "Classification loss = 30.6595\n",
      "Comparison loss = 1.6833\n",
      "Epoch no 23 : \n",
      "Classification loss = 31.0461\n",
      "Comparison loss = 2.0604\n",
      "Epoch no 24 : \n",
      "Classification loss = 31.0516\n",
      "Comparison loss = 1.7580\n",
      "Epoch no 25 : \n",
      "Classification loss = 30.5141\n",
      "Comparison loss = 1.5934\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 5.150% \n",
      "Comparison = 3.600%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 11.350% \n",
      "Comparison = 7.200%\u001b[0m\n",
      "RUN NO 2\n",
      "Epoch no 1 : \n",
      "Classification loss = 30.1668\n",
      "Comparison loss = 6.8831\n",
      "Epoch no 2 : \n",
      "Classification loss = 30.0055\n",
      "Comparison loss = 6.8103\n",
      "Epoch no 3 : \n",
      "Classification loss = 29.8939\n",
      "Comparison loss = 6.4608\n",
      "Epoch no 4 : \n",
      "Classification loss = 29.7184\n",
      "Comparison loss = 5.4023\n",
      "Epoch no 5 : \n",
      "Classification loss = 29.7263\n",
      "Comparison loss = 3.9308\n",
      "Epoch no 6 : \n",
      "Classification loss = 29.7087\n",
      "Comparison loss = 3.1851\n",
      "Epoch no 7 : \n",
      "Classification loss = 29.7549\n",
      "Comparison loss = 3.0602\n",
      "Epoch no 8 : \n",
      "Classification loss = 29.6719\n",
      "Comparison loss = 8.1164\n",
      "Epoch no 9 : \n",
      "Classification loss = 29.5672\n",
      "Comparison loss = 3.2891\n",
      "Epoch no 10 : \n",
      "Classification loss = 29.6425\n",
      "Comparison loss = 2.0411\n",
      "Epoch no 11 : \n",
      "Classification loss = 29.6650\n",
      "Comparison loss = 2.1065\n",
      "Epoch no 12 : \n",
      "Classification loss = 29.7684\n",
      "Comparison loss = 1.7625\n",
      "Epoch no 13 : \n",
      "Classification loss = 29.8396\n",
      "Comparison loss = 1.4893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch no 14 : \n",
      "Classification loss = 29.9476\n",
      "Comparison loss = 1.1462\n",
      "Epoch no 15 : \n",
      "Classification loss = 30.0375\n",
      "Comparison loss = 0.9145\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.9940\n",
      "Comparison loss = 1.0915\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.9791\n",
      "Comparison loss = 0.9600\n",
      "Epoch no 18 : \n",
      "Classification loss = 30.0642\n",
      "Comparison loss = 1.0276\n",
      "Epoch no 19 : \n",
      "Classification loss = 30.1367\n",
      "Comparison loss = 1.1525\n",
      "Epoch no 20 : \n",
      "Classification loss = 30.5636\n",
      "Comparison loss = 1.3266\n",
      "Epoch no 21 : \n",
      "Classification loss = 30.0539\n",
      "Comparison loss = 0.9174\n",
      "Epoch no 22 : \n",
      "Classification loss = 30.1905\n",
      "Comparison loss = 0.8364\n",
      "Epoch no 23 : \n",
      "Classification loss = 30.0061\n",
      "Comparison loss = 0.7122\n",
      "Epoch no 24 : \n",
      "Classification loss = 30.0499\n",
      "Comparison loss = 0.8522\n",
      "Epoch no 25 : \n",
      "Classification loss = 30.1365\n",
      "Comparison loss = 1.1561\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 3.850% \n",
      "Comparison = 2.200%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 9.350% \n",
      "Comparison = 5.500%\u001b[0m\n",
      "RUN NO 3\n",
      "Epoch no 1 : \n",
      "Classification loss = 29.7477\n",
      "Comparison loss = 6.9237\n",
      "Epoch no 2 : \n",
      "Classification loss = 29.8004\n",
      "Comparison loss = 6.8588\n",
      "Epoch no 3 : \n",
      "Classification loss = 29.6929\n",
      "Comparison loss = 6.7154\n",
      "Epoch no 4 : \n",
      "Classification loss = 29.8120\n",
      "Comparison loss = 6.1307\n",
      "Epoch no 5 : \n",
      "Classification loss = 29.7291\n",
      "Comparison loss = 4.9415\n",
      "Epoch no 6 : \n",
      "Classification loss = 29.7800\n",
      "Comparison loss = 3.8239\n",
      "Epoch no 7 : \n",
      "Classification loss = 29.8052\n",
      "Comparison loss = 3.7495\n",
      "Epoch no 8 : \n",
      "Classification loss = 29.7846\n",
      "Comparison loss = 3.9966\n",
      "Epoch no 9 : \n",
      "Classification loss = 29.7198\n",
      "Comparison loss = 4.7403\n",
      "Epoch no 10 : \n",
      "Classification loss = 29.6901\n",
      "Comparison loss = 3.7922\n",
      "Epoch no 11 : \n",
      "Classification loss = 29.4735\n",
      "Comparison loss = 2.0172\n",
      "Epoch no 12 : \n",
      "Classification loss = 29.4321\n",
      "Comparison loss = 1.5239\n",
      "Epoch no 13 : \n",
      "Classification loss = 29.4353\n",
      "Comparison loss = 0.6235\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.5441\n",
      "Comparison loss = 0.5287\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.5892\n",
      "Comparison loss = 0.7772\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.7003\n",
      "Comparison loss = 0.5798\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.6983\n",
      "Comparison loss = 0.8381\n",
      "Epoch no 18 : \n",
      "Classification loss = 30.0202\n",
      "Comparison loss = 0.7517\n",
      "Epoch no 19 : \n",
      "Classification loss = 30.7883\n",
      "Comparison loss = 1.8339\n",
      "Epoch no 20 : \n",
      "Classification loss = 31.2373\n",
      "Comparison loss = 1.8661\n",
      "Epoch no 21 : \n",
      "Classification loss = 31.1019\n",
      "Comparison loss = 2.0152\n",
      "Epoch no 22 : \n",
      "Classification loss = 31.9082\n",
      "Comparison loss = 2.8876\n",
      "Epoch no 23 : \n",
      "Classification loss = 31.8720\n",
      "Comparison loss = 2.0084\n",
      "Epoch no 24 : \n",
      "Classification loss = 31.2491\n",
      "Comparison loss = 2.1434\n",
      "Epoch no 25 : \n",
      "Classification loss = 31.0963\n",
      "Comparison loss = 2.1563\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 10.300% \n",
      "Comparison = 6.400%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 14.850% \n",
      "Comparison = 11.200%\u001b[0m\n",
      "RUN NO 4\n",
      "Epoch no 1 : \n",
      "Classification loss = 30.4318\n",
      "Comparison loss = 6.9159\n",
      "Epoch no 2 : \n",
      "Classification loss = 30.1765\n",
      "Comparison loss = 6.8467\n",
      "Epoch no 3 : \n",
      "Classification loss = 29.7675\n",
      "Comparison loss = 6.6502\n",
      "Epoch no 4 : \n",
      "Classification loss = 29.6467\n",
      "Comparison loss = 5.8192\n",
      "Epoch no 5 : \n",
      "Classification loss = 29.5489\n",
      "Comparison loss = 4.4323\n",
      "Epoch no 6 : \n",
      "Classification loss = 29.4593\n",
      "Comparison loss = 3.4727\n",
      "Epoch no 7 : \n",
      "Classification loss = 29.4081\n",
      "Comparison loss = 3.0425\n",
      "Epoch no 8 : \n",
      "Classification loss = 29.3712\n",
      "Comparison loss = 2.7485\n",
      "Epoch no 9 : \n",
      "Classification loss = 29.3374\n",
      "Comparison loss = 2.5484\n",
      "Epoch no 10 : \n",
      "Classification loss = 29.3233\n",
      "Comparison loss = 2.4225\n",
      "Epoch no 11 : \n",
      "Classification loss = 29.3074\n",
      "Comparison loss = 1.3863\n",
      "Epoch no 12 : \n",
      "Classification loss = 29.3322\n",
      "Comparison loss = 0.6888\n",
      "Epoch no 13 : \n",
      "Classification loss = 29.3178\n",
      "Comparison loss = 1.4366\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.3100\n",
      "Comparison loss = 0.8714\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.3155\n",
      "Comparison loss = 0.5496\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.2958\n",
      "Comparison loss = 0.5470\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.2858\n",
      "Comparison loss = 0.2570\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.2851\n",
      "Comparison loss = 0.1663\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.2839\n",
      "Comparison loss = 0.0894\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.2764\n",
      "Comparison loss = 0.0075\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.2745\n",
      "Comparison loss = 0.0049\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.2751\n",
      "Comparison loss = 0.0393\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.3780\n",
      "Comparison loss = 0.3207\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4615\n",
      "Comparison loss = 0.2582\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.5888\n",
      "Comparison loss = 0.8520\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 2.200% \n",
      "Comparison = 1.600%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 8.400% \n",
      "Comparison = 5.400%\u001b[0m\n",
      "RUN NO 5\n",
      "Epoch no 1 : \n",
      "Classification loss = 29.7184\n",
      "Comparison loss = 6.8869\n",
      "Epoch no 2 : \n",
      "Classification loss = 29.5405\n",
      "Comparison loss = 6.8432\n",
      "Epoch no 3 : \n",
      "Classification loss = 29.5300\n",
      "Comparison loss = 6.6371\n",
      "Epoch no 4 : \n",
      "Classification loss = 29.5861\n",
      "Comparison loss = 5.8570\n",
      "Epoch no 5 : \n",
      "Classification loss = 29.6040\n",
      "Comparison loss = 4.3354\n",
      "Epoch no 6 : \n",
      "Classification loss = 29.4217\n",
      "Comparison loss = 2.9550\n",
      "Epoch no 7 : \n",
      "Classification loss = 29.4464\n",
      "Comparison loss = 2.0068\n",
      "Epoch no 8 : \n",
      "Classification loss = 29.4629\n",
      "Comparison loss = 3.4014\n",
      "Epoch no 9 : \n",
      "Classification loss = 29.3881\n",
      "Comparison loss = 8.5278\n",
      "Epoch no 10 : \n",
      "Classification loss = 29.3897\n",
      "Comparison loss = 3.5584\n",
      "Epoch no 11 : \n",
      "Classification loss = 29.3676\n",
      "Comparison loss = 5.0879\n",
      "Epoch no 12 : \n",
      "Classification loss = 29.3146\n",
      "Comparison loss = 2.8771\n",
      "Epoch no 13 : \n",
      "Classification loss = 29.3199\n",
      "Comparison loss = 1.9592\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.3562\n",
      "Comparison loss = 1.5561\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.3325\n",
      "Comparison loss = 0.8508\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.3148\n",
      "Comparison loss = 0.3926\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.3282\n",
      "Comparison loss = 0.1687\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.2938\n",
      "Comparison loss = 0.0744\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.2838\n",
      "Comparison loss = 0.0390\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.2864\n",
      "Comparison loss = 0.0237\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.2750\n",
      "Comparison loss = 0.0159\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.2745\n",
      "Comparison loss = 0.0112\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.2740\n",
      "Comparison loss = 0.0083\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.2738\n",
      "Comparison loss = 0.0059\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.2737\n",
      "Comparison loss = 0.0039\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.250% \n",
      "Comparison = 0.000%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 6.300% \n",
      "Comparison = 4.700%\u001b[0m\n",
      "RUN NO 6\n",
      "Epoch no 1 : \n",
      "Classification loss = 29.2878\n",
      "Comparison loss = 6.9143\n",
      "Epoch no 2 : \n",
      "Classification loss = 29.3132\n",
      "Comparison loss = 6.8321\n",
      "Epoch no 3 : \n",
      "Classification loss = 29.3315\n",
      "Comparison loss = 6.5771\n",
      "Epoch no 4 : \n",
      "Classification loss = 29.4113\n",
      "Comparison loss = 5.7275\n",
      "Epoch no 5 : \n",
      "Classification loss = 29.6864\n",
      "Comparison loss = 4.5081\n",
      "Epoch no 6 : \n",
      "Classification loss = 29.9062\n",
      "Comparison loss = 3.5239\n",
      "Epoch no 7 : \n",
      "Classification loss = 29.7074\n",
      "Comparison loss = 2.8123\n",
      "Epoch no 8 : \n",
      "Classification loss = 29.5966\n",
      "Comparison loss = 3.0689\n",
      "Epoch no 9 : \n",
      "Classification loss = 29.6565\n",
      "Comparison loss = 3.8200\n",
      "Epoch no 10 : \n",
      "Classification loss = 30.1491\n",
      "Comparison loss = 3.0540\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.3876\n",
      "Comparison loss = 2.9433\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.0968\n",
      "Comparison loss = 1.8871\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.2001\n",
      "Comparison loss = 1.6077\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.0911\n",
      "Comparison loss = 1.3171\n",
      "Epoch no 15 : \n",
      "Classification loss = 30.1680\n",
      "Comparison loss = 0.9172\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.9747\n",
      "Comparison loss = 0.7650\n",
      "Epoch no 17 : \n",
      "Classification loss = 30.1412\n",
      "Comparison loss = 0.7739\n",
      "Epoch no 18 : \n",
      "Classification loss = 30.2036\n",
      "Comparison loss = 0.8783\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.8717\n",
      "Comparison loss = 0.7743\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.9879\n",
      "Comparison loss = 0.8318\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.6625\n",
      "Comparison loss = 0.4733\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.5775\n",
      "Comparison loss = 0.3893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch no 23 : \n",
      "Classification loss = 29.5342\n",
      "Comparison loss = 0.3600\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4074\n",
      "Comparison loss = 0.1078\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3677\n",
      "Comparison loss = 0.0886\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.650% \n",
      "Comparison = 0.100%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 7.200% \n",
      "Comparison = 4.700%\u001b[0m\n",
      "RUN NO 7\n",
      "Epoch no 1 : \n",
      "Classification loss = 29.3924\n",
      "Comparison loss = 6.9087\n",
      "Epoch no 2 : \n",
      "Classification loss = 29.5185\n",
      "Comparison loss = 6.8283\n",
      "Epoch no 3 : \n",
      "Classification loss = 29.7457\n",
      "Comparison loss = 6.5368\n",
      "Epoch no 4 : \n",
      "Classification loss = 29.7938\n",
      "Comparison loss = 5.6312\n",
      "Epoch no 5 : \n",
      "Classification loss = 29.7130\n",
      "Comparison loss = 4.1727\n",
      "Epoch no 6 : \n",
      "Classification loss = 29.6356\n",
      "Comparison loss = 3.9090\n",
      "Epoch no 7 : \n",
      "Classification loss = 29.5451\n",
      "Comparison loss = 3.5390\n",
      "Epoch no 8 : \n",
      "Classification loss = 29.7131\n",
      "Comparison loss = 5.6537\n",
      "Epoch no 9 : \n",
      "Classification loss = 29.6865\n",
      "Comparison loss = 4.7565\n",
      "Epoch no 10 : \n",
      "Classification loss = 29.5216\n",
      "Comparison loss = 2.7613\n",
      "Epoch no 11 : \n",
      "Classification loss = 29.5129\n",
      "Comparison loss = 1.7903\n",
      "Epoch no 12 : \n",
      "Classification loss = 29.4781\n",
      "Comparison loss = 0.7688\n",
      "Epoch no 13 : \n",
      "Classification loss = 29.7067\n",
      "Comparison loss = 1.0275\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.5222\n",
      "Comparison loss = 0.7341\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.5986\n",
      "Comparison loss = 0.2810\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.5026\n",
      "Comparison loss = 0.1527\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.6600\n",
      "Comparison loss = 0.7651\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.5833\n",
      "Comparison loss = 0.3712\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.6654\n",
      "Comparison loss = 0.8150\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.5393\n",
      "Comparison loss = 0.3832\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.6080\n",
      "Comparison loss = 0.5192\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4901\n",
      "Comparison loss = 0.3179\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.5338\n",
      "Comparison loss = 0.2713\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.8196\n",
      "Comparison loss = 0.8124\n",
      "Epoch no 25 : \n",
      "Classification loss = 30.1586\n",
      "Comparison loss = 1.6180\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 2.900% \n",
      "Comparison = 1.100%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 9.950% \n",
      "Comparison = 6.300%\u001b[0m\n",
      "RUN NO 8\n",
      "Epoch no 1 : \n",
      "Classification loss = 29.7976\n",
      "Comparison loss = 6.9063\n",
      "Epoch no 2 : \n",
      "Classification loss = 30.0837\n",
      "Comparison loss = 6.7927\n",
      "Epoch no 3 : \n",
      "Classification loss = 29.6832\n",
      "Comparison loss = 6.3980\n",
      "Epoch no 4 : \n",
      "Classification loss = 29.6313\n",
      "Comparison loss = 5.2358\n",
      "Epoch no 5 : \n",
      "Classification loss = 29.5604\n",
      "Comparison loss = 3.7370\n",
      "Epoch no 6 : \n",
      "Classification loss = 29.4432\n",
      "Comparison loss = 2.4385\n",
      "Epoch no 7 : \n",
      "Classification loss = 29.5264\n",
      "Comparison loss = 1.2989\n",
      "Epoch no 8 : \n",
      "Classification loss = 29.7091\n",
      "Comparison loss = 2.0810\n",
      "Epoch no 9 : \n",
      "Classification loss = 29.7219\n",
      "Comparison loss = 1.4918\n",
      "Epoch no 10 : \n",
      "Classification loss = 29.6426\n",
      "Comparison loss = 0.8076\n",
      "Epoch no 11 : \n",
      "Classification loss = 29.9214\n",
      "Comparison loss = 1.1200\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.0385\n",
      "Comparison loss = 1.9237\n",
      "Epoch no 13 : \n",
      "Classification loss = 29.7187\n",
      "Comparison loss = 1.0055\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.7171\n",
      "Comparison loss = 0.9905\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.5677\n",
      "Comparison loss = 0.5411\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.5048\n",
      "Comparison loss = 0.7071\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.3981\n",
      "Comparison loss = 0.1775\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.3339\n",
      "Comparison loss = 0.0758\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.3097\n",
      "Comparison loss = 0.0447\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.3109\n",
      "Comparison loss = 0.0093\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.3075\n",
      "Comparison loss = 0.0047\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.2813\n",
      "Comparison loss = 0.0035\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.2763\n",
      "Comparison loss = 0.0030\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.2723\n",
      "Comparison loss = 0.0027\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.2653\n",
      "Comparison loss = 0.0025\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.200% \n",
      "Comparison = 0.000%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 6.400% \n",
      "Comparison = 3.800%\u001b[0m\n",
      "RUN NO 9\n",
      "Epoch no 1 : \n",
      "Classification loss = 29.2927\n",
      "Comparison loss = 6.9143\n",
      "Epoch no 2 : \n",
      "Classification loss = 29.2920\n",
      "Comparison loss = 6.8342\n",
      "Epoch no 3 : \n",
      "Classification loss = 29.3314\n",
      "Comparison loss = 6.5872\n",
      "Epoch no 4 : \n",
      "Classification loss = 29.4045\n",
      "Comparison loss = 5.6501\n",
      "Epoch no 5 : \n",
      "Classification loss = 29.4161\n",
      "Comparison loss = 4.4767\n",
      "Epoch no 6 : \n",
      "Classification loss = 29.5262\n",
      "Comparison loss = 3.7720\n",
      "Epoch no 7 : \n",
      "Classification loss = 29.4280\n",
      "Comparison loss = 4.7887\n",
      "Epoch no 8 : \n",
      "Classification loss = 29.4875\n",
      "Comparison loss = 3.6055\n",
      "Epoch no 9 : \n",
      "Classification loss = 29.6048\n",
      "Comparison loss = 3.6079\n",
      "Epoch no 10 : \n",
      "Classification loss = 29.6766\n",
      "Comparison loss = 3.4978\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.1431\n",
      "Comparison loss = 3.4457\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.2012\n",
      "Comparison loss = 2.3763\n",
      "Epoch no 13 : \n",
      "Classification loss = 29.9594\n",
      "Comparison loss = 2.3514\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.0083\n",
      "Comparison loss = 1.6724\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.7733\n",
      "Comparison loss = 0.8496\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.8464\n",
      "Comparison loss = 0.7157\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.8990\n",
      "Comparison loss = 0.9568\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.6581\n",
      "Comparison loss = 0.6748\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.6362\n",
      "Comparison loss = 0.3654\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.5825\n",
      "Comparison loss = 0.3932\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.7320\n",
      "Comparison loss = 0.5571\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.7055\n",
      "Comparison loss = 0.7256\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.8159\n",
      "Comparison loss = 0.6783\n",
      "Epoch no 24 : \n",
      "Classification loss = 30.1317\n",
      "Comparison loss = 1.3079\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.9902\n",
      "Comparison loss = 1.2686\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 3.700% \n",
      "Comparison = 2.000%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 10.950% \n",
      "Comparison = 7.000%\u001b[0m\n",
      "RUN NO 10\n",
      "Epoch no 1 : \n",
      "Classification loss = 29.7780\n",
      "Comparison loss = 6.9305\n",
      "Epoch no 2 : \n",
      "Classification loss = 29.6971\n",
      "Comparison loss = 6.8499\n",
      "Epoch no 3 : \n",
      "Classification loss = 29.8001\n",
      "Comparison loss = 6.5877\n",
      "Epoch no 4 : \n",
      "Classification loss = 29.7510\n",
      "Comparison loss = 5.6791\n",
      "Epoch no 5 : \n",
      "Classification loss = 29.5386\n",
      "Comparison loss = 4.4464\n",
      "Epoch no 6 : \n",
      "Classification loss = 29.4650\n",
      "Comparison loss = 3.6650\n",
      "Epoch no 7 : \n",
      "Classification loss = 29.3757\n",
      "Comparison loss = 4.3575\n",
      "Epoch no 8 : \n",
      "Classification loss = 29.3393\n",
      "Comparison loss = 3.0119\n",
      "Epoch no 9 : \n",
      "Classification loss = 29.2889\n",
      "Comparison loss = 1.8821\n",
      "Epoch no 10 : \n",
      "Classification loss = 29.2845\n",
      "Comparison loss = 2.7045\n",
      "Epoch no 11 : \n",
      "Classification loss = 29.2603\n",
      "Comparison loss = 1.2199\n",
      "Epoch no 12 : \n",
      "Classification loss = 29.2631\n",
      "Comparison loss = 1.2161\n",
      "Epoch no 13 : \n",
      "Classification loss = 29.2605\n",
      "Comparison loss = 0.2567\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.2721\n",
      "Comparison loss = 0.2160\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.2607\n",
      "Comparison loss = 0.0424\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.2624\n",
      "Comparison loss = 0.0391\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.2542\n",
      "Comparison loss = 0.0274\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.2567\n",
      "Comparison loss = 0.0165\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.2538\n",
      "Comparison loss = 0.0099\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.2536\n",
      "Comparison loss = 0.0064\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.2535\n",
      "Comparison loss = 0.0044\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.2535\n",
      "Comparison loss = 0.0031\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.2534\n",
      "Comparison loss = 0.0022\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.2534\n",
      "Comparison loss = 0.0016\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.2534\n",
      "Comparison loss = 0.0011\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.150% \n",
      "Comparison = 0.000%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 5.400% \n",
      "Comparison = 3.700%\u001b[0m\n",
      "Final error for train batch : 1.70±2.0450\n",
      "Final error for test batch : 5.95±2.2027\n",
      "RUN NO 1\n",
      "Epoch no 1 : \n",
      "Classification loss = 31.2650\n",
      "Comparison loss = 6.6894\n",
      "Epoch no 2 : \n",
      "Classification loss = 33.1129\n",
      "Comparison loss = 5.9287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch no 3 : \n",
      "Classification loss = 34.1990\n",
      "Comparison loss = 6.4104\n",
      "Epoch no 4 : \n",
      "Classification loss = 33.5426\n",
      "Comparison loss = 5.6020\n",
      "Epoch no 5 : \n",
      "Classification loss = 35.3506\n",
      "Comparison loss = 6.0662\n",
      "Epoch no 6 : \n",
      "Classification loss = 35.7308\n",
      "Comparison loss = 6.5449\n",
      "Epoch no 7 : \n",
      "Classification loss = 36.0831\n",
      "Comparison loss = 5.9084\n",
      "Epoch no 8 : \n",
      "Classification loss = 34.5865\n",
      "Comparison loss = 5.1534\n",
      "Epoch no 9 : \n",
      "Classification loss = 36.1629\n",
      "Comparison loss = 5.9101\n",
      "Epoch no 10 : \n",
      "Classification loss = 34.0987\n",
      "Comparison loss = 5.2651\n",
      "Epoch no 11 : \n",
      "Classification loss = 33.4682\n",
      "Comparison loss = 5.2500\n",
      "Epoch no 12 : \n",
      "Classification loss = 34.2857\n",
      "Comparison loss = 5.8663\n",
      "Epoch no 13 : \n",
      "Classification loss = 34.2399\n",
      "Comparison loss = 5.3495\n",
      "Epoch no 14 : \n",
      "Classification loss = 33.6022\n",
      "Comparison loss = 4.7269\n",
      "Epoch no 15 : \n",
      "Classification loss = 33.1402\n",
      "Comparison loss = 4.0056\n",
      "Epoch no 16 : \n",
      "Classification loss = 33.3472\n",
      "Comparison loss = 4.3360\n",
      "Epoch no 17 : \n",
      "Classification loss = 33.9129\n",
      "Comparison loss = 5.6588\n",
      "Epoch no 18 : \n",
      "Classification loss = 34.1760\n",
      "Comparison loss = 4.0415\n",
      "Epoch no 19 : \n",
      "Classification loss = 33.8912\n",
      "Comparison loss = 4.0091\n",
      "Epoch no 20 : \n",
      "Classification loss = 35.2173\n",
      "Comparison loss = 5.0110\n",
      "Epoch no 21 : \n",
      "Classification loss = 35.2370\n",
      "Comparison loss = 4.8501\n",
      "Epoch no 22 : \n",
      "Classification loss = 36.2503\n",
      "Comparison loss = 4.3689\n",
      "Epoch no 23 : \n",
      "Classification loss = 36.1878\n",
      "Comparison loss = 4.5900\n",
      "Epoch no 24 : \n",
      "Classification loss = 38.0146\n",
      "Comparison loss = 4.5215\n",
      "Epoch no 25 : \n",
      "Classification loss = 37.8739\n",
      "Comparison loss = 4.7991\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 39.150% \n",
      "Comparison = 18.200%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 37.600% \n",
      "Comparison = 19.900%\u001b[0m\n",
      "RUN NO 2\n",
      "Epoch no 1 : \n",
      "Classification loss = 35.4226\n",
      "Comparison loss = 6.8103\n",
      "Epoch no 2 : \n",
      "Classification loss = 33.8182\n",
      "Comparison loss = 6.3032\n",
      "Epoch no 3 : \n",
      "Classification loss = 33.8041\n",
      "Comparison loss = 6.0388\n",
      "Epoch no 4 : \n",
      "Classification loss = 33.5679\n",
      "Comparison loss = 5.8173\n",
      "Epoch no 5 : \n",
      "Classification loss = 33.7198\n",
      "Comparison loss = 5.5436\n",
      "Epoch no 6 : \n",
      "Classification loss = 35.5125\n",
      "Comparison loss = 6.6959\n",
      "Epoch no 7 : \n",
      "Classification loss = 35.9658\n",
      "Comparison loss = 6.2993\n",
      "Epoch no 8 : \n",
      "Classification loss = 35.9601\n",
      "Comparison loss = 5.9113\n",
      "Epoch no 9 : \n",
      "Classification loss = 35.5445\n",
      "Comparison loss = 6.3636\n",
      "Epoch no 10 : \n",
      "Classification loss = 34.0410\n",
      "Comparison loss = 6.8770\n",
      "Epoch no 11 : \n",
      "Classification loss = 34.5742\n",
      "Comparison loss = 6.9231\n",
      "Epoch no 12 : \n",
      "Classification loss = 34.5371\n",
      "Comparison loss = 6.9003\n",
      "Epoch no 13 : \n",
      "Classification loss = 33.5995\n",
      "Comparison loss = 6.8401\n",
      "Epoch no 14 : \n",
      "Classification loss = 33.7841\n",
      "Comparison loss = 6.7021\n",
      "Epoch no 15 : \n",
      "Classification loss = 33.7507\n",
      "Comparison loss = 5.8665\n",
      "Epoch no 16 : \n",
      "Classification loss = 33.3896\n",
      "Comparison loss = 6.1970\n",
      "Epoch no 17 : \n",
      "Classification loss = 33.6935\n",
      "Comparison loss = 7.0315\n",
      "Epoch no 18 : \n",
      "Classification loss = 34.1396\n",
      "Comparison loss = 6.9443\n",
      "Epoch no 19 : \n",
      "Classification loss = 33.6056\n",
      "Comparison loss = 6.5977\n",
      "Epoch no 20 : \n",
      "Classification loss = 32.9663\n",
      "Comparison loss = 6.4691\n",
      "Epoch no 21 : \n",
      "Classification loss = 32.8237\n",
      "Comparison loss = 6.2144\n",
      "Epoch no 22 : \n",
      "Classification loss = 32.9047\n",
      "Comparison loss = 6.7849\n",
      "Epoch no 23 : \n",
      "Classification loss = 33.3609\n",
      "Comparison loss = 6.6834\n",
      "Epoch no 24 : \n",
      "Classification loss = 34.2280\n",
      "Comparison loss = 5.5917\n",
      "Epoch no 25 : \n",
      "Classification loss = 34.9390\n",
      "Comparison loss = 6.0619\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 26.850% \n",
      "Comparison = 24.500%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 29.050% \n",
      "Comparison = 23.500%\u001b[0m\n",
      "RUN NO 3\n",
      "Epoch no 1 : \n",
      "Classification loss = 34.6816\n",
      "Comparison loss = 6.8937\n",
      "Epoch no 2 : \n",
      "Classification loss = 34.1557\n",
      "Comparison loss = 6.9118\n",
      "Epoch no 3 : \n",
      "Classification loss = 33.9529\n",
      "Comparison loss = 5.3641\n",
      "Epoch no 4 : \n",
      "Classification loss = 33.7040\n",
      "Comparison loss = 5.1076\n",
      "Epoch no 5 : \n",
      "Classification loss = 34.9030\n",
      "Comparison loss = 6.5841\n",
      "Epoch no 6 : \n",
      "Classification loss = 35.7581\n",
      "Comparison loss = 5.8341\n",
      "Epoch no 7 : \n",
      "Classification loss = 36.6699\n",
      "Comparison loss = 5.7995\n",
      "Epoch no 8 : \n",
      "Classification loss = 37.3819\n",
      "Comparison loss = 6.1119\n",
      "Epoch no 9 : \n",
      "Classification loss = 38.2022\n",
      "Comparison loss = 5.7409\n",
      "Epoch no 10 : \n",
      "Classification loss = 37.2453\n",
      "Comparison loss = 5.9679\n",
      "Epoch no 11 : \n",
      "Classification loss = 36.5716\n",
      "Comparison loss = 6.2050\n",
      "Epoch no 12 : \n",
      "Classification loss = 36.2502\n",
      "Comparison loss = 5.4619\n",
      "Epoch no 13 : \n",
      "Classification loss = 36.3084\n",
      "Comparison loss = 5.7403\n",
      "Epoch no 14 : \n",
      "Classification loss = 37.2633\n",
      "Comparison loss = 5.5785\n",
      "Epoch no 15 : \n",
      "Classification loss = 37.6689\n",
      "Comparison loss = 6.6817\n",
      "Epoch no 16 : \n",
      "Classification loss = 37.1967\n",
      "Comparison loss = 6.3775\n",
      "Epoch no 17 : \n",
      "Classification loss = 36.6505\n",
      "Comparison loss = 6.2789\n",
      "Epoch no 18 : \n",
      "Classification loss = 35.3945\n",
      "Comparison loss = 5.6168\n",
      "Epoch no 19 : \n",
      "Classification loss = 35.3209\n",
      "Comparison loss = 5.4014\n",
      "Epoch no 20 : \n",
      "Classification loss = 35.0899\n",
      "Comparison loss = 4.9467\n",
      "Epoch no 21 : \n",
      "Classification loss = 34.6625\n",
      "Comparison loss = 4.5996\n",
      "Epoch no 22 : \n",
      "Classification loss = 35.6212\n",
      "Comparison loss = 4.7128\n",
      "Epoch no 23 : \n",
      "Classification loss = 36.4714\n",
      "Comparison loss = 5.0544\n",
      "Epoch no 24 : \n",
      "Classification loss = 35.4854\n",
      "Comparison loss = 4.6618\n",
      "Epoch no 25 : \n",
      "Classification loss = 35.1349\n",
      "Comparison loss = 4.3717\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 29.250% \n",
      "Comparison = 17.800%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 31.100% \n",
      "Comparison = 21.900%\u001b[0m\n",
      "RUN NO 4\n",
      "Epoch no 1 : \n",
      "Classification loss = 35.0898\n",
      "Comparison loss = 6.6118\n",
      "Epoch no 2 : \n",
      "Classification loss = 35.8933\n",
      "Comparison loss = 6.5614\n",
      "Epoch no 3 : \n",
      "Classification loss = 37.1851\n",
      "Comparison loss = 7.1502\n",
      "Epoch no 4 : \n",
      "Classification loss = 37.0151\n",
      "Comparison loss = 6.8555\n",
      "Epoch no 5 : \n",
      "Classification loss = 36.2146\n",
      "Comparison loss = 6.4428\n",
      "Epoch no 6 : \n",
      "Classification loss = 35.5997\n",
      "Comparison loss = 6.4983\n",
      "Epoch no 7 : \n",
      "Classification loss = 35.6526\n",
      "Comparison loss = 6.9186\n",
      "Epoch no 8 : \n",
      "Classification loss = 35.9372\n",
      "Comparison loss = 6.9270\n",
      "Epoch no 9 : \n",
      "Classification loss = 36.0720\n",
      "Comparison loss = 6.9169\n",
      "Epoch no 10 : \n",
      "Classification loss = 36.0963\n",
      "Comparison loss = 6.9029\n",
      "Epoch no 11 : \n",
      "Classification loss = 34.7494\n",
      "Comparison loss = 6.8922\n",
      "Epoch no 12 : \n",
      "Classification loss = 35.2331\n",
      "Comparison loss = 6.8859\n",
      "Epoch no 13 : \n",
      "Classification loss = 36.8351\n",
      "Comparison loss = 6.8828\n",
      "Epoch no 14 : \n",
      "Classification loss = 37.1544\n",
      "Comparison loss = 6.8815\n",
      "Epoch no 15 : \n",
      "Classification loss = 36.3679\n",
      "Comparison loss = 6.8810\n",
      "Epoch no 16 : \n",
      "Classification loss = 35.4718\n",
      "Comparison loss = 6.8809\n",
      "Epoch no 17 : \n",
      "Classification loss = 35.4925\n",
      "Comparison loss = 6.8810\n",
      "Epoch no 18 : \n",
      "Classification loss = 35.6792\n",
      "Comparison loss = 6.8811\n",
      "Epoch no 19 : \n",
      "Classification loss = 36.9578\n",
      "Comparison loss = 6.8812\n",
      "Epoch no 20 : \n",
      "Classification loss = 37.4599\n",
      "Comparison loss = 6.8812\n",
      "Epoch no 21 : \n",
      "Classification loss = 37.7441\n",
      "Comparison loss = 6.8813\n",
      "Epoch no 22 : \n",
      "Classification loss = 38.0518\n",
      "Comparison loss = 6.8813\n",
      "Epoch no 23 : \n",
      "Classification loss = 38.1423\n",
      "Comparison loss = 6.8813\n",
      "Epoch no 24 : \n",
      "Classification loss = 38.0093\n",
      "Comparison loss = 6.8813\n",
      "Epoch no 25 : \n",
      "Classification loss = 38.5944\n",
      "Comparison loss = 6.8813\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 48.300% \n",
      "Comparison = 44.900%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 47.350% \n",
      "Comparison = 47.400%\u001b[0m\n",
      "RUN NO 5\n",
      "Epoch no 1 : \n",
      "Classification loss = 38.5190\n",
      "Comparison loss = 6.8737\n",
      "Epoch no 2 : \n",
      "Classification loss = 38.4588\n",
      "Comparison loss = 7.1009\n",
      "Epoch no 3 : \n",
      "Classification loss = 37.8949\n",
      "Comparison loss = 6.5444\n",
      "Epoch no 4 : \n",
      "Classification loss = 37.5822\n",
      "Comparison loss = 6.4170\n",
      "Epoch no 5 : \n",
      "Classification loss = 37.2754\n",
      "Comparison loss = 6.5508\n",
      "Epoch no 6 : \n",
      "Classification loss = 36.9438\n",
      "Comparison loss = 6.6916\n",
      "Epoch no 7 : \n",
      "Classification loss = 37.1143\n",
      "Comparison loss = 6.4115\n",
      "Epoch no 8 : \n",
      "Classification loss = 37.5026\n",
      "Comparison loss = 6.7113\n",
      "Epoch no 9 : \n",
      "Classification loss = 37.8934\n",
      "Comparison loss = 7.0824\n",
      "Epoch no 10 : \n",
      "Classification loss = 37.3371\n",
      "Comparison loss = 6.7866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch no 11 : \n",
      "Classification loss = 37.3713\n",
      "Comparison loss = 6.1931\n",
      "Epoch no 12 : \n",
      "Classification loss = 37.4828\n",
      "Comparison loss = 5.5450\n",
      "Epoch no 13 : \n",
      "Classification loss = 37.5323\n",
      "Comparison loss = 5.9105\n",
      "Epoch no 14 : \n",
      "Classification loss = 37.3483\n",
      "Comparison loss = 6.6708\n",
      "Epoch no 15 : \n",
      "Classification loss = 36.3626\n",
      "Comparison loss = 6.4771\n",
      "Epoch no 16 : \n",
      "Classification loss = 34.8092\n",
      "Comparison loss = 5.5069\n",
      "Epoch no 17 : \n",
      "Classification loss = 33.9828\n",
      "Comparison loss = 5.4743\n",
      "Epoch no 18 : \n",
      "Classification loss = 33.8813\n",
      "Comparison loss = 6.1820\n",
      "Epoch no 19 : \n",
      "Classification loss = 33.5604\n",
      "Comparison loss = 5.4217\n",
      "Epoch no 20 : \n",
      "Classification loss = 34.5177\n",
      "Comparison loss = 4.6038\n",
      "Epoch no 21 : \n",
      "Classification loss = 36.0171\n",
      "Comparison loss = 4.9785\n",
      "Epoch no 22 : \n",
      "Classification loss = 36.9554\n",
      "Comparison loss = 6.3818\n",
      "Epoch no 23 : \n",
      "Classification loss = 35.7679\n",
      "Comparison loss = 6.2633\n",
      "Epoch no 24 : \n",
      "Classification loss = 36.4020\n",
      "Comparison loss = 5.8962\n",
      "Epoch no 25 : \n",
      "Classification loss = 37.1225\n",
      "Comparison loss = 5.6689\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 39.900% \n",
      "Comparison = 31.200%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 41.150% \n",
      "Comparison = 33.200%\u001b[0m\n",
      "RUN NO 6\n",
      "Epoch no 1 : \n",
      "Classification loss = 36.4550\n",
      "Comparison loss = 6.8708\n",
      "Epoch no 2 : \n",
      "Classification loss = 34.8059\n",
      "Comparison loss = 6.8541\n",
      "Epoch no 3 : \n",
      "Classification loss = 34.3226\n",
      "Comparison loss = 5.7924\n",
      "Epoch no 4 : \n",
      "Classification loss = 34.4496\n",
      "Comparison loss = 6.0407\n",
      "Epoch no 5 : \n",
      "Classification loss = 34.9724\n",
      "Comparison loss = 7.6792\n",
      "Epoch no 6 : \n",
      "Classification loss = 36.2541\n",
      "Comparison loss = 6.7323\n",
      "Epoch no 7 : \n",
      "Classification loss = 36.5719\n",
      "Comparison loss = 6.8693\n",
      "Epoch no 8 : \n",
      "Classification loss = 36.3918\n",
      "Comparison loss = 6.7351\n",
      "Epoch no 9 : \n",
      "Classification loss = 36.1529\n",
      "Comparison loss = 6.3704\n",
      "Epoch no 10 : \n",
      "Classification loss = 35.8926\n",
      "Comparison loss = 5.8415\n",
      "Epoch no 11 : \n",
      "Classification loss = 35.9630\n",
      "Comparison loss = 5.7914\n",
      "Epoch no 12 : \n",
      "Classification loss = 35.2909\n",
      "Comparison loss = 5.5924\n",
      "Epoch no 13 : \n",
      "Classification loss = 35.2433\n",
      "Comparison loss = 5.6256\n",
      "Epoch no 14 : \n",
      "Classification loss = 35.7269\n",
      "Comparison loss = 5.8948\n",
      "Epoch no 15 : \n",
      "Classification loss = 35.9227\n",
      "Comparison loss = 5.6954\n",
      "Epoch no 16 : \n",
      "Classification loss = 36.1038\n",
      "Comparison loss = 5.8212\n",
      "Epoch no 17 : \n",
      "Classification loss = 35.8827\n",
      "Comparison loss = 5.7354\n",
      "Epoch no 18 : \n",
      "Classification loss = 35.3898\n",
      "Comparison loss = 5.6553\n",
      "Epoch no 19 : \n",
      "Classification loss = 34.5827\n",
      "Comparison loss = 5.4898\n",
      "Epoch no 20 : \n",
      "Classification loss = 34.6606\n",
      "Comparison loss = 5.3330\n",
      "Epoch no 21 : \n",
      "Classification loss = 34.1988\n",
      "Comparison loss = 5.1829\n",
      "Epoch no 22 : \n",
      "Classification loss = 35.0529\n",
      "Comparison loss = 5.6274\n",
      "Epoch no 23 : \n",
      "Classification loss = 36.1888\n",
      "Comparison loss = 5.7300\n",
      "Epoch no 24 : \n",
      "Classification loss = 38.0129\n",
      "Comparison loss = 6.1067\n",
      "Epoch no 25 : \n",
      "Classification loss = 38.7339\n",
      "Comparison loss = 6.2215\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 46.700% \n",
      "Comparison = 31.300%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 46.400% \n",
      "Comparison = 34.300%\u001b[0m\n",
      "RUN NO 7\n",
      "Epoch no 1 : \n",
      "Classification loss = 37.8931\n",
      "Comparison loss = 6.7566\n",
      "Epoch no 2 : \n",
      "Classification loss = 37.7424\n",
      "Comparison loss = 6.5123\n",
      "Epoch no 3 : \n",
      "Classification loss = 37.1396\n",
      "Comparison loss = 7.1360\n",
      "Epoch no 4 : \n",
      "Classification loss = 36.7634\n",
      "Comparison loss = 6.8795\n",
      "Epoch no 5 : \n",
      "Classification loss = 36.5745\n",
      "Comparison loss = 6.7707\n",
      "Epoch no 6 : \n",
      "Classification loss = 36.4726\n",
      "Comparison loss = 6.4534\n",
      "Epoch no 7 : \n",
      "Classification loss = 36.3212\n",
      "Comparison loss = 6.4316\n",
      "Epoch no 8 : \n",
      "Classification loss = 35.5102\n",
      "Comparison loss = 6.8685\n",
      "Epoch no 9 : \n",
      "Classification loss = 34.7928\n",
      "Comparison loss = 6.9235\n",
      "Epoch no 10 : \n",
      "Classification loss = 34.5932\n",
      "Comparison loss = 6.9142\n",
      "Epoch no 11 : \n",
      "Classification loss = 33.8129\n",
      "Comparison loss = 6.9004\n",
      "Epoch no 12 : \n",
      "Classification loss = 33.3731\n",
      "Comparison loss = 6.8897\n",
      "Epoch no 13 : \n",
      "Classification loss = 33.4629\n",
      "Comparison loss = 6.8837\n",
      "Epoch no 14 : \n",
      "Classification loss = 33.4432\n",
      "Comparison loss = 6.8811\n",
      "Epoch no 15 : \n",
      "Classification loss = 33.3931\n",
      "Comparison loss = 6.8804\n",
      "Epoch no 16 : \n",
      "Classification loss = 33.4336\n",
      "Comparison loss = 6.8805\n",
      "Epoch no 17 : \n",
      "Classification loss = 33.5131\n",
      "Comparison loss = 6.8808\n",
      "Epoch no 18 : \n",
      "Classification loss = 33.3721\n",
      "Comparison loss = 6.8811\n",
      "Epoch no 19 : \n",
      "Classification loss = 33.3762\n",
      "Comparison loss = 6.8812\n",
      "Epoch no 20 : \n",
      "Classification loss = 33.3155\n",
      "Comparison loss = 6.8812\n",
      "Epoch no 21 : \n",
      "Classification loss = 33.6791\n",
      "Comparison loss = 6.8809\n",
      "Epoch no 22 : \n",
      "Classification loss = 33.5722\n",
      "Comparison loss = 6.8743\n",
      "Epoch no 23 : \n",
      "Classification loss = 33.4527\n",
      "Comparison loss = 6.7545\n",
      "Epoch no 24 : \n",
      "Classification loss = 33.4534\n",
      "Comparison loss = 5.9020\n",
      "Epoch no 25 : \n",
      "Classification loss = 33.3005\n",
      "Comparison loss = 4.4327\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 20.300% \n",
      "Comparison = 24.600%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 22.000% \n",
      "Comparison = 26.700%\u001b[0m\n",
      "RUN NO 8\n",
      "Epoch no 1 : \n",
      "Classification loss = 33.0702\n",
      "Comparison loss = 6.6096\n",
      "Epoch no 2 : \n",
      "Classification loss = 33.0620\n",
      "Comparison loss = 5.7459\n",
      "Epoch no 3 : \n",
      "Classification loss = 33.2630\n",
      "Comparison loss = 6.7441\n",
      "Epoch no 4 : \n",
      "Classification loss = 33.4130\n",
      "Comparison loss = 6.8917\n",
      "Epoch no 5 : \n",
      "Classification loss = 33.3263\n",
      "Comparison loss = 6.6043\n",
      "Epoch no 6 : \n",
      "Classification loss = 33.3339\n",
      "Comparison loss = 5.2716\n",
      "Epoch no 7 : \n",
      "Classification loss = 33.8124\n",
      "Comparison loss = 4.2162\n",
      "Epoch no 8 : \n",
      "Classification loss = 34.7531\n",
      "Comparison loss = 6.1729\n",
      "Epoch no 9 : \n",
      "Classification loss = 35.3725\n",
      "Comparison loss = 6.3806\n",
      "Epoch no 10 : \n",
      "Classification loss = 35.4030\n",
      "Comparison loss = 6.3849\n",
      "Epoch no 11 : \n",
      "Classification loss = 35.1223\n",
      "Comparison loss = 5.5229\n",
      "Epoch no 12 : \n",
      "Classification loss = 34.3160\n",
      "Comparison loss = 5.2023\n",
      "Epoch no 13 : \n",
      "Classification loss = 34.2141\n",
      "Comparison loss = 5.1239\n",
      "Epoch no 14 : \n",
      "Classification loss = 34.2213\n",
      "Comparison loss = 4.6220\n",
      "Epoch no 15 : \n",
      "Classification loss = 34.1328\n",
      "Comparison loss = 4.2403\n",
      "Epoch no 16 : \n",
      "Classification loss = 34.0516\n",
      "Comparison loss = 4.1137\n",
      "Epoch no 17 : \n",
      "Classification loss = 34.0730\n",
      "Comparison loss = 4.0361\n",
      "Epoch no 18 : \n",
      "Classification loss = 34.1830\n",
      "Comparison loss = 4.3211\n",
      "Epoch no 19 : \n",
      "Classification loss = 34.2427\n",
      "Comparison loss = 3.8818\n",
      "Epoch no 20 : \n",
      "Classification loss = 34.0822\n",
      "Comparison loss = 3.6294\n",
      "Epoch no 21 : \n",
      "Classification loss = 33.6862\n",
      "Comparison loss = 3.5355\n",
      "Epoch no 22 : \n",
      "Classification loss = 34.0751\n",
      "Comparison loss = 3.7211\n",
      "Epoch no 23 : \n",
      "Classification loss = 34.5225\n",
      "Comparison loss = 4.5852\n",
      "Epoch no 24 : \n",
      "Classification loss = 35.0542\n",
      "Comparison loss = 4.4480\n",
      "Epoch no 25 : \n",
      "Classification loss = 34.9718\n",
      "Comparison loss = 4.3742\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 30.700% \n",
      "Comparison = 16.000%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 35.100% \n",
      "Comparison = 18.400%\u001b[0m\n",
      "RUN NO 9\n",
      "Epoch no 1 : \n",
      "Classification loss = 35.1709\n",
      "Comparison loss = 6.7158\n",
      "Epoch no 2 : \n",
      "Classification loss = 34.8434\n",
      "Comparison loss = 6.2586\n",
      "Epoch no 3 : \n",
      "Classification loss = 34.8625\n",
      "Comparison loss = 6.4881\n",
      "Epoch no 4 : \n",
      "Classification loss = 34.5641\n",
      "Comparison loss = 6.3507\n",
      "Epoch no 5 : \n",
      "Classification loss = 34.3838\n",
      "Comparison loss = 6.2630\n",
      "Epoch no 6 : \n",
      "Classification loss = 34.2227\n",
      "Comparison loss = 6.6191\n",
      "Epoch no 7 : \n",
      "Classification loss = 34.2437\n",
      "Comparison loss = 6.7972\n",
      "Epoch no 8 : \n",
      "Classification loss = 34.4130\n",
      "Comparison loss = 6.6183\n",
      "Epoch no 9 : \n",
      "Classification loss = 34.6931\n",
      "Comparison loss = 5.9762\n",
      "Epoch no 10 : \n",
      "Classification loss = 34.6331\n",
      "Comparison loss = 5.6882\n",
      "Epoch no 11 : \n",
      "Classification loss = 34.5628\n",
      "Comparison loss = 5.9754\n",
      "Epoch no 12 : \n",
      "Classification loss = 34.4030\n",
      "Comparison loss = 6.1107\n",
      "Epoch no 13 : \n",
      "Classification loss = 34.3126\n",
      "Comparison loss = 5.7404\n",
      "Epoch no 14 : \n",
      "Classification loss = 34.3730\n",
      "Comparison loss = 5.3017\n",
      "Epoch no 15 : \n",
      "Classification loss = 34.3975\n",
      "Comparison loss = 5.0019\n",
      "Epoch no 16 : \n",
      "Classification loss = 34.2806\n",
      "Comparison loss = 4.7521\n",
      "Epoch no 17 : \n",
      "Classification loss = 33.6730\n",
      "Comparison loss = 3.9881\n",
      "Epoch no 18 : \n",
      "Classification loss = 33.5029\n",
      "Comparison loss = 4.3852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch no 19 : \n",
      "Classification loss = 33.4629\n",
      "Comparison loss = 4.2056\n",
      "Epoch no 20 : \n",
      "Classification loss = 33.8077\n",
      "Comparison loss = 4.9760\n",
      "Epoch no 21 : \n",
      "Classification loss = 35.5554\n",
      "Comparison loss = 6.6357\n",
      "Epoch no 22 : \n",
      "Classification loss = 37.3430\n",
      "Comparison loss = 6.4251\n",
      "Epoch no 23 : \n",
      "Classification loss = 38.1728\n",
      "Comparison loss = 6.3998\n",
      "Epoch no 24 : \n",
      "Classification loss = 38.1448\n",
      "Comparison loss = 6.0895\n",
      "Epoch no 25 : \n",
      "Classification loss = 39.1035\n",
      "Comparison loss = 6.0847\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 52.550% \n",
      "Comparison = 29.300%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 51.650% \n",
      "Comparison = 32.700%\u001b[0m\n",
      "RUN NO 10\n",
      "Epoch no 1 : \n",
      "Classification loss = 39.5408\n",
      "Comparison loss = 7.0020\n",
      "Epoch no 2 : \n",
      "Classification loss = 39.4811\n",
      "Comparison loss = 6.9031\n",
      "Epoch no 3 : \n",
      "Classification loss = 39.0628\n",
      "Comparison loss = 6.8917\n",
      "Epoch no 4 : \n",
      "Classification loss = 38.9148\n",
      "Comparison loss = 6.8518\n",
      "Epoch no 5 : \n",
      "Classification loss = 38.5524\n",
      "Comparison loss = 6.2801\n",
      "Epoch no 6 : \n",
      "Classification loss = 38.1129\n",
      "Comparison loss = 6.4978\n",
      "Epoch no 7 : \n",
      "Classification loss = 37.9854\n",
      "Comparison loss = 6.8079\n",
      "Epoch no 8 : \n",
      "Classification loss = 37.5735\n",
      "Comparison loss = 6.6300\n",
      "Epoch no 9 : \n",
      "Classification loss = 36.4428\n",
      "Comparison loss = 6.5767\n",
      "Epoch no 10 : \n",
      "Classification loss = 36.1230\n",
      "Comparison loss = 6.1824\n",
      "Epoch no 11 : \n",
      "Classification loss = 36.0530\n",
      "Comparison loss = 6.6758\n",
      "Epoch no 12 : \n",
      "Classification loss = 35.9323\n",
      "Comparison loss = 6.0398\n",
      "Epoch no 13 : \n",
      "Classification loss = 35.8628\n",
      "Comparison loss = 4.9278\n",
      "Epoch no 14 : \n",
      "Classification loss = 36.0029\n",
      "Comparison loss = 5.5937\n",
      "Epoch no 15 : \n",
      "Classification loss = 36.1134\n",
      "Comparison loss = 5.8973\n",
      "Epoch no 16 : \n",
      "Classification loss = 36.3536\n",
      "Comparison loss = 6.9215\n",
      "Epoch no 17 : \n",
      "Classification loss = 37.0436\n",
      "Comparison loss = 6.1408\n",
      "Epoch no 18 : \n",
      "Classification loss = 37.2603\n",
      "Comparison loss = 5.7879\n",
      "Epoch no 19 : \n",
      "Classification loss = 37.5044\n",
      "Comparison loss = 4.9872\n",
      "Epoch no 20 : \n",
      "Classification loss = 37.5246\n",
      "Comparison loss = 5.2759\n",
      "Epoch no 21 : \n",
      "Classification loss = 37.4829\n",
      "Comparison loss = 6.1661\n",
      "Epoch no 22 : \n",
      "Classification loss = 37.5830\n",
      "Comparison loss = 6.2236\n",
      "Epoch no 23 : \n",
      "Classification loss = 37.6130\n",
      "Comparison loss = 6.1533\n",
      "Epoch no 24 : \n",
      "Classification loss = 37.5931\n",
      "Comparison loss = 5.8965\n",
      "Epoch no 25 : \n",
      "Classification loss = 37.5042\n",
      "Comparison loss = 5.3318\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 39.600% \n",
      "Comparison = 23.400%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 40.150% \n",
      "Comparison = 26.100%\u001b[0m\n",
      "Final error for train batch : 26.12±8.5773\n",
      "Final error for test batch : 28.41±8.7180\n",
      "RUN NO 1\n",
      "Epoch no 1 : \n",
      "Classification loss = 29.8359\n",
      "Comparison loss = 6.8477\n",
      "Epoch no 2 : \n",
      "Classification loss = 32.1320\n",
      "Comparison loss = 6.4935\n",
      "Epoch no 3 : \n",
      "Classification loss = 32.9156\n",
      "Comparison loss = 6.2889\n",
      "Epoch no 4 : \n",
      "Classification loss = 35.6613\n",
      "Comparison loss = 6.9509\n",
      "Epoch no 5 : \n",
      "Classification loss = 35.6347\n",
      "Comparison loss = 6.9265\n",
      "Epoch no 6 : \n",
      "Classification loss = 35.0842\n",
      "Comparison loss = 6.8434\n",
      "Epoch no 7 : \n",
      "Classification loss = 35.4921\n",
      "Comparison loss = 6.7335\n",
      "Epoch no 8 : \n",
      "Classification loss = 34.3501\n",
      "Comparison loss = 5.9610\n",
      "Epoch no 9 : \n",
      "Classification loss = 33.8401\n",
      "Comparison loss = 4.4868\n",
      "Epoch no 10 : \n",
      "Classification loss = 33.1678\n",
      "Comparison loss = 5.3867\n",
      "Epoch no 11 : \n",
      "Classification loss = 32.3105\n",
      "Comparison loss = 5.0539\n",
      "Epoch no 12 : \n",
      "Classification loss = 32.8913\n",
      "Comparison loss = 4.1778\n",
      "Epoch no 13 : \n",
      "Classification loss = 35.1834\n",
      "Comparison loss = 4.9188\n",
      "Epoch no 14 : \n",
      "Classification loss = 35.0362\n",
      "Comparison loss = 4.6234\n",
      "Epoch no 15 : \n",
      "Classification loss = 35.6574\n",
      "Comparison loss = 4.8712\n",
      "Epoch no 16 : \n",
      "Classification loss = 36.3901\n",
      "Comparison loss = 4.6306\n",
      "Epoch no 17 : \n",
      "Classification loss = 36.4866\n",
      "Comparison loss = 5.1635\n",
      "Epoch no 18 : \n",
      "Classification loss = 37.5516\n",
      "Comparison loss = 5.5492\n",
      "Epoch no 19 : \n",
      "Classification loss = 39.8892\n",
      "Comparison loss = 6.2016\n",
      "Epoch no 20 : \n",
      "Classification loss = 40.0357\n",
      "Comparison loss = 5.6949\n",
      "Epoch no 21 : \n",
      "Classification loss = 39.0470\n",
      "Comparison loss = 5.0276\n",
      "Epoch no 22 : \n",
      "Classification loss = 38.8579\n",
      "Comparison loss = 5.1776\n",
      "Epoch no 23 : \n",
      "Classification loss = 39.4385\n",
      "Comparison loss = 5.5706\n",
      "Epoch no 24 : \n",
      "Classification loss = 37.9509\n",
      "Comparison loss = 4.9887\n",
      "Epoch no 25 : \n",
      "Classification loss = 36.4378\n",
      "Comparison loss = 5.3868\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 34.650% \n",
      "Comparison = 25.200%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 34.550% \n",
      "Comparison = 28.700%\u001b[0m\n",
      "RUN NO 2\n",
      "Epoch no 1 : \n",
      "Classification loss = 36.3110\n",
      "Comparison loss = 6.8115\n",
      "Epoch no 2 : \n",
      "Classification loss = 36.7055\n",
      "Comparison loss = 6.8905\n",
      "Epoch no 3 : \n",
      "Classification loss = 37.7479\n",
      "Comparison loss = 6.3331\n",
      "Epoch no 4 : \n",
      "Classification loss = 37.7361\n",
      "Comparison loss = 6.5054\n",
      "Epoch no 5 : \n",
      "Classification loss = 37.9811\n",
      "Comparison loss = 6.5336\n",
      "Epoch no 6 : \n",
      "Classification loss = 38.0569\n",
      "Comparison loss = 5.6081\n",
      "Epoch no 7 : \n",
      "Classification loss = 37.2065\n",
      "Comparison loss = 5.2290\n",
      "Epoch no 8 : \n",
      "Classification loss = 36.7619\n",
      "Comparison loss = 4.9389\n",
      "Epoch no 9 : \n",
      "Classification loss = 36.2554\n",
      "Comparison loss = 5.9001\n",
      "Epoch no 10 : \n",
      "Classification loss = 39.1214\n",
      "Comparison loss = 6.5279\n",
      "Epoch no 11 : \n",
      "Classification loss = 38.9602\n",
      "Comparison loss = 6.0286\n",
      "Epoch no 12 : \n",
      "Classification loss = 35.5889\n",
      "Comparison loss = 4.8725\n",
      "Epoch no 13 : \n",
      "Classification loss = 36.1917\n",
      "Comparison loss = 6.1068\n",
      "Epoch no 14 : \n",
      "Classification loss = 37.9864\n",
      "Comparison loss = 6.2044\n",
      "Epoch no 15 : \n",
      "Classification loss = 38.3267\n",
      "Comparison loss = 6.1429\n",
      "Epoch no 16 : \n",
      "Classification loss = 38.6143\n",
      "Comparison loss = 6.3308\n",
      "Epoch no 17 : \n",
      "Classification loss = 39.1332\n",
      "Comparison loss = 6.3976\n",
      "Epoch no 18 : \n",
      "Classification loss = 39.1378\n",
      "Comparison loss = 6.5117\n",
      "Epoch no 19 : \n",
      "Classification loss = 39.3674\n",
      "Comparison loss = 6.6125\n",
      "Epoch no 20 : \n",
      "Classification loss = 39.3350\n",
      "Comparison loss = 6.3208\n",
      "Epoch no 21 : \n",
      "Classification loss = 39.2190\n",
      "Comparison loss = 5.9615\n",
      "Epoch no 22 : \n",
      "Classification loss = 37.9635\n",
      "Comparison loss = 5.6628\n",
      "Epoch no 23 : \n",
      "Classification loss = 39.6203\n",
      "Comparison loss = 5.6403\n",
      "Epoch no 24 : \n",
      "Classification loss = 41.3335\n",
      "Comparison loss = 6.2797\n",
      "Epoch no 25 : \n",
      "Classification loss = 41.8874\n",
      "Comparison loss = 6.2885\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 58.250% \n",
      "Comparison = 28.200%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 59.750% \n",
      "Comparison = 30.200%\u001b[0m\n",
      "RUN NO 3\n",
      "Epoch no 1 : \n",
      "Classification loss = 41.0711\n",
      "Comparison loss = 6.8816\n",
      "Epoch no 2 : \n",
      "Classification loss = 40.5537\n",
      "Comparison loss = 6.9073\n",
      "Epoch no 3 : \n",
      "Classification loss = 39.2986\n",
      "Comparison loss = 6.8518\n",
      "Epoch no 4 : \n",
      "Classification loss = 39.2436\n",
      "Comparison loss = 6.8219\n",
      "Epoch no 5 : \n",
      "Classification loss = 38.9834\n",
      "Comparison loss = 6.5172\n",
      "Epoch no 6 : \n",
      "Classification loss = 39.0721\n",
      "Comparison loss = 6.6945\n",
      "Epoch no 7 : \n",
      "Classification loss = 39.4626\n",
      "Comparison loss = 6.3956\n",
      "Epoch no 8 : \n",
      "Classification loss = 39.3217\n",
      "Comparison loss = 6.2636\n",
      "Epoch no 9 : \n",
      "Classification loss = 38.4322\n",
      "Comparison loss = 6.1496\n",
      "Epoch no 10 : \n",
      "Classification loss = 38.4832\n",
      "Comparison loss = 6.1439\n",
      "Epoch no 11 : \n",
      "Classification loss = 38.6328\n",
      "Comparison loss = 6.1418\n",
      "Epoch no 12 : \n",
      "Classification loss = 38.6235\n",
      "Comparison loss = 6.1041\n",
      "Epoch no 13 : \n",
      "Classification loss = 39.2985\n",
      "Comparison loss = 6.2968\n",
      "Epoch no 14 : \n",
      "Classification loss = 40.3529\n",
      "Comparison loss = 7.3003\n",
      "Epoch no 15 : \n",
      "Classification loss = 40.1592\n",
      "Comparison loss = 6.9387\n",
      "Epoch no 16 : \n",
      "Classification loss = 38.8720\n",
      "Comparison loss = 6.7334\n",
      "Epoch no 17 : \n",
      "Classification loss = 38.5521\n",
      "Comparison loss = 6.6022\n",
      "Epoch no 18 : \n",
      "Classification loss = 38.5182\n",
      "Comparison loss = 6.5214\n",
      "Epoch no 19 : \n",
      "Classification loss = 38.7181\n",
      "Comparison loss = 6.5212\n",
      "Epoch no 20 : \n",
      "Classification loss = 38.6885\n",
      "Comparison loss = 6.2406\n",
      "Epoch no 21 : \n",
      "Classification loss = 39.1026\n",
      "Comparison loss = 6.1602\n",
      "Epoch no 22 : \n",
      "Classification loss = 39.2725\n",
      "Comparison loss = 6.2347\n",
      "Epoch no 23 : \n",
      "Classification loss = 39.3234\n",
      "Comparison loss = 6.2037\n",
      "Epoch no 24 : \n",
      "Classification loss = 39.6603\n",
      "Comparison loss = 6.3237\n",
      "Epoch no 25 : \n",
      "Classification loss = 41.4426\n",
      "Comparison loss = 6.6442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[3;37;41mError in training: \n",
      "Classification = 64.400% \n",
      "Comparison = 42.300%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 64.600% \n",
      "Comparison = 43.200%\u001b[0m\n",
      "RUN NO 4\n",
      "Epoch no 1 : \n",
      "Classification loss = 42.1534\n",
      "Comparison loss = 6.9558\n",
      "Epoch no 2 : \n",
      "Classification loss = 41.6461\n",
      "Comparison loss = 6.9301\n",
      "Epoch no 3 : \n",
      "Classification loss = 41.9730\n",
      "Comparison loss = 6.9035\n",
      "Epoch no 4 : \n",
      "Classification loss = 42.0515\n",
      "Comparison loss = 6.8851\n",
      "Epoch no 5 : \n",
      "Classification loss = 41.4446\n",
      "Comparison loss = 6.8031\n",
      "Epoch no 6 : \n",
      "Classification loss = 41.4624\n",
      "Comparison loss = 6.4649\n",
      "Epoch no 7 : \n",
      "Classification loss = 41.7949\n",
      "Comparison loss = 6.4804\n",
      "Epoch no 8 : \n",
      "Classification loss = 41.8384\n",
      "Comparison loss = 6.4346\n",
      "Epoch no 9 : \n",
      "Classification loss = 41.7872\n",
      "Comparison loss = 6.5362\n",
      "Epoch no 10 : \n",
      "Classification loss = 41.7929\n",
      "Comparison loss = 6.4447\n",
      "Epoch no 11 : \n",
      "Classification loss = 41.9193\n",
      "Comparison loss = 6.2437\n",
      "Epoch no 12 : \n",
      "Classification loss = 42.1929\n",
      "Comparison loss = 6.3036\n",
      "Epoch no 13 : \n",
      "Classification loss = 42.6508\n",
      "Comparison loss = 6.3110\n",
      "Epoch no 14 : \n",
      "Classification loss = 42.1540\n",
      "Comparison loss = 6.2023\n",
      "Epoch no 15 : \n",
      "Classification loss = 41.5329\n",
      "Comparison loss = 5.9324\n",
      "Epoch no 16 : \n",
      "Classification loss = 41.4130\n",
      "Comparison loss = 6.1642\n",
      "Epoch no 17 : \n",
      "Classification loss = 41.4131\n",
      "Comparison loss = 6.2964\n",
      "Epoch no 18 : \n",
      "Classification loss = 41.1337\n",
      "Comparison loss = 6.0461\n",
      "Epoch no 19 : \n",
      "Classification loss = 40.8173\n",
      "Comparison loss = 5.7103\n",
      "Epoch no 20 : \n",
      "Classification loss = 40.8727\n",
      "Comparison loss = 6.0542\n",
      "Epoch no 21 : \n",
      "Classification loss = 41.1230\n",
      "Comparison loss = 6.2694\n",
      "Epoch no 22 : \n",
      "Classification loss = 41.2230\n",
      "Comparison loss = 5.9932\n",
      "Epoch no 23 : \n",
      "Classification loss = 41.2530\n",
      "Comparison loss = 5.8264\n",
      "Epoch no 24 : \n",
      "Classification loss = 41.2728\n",
      "Comparison loss = 5.9356\n",
      "Epoch no 25 : \n",
      "Classification loss = 41.2628\n",
      "Comparison loss = 5.6182\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 60.050% \n",
      "Comparison = 28.800%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 61.300% \n",
      "Comparison = 31.600%\u001b[0m\n",
      "RUN NO 5\n",
      "Epoch no 1 : \n",
      "Classification loss = 41.0029\n",
      "Comparison loss = 6.9458\n",
      "Epoch no 2 : \n",
      "Classification loss = 41.1930\n",
      "Comparison loss = 6.9138\n",
      "Epoch no 3 : \n",
      "Classification loss = 41.2824\n",
      "Comparison loss = 6.7451\n",
      "Epoch no 4 : \n",
      "Classification loss = 41.0830\n",
      "Comparison loss = 6.0328\n",
      "Epoch no 5 : \n",
      "Classification loss = 41.1531\n",
      "Comparison loss = 6.5200\n",
      "Epoch no 6 : \n",
      "Classification loss = 40.6914\n",
      "Comparison loss = 6.2387\n",
      "Epoch no 7 : \n",
      "Classification loss = 40.5333\n",
      "Comparison loss = 5.9276\n",
      "Epoch no 8 : \n",
      "Classification loss = 40.6083\n",
      "Comparison loss = 6.5693\n",
      "Epoch no 9 : \n",
      "Classification loss = 40.6929\n",
      "Comparison loss = 6.5699\n",
      "Epoch no 10 : \n",
      "Classification loss = 41.0529\n",
      "Comparison loss = 6.5368\n",
      "Epoch no 11 : \n",
      "Classification loss = 40.9883\n",
      "Comparison loss = 6.3845\n",
      "Epoch no 12 : \n",
      "Classification loss = 40.9208\n",
      "Comparison loss = 6.5312\n",
      "Epoch no 13 : \n",
      "Classification loss = 41.2634\n",
      "Comparison loss = 6.4747\n",
      "Epoch no 14 : \n",
      "Classification loss = 40.5044\n",
      "Comparison loss = 6.5773\n",
      "Epoch no 15 : \n",
      "Classification loss = 40.0129\n",
      "Comparison loss = 6.5874\n",
      "Epoch no 16 : \n",
      "Classification loss = 39.8929\n",
      "Comparison loss = 6.4019\n",
      "Epoch no 17 : \n",
      "Classification loss = 39.9129\n",
      "Comparison loss = 6.3524\n",
      "Epoch no 18 : \n",
      "Classification loss = 39.8722\n",
      "Comparison loss = 6.1111\n",
      "Epoch no 19 : \n",
      "Classification loss = 39.7927\n",
      "Comparison loss = 6.0305\n",
      "Epoch no 20 : \n",
      "Classification loss = 39.8136\n",
      "Comparison loss = 6.0617\n",
      "Epoch no 21 : \n",
      "Classification loss = 40.0027\n",
      "Comparison loss = 5.9948\n",
      "Epoch no 22 : \n",
      "Classification loss = 40.1329\n",
      "Comparison loss = 6.0205\n",
      "Epoch no 23 : \n",
      "Classification loss = 40.1930\n",
      "Comparison loss = 6.2033\n",
      "Epoch no 24 : \n",
      "Classification loss = 40.3026\n",
      "Comparison loss = 5.7249\n",
      "Epoch no 25 : \n",
      "Classification loss = 40.3228\n",
      "Comparison loss = 5.7225\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 55.550% \n",
      "Comparison = 25.500%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 57.700% \n",
      "Comparison = 27.800%\u001b[0m\n",
      "RUN NO 6\n",
      "Epoch no 1 : \n",
      "Classification loss = 40.2725\n",
      "Comparison loss = 6.7831\n",
      "Epoch no 2 : \n",
      "Classification loss = 40.1925\n",
      "Comparison loss = 6.2935\n",
      "Epoch no 3 : \n",
      "Classification loss = 40.2528\n",
      "Comparison loss = 6.7951\n",
      "Epoch no 4 : \n",
      "Classification loss = 40.4630\n",
      "Comparison loss = 6.8005\n",
      "Epoch no 5 : \n",
      "Classification loss = 40.5276\n",
      "Comparison loss = 6.4241\n",
      "Epoch no 6 : \n",
      "Classification loss = 40.4226\n",
      "Comparison loss = 6.1534\n",
      "Epoch no 7 : \n",
      "Classification loss = 40.2048\n",
      "Comparison loss = 6.4530\n",
      "Epoch no 8 : \n",
      "Classification loss = 40.2328\n",
      "Comparison loss = 6.4110\n",
      "Epoch no 9 : \n",
      "Classification loss = 40.4925\n",
      "Comparison loss = 6.7363\n",
      "Epoch no 10 : \n",
      "Classification loss = 40.6030\n",
      "Comparison loss = 6.6564\n",
      "Epoch no 11 : \n",
      "Classification loss = 40.6218\n",
      "Comparison loss = 6.1905\n",
      "Epoch no 12 : \n",
      "Classification loss = 40.6630\n",
      "Comparison loss = 5.7772\n",
      "Epoch no 13 : \n",
      "Classification loss = 40.7928\n",
      "Comparison loss = 5.6015\n",
      "Epoch no 14 : \n",
      "Classification loss = 40.7330\n",
      "Comparison loss = 5.6100\n",
      "Epoch no 15 : \n",
      "Classification loss = 40.2702\n",
      "Comparison loss = 5.6828\n",
      "Epoch no 16 : \n",
      "Classification loss = 40.3628\n",
      "Comparison loss = 5.9686\n",
      "Epoch no 17 : \n",
      "Classification loss = 40.5230\n",
      "Comparison loss = 5.9415\n",
      "Epoch no 18 : \n",
      "Classification loss = 40.5428\n",
      "Comparison loss = 5.7948\n",
      "Epoch no 19 : \n",
      "Classification loss = 40.5429\n",
      "Comparison loss = 5.8539\n",
      "Epoch no 20 : \n",
      "Classification loss = 40.5228\n",
      "Comparison loss = 5.6495\n",
      "Epoch no 21 : \n",
      "Classification loss = 40.6329\n",
      "Comparison loss = 5.7864\n",
      "Epoch no 22 : \n",
      "Classification loss = 40.3582\n",
      "Comparison loss = 6.0043\n",
      "Epoch no 23 : \n",
      "Classification loss = 40.2726\n",
      "Comparison loss = 6.0590\n",
      "Epoch no 24 : \n",
      "Classification loss = 40.3830\n",
      "Comparison loss = 6.3347\n",
      "Epoch no 25 : \n",
      "Classification loss = 40.5899\n",
      "Comparison loss = 6.1767\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 56.650% \n",
      "Comparison = 30.100%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 57.050% \n",
      "Comparison = 30.500%\u001b[0m\n",
      "RUN NO 7\n",
      "Epoch no 1 : \n",
      "Classification loss = 40.5721\n",
      "Comparison loss = 6.9129\n",
      "Epoch no 2 : \n",
      "Classification loss = 40.5930\n",
      "Comparison loss = 6.8801\n",
      "Epoch no 3 : \n",
      "Classification loss = 41.0430\n",
      "Comparison loss = 6.7126\n",
      "Epoch no 4 : \n",
      "Classification loss = 41.2530\n",
      "Comparison loss = 6.6691\n",
      "Epoch no 5 : \n",
      "Classification loss = 41.1354\n",
      "Comparison loss = 6.5180\n",
      "Epoch no 6 : \n",
      "Classification loss = 40.7130\n",
      "Comparison loss = 6.2378\n",
      "Epoch no 7 : \n",
      "Classification loss = 40.7027\n",
      "Comparison loss = 6.3337\n",
      "Epoch no 8 : \n",
      "Classification loss = 40.9036\n",
      "Comparison loss = 6.2098\n",
      "Epoch no 9 : \n",
      "Classification loss = 40.9936\n",
      "Comparison loss = 6.4769\n",
      "Epoch no 10 : \n",
      "Classification loss = 41.3018\n",
      "Comparison loss = 6.1336\n",
      "Epoch no 11 : \n",
      "Classification loss = 41.4729\n",
      "Comparison loss = 6.0684\n",
      "Epoch no 12 : \n",
      "Classification loss = 41.5727\n",
      "Comparison loss = 6.0427\n",
      "Epoch no 13 : \n",
      "Classification loss = 41.6428\n",
      "Comparison loss = 5.9210\n",
      "Epoch no 14 : \n",
      "Classification loss = 41.6227\n",
      "Comparison loss = 5.9291\n",
      "Epoch no 15 : \n",
      "Classification loss = 41.6826\n",
      "Comparison loss = 6.1562\n",
      "Epoch no 16 : \n",
      "Classification loss = 41.6627\n",
      "Comparison loss = 5.8431\n",
      "Epoch no 17 : \n",
      "Classification loss = 41.9834\n",
      "Comparison loss = 6.3033\n",
      "Epoch no 18 : \n",
      "Classification loss = 43.0030\n",
      "Comparison loss = 6.6663\n",
      "Epoch no 19 : \n",
      "Classification loss = 42.9537\n",
      "Comparison loss = 6.5392\n",
      "Epoch no 20 : \n",
      "Classification loss = 42.1429\n",
      "Comparison loss = 6.2821\n",
      "Epoch no 21 : \n",
      "Classification loss = 41.9731\n",
      "Comparison loss = 6.1585\n",
      "Epoch no 22 : \n",
      "Classification loss = 41.8625\n",
      "Comparison loss = 5.8864\n",
      "Epoch no 23 : \n",
      "Classification loss = 41.7532\n",
      "Comparison loss = 6.0061\n",
      "Epoch no 24 : \n",
      "Classification loss = 41.4530\n",
      "Comparison loss = 5.7886\n",
      "Epoch no 25 : \n",
      "Classification loss = 41.2031\n",
      "Comparison loss = 5.8635\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 59.850% \n",
      "Comparison = 26.300%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 61.050% \n",
      "Comparison = 28.300%\u001b[0m\n",
      "RUN NO 8\n",
      "Epoch no 1 : \n",
      "Classification loss = 41.2527\n",
      "Comparison loss = 6.9126\n",
      "Epoch no 2 : \n",
      "Classification loss = 41.4036\n",
      "Comparison loss = 6.8934\n",
      "Epoch no 3 : \n",
      "Classification loss = 41.6330\n",
      "Comparison loss = 6.4180\n",
      "Epoch no 4 : \n",
      "Classification loss = 41.7530\n",
      "Comparison loss = 6.1451\n",
      "Epoch no 5 : \n",
      "Classification loss = 41.7530\n",
      "Comparison loss = 6.8151\n",
      "Epoch no 6 : \n",
      "Classification loss = 41.7827\n",
      "Comparison loss = 6.7543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch no 7 : \n",
      "Classification loss = 41.6930\n",
      "Comparison loss = 6.3490\n",
      "Epoch no 8 : \n",
      "Classification loss = 41.6930\n",
      "Comparison loss = 6.1188\n",
      "Epoch no 9 : \n",
      "Classification loss = 41.5305\n",
      "Comparison loss = 6.1906\n",
      "Epoch no 10 : \n",
      "Classification loss = 41.5527\n",
      "Comparison loss = 6.6978\n",
      "Epoch no 11 : \n",
      "Classification loss = 42.2532\n",
      "Comparison loss = 6.5431\n",
      "Epoch no 12 : \n",
      "Classification loss = 42.0531\n",
      "Comparison loss = 6.3955\n",
      "Epoch no 13 : \n",
      "Classification loss = 41.4730\n",
      "Comparison loss = 5.9488\n",
      "Epoch no 14 : \n",
      "Classification loss = 41.4230\n",
      "Comparison loss = 5.8336\n",
      "Epoch no 15 : \n",
      "Classification loss = 41.4430\n",
      "Comparison loss = 5.9840\n",
      "Epoch no 16 : \n",
      "Classification loss = 41.4627\n",
      "Comparison loss = 6.0503\n",
      "Epoch no 17 : \n",
      "Classification loss = 41.3945\n",
      "Comparison loss = 5.7797\n",
      "Epoch no 18 : \n",
      "Classification loss = 41.8329\n",
      "Comparison loss = 6.3780\n",
      "Epoch no 19 : \n",
      "Classification loss = 42.3529\n",
      "Comparison loss = 6.5200\n",
      "Epoch no 20 : \n",
      "Classification loss = 42.4930\n",
      "Comparison loss = 6.5107\n",
      "Epoch no 21 : \n",
      "Classification loss = 42.5931\n",
      "Comparison loss = 6.4152\n",
      "Epoch no 22 : \n",
      "Classification loss = 42.6226\n",
      "Comparison loss = 6.3506\n",
      "Epoch no 23 : \n",
      "Classification loss = 42.7830\n",
      "Comparison loss = 6.2559\n",
      "Epoch no 24 : \n",
      "Classification loss = 42.8330\n",
      "Comparison loss = 6.3042\n",
      "Epoch no 25 : \n",
      "Classification loss = 42.6602\n",
      "Comparison loss = 6.1136\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 66.450% \n",
      "Comparison = 34.600%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 68.100% \n",
      "Comparison = 34.100%\u001b[0m\n",
      "RUN NO 9\n",
      "Epoch no 1 : \n",
      "Classification loss = 42.6029\n",
      "Comparison loss = 6.8663\n",
      "Epoch no 2 : \n",
      "Classification loss = 42.9126\n",
      "Comparison loss = 7.0167\n",
      "Epoch no 3 : \n",
      "Classification loss = 42.9969\n",
      "Comparison loss = 6.8386\n",
      "Epoch no 4 : \n",
      "Classification loss = 42.2230\n",
      "Comparison loss = 6.7617\n",
      "Epoch no 5 : \n",
      "Classification loss = 42.1330\n",
      "Comparison loss = 6.6593\n",
      "Epoch no 6 : \n",
      "Classification loss = 42.0727\n",
      "Comparison loss = 6.8539\n",
      "Epoch no 7 : \n",
      "Classification loss = 42.2030\n",
      "Comparison loss = 6.7220\n",
      "Epoch no 8 : \n",
      "Classification loss = 42.2830\n",
      "Comparison loss = 6.7092\n",
      "Epoch no 9 : \n",
      "Classification loss = 42.2322\n",
      "Comparison loss = 6.8767\n",
      "Epoch no 10 : \n",
      "Classification loss = 41.8330\n",
      "Comparison loss = 6.9492\n",
      "Epoch no 11 : \n",
      "Classification loss = 41.6028\n",
      "Comparison loss = 6.9261\n",
      "Epoch no 12 : \n",
      "Classification loss = 41.5629\n",
      "Comparison loss = 6.8863\n",
      "Epoch no 13 : \n",
      "Classification loss = 41.5530\n",
      "Comparison loss = 6.8057\n",
      "Epoch no 14 : \n",
      "Classification loss = 41.5830\n",
      "Comparison loss = 6.7042\n",
      "Epoch no 15 : \n",
      "Classification loss = 41.7230\n",
      "Comparison loss = 6.4827\n",
      "Epoch no 16 : \n",
      "Classification loss = 41.7230\n",
      "Comparison loss = 6.6942\n",
      "Epoch no 17 : \n",
      "Classification loss = 41.7330\n",
      "Comparison loss = 6.5258\n",
      "Epoch no 18 : \n",
      "Classification loss = 41.7330\n",
      "Comparison loss = 6.3931\n",
      "Epoch no 19 : \n",
      "Classification loss = 41.7330\n",
      "Comparison loss = 6.6993\n",
      "Epoch no 20 : \n",
      "Classification loss = 41.7330\n",
      "Comparison loss = 6.6859\n",
      "Epoch no 21 : \n",
      "Classification loss = 41.7330\n",
      "Comparison loss = 6.4362\n",
      "Epoch no 22 : \n",
      "Classification loss = 41.7330\n",
      "Comparison loss = 6.5995\n",
      "Epoch no 23 : \n",
      "Classification loss = 41.7330\n",
      "Comparison loss = 6.6622\n",
      "Epoch no 24 : \n",
      "Classification loss = 41.7330\n",
      "Comparison loss = 6.8260\n",
      "Epoch no 25 : \n",
      "Classification loss = 41.7330\n",
      "Comparison loss = 6.8420\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 62.750% \n",
      "Comparison = 44.900%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 66.200% \n",
      "Comparison = 47.400%\u001b[0m\n",
      "RUN NO 10\n",
      "Epoch no 1 : \n",
      "Classification loss = 41.7330\n",
      "Comparison loss = 6.7082\n",
      "Epoch no 2 : \n",
      "Classification loss = 41.7630\n",
      "Comparison loss = 6.8984\n",
      "Epoch no 3 : \n",
      "Classification loss = 42.2730\n",
      "Comparison loss = 6.7731\n",
      "Epoch no 4 : \n",
      "Classification loss = 42.5827\n",
      "Comparison loss = 6.6192\n",
      "Epoch no 5 : \n",
      "Classification loss = 42.7330\n",
      "Comparison loss = 6.8030\n",
      "Epoch no 6 : \n",
      "Classification loss = 42.7790\n",
      "Comparison loss = 6.8285\n",
      "Epoch no 7 : \n",
      "Classification loss = 42.5330\n",
      "Comparison loss = 6.7627\n",
      "Epoch no 8 : \n",
      "Classification loss = 42.2530\n",
      "Comparison loss = 6.7352\n",
      "Epoch no 9 : \n",
      "Classification loss = 42.3330\n",
      "Comparison loss = 6.6719\n",
      "Epoch no 10 : \n",
      "Classification loss = 42.2530\n",
      "Comparison loss = 6.6400\n",
      "Epoch no 11 : \n",
      "Classification loss = 42.1530\n",
      "Comparison loss = 6.6828\n",
      "Epoch no 12 : \n",
      "Classification loss = 41.7930\n",
      "Comparison loss = 6.6191\n",
      "Epoch no 13 : \n",
      "Classification loss = 41.6830\n",
      "Comparison loss = 6.6457\n",
      "Epoch no 14 : \n",
      "Classification loss = 41.6407\n",
      "Comparison loss = 6.6438\n",
      "Epoch no 15 : \n",
      "Classification loss = 41.3230\n",
      "Comparison loss = 6.5556\n",
      "Epoch no 16 : \n",
      "Classification loss = 41.2630\n",
      "Comparison loss = 6.5140\n",
      "Epoch no 17 : \n",
      "Classification loss = 41.2827\n",
      "Comparison loss = 6.6227\n",
      "Epoch no 18 : \n",
      "Classification loss = 41.1927\n",
      "Comparison loss = 7.0092\n",
      "Epoch no 19 : \n",
      "Classification loss = 41.3527\n",
      "Comparison loss = 6.6380\n",
      "Epoch no 20 : \n",
      "Classification loss = 41.5727\n",
      "Comparison loss = 6.6755\n",
      "Epoch no 21 : \n",
      "Classification loss = 41.6226\n",
      "Comparison loss = 6.5091\n",
      "Epoch no 22 : \n",
      "Classification loss = 41.9330\n",
      "Comparison loss = 6.1476\n",
      "Epoch no 23 : \n",
      "Classification loss = 42.1730\n",
      "Comparison loss = 6.2299\n",
      "Epoch no 24 : \n",
      "Classification loss = 41.8910\n",
      "Comparison loss = 6.4803\n",
      "Epoch no 25 : \n",
      "Classification loss = 41.4930\n",
      "Comparison loss = 6.5639\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 61.450% \n",
      "Comparison = 35.700%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 64.250% \n",
      "Comparison = 37.700%\u001b[0m\n",
      "Final error for train batch : 32.16±7.0076\n",
      "Final error for test batch : 33.95±6.7441\n",
      "RUN NO 1\n",
      "Epoch no 1 : \n",
      "Classification loss = 32.5442\n",
      "Comparison loss = 6.6826\n",
      "Epoch no 2 : \n",
      "Classification loss = 39.1492\n",
      "Comparison loss = 6.5884\n",
      "Epoch no 3 : \n",
      "Classification loss = 41.2271\n",
      "Comparison loss = 6.8884\n",
      "Epoch no 4 : \n",
      "Classification loss = 40.3052\n",
      "Comparison loss = 6.8282\n",
      "Epoch no 5 : \n",
      "Classification loss = 41.7419\n",
      "Comparison loss = 6.7473\n",
      "Epoch no 6 : \n",
      "Classification loss = 44.3238\n",
      "Comparison loss = 6.9230\n",
      "Epoch no 7 : \n",
      "Classification loss = 45.9180\n",
      "Comparison loss = 6.9367\n",
      "Epoch no 8 : \n",
      "Classification loss = 47.1982\n",
      "Comparison loss = 6.8928\n",
      "Epoch no 9 : \n",
      "Classification loss = 47.3130\n",
      "Comparison loss = 6.8955\n",
      "Epoch no 10 : \n",
      "Classification loss = 46.5347\n",
      "Comparison loss = 6.9163\n",
      "Epoch no 11 : \n",
      "Classification loss = 45.4450\n",
      "Comparison loss = 6.8976\n",
      "Epoch no 12 : \n",
      "Classification loss = 46.2200\n",
      "Comparison loss = 6.8948\n",
      "Epoch no 13 : \n",
      "Classification loss = 46.2669\n",
      "Comparison loss = 6.8771\n",
      "Epoch no 14 : \n",
      "Classification loss = 45.7073\n",
      "Comparison loss = 6.8845\n",
      "Epoch no 15 : \n",
      "Classification loss = 45.2726\n",
      "Comparison loss = 6.9369\n",
      "Epoch no 16 : \n",
      "Classification loss = 45.1866\n",
      "Comparison loss = 6.8735\n",
      "Epoch no 17 : \n",
      "Classification loss = 46.9373\n",
      "Comparison loss = 6.8819\n",
      "Epoch no 18 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8871\n",
      "Epoch no 19 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8815\n",
      "Epoch no 20 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8792\n",
      "Epoch no 21 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8816\n",
      "Epoch no 22 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8837\n",
      "Epoch no 23 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8823\n",
      "Epoch no 24 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8804\n",
      "Epoch no 25 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8812\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 90.200% \n",
      "Comparison = 44.900%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 90.350% \n",
      "Comparison = 47.400%\u001b[0m\n",
      "RUN NO 2\n",
      "Epoch no 1 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8882\n",
      "Epoch no 2 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8817\n",
      "Epoch no 3 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8875\n",
      "Epoch no 4 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8876\n",
      "Epoch no 5 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8788\n",
      "Epoch no 6 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8821\n",
      "Epoch no 7 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8848\n",
      "Epoch no 8 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8818\n",
      "Epoch no 9 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8800\n",
      "Epoch no 10 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8819\n",
      "Epoch no 11 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8834\n",
      "Epoch no 12 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8818\n",
      "Epoch no 13 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch no 14 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8815\n",
      "Epoch no 15 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8825\n",
      "Epoch no 16 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8819\n",
      "Epoch no 17 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8811\n",
      "Epoch no 18 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8815\n",
      "Epoch no 19 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8820\n",
      "Epoch no 20 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8819\n",
      "Epoch no 21 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8815\n",
      "Epoch no 22 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8815\n",
      "Epoch no 23 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8818\n",
      "Epoch no 24 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8818\n",
      "Epoch no 25 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8816\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 90.200% \n",
      "Comparison = 44.900%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 90.350% \n",
      "Comparison = 47.400%\u001b[0m\n",
      "RUN NO 3\n",
      "Epoch no 1 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9403\n",
      "Epoch no 2 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8888\n",
      "Epoch no 3 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8859\n",
      "Epoch no 4 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8906\n",
      "Epoch no 5 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8816\n",
      "Epoch no 6 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8808\n",
      "Epoch no 7 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8834\n",
      "Epoch no 8 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8826\n",
      "Epoch no 9 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8810\n",
      "Epoch no 10 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8808\n",
      "Epoch no 11 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8817\n",
      "Epoch no 12 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8822\n",
      "Epoch no 13 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8818\n",
      "Epoch no 14 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8813\n",
      "Epoch no 15 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8814\n",
      "Epoch no 16 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8818\n",
      "Epoch no 17 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8818\n",
      "Epoch no 18 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8816\n",
      "Epoch no 19 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8815\n",
      "Epoch no 20 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8816\n",
      "Epoch no 21 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8817\n",
      "Epoch no 22 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8817\n",
      "Epoch no 23 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8816\n",
      "Epoch no 24 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8816\n",
      "Epoch no 25 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8817\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 90.200% \n",
      "Comparison = 44.900%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 90.350% \n",
      "Comparison = 47.400%\u001b[0m\n",
      "RUN NO 4\n",
      "Epoch no 1 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9218\n",
      "Epoch no 2 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8951\n",
      "Epoch no 3 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8897\n",
      "Epoch no 4 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8950\n",
      "Epoch no 5 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8806\n",
      "Epoch no 6 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8789\n",
      "Epoch no 7 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8812\n",
      "Epoch no 8 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8835\n",
      "Epoch no 9 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8832\n",
      "Epoch no 10 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8808\n",
      "Epoch no 11 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8806\n",
      "Epoch no 12 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8819\n",
      "Epoch no 13 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8825\n",
      "Epoch no 14 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8817\n",
      "Epoch no 15 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8811\n",
      "Epoch no 16 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8815\n",
      "Epoch no 17 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8821\n",
      "Epoch no 18 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8818\n",
      "Epoch no 19 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8814\n",
      "Epoch no 20 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8816\n",
      "Epoch no 21 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8819\n",
      "Epoch no 22 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8818\n",
      "Epoch no 23 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8816\n",
      "Epoch no 24 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8816\n",
      "Epoch no 25 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8818\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 90.200% \n",
      "Comparison = 44.900%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 90.350% \n",
      "Comparison = 47.400%\u001b[0m\n",
      "RUN NO 5\n",
      "Epoch no 1 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9487\n",
      "Epoch no 2 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8824\n",
      "Epoch no 3 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8900\n",
      "Epoch no 4 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8873\n",
      "Epoch no 5 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8791\n",
      "Epoch no 6 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8805\n",
      "Epoch no 7 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8837\n",
      "Epoch no 8 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8835\n",
      "Epoch no 9 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8804\n",
      "Epoch no 10 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8807\n",
      "Epoch no 11 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8827\n",
      "Epoch no 12 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8827\n",
      "Epoch no 13 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8810\n",
      "Epoch no 14 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8811\n",
      "Epoch no 15 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8824\n",
      "Epoch no 16 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8823\n",
      "Epoch no 17 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8812\n",
      "Epoch no 18 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8815\n",
      "Epoch no 19 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8823\n",
      "Epoch no 20 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8820\n",
      "Epoch no 21 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8814\n",
      "Epoch no 22 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8817\n",
      "Epoch no 23 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8822\n",
      "Epoch no 24 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8818\n",
      "Epoch no 25 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8815\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 90.200% \n",
      "Comparison = 44.900%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 90.350% \n",
      "Comparison = 47.400%\u001b[0m\n",
      "RUN NO 6\n",
      "Epoch no 1 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 7.0059\n",
      "Epoch no 2 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9051\n",
      "Epoch no 3 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8919\n",
      "Epoch no 4 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8854\n",
      "Epoch no 5 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8890\n",
      "Epoch no 6 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8918\n",
      "Epoch no 7 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8766\n",
      "Epoch no 8 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8840\n",
      "Epoch no 9 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8884\n",
      "Epoch no 10 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8841\n",
      "Epoch no 11 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8798\n",
      "Epoch no 12 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8799\n",
      "Epoch no 13 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8814\n",
      "Epoch no 14 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8826\n",
      "Epoch no 15 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8823\n",
      "Epoch no 16 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8813\n",
      "Epoch no 17 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8810\n",
      "Epoch no 18 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8814\n",
      "Epoch no 19 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8818\n",
      "Epoch no 20 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8818\n",
      "Epoch no 21 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch no 22 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8814\n",
      "Epoch no 23 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8815\n",
      "Epoch no 24 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8817\n",
      "Epoch no 25 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8816\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 90.200% \n",
      "Comparison = 44.900%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 90.350% \n",
      "Comparison = 47.400%\u001b[0m\n",
      "RUN NO 7\n",
      "Epoch no 1 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9110\n",
      "Epoch no 2 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9086\n",
      "Epoch no 3 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9064\n",
      "Epoch no 4 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8834\n",
      "Epoch no 5 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8808\n",
      "Epoch no 6 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8877\n",
      "Epoch no 7 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8903\n",
      "Epoch no 8 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8779\n",
      "Epoch no 9 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8802\n",
      "Epoch no 10 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8853\n",
      "Epoch no 11 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8857\n",
      "Epoch no 12 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8795\n",
      "Epoch no 13 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8802\n",
      "Epoch no 14 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8833\n",
      "Epoch no 15 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8838\n",
      "Epoch no 16 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8807\n",
      "Epoch no 17 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8806\n",
      "Epoch no 18 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8825\n",
      "Epoch no 19 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8829\n",
      "Epoch no 20 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8812\n",
      "Epoch no 21 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8810\n",
      "Epoch no 22 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8822\n",
      "Epoch no 23 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8824\n",
      "Epoch no 24 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8814\n",
      "Epoch no 25 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8813\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 90.200% \n",
      "Comparison = 44.900%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 90.350% \n",
      "Comparison = 47.400%\u001b[0m\n",
      "RUN NO 8\n",
      "Epoch no 1 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8946\n",
      "Epoch no 2 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8978\n",
      "Epoch no 3 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8906\n",
      "Epoch no 4 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8820\n",
      "Epoch no 5 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8950\n",
      "Epoch no 6 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8963\n",
      "Epoch no 7 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8796\n",
      "Epoch no 8 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8786\n",
      "Epoch no 9 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8830\n",
      "Epoch no 10 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8862\n",
      "Epoch no 11 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8835\n",
      "Epoch no 12 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8798\n",
      "Epoch no 13 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8804\n",
      "Epoch no 14 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8822\n",
      "Epoch no 15 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8830\n",
      "Epoch no 16 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8817\n",
      "Epoch no 17 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8808\n",
      "Epoch no 18 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8813\n",
      "Epoch no 19 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8820\n",
      "Epoch no 20 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8820\n",
      "Epoch no 21 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8815\n",
      "Epoch no 22 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8813\n",
      "Epoch no 23 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8817\n",
      "Epoch no 24 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8819\n",
      "Epoch no 25 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8817\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 90.200% \n",
      "Comparison = 44.900%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 90.350% \n",
      "Comparison = 47.400%\u001b[0m\n",
      "RUN NO 9\n",
      "Epoch no 1 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9384\n",
      "Epoch no 2 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9112\n",
      "Epoch no 3 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8920\n",
      "Epoch no 4 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9019\n",
      "Epoch no 5 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8787\n",
      "Epoch no 6 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8788\n",
      "Epoch no 7 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8818\n",
      "Epoch no 8 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8846\n",
      "Epoch no 9 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8837\n",
      "Epoch no 10 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8805\n",
      "Epoch no 11 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8803\n",
      "Epoch no 12 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8817\n",
      "Epoch no 13 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8826\n",
      "Epoch no 14 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8819\n",
      "Epoch no 15 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8810\n",
      "Epoch no 16 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8813\n",
      "Epoch no 17 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8819\n",
      "Epoch no 18 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8820\n",
      "Epoch no 19 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8815\n",
      "Epoch no 20 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8814\n",
      "Epoch no 21 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8817\n",
      "Epoch no 22 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8819\n",
      "Epoch no 23 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8817\n",
      "Epoch no 24 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8815\n",
      "Epoch no 25 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8817\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 90.200% \n",
      "Comparison = 44.900%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 90.350% \n",
      "Comparison = 47.400%\u001b[0m\n",
      "RUN NO 10\n",
      "Epoch no 1 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9070\n",
      "Epoch no 2 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9134\n",
      "Epoch no 3 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9299\n",
      "Epoch no 4 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8779\n",
      "Epoch no 5 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8840\n",
      "Epoch no 6 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8894\n",
      "Epoch no 7 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8830\n",
      "Epoch no 8 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8783\n",
      "Epoch no 9 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8815\n",
      "Epoch no 10 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8849\n",
      "Epoch no 11 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8830\n",
      "Epoch no 12 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8798\n",
      "Epoch no 13 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8811\n",
      "Epoch no 14 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8834\n",
      "Epoch no 15 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8825\n",
      "Epoch no 16 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8806\n",
      "Epoch no 17 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8814\n",
      "Epoch no 18 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8828\n",
      "Epoch no 19 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8821\n",
      "Epoch no 20 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8810\n",
      "Epoch no 21 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8817\n",
      "Epoch no 22 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8825\n",
      "Epoch no 23 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8818\n",
      "Epoch no 24 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8813\n",
      "Epoch no 25 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.8820\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 90.200% \n",
      "Comparison = 44.900%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 90.350% \n",
      "Comparison = 47.400%\u001b[0m\n",
      "Final error for train batch : 44.90±0.0000\n",
      "Final error for test batch : 47.40±0.0000\n",
      "RUN NO 1\n",
      "Epoch no 1 : \n",
      "Classification loss = 37.7333\n",
      "Comparison loss = 10.6556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch no 2 : \n",
      "Classification loss = 44.2818\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 3 : \n",
      "Classification loss = 47.0130\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 4 : \n",
      "Classification loss = 47.2730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 5 : \n",
      "Classification loss = 47.3630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 6 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 7 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 8 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 9 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 10 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 11 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 12 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 13 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 14 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 15 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 16 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 17 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 18 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 19 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 20 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 21 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 22 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 23 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 24 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 25 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 90.750% \n",
      "Comparison = 44.900%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 90.150% \n",
      "Comparison = 47.400%\u001b[0m\n",
      "RUN NO 2\n",
      "Epoch no 1 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 11.8069\n",
      "Epoch no 2 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 3 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 4 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 5 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 6 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 7 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 8 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 9 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 10 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 11 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 12 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 13 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 14 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 15 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 16 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 17 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 18 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 19 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 20 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 21 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 22 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 23 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 24 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 25 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 90.750% \n",
      "Comparison = 44.900%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 90.150% \n",
      "Comparison = 47.400%\u001b[0m\n",
      "RUN NO 3\n",
      "Epoch no 1 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 22.4421\n",
      "Epoch no 2 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 3 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 4 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 5 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 6 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 7 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 8 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 9 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 10 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 11 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 12 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 13 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 14 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 15 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 16 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 17 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 18 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 19 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 20 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 21 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 22 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 23 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 24 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 25 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 90.750% \n",
      "Comparison = 44.900%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 90.150% \n",
      "Comparison = 47.400%\u001b[0m\n",
      "RUN NO 4\n",
      "Epoch no 1 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 12.1294\n",
      "Epoch no 2 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9280\n",
      "Epoch no 3 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.8881\n",
      "Epoch no 4 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9145\n",
      "Epoch no 5 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 6 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 7 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 8 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 9 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 10 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 11 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 12 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 13 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 14 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 15 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 16 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 17 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 18 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 19 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 20 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 21 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 22 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 23 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 24 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 25 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 90.750% \n",
      "Comparison = 44.900%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 90.150% \n",
      "Comparison = 47.400%\u001b[0m\n",
      "RUN NO 5\n",
      "Epoch no 1 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 12.5136\n",
      "Epoch no 2 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 3 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 4 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 5 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 6 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 7 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 8 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 9 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch no 10 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 11 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 12 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 13 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 14 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 15 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 16 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 17 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 18 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 19 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 20 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 21 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 22 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 23 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 24 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 25 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 90.750% \n",
      "Comparison = 44.900%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 90.150% \n",
      "Comparison = 47.400%\u001b[0m\n",
      "RUN NO 6\n",
      "Epoch no 1 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 38.2813\n",
      "Epoch no 2 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 3 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 4 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 5 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 6 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 7 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 8 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 9 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 10 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 11 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 12 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 13 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 14 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 15 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 16 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 17 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 18 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 19 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 20 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 21 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 22 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 23 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 24 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 25 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 90.750% \n",
      "Comparison = 44.900%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 90.150% \n",
      "Comparison = 47.400%\u001b[0m\n",
      "RUN NO 7\n",
      "Epoch no 1 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 13.2843\n",
      "Epoch no 2 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 3 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 4 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 5 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 6 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 7 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 8 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 9 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 10 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 11 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 12 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 13 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 14 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 15 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 16 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 17 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 18 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 19 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 20 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 21 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 22 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 23 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 24 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 25 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 90.750% \n",
      "Comparison = 44.900%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 90.150% \n",
      "Comparison = 47.400%\u001b[0m\n",
      "RUN NO 8\n",
      "Epoch no 1 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 12.5628\n",
      "Epoch no 2 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 3 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 4 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 5 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 6 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 7 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 8 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 9 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 10 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 11 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 12 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 13 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 14 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 15 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 16 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 17 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 18 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 19 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 20 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 21 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 22 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 23 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 24 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 25 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 90.750% \n",
      "Comparison = 44.900%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 90.150% \n",
      "Comparison = 47.400%\u001b[0m\n",
      "RUN NO 9\n",
      "Epoch no 1 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 12.2538\n",
      "Epoch no 2 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 8.6304\n",
      "Epoch no 3 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 4 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 5 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 6 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 7 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 8 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 9 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 10 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 11 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 12 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 13 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 14 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 15 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 16 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 17 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch no 18 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 19 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 20 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 21 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 22 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 23 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 24 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 25 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 90.750% \n",
      "Comparison = 44.900%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 90.150% \n",
      "Comparison = 47.400%\u001b[0m\n",
      "RUN NO 10\n",
      "Epoch no 1 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 18.6658\n",
      "Epoch no 2 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 3 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 4 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 5 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 6 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 7 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 8 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 9 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 10 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 11 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 12 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 13 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 14 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 15 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 16 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 17 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 18 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 19 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 20 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 21 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 22 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 23 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 24 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 25 : \n",
      "Classification loss = 47.3730\n",
      "Comparison loss = 6.9315\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 90.750% \n",
      "Comparison = 44.900%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 90.150% \n",
      "Comparison = 47.400%\u001b[0m\n",
      "Final error for train batch : 44.90±0.0000\n",
      "Final error for test batch : 47.40±0.0000\n",
      "RUN NO 1\n",
      "Epoch no 1 : \n",
      "Classification loss = 43.2930\n",
      "Comparison loss = 45.2697\n",
      "Epoch no 2 : \n",
      "Classification loss = 45.5730\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 3 : \n",
      "Classification loss = 46.8028\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 4 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 5 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 6 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 7 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 8 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 9 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 10 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 11 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 12 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 13 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 14 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 15 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 16 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 17 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 18 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 19 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 20 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 21 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 22 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 23 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 24 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 25 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 88.300% \n",
      "Comparison = 44.900%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 90.400% \n",
      "Comparison = 47.400%\u001b[0m\n",
      "RUN NO 2\n",
      "Epoch no 1 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 16.9163\n",
      "Epoch no 2 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 3 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 4 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 5 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 6 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 7 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 8 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 9 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 10 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 11 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 12 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 13 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 14 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 15 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 16 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 17 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 18 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 19 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 20 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 21 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 22 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 23 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 24 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 25 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 88.300% \n",
      "Comparison = 44.900%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 90.400% \n",
      "Comparison = 47.400%\u001b[0m\n",
      "RUN NO 3\n",
      "Epoch no 1 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 14.6889\n",
      "Epoch no 2 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 3 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 4 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 5 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 6 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 7 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 8 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 9 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 10 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 11 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 12 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 13 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 14 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 15 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 16 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 17 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 18 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 19 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 20 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 21 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 22 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 23 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 24 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch no 25 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 88.300% \n",
      "Comparison = 44.900%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 90.400% \n",
      "Comparison = 47.400%\u001b[0m\n",
      "RUN NO 4\n",
      "Epoch no 1 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 15.7869\n",
      "Epoch no 2 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 3 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 4 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 5 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 6 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 7 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 8 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 9 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 10 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 11 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 12 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 13 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 14 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 15 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 16 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 17 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 18 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 19 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 20 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 21 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 22 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 23 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 24 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 25 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 88.300% \n",
      "Comparison = 44.900%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 90.400% \n",
      "Comparison = 47.400%\u001b[0m\n",
      "RUN NO 5\n",
      "Epoch no 1 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 11.1399\n",
      "Epoch no 2 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 7.7844\n",
      "Epoch no 3 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 4 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 5 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 6 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 7 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 8 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 9 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 10 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 11 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 12 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 13 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 14 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 15 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 16 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 17 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 18 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 19 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 20 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 21 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 22 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 23 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 24 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 25 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 88.300% \n",
      "Comparison = 44.900%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 90.400% \n",
      "Comparison = 47.400%\u001b[0m\n",
      "RUN NO 6\n",
      "Epoch no 1 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 7.5890\n",
      "Epoch no 2 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 7.0584\n",
      "Epoch no 3 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9036\n",
      "Epoch no 4 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9188\n",
      "Epoch no 5 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.8817\n",
      "Epoch no 6 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.8811\n",
      "Epoch no 7 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.8827\n",
      "Epoch no 8 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.8810\n",
      "Epoch no 9 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.8818\n",
      "Epoch no 10 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.8822\n",
      "Epoch no 11 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.8820\n",
      "Epoch no 12 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.8815\n",
      "Epoch no 13 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.8812\n",
      "Epoch no 14 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.8812\n",
      "Epoch no 15 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.8812\n",
      "Epoch no 16 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.8814\n",
      "Epoch no 17 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.8814\n",
      "Epoch no 18 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.8814\n",
      "Epoch no 19 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.8814\n",
      "Epoch no 20 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.8814\n",
      "Epoch no 21 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.8814\n",
      "Epoch no 22 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.8814\n",
      "Epoch no 23 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.8814\n",
      "Epoch no 24 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.8814\n",
      "Epoch no 25 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.8814\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 88.300% \n",
      "Comparison = 44.900%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 90.400% \n",
      "Comparison = 47.400%\u001b[0m\n",
      "RUN NO 7\n",
      "Epoch no 1 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 11.8361\n",
      "Epoch no 2 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 3 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 4 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 5 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 6 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 7 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 8 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 9 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 10 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 11 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 12 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 13 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 14 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 15 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 16 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 17 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 18 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 19 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 20 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 21 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 22 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 23 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 24 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 25 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 88.300% \n",
      "Comparison = 44.900%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 90.400% \n",
      "Comparison = 47.400%\u001b[0m\n",
      "RUN NO 8\n",
      "Epoch no 1 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 13.6634\n",
      "Epoch no 2 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 3 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 4 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 5 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch no 6 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 7 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 8 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 9 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 10 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 11 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 12 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 13 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 14 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 15 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 16 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 17 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 18 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 19 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 20 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 21 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 22 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 23 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 24 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 25 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 88.300% \n",
      "Comparison = 44.900%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 90.400% \n",
      "Comparison = 47.400%\u001b[0m\n",
      "RUN NO 9\n",
      "Epoch no 1 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 20.7586\n",
      "Epoch no 2 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 3 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 4 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 5 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 6 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 7 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 8 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 9 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 10 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 11 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 12 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 13 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 14 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 15 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 16 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 17 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 18 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 19 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 20 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 21 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 22 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 23 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 24 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 25 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 88.300% \n",
      "Comparison = 44.900%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 90.400% \n",
      "Comparison = 47.400%\u001b[0m\n",
      "RUN NO 10\n",
      "Epoch no 1 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 21.6737\n",
      "Epoch no 2 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 3 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 4 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 5 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 6 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 7 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 8 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 9 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 10 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 11 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 12 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 13 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 14 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 15 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 16 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 17 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 18 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 19 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 20 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 21 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 22 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 23 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 24 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 25 : \n",
      "Classification loss = 46.8830\n",
      "Comparison loss = 6.9315\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 88.300% \n",
      "Comparison = 44.900%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 90.400% \n",
      "Comparison = 47.400%\u001b[0m\n",
      "Final error for train batch : 44.90±0.0000\n",
      "Final error for test batch : 47.40±0.0000\n",
      "RUN NO 1\n",
      "Epoch no 1 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 20.5265\n",
      "Epoch no 2 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 3 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 4 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 5 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 6 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 7 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 8 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 9 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 10 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 11 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 12 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 13 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 14 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 15 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 16 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 17 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 18 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 19 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 20 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 21 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 22 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 23 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 24 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 25 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 90.200% \n",
      "Comparison = 44.900%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 90.350% \n",
      "Comparison = 47.400%\u001b[0m\n",
      "RUN NO 2\n",
      "Epoch no 1 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 15.2853\n",
      "Epoch no 2 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 3 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 4 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 5 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 6 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 7 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 8 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 9 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 10 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 11 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 12 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch no 13 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 14 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 15 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 16 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 17 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 18 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 19 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 20 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 21 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 22 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 23 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 24 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 25 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 90.200% \n",
      "Comparison = 44.900%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 90.350% \n",
      "Comparison = 47.400%\u001b[0m\n",
      "RUN NO 3\n",
      "Epoch no 1 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 34.7360\n",
      "Epoch no 2 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 3 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 4 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 5 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 6 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 7 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 8 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 9 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 10 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 11 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 12 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 13 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 14 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 15 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 16 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 17 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 18 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 19 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 20 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 21 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 22 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 23 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 24 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 25 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 90.200% \n",
      "Comparison = 44.900%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 90.350% \n",
      "Comparison = 47.400%\u001b[0m\n",
      "RUN NO 4\n",
      "Epoch no 1 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 18.0854\n",
      "Epoch no 2 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 3 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 4 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 5 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 6 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 7 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 8 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 9 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 10 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 11 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 12 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 13 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 14 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 15 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 16 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 17 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 18 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 19 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 20 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 21 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 22 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 23 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 24 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 25 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 90.200% \n",
      "Comparison = 44.900%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 90.350% \n",
      "Comparison = 47.400%\u001b[0m\n",
      "RUN NO 5\n",
      "Epoch no 1 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 18.8956\n",
      "Epoch no 2 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9317\n",
      "Epoch no 3 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 4 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 5 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 6 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 7 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 8 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 9 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 10 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 11 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 12 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 13 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 14 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 15 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 16 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 17 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 18 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 19 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 20 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 21 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 22 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 23 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 24 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 25 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 90.200% \n",
      "Comparison = 44.900%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 90.350% \n",
      "Comparison = 47.400%\u001b[0m\n",
      "RUN NO 6\n",
      "Epoch no 1 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 11.2865\n",
      "Epoch no 2 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 8.8593\n",
      "Epoch no 3 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 4 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 5 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 6 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 7 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 8 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 9 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 10 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 11 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 12 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 13 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 14 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 15 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 16 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 17 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 18 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 19 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 20 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch no 21 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 22 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 23 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 24 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 25 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 90.200% \n",
      "Comparison = 44.900%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 90.350% \n",
      "Comparison = 47.400%\u001b[0m\n",
      "RUN NO 7\n",
      "Epoch no 1 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 15.1246\n",
      "Epoch no 2 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 3 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 4 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 5 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 6 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 7 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 8 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 9 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 10 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 11 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 12 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 13 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 14 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 15 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 16 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 17 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 18 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 19 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 20 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 21 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 22 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 23 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 24 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 25 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 90.200% \n",
      "Comparison = 55.100%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 90.350% \n",
      "Comparison = 52.600%\u001b[0m\n",
      "RUN NO 8\n",
      "Epoch no 1 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 17.1630\n",
      "Epoch no 2 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 3 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 4 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 5 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 6 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 7 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 8 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 9 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 10 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 11 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 12 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 13 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 14 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 15 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 16 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 17 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 18 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 19 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 20 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 21 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 22 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 23 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 24 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 25 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 90.200% \n",
      "Comparison = 44.900%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 90.350% \n",
      "Comparison = 47.400%\u001b[0m\n",
      "RUN NO 9\n",
      "Epoch no 1 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 16.1060\n",
      "Epoch no 2 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 3 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 4 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 5 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 6 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 7 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 8 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 9 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 10 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 11 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 12 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 13 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 14 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 15 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 16 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 17 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 18 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 19 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 20 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 21 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 22 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 23 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 24 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 25 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 90.200% \n",
      "Comparison = 44.900%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 90.350% \n",
      "Comparison = 47.400%\u001b[0m\n",
      "RUN NO 10\n",
      "Epoch no 1 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 18.9060\n",
      "Epoch no 2 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 8.7568\n",
      "Epoch no 3 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 4 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 5 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 6 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 7 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 8 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 9 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 10 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 11 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 12 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 13 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 14 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 15 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 16 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 17 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 18 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 19 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 20 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 21 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 22 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 23 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 24 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "Epoch no 25 : \n",
      "Classification loss = 47.2630\n",
      "Comparison loss = 6.9315\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 90.200% \n",
      "Comparison = 44.900%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 90.350% \n",
      "Comparison = 47.400%\u001b[0m\n",
      "Final error for train batch : 45.92±3.2255\n",
      "Final error for test batch : 47.92±1.6444\n"
     ]
    }
   ],
   "source": [
    "train_class = t.empty(NB_RUN)\n",
    "train_comp = t.empty(NB_RUN)\n",
    "test_class = t.empty(NB_RUN)\n",
    "test_comp = t.empty(NB_RUN)\n",
    "\n",
    "train_errors = np.zeros((len(lrs), len(classification_models)))\n",
    "test_errors = np.zeros((len(lrs), len(classification_models)))\n",
    "\n",
    "\n",
    "for k in range(len(lrs)):\n",
    "    for l in range(len(classification_models)):\n",
    "        for i in range(NB_RUN):\n",
    "            model_cl = classification_models[l]\n",
    "            model_co= Comparison()\n",
    "            print(\"RUN NO {}\".format(i+1))\n",
    "            training(model_cl, model_co, lrs[k])\n",
    "\n",
    "            e1, e2 = test_models(model_cl, model_co, train_input, train_classes, train_target)\n",
    "            e3, e4 = test_models(model_cl, model_co, test_input, test_classes, test_target, False)\n",
    "            train_class[i] = (e1)\n",
    "            train_comp[i] = (e2)\n",
    "            test_class[i] = (e3)\n",
    "            test_comp[i] = (e4)\n",
    "\n",
    "        print(\"Final error for train batch : {:0.2f}\\u00B1{:0.4f}\".format(t.mean(train_comp)*100, t.std(train_comp)*100))\n",
    "        print(\"Final error for test batch : {:0.2f}\\u00B1{:0.4f}\".format(t.mean(test_comp)*100, t.std(test_comp)*100))\n",
    "        \n",
    "        train_error = t.mean(train_comp) * 100\n",
    "        test_error = t.mean(test_comp) * 100\n",
    "        \n",
    "        train_errors[k, l] = train_error\n",
    "        test_errors[k, l] = test_error\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14.17000008, 14.03999805, 19.3900013 ],\n",
       "       [ 3.29999995,  3.56000018,  5.94999981],\n",
       "       [28.40999985, 33.95000076, 47.40000534],\n",
       "       [47.40000534, 47.40000534, 47.92000198]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Test error [%]')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Grid: model 1 (classification) optimisation\n",
    "ax = sns.heatmap(test_errors, cmap = 'Blues',\n",
    "                 xticklabels = ['ReLU', 'Leaky ReLU', 'Sigmoid'], yticklabels = ['1e-4', '1e-3', '1e-2', '1e-1'])\n",
    "ax.set_xlabel('Activation function')\n",
    "ax.set_ylabel('Learning rate')\n",
    "ax.set_title('Test error [%]')\n",
    "#plt.savefig('lr_vs_actfct_2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save variables\n",
    "with open('errors_part_1.pkl', 'wb') as f:  \n",
    "    pickle.dump([train_errors, test_errors], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid search babe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "layers = range(6)\n",
    "models_2 = [[Comparison_2(), Comparison_2_leaky_relu(), Comparison_2_sigmoid()]]\n",
    "models_3 = [[Comparison_3(), Comparison_3_leaky_relu(), Comparison_3_sigmoid()]]\n",
    "models_4 = [[Comparison_4(), Comparison_4_leaky_relu(), Comparison_4_sigmoid()]]\n",
    "models_5 = [[Comparison_5(), Comparison_5_leaky_relu(), Comparison_5_sigmoid()]]\n",
    "models_6 = [[Comparison_6(), Comparison_6_leaky_relu(), Comparison_6_sigmoid()]]\n",
    "\n",
    "all_models = np.concatenate((models_2, models_3, models_4, models_5, models_6), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN NO 1\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.6029\n",
      "Comparison loss = 5.5981\n",
      "Epoch no 2 : \n",
      "Classification loss = 43.8254\n",
      "Comparison loss = 4.7155\n",
      "Epoch no 3 : \n",
      "Classification loss = 41.6939\n",
      "Comparison loss = 4.5912\n",
      "Epoch no 4 : \n",
      "Classification loss = 39.2118\n",
      "Comparison loss = 4.1515\n",
      "Epoch no 5 : \n",
      "Classification loss = 36.9165\n",
      "Comparison loss = 3.1460\n",
      "Epoch no 6 : \n",
      "Classification loss = 35.2839\n",
      "Comparison loss = 2.8594\n",
      "Epoch no 7 : \n",
      "Classification loss = 34.1567\n",
      "Comparison loss = 2.5795\n",
      "Epoch no 8 : \n",
      "Classification loss = 32.8788\n",
      "Comparison loss = 1.9375\n",
      "Epoch no 9 : \n",
      "Classification loss = 32.2426\n",
      "Comparison loss = 1.6657\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.7334\n",
      "Comparison loss = 2.0034\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.8173\n",
      "Comparison loss = 1.1279\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.6376\n",
      "Comparison loss = 1.0497\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.3638\n",
      "Comparison loss = 1.1078\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.1487\n",
      "Comparison loss = 0.7919\n",
      "Epoch no 15 : \n",
      "Classification loss = 30.0094\n",
      "Comparison loss = 0.6855\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.9378\n",
      "Comparison loss = 0.6281\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.7918\n",
      "Comparison loss = 0.4967\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.7109\n",
      "Comparison loss = 0.4740\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.6329\n",
      "Comparison loss = 0.4343\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.5844\n",
      "Comparison loss = 0.3967\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.5288\n",
      "Comparison loss = 0.3423\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.5078\n",
      "Comparison loss = 0.2872\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4660\n",
      "Comparison loss = 0.2675\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4534\n",
      "Comparison loss = 0.2425\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.4416\n",
      "Comparison loss = 0.1955\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.950% \n",
      "Comparison = 0.200%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.650% \n",
      "Comparison = 3.100%\u001b[0m\n",
      "RUN NO 2\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.4908\n",
      "Comparison loss = 5.1770\n",
      "Epoch no 2 : \n",
      "Classification loss = 43.1281\n",
      "Comparison loss = 4.5415\n",
      "Epoch no 3 : \n",
      "Classification loss = 40.9396\n",
      "Comparison loss = 4.3224\n",
      "Epoch no 4 : \n",
      "Classification loss = 38.7005\n",
      "Comparison loss = 3.0839\n",
      "Epoch no 5 : \n",
      "Classification loss = 36.0133\n",
      "Comparison loss = 2.2558\n",
      "Epoch no 6 : \n",
      "Classification loss = 34.0166\n",
      "Comparison loss = 2.6018\n",
      "Epoch no 7 : \n",
      "Classification loss = 33.1202\n",
      "Comparison loss = 1.7824\n",
      "Epoch no 8 : \n",
      "Classification loss = 31.7437\n",
      "Comparison loss = 1.3973\n",
      "Epoch no 9 : \n",
      "Classification loss = 31.2481\n",
      "Comparison loss = 1.2184\n",
      "Epoch no 10 : \n",
      "Classification loss = 30.6236\n",
      "Comparison loss = 0.9329\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.3685\n",
      "Comparison loss = 0.8998\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.0567\n",
      "Comparison loss = 0.6325\n",
      "Epoch no 13 : \n",
      "Classification loss = 29.9278\n",
      "Comparison loss = 0.5215\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.7362\n",
      "Comparison loss = 0.4587\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.6494\n",
      "Comparison loss = 0.4045\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.5707\n",
      "Comparison loss = 0.3765\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.5174\n",
      "Comparison loss = 0.3338\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.4508\n",
      "Comparison loss = 0.3062\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.4208\n",
      "Comparison loss = 0.2869\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.3835\n",
      "Comparison loss = 0.2435\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.3471\n",
      "Comparison loss = 0.2118\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.3249\n",
      "Comparison loss = 0.1953\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.3113\n",
      "Comparison loss = 0.1883\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.3047\n",
      "Comparison loss = 0.1821\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3005\n",
      "Comparison loss = 0.1764\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.300% \n",
      "Comparison = 0.100%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.550% \n",
      "Comparison = 3.100%\u001b[0m\n",
      "RUN NO 3\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.6203\n",
      "Comparison loss = 5.5434\n",
      "Epoch no 2 : \n",
      "Classification loss = 43.7103\n",
      "Comparison loss = 4.5135\n",
      "Epoch no 3 : \n",
      "Classification loss = 40.6860\n",
      "Comparison loss = 4.0475\n",
      "Epoch no 4 : \n",
      "Classification loss = 38.3298\n",
      "Comparison loss = 3.3480\n",
      "Epoch no 5 : \n",
      "Classification loss = 36.1277\n",
      "Comparison loss = 2.5778\n",
      "Epoch no 6 : \n",
      "Classification loss = 34.6594\n",
      "Comparison loss = 2.5582\n",
      "Epoch no 7 : \n",
      "Classification loss = 33.9124\n",
      "Comparison loss = 2.4204\n",
      "Epoch no 8 : \n",
      "Classification loss = 33.2959\n",
      "Comparison loss = 2.3410\n",
      "Epoch no 9 : \n",
      "Classification loss = 32.4313\n",
      "Comparison loss = 1.3817\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.9333\n",
      "Comparison loss = 1.3490\n",
      "Epoch no 11 : \n",
      "Classification loss = 31.0750\n",
      "Comparison loss = 0.8141\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.6180\n",
      "Comparison loss = 0.6896\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.1457\n",
      "Comparison loss = 0.5898\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.0638\n",
      "Comparison loss = 0.6580\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.9396\n",
      "Comparison loss = 0.5639\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.8094\n",
      "Comparison loss = 0.5130\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.7039\n",
      "Comparison loss = 0.4179\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.7060\n",
      "Comparison loss = 0.4023\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.6090\n",
      "Comparison loss = 0.2968\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.5281\n",
      "Comparison loss = 0.2948\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4999\n",
      "Comparison loss = 0.2757\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4326\n",
      "Comparison loss = 0.1752\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4048\n",
      "Comparison loss = 0.1396\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.3866\n",
      "Comparison loss = 0.1346\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3740\n",
      "Comparison loss = 0.1283\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.650% \n",
      "Comparison = 0.000%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 3.850% \n",
      "Comparison = 2.600%\u001b[0m\n",
      "RUN NO 4\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.6715\n",
      "Comparison loss = 5.6369\n",
      "Epoch no 2 : \n",
      "Classification loss = 44.2004\n",
      "Comparison loss = 5.0719\n",
      "Epoch no 3 : \n",
      "Classification loss = 42.3646\n",
      "Comparison loss = 5.3180\n",
      "Epoch no 4 : \n",
      "Classification loss = 40.7203\n",
      "Comparison loss = 4.4769\n",
      "Epoch no 5 : \n",
      "Classification loss = 39.3866\n",
      "Comparison loss = 3.5955\n",
      "Epoch no 6 : \n",
      "Classification loss = 37.7878\n",
      "Comparison loss = 3.4174\n",
      "Epoch no 7 : \n",
      "Classification loss = 36.6151\n",
      "Comparison loss = 4.0745\n",
      "Epoch no 8 : \n",
      "Classification loss = 35.9033\n",
      "Comparison loss = 3.4702\n",
      "Epoch no 9 : \n",
      "Classification loss = 34.8584\n",
      "Comparison loss = 2.6074\n",
      "Epoch no 10 : \n",
      "Classification loss = 34.2245\n",
      "Comparison loss = 2.4520\n",
      "Epoch no 11 : \n",
      "Classification loss = 34.3050\n",
      "Comparison loss = 2.4665\n",
      "Epoch no 12 : \n",
      "Classification loss = 33.5452\n",
      "Comparison loss = 2.3972\n",
      "Epoch no 13 : \n",
      "Classification loss = 32.9339\n",
      "Comparison loss = 2.0512\n",
      "Epoch no 14 : \n",
      "Classification loss = 32.5679\n",
      "Comparison loss = 1.5235\n",
      "Epoch no 15 : \n",
      "Classification loss = 31.9667\n",
      "Comparison loss = 1.5123\n",
      "Epoch no 16 : \n",
      "Classification loss = 31.6118\n",
      "Comparison loss = 1.3693\n",
      "Epoch no 17 : \n",
      "Classification loss = 31.0707\n",
      "Comparison loss = 1.2999\n",
      "Epoch no 18 : \n",
      "Classification loss = 30.8099\n",
      "Comparison loss = 1.0561\n",
      "Epoch no 19 : \n",
      "Classification loss = 30.6273\n",
      "Comparison loss = 1.0277\n",
      "Epoch no 20 : \n",
      "Classification loss = 30.3229\n",
      "Comparison loss = 0.8848\n",
      "Epoch no 21 : \n",
      "Classification loss = 30.2006\n",
      "Comparison loss = 0.7541\n",
      "Epoch no 22 : \n",
      "Classification loss = 30.0549\n",
      "Comparison loss = 0.6574\n",
      "Epoch no 23 : \n",
      "Classification loss = 30.0026\n",
      "Comparison loss = 0.6486\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.9614\n",
      "Comparison loss = 0.5738\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.8873\n",
      "Comparison loss = 0.4553\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 2.600% \n",
      "Comparison = 0.900%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 7.050% \n",
      "Comparison = 5.700%\u001b[0m\n",
      "RUN NO 5\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.2996\n",
      "Comparison loss = 5.1721\n",
      "Epoch no 2 : \n",
      "Classification loss = 43.0915\n",
      "Comparison loss = 4.6545\n",
      "Epoch no 3 : \n",
      "Classification loss = 41.2783\n",
      "Comparison loss = 4.2288\n",
      "Epoch no 4 : \n",
      "Classification loss = 38.6422\n",
      "Comparison loss = 3.1543\n",
      "Epoch no 5 : \n",
      "Classification loss = 35.7472\n",
      "Comparison loss = 2.3663\n",
      "Epoch no 6 : \n",
      "Classification loss = 34.1616\n",
      "Comparison loss = 2.5843\n",
      "Epoch no 7 : \n",
      "Classification loss = 34.0414\n",
      "Comparison loss = 2.5262\n",
      "Epoch no 8 : \n",
      "Classification loss = 33.1246\n",
      "Comparison loss = 1.8925\n",
      "Epoch no 9 : \n",
      "Classification loss = 32.6844\n",
      "Comparison loss = 2.2934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch no 10 : \n",
      "Classification loss = 31.5846\n",
      "Comparison loss = 1.2716\n",
      "Epoch no 11 : \n",
      "Classification loss = 31.1541\n",
      "Comparison loss = 1.0041\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.7143\n",
      "Comparison loss = 0.8096\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.4352\n",
      "Comparison loss = 0.6671\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.2377\n",
      "Comparison loss = 0.5744\n",
      "Epoch no 15 : \n",
      "Classification loss = 30.1381\n",
      "Comparison loss = 0.6078\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.9466\n",
      "Comparison loss = 0.5079\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.8967\n",
      "Comparison loss = 0.4771\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.6970\n",
      "Comparison loss = 0.3705\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.6560\n",
      "Comparison loss = 0.3187\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.6086\n",
      "Comparison loss = 0.2786\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.5636\n",
      "Comparison loss = 0.2666\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.5252\n",
      "Comparison loss = 0.2548\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4981\n",
      "Comparison loss = 0.2258\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4788\n",
      "Comparison loss = 0.2037\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.4507\n",
      "Comparison loss = 0.1983\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 1.000% \n",
      "Comparison = 0.100%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.200% \n",
      "Comparison = 3.100%\u001b[0m\n",
      "RUN NO 6\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.2613\n",
      "Comparison loss = 5.2387\n",
      "Epoch no 2 : \n",
      "Classification loss = 42.9697\n",
      "Comparison loss = 4.9748\n",
      "Epoch no 3 : \n",
      "Classification loss = 41.2263\n",
      "Comparison loss = 4.8111\n",
      "Epoch no 4 : \n",
      "Classification loss = 39.6513\n",
      "Comparison loss = 4.0939\n",
      "Epoch no 5 : \n",
      "Classification loss = 37.8619\n",
      "Comparison loss = 3.0877\n",
      "Epoch no 6 : \n",
      "Classification loss = 36.0096\n",
      "Comparison loss = 2.1802\n",
      "Epoch no 7 : \n",
      "Classification loss = 34.8168\n",
      "Comparison loss = 1.8034\n",
      "Epoch no 8 : \n",
      "Classification loss = 33.2310\n",
      "Comparison loss = 2.0408\n",
      "Epoch no 9 : \n",
      "Classification loss = 32.4875\n",
      "Comparison loss = 1.6566\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.5712\n",
      "Comparison loss = 1.3477\n",
      "Epoch no 11 : \n",
      "Classification loss = 31.1152\n",
      "Comparison loss = 1.2489\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.7913\n",
      "Comparison loss = 0.9683\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.4212\n",
      "Comparison loss = 0.7800\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.1647\n",
      "Comparison loss = 0.7013\n",
      "Epoch no 15 : \n",
      "Classification loss = 30.0654\n",
      "Comparison loss = 0.5929\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.9371\n",
      "Comparison loss = 0.5357\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.8332\n",
      "Comparison loss = 0.4610\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.7791\n",
      "Comparison loss = 0.4412\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.6836\n",
      "Comparison loss = 0.4215\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.6679\n",
      "Comparison loss = 0.4247\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.6081\n",
      "Comparison loss = 0.3638\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.6442\n",
      "Comparison loss = 0.3873\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.8175\n",
      "Comparison loss = 0.7162\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.5735\n",
      "Comparison loss = 0.4247\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.6273\n",
      "Comparison loss = 0.4512\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 1.200% \n",
      "Comparison = 0.300%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 5.600% \n",
      "Comparison = 3.800%\u001b[0m\n",
      "RUN NO 7\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.6427\n",
      "Comparison loss = 5.7493\n",
      "Epoch no 2 : \n",
      "Classification loss = 43.6601\n",
      "Comparison loss = 4.4653\n",
      "Epoch no 3 : \n",
      "Classification loss = 41.4996\n",
      "Comparison loss = 4.3846\n",
      "Epoch no 4 : \n",
      "Classification loss = 39.2431\n",
      "Comparison loss = 3.4317\n",
      "Epoch no 5 : \n",
      "Classification loss = 36.8021\n",
      "Comparison loss = 2.9089\n",
      "Epoch no 6 : \n",
      "Classification loss = 35.1231\n",
      "Comparison loss = 2.4295\n",
      "Epoch no 7 : \n",
      "Classification loss = 34.1925\n",
      "Comparison loss = 2.1043\n",
      "Epoch no 8 : \n",
      "Classification loss = 33.4271\n",
      "Comparison loss = 2.2335\n",
      "Epoch no 9 : \n",
      "Classification loss = 32.2661\n",
      "Comparison loss = 1.7767\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.6095\n",
      "Comparison loss = 1.3769\n",
      "Epoch no 11 : \n",
      "Classification loss = 31.3373\n",
      "Comparison loss = 1.2169\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.5546\n",
      "Comparison loss = 0.8779\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.2414\n",
      "Comparison loss = 0.6490\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.0708\n",
      "Comparison loss = 0.6232\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.8556\n",
      "Comparison loss = 0.4743\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.7379\n",
      "Comparison loss = 0.4245\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.6475\n",
      "Comparison loss = 0.3844\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.5915\n",
      "Comparison loss = 0.3333\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.5353\n",
      "Comparison loss = 0.3094\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.4967\n",
      "Comparison loss = 0.3262\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4633\n",
      "Comparison loss = 0.2748\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4372\n",
      "Comparison loss = 0.2481\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4209\n",
      "Comparison loss = 0.2279\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4101\n",
      "Comparison loss = 0.2203\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3923\n",
      "Comparison loss = 0.1881\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.700% \n",
      "Comparison = 0.200%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.500% \n",
      "Comparison = 3.200%\u001b[0m\n",
      "RUN NO 8\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.4484\n",
      "Comparison loss = 5.4541\n",
      "Epoch no 2 : \n",
      "Classification loss = 42.9170\n",
      "Comparison loss = 4.3963\n",
      "Epoch no 3 : \n",
      "Classification loss = 40.0862\n",
      "Comparison loss = 3.8210\n",
      "Epoch no 4 : \n",
      "Classification loss = 37.7893\n",
      "Comparison loss = 2.9384\n",
      "Epoch no 5 : \n",
      "Classification loss = 35.5782\n",
      "Comparison loss = 2.4942\n",
      "Epoch no 6 : \n",
      "Classification loss = 33.4997\n",
      "Comparison loss = 2.0526\n",
      "Epoch no 7 : \n",
      "Classification loss = 32.8931\n",
      "Comparison loss = 1.5989\n",
      "Epoch no 8 : \n",
      "Classification loss = 32.6659\n",
      "Comparison loss = 1.8732\n",
      "Epoch no 9 : \n",
      "Classification loss = 32.4114\n",
      "Comparison loss = 1.9050\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.4428\n",
      "Comparison loss = 0.8940\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.9231\n",
      "Comparison loss = 0.8772\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.4050\n",
      "Comparison loss = 0.6820\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.1462\n",
      "Comparison loss = 0.5319\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.8909\n",
      "Comparison loss = 0.3861\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.7738\n",
      "Comparison loss = 0.2995\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.6199\n",
      "Comparison loss = 0.2459\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.5649\n",
      "Comparison loss = 0.2232\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.4960\n",
      "Comparison loss = 0.2047\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.4441\n",
      "Comparison loss = 0.1888\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.4044\n",
      "Comparison loss = 0.1770\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.3859\n",
      "Comparison loss = 0.1651\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.3727\n",
      "Comparison loss = 0.1499\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.3624\n",
      "Comparison loss = 0.1306\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.3549\n",
      "Comparison loss = 0.1195\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3505\n",
      "Comparison loss = 0.1133\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.550% \n",
      "Comparison = 0.000%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.250% \n",
      "Comparison = 3.200%\u001b[0m\n",
      "RUN NO 9\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.5648\n",
      "Comparison loss = 5.3856\n",
      "Epoch no 2 : \n",
      "Classification loss = 43.2930\n",
      "Comparison loss = 4.3166\n",
      "Epoch no 3 : \n",
      "Classification loss = 41.2987\n",
      "Comparison loss = 4.2117\n",
      "Epoch no 4 : \n",
      "Classification loss = 39.4903\n",
      "Comparison loss = 3.9563\n",
      "Epoch no 5 : \n",
      "Classification loss = 37.1704\n",
      "Comparison loss = 3.4317\n",
      "Epoch no 6 : \n",
      "Classification loss = 34.7747\n",
      "Comparison loss = 2.7866\n",
      "Epoch no 7 : \n",
      "Classification loss = 33.1784\n",
      "Comparison loss = 1.6291\n",
      "Epoch no 8 : \n",
      "Classification loss = 32.7079\n",
      "Comparison loss = 1.9988\n",
      "Epoch no 9 : \n",
      "Classification loss = 32.1187\n",
      "Comparison loss = 1.2059\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.0964\n",
      "Comparison loss = 0.8646\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.6184\n",
      "Comparison loss = 0.6911\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.5115\n",
      "Comparison loss = 0.7807\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.1364\n",
      "Comparison loss = 0.4920\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.1372\n",
      "Comparison loss = 0.6441\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.9710\n",
      "Comparison loss = 0.4296\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.8100\n",
      "Comparison loss = 0.4671\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.7255\n",
      "Comparison loss = 0.2968\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.6482\n",
      "Comparison loss = 0.3317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch no 19 : \n",
      "Classification loss = 29.5666\n",
      "Comparison loss = 0.2765\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.5166\n",
      "Comparison loss = 0.2498\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4809\n",
      "Comparison loss = 0.2384\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4548\n",
      "Comparison loss = 0.2258\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4258\n",
      "Comparison loss = 0.2138\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4070\n",
      "Comparison loss = 0.2022\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.4002\n",
      "Comparison loss = 0.1918\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.800% \n",
      "Comparison = 0.200%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.600% \n",
      "Comparison = 3.300%\u001b[0m\n",
      "RUN NO 10\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.5857\n",
      "Comparison loss = 5.8672\n",
      "Epoch no 2 : \n",
      "Classification loss = 43.5713\n",
      "Comparison loss = 5.3500\n",
      "Epoch no 3 : \n",
      "Classification loss = 42.5072\n",
      "Comparison loss = 4.8792\n",
      "Epoch no 4 : \n",
      "Classification loss = 41.6150\n",
      "Comparison loss = 3.7898\n",
      "Epoch no 5 : \n",
      "Classification loss = 40.2831\n",
      "Comparison loss = 3.9698\n",
      "Epoch no 6 : \n",
      "Classification loss = 38.7393\n",
      "Comparison loss = 3.3886\n",
      "Epoch no 7 : \n",
      "Classification loss = 36.7086\n",
      "Comparison loss = 3.3654\n",
      "Epoch no 8 : \n",
      "Classification loss = 35.4150\n",
      "Comparison loss = 2.8539\n",
      "Epoch no 9 : \n",
      "Classification loss = 34.0901\n",
      "Comparison loss = 2.1267\n",
      "Epoch no 10 : \n",
      "Classification loss = 33.3982\n",
      "Comparison loss = 1.7284\n",
      "Epoch no 11 : \n",
      "Classification loss = 32.7745\n",
      "Comparison loss = 1.6228\n",
      "Epoch no 12 : \n",
      "Classification loss = 32.3993\n",
      "Comparison loss = 1.4247\n",
      "Epoch no 13 : \n",
      "Classification loss = 31.8680\n",
      "Comparison loss = 1.4123\n",
      "Epoch no 14 : \n",
      "Classification loss = 31.4378\n",
      "Comparison loss = 1.2919\n",
      "Epoch no 15 : \n",
      "Classification loss = 31.1451\n",
      "Comparison loss = 1.0330\n",
      "Epoch no 16 : \n",
      "Classification loss = 31.2672\n",
      "Comparison loss = 2.0015\n",
      "Epoch no 17 : \n",
      "Classification loss = 31.1329\n",
      "Comparison loss = 1.8407\n",
      "Epoch no 18 : \n",
      "Classification loss = 31.1935\n",
      "Comparison loss = 1.0286\n",
      "Epoch no 19 : \n",
      "Classification loss = 30.4838\n",
      "Comparison loss = 0.9466\n",
      "Epoch no 20 : \n",
      "Classification loss = 30.2769\n",
      "Comparison loss = 0.7257\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.9633\n",
      "Comparison loss = 0.5538\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.8997\n",
      "Comparison loss = 0.5153\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.7497\n",
      "Comparison loss = 0.4059\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.6760\n",
      "Comparison loss = 0.3384\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.6207\n",
      "Comparison loss = 0.3033\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 1.600% \n",
      "Comparison = 0.300%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 6.100% \n",
      "Comparison = 4.000%\u001b[0m\n",
      "Final error for train batch : 0.23±0.2584\n",
      "Final error for test batch : 3.51±0.8621\n",
      "RUN NO 1\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.3049\n",
      "Comparison loss = 6.9446\n",
      "Epoch no 2 : \n",
      "Classification loss = 42.5072\n",
      "Comparison loss = 6.9337\n",
      "Epoch no 3 : \n",
      "Classification loss = 39.3268\n",
      "Comparison loss = 6.8949\n",
      "Epoch no 4 : \n",
      "Classification loss = 36.9726\n",
      "Comparison loss = 6.8348\n",
      "Epoch no 5 : \n",
      "Classification loss = 34.9921\n",
      "Comparison loss = 6.7589\n",
      "Epoch no 6 : \n",
      "Classification loss = 34.0422\n",
      "Comparison loss = 6.6782\n",
      "Epoch no 7 : \n",
      "Classification loss = 33.5250\n",
      "Comparison loss = 6.5650\n",
      "Epoch no 8 : \n",
      "Classification loss = 32.6590\n",
      "Comparison loss = 6.4296\n",
      "Epoch no 9 : \n",
      "Classification loss = 31.7081\n",
      "Comparison loss = 6.2603\n",
      "Epoch no 10 : \n",
      "Classification loss = 30.8852\n",
      "Comparison loss = 6.0438\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.4690\n",
      "Comparison loss = 5.7291\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.0731\n",
      "Comparison loss = 5.4003\n",
      "Epoch no 13 : \n",
      "Classification loss = 29.8500\n",
      "Comparison loss = 5.0446\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.7602\n",
      "Comparison loss = 4.6600\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.6539\n",
      "Comparison loss = 4.2627\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.5712\n",
      "Comparison loss = 3.8692\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.5397\n",
      "Comparison loss = 3.5071\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.4961\n",
      "Comparison loss = 3.1808\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.4704\n",
      "Comparison loss = 2.8865\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.4789\n",
      "Comparison loss = 2.6341\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4414\n",
      "Comparison loss = 2.4077\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4298\n",
      "Comparison loss = 2.2121\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4164\n",
      "Comparison loss = 2.0436\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4033\n",
      "Comparison loss = 1.8926\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3941\n",
      "Comparison loss = 1.7485\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.700% \n",
      "Comparison = 2.600%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.050% \n",
      "Comparison = 4.900%\u001b[0m\n",
      "RUN NO 2\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.3117\n",
      "Comparison loss = 6.1506\n",
      "Epoch no 2 : \n",
      "Classification loss = 42.2705\n",
      "Comparison loss = 4.3900\n",
      "Epoch no 3 : \n",
      "Classification loss = 38.7075\n",
      "Comparison loss = 3.9513\n",
      "Epoch no 4 : \n",
      "Classification loss = 35.9986\n",
      "Comparison loss = 3.4837\n",
      "Epoch no 5 : \n",
      "Classification loss = 34.6796\n",
      "Comparison loss = 2.7603\n",
      "Epoch no 6 : \n",
      "Classification loss = 33.9043\n",
      "Comparison loss = 2.5419\n",
      "Epoch no 7 : \n",
      "Classification loss = 33.4465\n",
      "Comparison loss = 2.5868\n",
      "Epoch no 8 : \n",
      "Classification loss = 32.8966\n",
      "Comparison loss = 2.4560\n",
      "Epoch no 9 : \n",
      "Classification loss = 31.8470\n",
      "Comparison loss = 2.0011\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.2832\n",
      "Comparison loss = 1.9014\n",
      "Epoch no 11 : \n",
      "Classification loss = 31.0533\n",
      "Comparison loss = 1.8615\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.5048\n",
      "Comparison loss = 1.6172\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.2173\n",
      "Comparison loss = 1.5746\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.0627\n",
      "Comparison loss = 1.3941\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.8901\n",
      "Comparison loss = 1.2821\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.7392\n",
      "Comparison loss = 1.1448\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.6454\n",
      "Comparison loss = 1.0735\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.5602\n",
      "Comparison loss = 0.9864\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.5071\n",
      "Comparison loss = 0.8990\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.4793\n",
      "Comparison loss = 0.8552\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4599\n",
      "Comparison loss = 0.8323\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4446\n",
      "Comparison loss = 0.7859\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4373\n",
      "Comparison loss = 0.7488\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4423\n",
      "Comparison loss = 0.7141\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.4527\n",
      "Comparison loss = 0.7284\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 1.050% \n",
      "Comparison = 0.500%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.700% \n",
      "Comparison = 3.700%\u001b[0m\n",
      "RUN NO 3\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.3179\n",
      "Comparison loss = 5.6496\n",
      "Epoch no 2 : \n",
      "Classification loss = 42.7622\n",
      "Comparison loss = 4.1126\n",
      "Epoch no 3 : \n",
      "Classification loss = 40.4235\n",
      "Comparison loss = 3.6956\n",
      "Epoch no 4 : \n",
      "Classification loss = 37.8645\n",
      "Comparison loss = 3.4508\n",
      "Epoch no 5 : \n",
      "Classification loss = 36.1552\n",
      "Comparison loss = 2.7721\n",
      "Epoch no 6 : \n",
      "Classification loss = 34.7846\n",
      "Comparison loss = 2.3952\n",
      "Epoch no 7 : \n",
      "Classification loss = 33.9851\n",
      "Comparison loss = 1.9152\n",
      "Epoch no 8 : \n",
      "Classification loss = 33.5945\n",
      "Comparison loss = 1.8777\n",
      "Epoch no 9 : \n",
      "Classification loss = 32.7120\n",
      "Comparison loss = 1.5453\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.3916\n",
      "Comparison loss = 1.3127\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.7699\n",
      "Comparison loss = 1.3486\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.6068\n",
      "Comparison loss = 1.1619\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.3623\n",
      "Comparison loss = 0.9795\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.0248\n",
      "Comparison loss = 1.0714\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.9209\n",
      "Comparison loss = 0.8515\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.7790\n",
      "Comparison loss = 0.7809\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.6405\n",
      "Comparison loss = 0.6808\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.5394\n",
      "Comparison loss = 0.6170\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.4880\n",
      "Comparison loss = 0.5870\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.4318\n",
      "Comparison loss = 0.5585\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4019\n",
      "Comparison loss = 0.5345\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.3786\n",
      "Comparison loss = 0.5087\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.3653\n",
      "Comparison loss = 0.4790\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.3575\n",
      "Comparison loss = 0.4507\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3501\n",
      "Comparison loss = 0.4311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.500% \n",
      "Comparison = 0.000%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 3.950% \n",
      "Comparison = 2.500%\u001b[0m\n",
      "RUN NO 4\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.5862\n",
      "Comparison loss = 6.3922\n",
      "Epoch no 2 : \n",
      "Classification loss = 43.5108\n",
      "Comparison loss = 4.5437\n",
      "Epoch no 3 : \n",
      "Classification loss = 41.4873\n",
      "Comparison loss = 4.4370\n",
      "Epoch no 4 : \n",
      "Classification loss = 39.1506\n",
      "Comparison loss = 3.7151\n",
      "Epoch no 5 : \n",
      "Classification loss = 37.2376\n",
      "Comparison loss = 3.7409\n",
      "Epoch no 6 : \n",
      "Classification loss = 35.8387\n",
      "Comparison loss = 3.5968\n",
      "Epoch no 7 : \n",
      "Classification loss = 34.4590\n",
      "Comparison loss = 2.2108\n",
      "Epoch no 8 : \n",
      "Classification loss = 32.7613\n",
      "Comparison loss = 1.8622\n",
      "Epoch no 9 : \n",
      "Classification loss = 31.5413\n",
      "Comparison loss = 1.5640\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.0908\n",
      "Comparison loss = 1.3438\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.5920\n",
      "Comparison loss = 1.2437\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.2012\n",
      "Comparison loss = 1.0749\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.1346\n",
      "Comparison loss = 0.9434\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.8553\n",
      "Comparison loss = 0.7222\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.7820\n",
      "Comparison loss = 0.6793\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.6622\n",
      "Comparison loss = 0.5657\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.6163\n",
      "Comparison loss = 0.5577\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.5432\n",
      "Comparison loss = 0.5108\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.4633\n",
      "Comparison loss = 0.4435\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.4455\n",
      "Comparison loss = 0.4006\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4198\n",
      "Comparison loss = 0.3947\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.3824\n",
      "Comparison loss = 0.3932\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.3704\n",
      "Comparison loss = 0.3788\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.3577\n",
      "Comparison loss = 0.3714\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3448\n",
      "Comparison loss = 0.3578\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.500% \n",
      "Comparison = 0.000%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.250% \n",
      "Comparison = 2.900%\u001b[0m\n",
      "RUN NO 5\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.6383\n",
      "Comparison loss = 6.2829\n",
      "Epoch no 2 : \n",
      "Classification loss = 43.8064\n",
      "Comparison loss = 4.7891\n",
      "Epoch no 3 : \n",
      "Classification loss = 41.0238\n",
      "Comparison loss = 4.6529\n",
      "Epoch no 4 : \n",
      "Classification loss = 38.4684\n",
      "Comparison loss = 3.9645\n",
      "Epoch no 5 : \n",
      "Classification loss = 35.9299\n",
      "Comparison loss = 3.4547\n",
      "Epoch no 6 : \n",
      "Classification loss = 34.2359\n",
      "Comparison loss = 2.3828\n",
      "Epoch no 7 : \n",
      "Classification loss = 33.2189\n",
      "Comparison loss = 2.4011\n",
      "Epoch no 8 : \n",
      "Classification loss = 32.4306\n",
      "Comparison loss = 2.0053\n",
      "Epoch no 9 : \n",
      "Classification loss = 31.6248\n",
      "Comparison loss = 1.4669\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.1161\n",
      "Comparison loss = 1.5416\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.9453\n",
      "Comparison loss = 1.2004\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.4197\n",
      "Comparison loss = 1.1055\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.3165\n",
      "Comparison loss = 0.9676\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.0607\n",
      "Comparison loss = 0.7735\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.9344\n",
      "Comparison loss = 0.7745\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.7981\n",
      "Comparison loss = 0.6071\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.7076\n",
      "Comparison loss = 0.5712\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.6559\n",
      "Comparison loss = 0.5617\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.5847\n",
      "Comparison loss = 0.5290\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.5504\n",
      "Comparison loss = 0.4908\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.5063\n",
      "Comparison loss = 0.4773\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4856\n",
      "Comparison loss = 0.4775\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4683\n",
      "Comparison loss = 0.4601\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4542\n",
      "Comparison loss = 0.4221\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.4354\n",
      "Comparison loss = 0.4034\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.850% \n",
      "Comparison = 0.200%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.200% \n",
      "Comparison = 3.300%\u001b[0m\n",
      "RUN NO 6\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.5860\n",
      "Comparison loss = 6.0836\n",
      "Epoch no 2 : \n",
      "Classification loss = 43.5567\n",
      "Comparison loss = 4.8436\n",
      "Epoch no 3 : \n",
      "Classification loss = 41.9914\n",
      "Comparison loss = 4.4858\n",
      "Epoch no 4 : \n",
      "Classification loss = 39.9221\n",
      "Comparison loss = 3.1939\n",
      "Epoch no 5 : \n",
      "Classification loss = 36.8309\n",
      "Comparison loss = 2.8580\n",
      "Epoch no 6 : \n",
      "Classification loss = 34.9454\n",
      "Comparison loss = 2.2336\n",
      "Epoch no 7 : \n",
      "Classification loss = 34.1182\n",
      "Comparison loss = 2.7258\n",
      "Epoch no 8 : \n",
      "Classification loss = 33.0258\n",
      "Comparison loss = 1.8378\n",
      "Epoch no 9 : \n",
      "Classification loss = 31.9869\n",
      "Comparison loss = 1.2700\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.1197\n",
      "Comparison loss = 1.2830\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.6784\n",
      "Comparison loss = 1.2028\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.2354\n",
      "Comparison loss = 0.7670\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.1087\n",
      "Comparison loss = 0.7391\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.8930\n",
      "Comparison loss = 0.6819\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.7683\n",
      "Comparison loss = 0.5016\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.6745\n",
      "Comparison loss = 0.4676\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.6804\n",
      "Comparison loss = 0.5345\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.6035\n",
      "Comparison loss = 0.3941\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.5319\n",
      "Comparison loss = 0.3456\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.4869\n",
      "Comparison loss = 0.3115\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4570\n",
      "Comparison loss = 0.2897\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4221\n",
      "Comparison loss = 0.3093\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4004\n",
      "Comparison loss = 0.2891\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.3763\n",
      "Comparison loss = 0.2685\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3653\n",
      "Comparison loss = 0.2614\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.600% \n",
      "Comparison = 0.000%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.550% \n",
      "Comparison = 3.100%\u001b[0m\n",
      "RUN NO 7\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.4611\n",
      "Comparison loss = 5.8152\n",
      "Epoch no 2 : \n",
      "Classification loss = 43.1923\n",
      "Comparison loss = 4.6092\n",
      "Epoch no 3 : \n",
      "Classification loss = 40.8027\n",
      "Comparison loss = 4.2655\n",
      "Epoch no 4 : \n",
      "Classification loss = 38.4116\n",
      "Comparison loss = 3.5336\n",
      "Epoch no 5 : \n",
      "Classification loss = 36.1525\n",
      "Comparison loss = 3.0202\n",
      "Epoch no 6 : \n",
      "Classification loss = 34.7658\n",
      "Comparison loss = 2.6131\n",
      "Epoch no 7 : \n",
      "Classification loss = 34.0896\n",
      "Comparison loss = 1.9954\n",
      "Epoch no 8 : \n",
      "Classification loss = 32.9258\n",
      "Comparison loss = 1.4555\n",
      "Epoch no 9 : \n",
      "Classification loss = 32.0293\n",
      "Comparison loss = 1.3416\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.2913\n",
      "Comparison loss = 1.0502\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.5677\n",
      "Comparison loss = 0.7633\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.3284\n",
      "Comparison loss = 0.6144\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.1915\n",
      "Comparison loss = 0.7499\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.9859\n",
      "Comparison loss = 0.5724\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.8372\n",
      "Comparison loss = 0.5869\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.7228\n",
      "Comparison loss = 0.4768\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.6217\n",
      "Comparison loss = 0.4519\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.5833\n",
      "Comparison loss = 0.4164\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.4788\n",
      "Comparison loss = 0.3747\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.4269\n",
      "Comparison loss = 0.3535\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4107\n",
      "Comparison loss = 0.3482\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.3970\n",
      "Comparison loss = 0.3417\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.3737\n",
      "Comparison loss = 0.3373\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.3652\n",
      "Comparison loss = 0.3260\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3578\n",
      "Comparison loss = 0.3146\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.600% \n",
      "Comparison = 0.200%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.400% \n",
      "Comparison = 3.600%\u001b[0m\n",
      "RUN NO 8\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.4538\n",
      "Comparison loss = 5.5282\n",
      "Epoch no 2 : \n",
      "Classification loss = 43.2837\n",
      "Comparison loss = 4.6043\n",
      "Epoch no 3 : \n",
      "Classification loss = 41.4682\n",
      "Comparison loss = 4.3879\n",
      "Epoch no 4 : \n",
      "Classification loss = 39.6880\n",
      "Comparison loss = 3.6191\n",
      "Epoch no 5 : \n",
      "Classification loss = 37.1157\n",
      "Comparison loss = 3.5397\n",
      "Epoch no 6 : \n",
      "Classification loss = 35.1817\n",
      "Comparison loss = 3.2503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch no 7 : \n",
      "Classification loss = 33.6473\n",
      "Comparison loss = 2.1267\n",
      "Epoch no 8 : \n",
      "Classification loss = 32.7694\n",
      "Comparison loss = 1.8475\n",
      "Epoch no 9 : \n",
      "Classification loss = 31.9471\n",
      "Comparison loss = 1.6330\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.3624\n",
      "Comparison loss = 1.0218\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.9665\n",
      "Comparison loss = 1.2386\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.5388\n",
      "Comparison loss = 1.0316\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.3871\n",
      "Comparison loss = 0.7755\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.1117\n",
      "Comparison loss = 0.5955\n",
      "Epoch no 15 : \n",
      "Classification loss = 30.0311\n",
      "Comparison loss = 0.7215\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.8216\n",
      "Comparison loss = 0.4736\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.8469\n",
      "Comparison loss = 0.5673\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.6692\n",
      "Comparison loss = 0.3982\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.6713\n",
      "Comparison loss = 0.4178\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.5939\n",
      "Comparison loss = 0.4021\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.5789\n",
      "Comparison loss = 0.3149\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4968\n",
      "Comparison loss = 0.2883\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4993\n",
      "Comparison loss = 0.2437\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4871\n",
      "Comparison loss = 0.2965\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.4595\n",
      "Comparison loss = 0.2556\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.950% \n",
      "Comparison = 0.100%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.100% \n",
      "Comparison = 2.900%\u001b[0m\n",
      "RUN NO 9\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.5669\n",
      "Comparison loss = 5.7208\n",
      "Epoch no 2 : \n",
      "Classification loss = 43.2502\n",
      "Comparison loss = 4.9035\n",
      "Epoch no 3 : \n",
      "Classification loss = 40.6985\n",
      "Comparison loss = 4.5518\n",
      "Epoch no 4 : \n",
      "Classification loss = 38.9347\n",
      "Comparison loss = 3.9267\n",
      "Epoch no 5 : \n",
      "Classification loss = 36.9111\n",
      "Comparison loss = 3.1760\n",
      "Epoch no 6 : \n",
      "Classification loss = 34.2146\n",
      "Comparison loss = 2.5621\n",
      "Epoch no 7 : \n",
      "Classification loss = 32.9983\n",
      "Comparison loss = 1.8012\n",
      "Epoch no 8 : \n",
      "Classification loss = 32.5015\n",
      "Comparison loss = 1.8160\n",
      "Epoch no 9 : \n",
      "Classification loss = 31.9718\n",
      "Comparison loss = 1.8744\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.5508\n",
      "Comparison loss = 2.0897\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.7786\n",
      "Comparison loss = 1.2328\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.4265\n",
      "Comparison loss = 0.8681\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.1704\n",
      "Comparison loss = 0.6993\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.0050\n",
      "Comparison loss = 0.6249\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.7845\n",
      "Comparison loss = 0.5005\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.6746\n",
      "Comparison loss = 0.4494\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.6059\n",
      "Comparison loss = 0.4294\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.5714\n",
      "Comparison loss = 0.3639\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.5270\n",
      "Comparison loss = 0.3414\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.5041\n",
      "Comparison loss = 0.3284\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4605\n",
      "Comparison loss = 0.3084\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4364\n",
      "Comparison loss = 0.2858\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4249\n",
      "Comparison loss = 0.2797\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4121\n",
      "Comparison loss = 0.2770\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.4040\n",
      "Comparison loss = 0.2737\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.800% \n",
      "Comparison = 0.200%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.250% \n",
      "Comparison = 3.100%\u001b[0m\n",
      "RUN NO 10\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.6719\n",
      "Comparison loss = 5.8914\n",
      "Epoch no 2 : \n",
      "Classification loss = 44.1646\n",
      "Comparison loss = 4.8798\n",
      "Epoch no 3 : \n",
      "Classification loss = 41.8478\n",
      "Comparison loss = 4.5182\n",
      "Epoch no 4 : \n",
      "Classification loss = 39.6585\n",
      "Comparison loss = 3.6472\n",
      "Epoch no 5 : \n",
      "Classification loss = 37.3911\n",
      "Comparison loss = 3.0979\n",
      "Epoch no 6 : \n",
      "Classification loss = 34.9829\n",
      "Comparison loss = 2.8072\n",
      "Epoch no 7 : \n",
      "Classification loss = 33.7138\n",
      "Comparison loss = 2.8404\n",
      "Epoch no 8 : \n",
      "Classification loss = 32.5034\n",
      "Comparison loss = 1.8972\n",
      "Epoch no 9 : \n",
      "Classification loss = 31.4258\n",
      "Comparison loss = 1.4136\n",
      "Epoch no 10 : \n",
      "Classification loss = 30.9276\n",
      "Comparison loss = 1.0880\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.6409\n",
      "Comparison loss = 1.0277\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.3097\n",
      "Comparison loss = 0.9128\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.1915\n",
      "Comparison loss = 0.7713\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.0222\n",
      "Comparison loss = 0.6502\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.8518\n",
      "Comparison loss = 0.5582\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.7063\n",
      "Comparison loss = 0.5141\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.6431\n",
      "Comparison loss = 0.4240\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.5650\n",
      "Comparison loss = 0.3553\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.5312\n",
      "Comparison loss = 0.3039\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.4526\n",
      "Comparison loss = 0.2985\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4277\n",
      "Comparison loss = 0.2550\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.3975\n",
      "Comparison loss = 0.2121\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.3855\n",
      "Comparison loss = 0.2038\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.3745\n",
      "Comparison loss = 0.2061\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3637\n",
      "Comparison loss = 0.1927\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.550% \n",
      "Comparison = 0.000%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.150% \n",
      "Comparison = 3.100%\u001b[0m\n",
      "Final error for train batch : 0.38±0.7955\n",
      "Final error for test batch : 3.31±0.6574\n",
      "RUN NO 1\n",
      "Epoch no 1 : \n",
      "Classification loss = 44.9317\n",
      "Comparison loss = 6.9496\n",
      "Epoch no 2 : \n",
      "Classification loss = 41.8210\n",
      "Comparison loss = 6.8979\n",
      "Epoch no 3 : \n",
      "Classification loss = 39.4174\n",
      "Comparison loss = 6.8968\n",
      "Epoch no 4 : \n",
      "Classification loss = 37.1708\n",
      "Comparison loss = 6.8805\n",
      "Epoch no 5 : \n",
      "Classification loss = 35.6059\n",
      "Comparison loss = 6.8410\n",
      "Epoch no 6 : \n",
      "Classification loss = 33.7588\n",
      "Comparison loss = 6.8081\n",
      "Epoch no 7 : \n",
      "Classification loss = 33.1073\n",
      "Comparison loss = 6.7787\n",
      "Epoch no 8 : \n",
      "Classification loss = 32.6471\n",
      "Comparison loss = 6.7421\n",
      "Epoch no 9 : \n",
      "Classification loss = 31.5433\n",
      "Comparison loss = 6.6965\n",
      "Epoch no 10 : \n",
      "Classification loss = 30.9517\n",
      "Comparison loss = 6.6466\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.5551\n",
      "Comparison loss = 6.5747\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.3590\n",
      "Comparison loss = 6.5008\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.1218\n",
      "Comparison loss = 6.4208\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.0369\n",
      "Comparison loss = 6.3167\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.8009\n",
      "Comparison loss = 6.1836\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.7296\n",
      "Comparison loss = 6.0449\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.6654\n",
      "Comparison loss = 5.8918\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.6048\n",
      "Comparison loss = 5.7207\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.5647\n",
      "Comparison loss = 5.5375\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.5448\n",
      "Comparison loss = 5.3469\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.5270\n",
      "Comparison loss = 5.1507\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.5046\n",
      "Comparison loss = 4.9523\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4787\n",
      "Comparison loss = 4.7538\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4539\n",
      "Comparison loss = 4.5582\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.4336\n",
      "Comparison loss = 4.3690\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.900% \n",
      "Comparison = 13.600%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.300% \n",
      "Comparison = 15.200%\u001b[0m\n",
      "RUN NO 2\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.4713\n",
      "Comparison loss = 6.7644\n",
      "Epoch no 2 : \n",
      "Classification loss = 42.9267\n",
      "Comparison loss = 6.2520\n",
      "Epoch no 3 : \n",
      "Classification loss = 39.5718\n",
      "Comparison loss = 5.7067\n",
      "Epoch no 4 : \n",
      "Classification loss = 36.9399\n",
      "Comparison loss = 5.4951\n",
      "Epoch no 5 : \n",
      "Classification loss = 35.3351\n",
      "Comparison loss = 4.9871\n",
      "Epoch no 6 : \n",
      "Classification loss = 34.3546\n",
      "Comparison loss = 4.7163\n",
      "Epoch no 7 : \n",
      "Classification loss = 33.9790\n",
      "Comparison loss = 4.4800\n",
      "Epoch no 8 : \n",
      "Classification loss = 34.2517\n",
      "Comparison loss = 4.4388\n",
      "Epoch no 9 : \n",
      "Classification loss = 33.0068\n",
      "Comparison loss = 4.0517\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.7374\n",
      "Comparison loss = 3.7714\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.9363\n",
      "Comparison loss = 3.5281\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.3082\n",
      "Comparison loss = 3.3387\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.1275\n",
      "Comparison loss = 3.1762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch no 14 : \n",
      "Classification loss = 30.0509\n",
      "Comparison loss = 3.0441\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.8250\n",
      "Comparison loss = 2.9244\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.7732\n",
      "Comparison loss = 2.7993\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.6950\n",
      "Comparison loss = 2.6903\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.6370\n",
      "Comparison loss = 2.5925\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.5724\n",
      "Comparison loss = 2.4874\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.5061\n",
      "Comparison loss = 2.3918\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4491\n",
      "Comparison loss = 2.2980\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4253\n",
      "Comparison loss = 2.2174\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4095\n",
      "Comparison loss = 2.1546\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.3880\n",
      "Comparison loss = 2.0931\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3743\n",
      "Comparison loss = 2.0306\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.650% \n",
      "Comparison = 2.400%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.100% \n",
      "Comparison = 5.100%\u001b[0m\n",
      "RUN NO 3\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.0558\n",
      "Comparison loss = 5.8135\n",
      "Epoch no 2 : \n",
      "Classification loss = 42.7810\n",
      "Comparison loss = 4.6901\n",
      "Epoch no 3 : \n",
      "Classification loss = 41.0462\n",
      "Comparison loss = 4.3413\n",
      "Epoch no 4 : \n",
      "Classification loss = 38.7726\n",
      "Comparison loss = 3.7930\n",
      "Epoch no 5 : \n",
      "Classification loss = 36.4968\n",
      "Comparison loss = 3.4090\n",
      "Epoch no 6 : \n",
      "Classification loss = 34.9272\n",
      "Comparison loss = 3.2555\n",
      "Epoch no 7 : \n",
      "Classification loss = 33.9093\n",
      "Comparison loss = 2.8665\n",
      "Epoch no 8 : \n",
      "Classification loss = 33.3607\n",
      "Comparison loss = 3.0626\n",
      "Epoch no 9 : \n",
      "Classification loss = 32.9463\n",
      "Comparison loss = 2.8095\n",
      "Epoch no 10 : \n",
      "Classification loss = 32.1654\n",
      "Comparison loss = 2.5211\n",
      "Epoch no 11 : \n",
      "Classification loss = 31.3400\n",
      "Comparison loss = 2.2984\n",
      "Epoch no 12 : \n",
      "Classification loss = 31.1113\n",
      "Comparison loss = 2.2137\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.4613\n",
      "Comparison loss = 2.0021\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.4001\n",
      "Comparison loss = 1.9140\n",
      "Epoch no 15 : \n",
      "Classification loss = 30.0259\n",
      "Comparison loss = 1.8348\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.8939\n",
      "Comparison loss = 1.7514\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.7700\n",
      "Comparison loss = 1.6768\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.6642\n",
      "Comparison loss = 1.6201\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.6166\n",
      "Comparison loss = 1.5787\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.5718\n",
      "Comparison loss = 1.5327\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.5317\n",
      "Comparison loss = 1.4840\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4939\n",
      "Comparison loss = 1.4476\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4676\n",
      "Comparison loss = 1.4128\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4455\n",
      "Comparison loss = 1.3839\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.4291\n",
      "Comparison loss = 1.3547\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.950% \n",
      "Comparison = 1.600%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 5.300% \n",
      "Comparison = 4.800%\u001b[0m\n",
      "RUN NO 4\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.4160\n",
      "Comparison loss = 5.7614\n",
      "Epoch no 2 : \n",
      "Classification loss = 42.8984\n",
      "Comparison loss = 4.1402\n",
      "Epoch no 3 : \n",
      "Classification loss = 39.6836\n",
      "Comparison loss = 3.7904\n",
      "Epoch no 4 : \n",
      "Classification loss = 36.9476\n",
      "Comparison loss = 3.0995\n",
      "Epoch no 5 : \n",
      "Classification loss = 34.6449\n",
      "Comparison loss = 2.5535\n",
      "Epoch no 6 : \n",
      "Classification loss = 33.2997\n",
      "Comparison loss = 2.4079\n",
      "Epoch no 7 : \n",
      "Classification loss = 32.7300\n",
      "Comparison loss = 2.2121\n",
      "Epoch no 8 : \n",
      "Classification loss = 32.6371\n",
      "Comparison loss = 2.3529\n",
      "Epoch no 9 : \n",
      "Classification loss = 31.4255\n",
      "Comparison loss = 1.7561\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.0785\n",
      "Comparison loss = 1.7822\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.6440\n",
      "Comparison loss = 1.6502\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.3119\n",
      "Comparison loss = 1.5179\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.0536\n",
      "Comparison loss = 1.5286\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.9236\n",
      "Comparison loss = 1.4236\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.7963\n",
      "Comparison loss = 1.3847\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.6836\n",
      "Comparison loss = 1.3348\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.6144\n",
      "Comparison loss = 1.2569\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.5621\n",
      "Comparison loss = 1.2106\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.5227\n",
      "Comparison loss = 1.1539\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.4988\n",
      "Comparison loss = 1.1210\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4808\n",
      "Comparison loss = 1.1017\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4723\n",
      "Comparison loss = 1.0837\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4669\n",
      "Comparison loss = 1.0639\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4597\n",
      "Comparison loss = 1.0398\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.4563\n",
      "Comparison loss = 1.0156\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 1.100% \n",
      "Comparison = 0.800%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.750% \n",
      "Comparison = 4.200%\u001b[0m\n",
      "RUN NO 5\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.4777\n",
      "Comparison loss = 5.5472\n",
      "Epoch no 2 : \n",
      "Classification loss = 43.1396\n",
      "Comparison loss = 4.0794\n",
      "Epoch no 3 : \n",
      "Classification loss = 40.2659\n",
      "Comparison loss = 3.7460\n",
      "Epoch no 4 : \n",
      "Classification loss = 37.2140\n",
      "Comparison loss = 3.3800\n",
      "Epoch no 5 : \n",
      "Classification loss = 35.0737\n",
      "Comparison loss = 2.5791\n",
      "Epoch no 6 : \n",
      "Classification loss = 33.7143\n",
      "Comparison loss = 2.4463\n",
      "Epoch no 7 : \n",
      "Classification loss = 32.5118\n",
      "Comparison loss = 2.0664\n",
      "Epoch no 8 : \n",
      "Classification loss = 31.2116\n",
      "Comparison loss = 1.8462\n",
      "Epoch no 9 : \n",
      "Classification loss = 30.9056\n",
      "Comparison loss = 1.6512\n",
      "Epoch no 10 : \n",
      "Classification loss = 30.3092\n",
      "Comparison loss = 1.4231\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.1316\n",
      "Comparison loss = 1.3990\n",
      "Epoch no 12 : \n",
      "Classification loss = 29.8879\n",
      "Comparison loss = 1.2605\n",
      "Epoch no 13 : \n",
      "Classification loss = 29.7462\n",
      "Comparison loss = 1.1719\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.5991\n",
      "Comparison loss = 1.1073\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.5463\n",
      "Comparison loss = 1.0489\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.4759\n",
      "Comparison loss = 1.0279\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.4339\n",
      "Comparison loss = 0.9947\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.4020\n",
      "Comparison loss = 0.9662\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.3823\n",
      "Comparison loss = 0.9472\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.3617\n",
      "Comparison loss = 0.9219\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.3398\n",
      "Comparison loss = 0.8864\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.3203\n",
      "Comparison loss = 0.8733\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.3084\n",
      "Comparison loss = 0.8636\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.2956\n",
      "Comparison loss = 0.8534\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.2871\n",
      "Comparison loss = 0.8441\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.200% \n",
      "Comparison = 0.500%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 5.000% \n",
      "Comparison = 3.500%\u001b[0m\n",
      "RUN NO 6\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.5725\n",
      "Comparison loss = 5.8849\n",
      "Epoch no 2 : \n",
      "Classification loss = 43.3226\n",
      "Comparison loss = 4.4770\n",
      "Epoch no 3 : \n",
      "Classification loss = 39.6059\n",
      "Comparison loss = 4.0545\n",
      "Epoch no 4 : \n",
      "Classification loss = 36.3020\n",
      "Comparison loss = 3.5109\n",
      "Epoch no 5 : \n",
      "Classification loss = 34.2232\n",
      "Comparison loss = 2.6008\n",
      "Epoch no 6 : \n",
      "Classification loss = 33.2613\n",
      "Comparison loss = 2.5635\n",
      "Epoch no 7 : \n",
      "Classification loss = 33.0743\n",
      "Comparison loss = 2.6843\n",
      "Epoch no 8 : \n",
      "Classification loss = 32.5223\n",
      "Comparison loss = 2.2543\n",
      "Epoch no 9 : \n",
      "Classification loss = 32.1440\n",
      "Comparison loss = 1.8514\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.7946\n",
      "Comparison loss = 1.7622\n",
      "Epoch no 11 : \n",
      "Classification loss = 31.1169\n",
      "Comparison loss = 1.4917\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.6345\n",
      "Comparison loss = 1.4686\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.5768\n",
      "Comparison loss = 1.4330\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.2173\n",
      "Comparison loss = 1.4105\n",
      "Epoch no 15 : \n",
      "Classification loss = 30.0460\n",
      "Comparison loss = 1.4237\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.8394\n",
      "Comparison loss = 1.2450\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.7252\n",
      "Comparison loss = 1.1604\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.6295\n",
      "Comparison loss = 1.0853\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.5825\n",
      "Comparison loss = 1.0778\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.5247\n",
      "Comparison loss = 0.9950\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4809\n",
      "Comparison loss = 0.9056\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4551\n",
      "Comparison loss = 0.8711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch no 23 : \n",
      "Classification loss = 29.4386\n",
      "Comparison loss = 0.8475\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4227\n",
      "Comparison loss = 0.8410\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.4092\n",
      "Comparison loss = 0.8375\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.800% \n",
      "Comparison = 0.700%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.650% \n",
      "Comparison = 3.600%\u001b[0m\n",
      "RUN NO 7\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.6170\n",
      "Comparison loss = 5.9312\n",
      "Epoch no 2 : \n",
      "Classification loss = 43.5229\n",
      "Comparison loss = 4.1097\n",
      "Epoch no 3 : \n",
      "Classification loss = 40.0578\n",
      "Comparison loss = 3.6499\n",
      "Epoch no 4 : \n",
      "Classification loss = 37.3553\n",
      "Comparison loss = 3.1599\n",
      "Epoch no 5 : \n",
      "Classification loss = 35.6262\n",
      "Comparison loss = 2.6284\n",
      "Epoch no 6 : \n",
      "Classification loss = 34.4554\n",
      "Comparison loss = 2.6046\n",
      "Epoch no 7 : \n",
      "Classification loss = 33.5839\n",
      "Comparison loss = 2.5013\n",
      "Epoch no 8 : \n",
      "Classification loss = 33.0580\n",
      "Comparison loss = 2.7365\n",
      "Epoch no 9 : \n",
      "Classification loss = 32.4616\n",
      "Comparison loss = 1.7460\n",
      "Epoch no 10 : \n",
      "Classification loss = 32.1834\n",
      "Comparison loss = 1.6874\n",
      "Epoch no 11 : \n",
      "Classification loss = 31.9877\n",
      "Comparison loss = 1.6226\n",
      "Epoch no 12 : \n",
      "Classification loss = 31.4433\n",
      "Comparison loss = 1.5500\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.7758\n",
      "Comparison loss = 1.1620\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.6592\n",
      "Comparison loss = 1.2095\n",
      "Epoch no 15 : \n",
      "Classification loss = 30.3688\n",
      "Comparison loss = 1.2543\n",
      "Epoch no 16 : \n",
      "Classification loss = 30.2212\n",
      "Comparison loss = 1.2014\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.9686\n",
      "Comparison loss = 1.0297\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.8286\n",
      "Comparison loss = 1.0160\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.6955\n",
      "Comparison loss = 0.9145\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.5934\n",
      "Comparison loss = 0.8742\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.5467\n",
      "Comparison loss = 0.8484\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.5037\n",
      "Comparison loss = 0.8400\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4643\n",
      "Comparison loss = 0.8045\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4491\n",
      "Comparison loss = 0.7929\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.4384\n",
      "Comparison loss = 0.7852\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.900% \n",
      "Comparison = 0.200%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 5.150% \n",
      "Comparison = 3.600%\u001b[0m\n",
      "RUN NO 8\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.2952\n",
      "Comparison loss = 5.4865\n",
      "Epoch no 2 : \n",
      "Classification loss = 42.8995\n",
      "Comparison loss = 4.1115\n",
      "Epoch no 3 : \n",
      "Classification loss = 40.6323\n",
      "Comparison loss = 4.1367\n",
      "Epoch no 4 : \n",
      "Classification loss = 38.6039\n",
      "Comparison loss = 3.5653\n",
      "Epoch no 5 : \n",
      "Classification loss = 36.4488\n",
      "Comparison loss = 2.9022\n",
      "Epoch no 6 : \n",
      "Classification loss = 34.1385\n",
      "Comparison loss = 2.2189\n",
      "Epoch no 7 : \n",
      "Classification loss = 33.2626\n",
      "Comparison loss = 2.4170\n",
      "Epoch no 8 : \n",
      "Classification loss = 33.2090\n",
      "Comparison loss = 2.4982\n",
      "Epoch no 9 : \n",
      "Classification loss = 32.6453\n",
      "Comparison loss = 3.3257\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.8669\n",
      "Comparison loss = 1.8515\n",
      "Epoch no 11 : \n",
      "Classification loss = 31.0824\n",
      "Comparison loss = 1.7017\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.5463\n",
      "Comparison loss = 1.4151\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.3403\n",
      "Comparison loss = 1.0913\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.0927\n",
      "Comparison loss = 1.0937\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.9349\n",
      "Comparison loss = 0.9553\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.8415\n",
      "Comparison loss = 0.9488\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.7065\n",
      "Comparison loss = 0.9029\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.7075\n",
      "Comparison loss = 0.8980\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.6022\n",
      "Comparison loss = 0.8438\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.5820\n",
      "Comparison loss = 0.8377\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.5340\n",
      "Comparison loss = 0.8361\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.5194\n",
      "Comparison loss = 0.8298\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4961\n",
      "Comparison loss = 0.8207\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4753\n",
      "Comparison loss = 0.8153\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.4552\n",
      "Comparison loss = 0.8094\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 1.050% \n",
      "Comparison = 0.300%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.800% \n",
      "Comparison = 3.900%\u001b[0m\n",
      "RUN NO 9\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.5891\n",
      "Comparison loss = 5.9747\n",
      "Epoch no 2 : \n",
      "Classification loss = 43.9232\n",
      "Comparison loss = 4.5248\n",
      "Epoch no 3 : \n",
      "Classification loss = 42.1385\n",
      "Comparison loss = 5.3333\n",
      "Epoch no 4 : \n",
      "Classification loss = 39.8045\n",
      "Comparison loss = 5.1712\n",
      "Epoch no 5 : \n",
      "Classification loss = 37.3232\n",
      "Comparison loss = 4.1482\n",
      "Epoch no 6 : \n",
      "Classification loss = 35.7256\n",
      "Comparison loss = 3.0955\n",
      "Epoch no 7 : \n",
      "Classification loss = 34.5188\n",
      "Comparison loss = 2.6574\n",
      "Epoch no 8 : \n",
      "Classification loss = 33.4028\n",
      "Comparison loss = 2.2396\n",
      "Epoch no 9 : \n",
      "Classification loss = 32.8041\n",
      "Comparison loss = 2.1081\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.9933\n",
      "Comparison loss = 1.7122\n",
      "Epoch no 11 : \n",
      "Classification loss = 31.5042\n",
      "Comparison loss = 1.8118\n",
      "Epoch no 12 : \n",
      "Classification loss = 31.5596\n",
      "Comparison loss = 1.9630\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.6882\n",
      "Comparison loss = 1.4257\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.6957\n",
      "Comparison loss = 1.4560\n",
      "Epoch no 15 : \n",
      "Classification loss = 30.2996\n",
      "Comparison loss = 1.0550\n",
      "Epoch no 16 : \n",
      "Classification loss = 30.0805\n",
      "Comparison loss = 1.0294\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.9373\n",
      "Comparison loss = 0.9716\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.8635\n",
      "Comparison loss = 0.9299\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.7116\n",
      "Comparison loss = 0.8532\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.6501\n",
      "Comparison loss = 0.8102\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.5610\n",
      "Comparison loss = 0.7559\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.5319\n",
      "Comparison loss = 0.7430\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4888\n",
      "Comparison loss = 0.7501\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4614\n",
      "Comparison loss = 0.7337\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.4366\n",
      "Comparison loss = 0.7135\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.850% \n",
      "Comparison = 0.100%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 5.150% \n",
      "Comparison = 4.300%\u001b[0m\n",
      "RUN NO 10\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.7087\n",
      "Comparison loss = 6.3016\n",
      "Epoch no 2 : \n",
      "Classification loss = 44.1978\n",
      "Comparison loss = 4.7037\n",
      "Epoch no 3 : \n",
      "Classification loss = 42.4914\n",
      "Comparison loss = 4.9235\n",
      "Epoch no 4 : \n",
      "Classification loss = 41.1176\n",
      "Comparison loss = 3.8412\n",
      "Epoch no 5 : \n",
      "Classification loss = 39.3312\n",
      "Comparison loss = 3.1190\n",
      "Epoch no 6 : \n",
      "Classification loss = 37.0575\n",
      "Comparison loss = 2.8624\n",
      "Epoch no 7 : \n",
      "Classification loss = 34.9858\n",
      "Comparison loss = 2.1944\n",
      "Epoch no 8 : \n",
      "Classification loss = 33.3692\n",
      "Comparison loss = 2.3015\n",
      "Epoch no 9 : \n",
      "Classification loss = 32.5862\n",
      "Comparison loss = 2.0320\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.7421\n",
      "Comparison loss = 1.7257\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.7768\n",
      "Comparison loss = 1.3578\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.5360\n",
      "Comparison loss = 1.3131\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.1788\n",
      "Comparison loss = 1.2320\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.1129\n",
      "Comparison loss = 1.1333\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.8538\n",
      "Comparison loss = 1.0208\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.8074\n",
      "Comparison loss = 0.9257\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.6706\n",
      "Comparison loss = 0.8917\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.5691\n",
      "Comparison loss = 0.8636\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.5235\n",
      "Comparison loss = 0.8419\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.4828\n",
      "Comparison loss = 0.8294\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4444\n",
      "Comparison loss = 0.7792\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4155\n",
      "Comparison loss = 0.7260\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.3987\n",
      "Comparison loss = 0.7186\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.3887\n",
      "Comparison loss = 0.7154\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3786\n",
      "Comparison loss = 0.7144\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.650% \n",
      "Comparison = 0.200%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.400% \n",
      "Comparison = 3.300%\u001b[0m\n",
      "Final error for train batch : 2.04±4.1261\n",
      "Final error for test batch : 5.15±3.5787\n",
      "RUN NO 1\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.2362\n",
      "Comparison loss = 6.9162\n",
      "Epoch no 2 : \n",
      "Classification loss = 42.0756\n",
      "Comparison loss = 6.8728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch no 3 : \n",
      "Classification loss = 38.5673\n",
      "Comparison loss = 6.8141\n",
      "Epoch no 4 : \n",
      "Classification loss = 36.7620\n",
      "Comparison loss = 6.7131\n",
      "Epoch no 5 : \n",
      "Classification loss = 35.1965\n",
      "Comparison loss = 6.5604\n",
      "Epoch no 6 : \n",
      "Classification loss = 34.0285\n",
      "Comparison loss = 6.3453\n",
      "Epoch no 7 : \n",
      "Classification loss = 32.7797\n",
      "Comparison loss = 5.9783\n",
      "Epoch no 8 : \n",
      "Classification loss = 31.8273\n",
      "Comparison loss = 5.4427\n",
      "Epoch no 9 : \n",
      "Classification loss = 31.1046\n",
      "Comparison loss = 4.7610\n",
      "Epoch no 10 : \n",
      "Classification loss = 30.7241\n",
      "Comparison loss = 4.0723\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.3957\n",
      "Comparison loss = 3.1016\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.4549\n",
      "Comparison loss = 2.4389\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.1909\n",
      "Comparison loss = 1.8111\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.8192\n",
      "Comparison loss = 1.3937\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.7563\n",
      "Comparison loss = 1.2090\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.6915\n",
      "Comparison loss = 0.9880\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.6377\n",
      "Comparison loss = 0.8191\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.5498\n",
      "Comparison loss = 0.8383\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.5178\n",
      "Comparison loss = 0.6755\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.4842\n",
      "Comparison loss = 0.6449\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4542\n",
      "Comparison loss = 0.5858\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4384\n",
      "Comparison loss = 0.4481\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4314\n",
      "Comparison loss = 0.3646\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4259\n",
      "Comparison loss = 0.3613\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.4215\n",
      "Comparison loss = 0.3288\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 1.000% \n",
      "Comparison = 0.500%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.700% \n",
      "Comparison = 3.800%\u001b[0m\n",
      "RUN NO 2\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.3679\n",
      "Comparison loss = 5.9642\n",
      "Epoch no 2 : \n",
      "Classification loss = 42.9204\n",
      "Comparison loss = 6.3735\n",
      "Epoch no 3 : \n",
      "Classification loss = 41.4214\n",
      "Comparison loss = 5.4246\n",
      "Epoch no 4 : \n",
      "Classification loss = 40.1069\n",
      "Comparison loss = 3.7847\n",
      "Epoch no 5 : \n",
      "Classification loss = 37.3288\n",
      "Comparison loss = 2.7655\n",
      "Epoch no 6 : \n",
      "Classification loss = 34.6844\n",
      "Comparison loss = 2.3260\n",
      "Epoch no 7 : \n",
      "Classification loss = 33.4736\n",
      "Comparison loss = 1.9004\n",
      "Epoch no 8 : \n",
      "Classification loss = 33.0798\n",
      "Comparison loss = 2.0299\n",
      "Epoch no 9 : \n",
      "Classification loss = 32.5404\n",
      "Comparison loss = 1.6156\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.9200\n",
      "Comparison loss = 1.4442\n",
      "Epoch no 11 : \n",
      "Classification loss = 31.2837\n",
      "Comparison loss = 1.0157\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.7697\n",
      "Comparison loss = 0.9507\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.6725\n",
      "Comparison loss = 0.8546\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.2333\n",
      "Comparison loss = 0.7120\n",
      "Epoch no 15 : \n",
      "Classification loss = 30.1251\n",
      "Comparison loss = 0.6239\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.9376\n",
      "Comparison loss = 0.4835\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.8385\n",
      "Comparison loss = 0.3976\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.6590\n",
      "Comparison loss = 0.3315\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.6116\n",
      "Comparison loss = 0.2793\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.5413\n",
      "Comparison loss = 0.2138\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4951\n",
      "Comparison loss = 0.1608\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4627\n",
      "Comparison loss = 0.0944\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4290\n",
      "Comparison loss = 0.0820\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4008\n",
      "Comparison loss = 0.0735\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3827\n",
      "Comparison loss = 0.0675\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.550% \n",
      "Comparison = 0.100%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.450% \n",
      "Comparison = 3.800%\u001b[0m\n",
      "RUN NO 3\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.5030\n",
      "Comparison loss = 5.2143\n",
      "Epoch no 2 : \n",
      "Classification loss = 43.4174\n",
      "Comparison loss = 5.1625\n",
      "Epoch no 3 : \n",
      "Classification loss = 41.4892\n",
      "Comparison loss = 4.9355\n",
      "Epoch no 4 : \n",
      "Classification loss = 39.5111\n",
      "Comparison loss = 4.4538\n",
      "Epoch no 5 : \n",
      "Classification loss = 37.7545\n",
      "Comparison loss = 3.1710\n",
      "Epoch no 6 : \n",
      "Classification loss = 35.9955\n",
      "Comparison loss = 2.6290\n",
      "Epoch no 7 : \n",
      "Classification loss = 34.6027\n",
      "Comparison loss = 2.2967\n",
      "Epoch no 8 : \n",
      "Classification loss = 33.6616\n",
      "Comparison loss = 2.0861\n",
      "Epoch no 9 : \n",
      "Classification loss = 32.9601\n",
      "Comparison loss = 1.9655\n",
      "Epoch no 10 : \n",
      "Classification loss = 32.5549\n",
      "Comparison loss = 1.5453\n",
      "Epoch no 11 : \n",
      "Classification loss = 32.3286\n",
      "Comparison loss = 1.3559\n",
      "Epoch no 12 : \n",
      "Classification loss = 31.7488\n",
      "Comparison loss = 1.0640\n",
      "Epoch no 13 : \n",
      "Classification loss = 31.2306\n",
      "Comparison loss = 1.0557\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.6979\n",
      "Comparison loss = 0.8872\n",
      "Epoch no 15 : \n",
      "Classification loss = 30.2939\n",
      "Comparison loss = 0.7712\n",
      "Epoch no 16 : \n",
      "Classification loss = 30.1413\n",
      "Comparison loss = 0.6784\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.9676\n",
      "Comparison loss = 0.5151\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.9349\n",
      "Comparison loss = 0.5509\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.8102\n",
      "Comparison loss = 0.4634\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.9506\n",
      "Comparison loss = 0.3972\n",
      "Epoch no 21 : \n",
      "Classification loss = 30.0932\n",
      "Comparison loss = 0.8397\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.9040\n",
      "Comparison loss = 0.5137\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.8137\n",
      "Comparison loss = 0.4709\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.6692\n",
      "Comparison loss = 0.3115\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.6285\n",
      "Comparison loss = 0.2297\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 1.550% \n",
      "Comparison = 0.500%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 5.250% \n",
      "Comparison = 3.800%\u001b[0m\n",
      "RUN NO 4\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.6601\n",
      "Comparison loss = 5.4570\n",
      "Epoch no 2 : \n",
      "Classification loss = 43.7608\n",
      "Comparison loss = 4.6750\n",
      "Epoch no 3 : \n",
      "Classification loss = 41.3269\n",
      "Comparison loss = 4.5072\n",
      "Epoch no 4 : \n",
      "Classification loss = 39.3260\n",
      "Comparison loss = 3.8464\n",
      "Epoch no 5 : \n",
      "Classification loss = 37.4528\n",
      "Comparison loss = 3.5466\n",
      "Epoch no 6 : \n",
      "Classification loss = 35.6844\n",
      "Comparison loss = 2.5378\n",
      "Epoch no 7 : \n",
      "Classification loss = 34.4206\n",
      "Comparison loss = 2.0972\n",
      "Epoch no 8 : \n",
      "Classification loss = 33.5003\n",
      "Comparison loss = 1.8511\n",
      "Epoch no 9 : \n",
      "Classification loss = 32.5331\n",
      "Comparison loss = 1.5855\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.6420\n",
      "Comparison loss = 1.2331\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.9070\n",
      "Comparison loss = 0.9648\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.6846\n",
      "Comparison loss = 0.8841\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.3224\n",
      "Comparison loss = 0.7961\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.1074\n",
      "Comparison loss = 0.6301\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.9656\n",
      "Comparison loss = 0.5168\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.8182\n",
      "Comparison loss = 0.3172\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.7132\n",
      "Comparison loss = 0.2662\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.6066\n",
      "Comparison loss = 0.2527\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.5542\n",
      "Comparison loss = 0.2007\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.5010\n",
      "Comparison loss = 0.1861\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4777\n",
      "Comparison loss = 0.1712\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4676\n",
      "Comparison loss = 0.1644\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4556\n",
      "Comparison loss = 0.1583\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4431\n",
      "Comparison loss = 0.1509\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.4307\n",
      "Comparison loss = 0.1350\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.850% \n",
      "Comparison = 0.100%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.800% \n",
      "Comparison = 3.600%\u001b[0m\n",
      "RUN NO 5\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.7038\n",
      "Comparison loss = 5.4150\n",
      "Epoch no 2 : \n",
      "Classification loss = 43.7657\n",
      "Comparison loss = 4.8456\n",
      "Epoch no 3 : \n",
      "Classification loss = 41.0249\n",
      "Comparison loss = 4.4577\n",
      "Epoch no 4 : \n",
      "Classification loss = 38.6658\n",
      "Comparison loss = 3.5641\n",
      "Epoch no 5 : \n",
      "Classification loss = 36.5974\n",
      "Comparison loss = 3.0616\n",
      "Epoch no 6 : \n",
      "Classification loss = 35.2869\n",
      "Comparison loss = 3.7285\n",
      "Epoch no 7 : \n",
      "Classification loss = 33.7231\n",
      "Comparison loss = 1.9972\n",
      "Epoch no 8 : \n",
      "Classification loss = 32.6493\n",
      "Comparison loss = 1.7461\n",
      "Epoch no 9 : \n",
      "Classification loss = 31.9385\n",
      "Comparison loss = 1.3534\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.2610\n",
      "Comparison loss = 1.3987\n",
      "Epoch no 11 : \n",
      "Classification loss = 31.3521\n",
      "Comparison loss = 1.1741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch no 12 : \n",
      "Classification loss = 30.6274\n",
      "Comparison loss = 0.9219\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.4837\n",
      "Comparison loss = 1.0900\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.2224\n",
      "Comparison loss = 0.7493\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.9659\n",
      "Comparison loss = 0.5428\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.8641\n",
      "Comparison loss = 0.5183\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.6701\n",
      "Comparison loss = 0.4266\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.5959\n",
      "Comparison loss = 0.3728\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.5463\n",
      "Comparison loss = 0.2914\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.4948\n",
      "Comparison loss = 0.2507\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4513\n",
      "Comparison loss = 0.2019\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4238\n",
      "Comparison loss = 0.1859\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4084\n",
      "Comparison loss = 0.1722\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4014\n",
      "Comparison loss = 0.1545\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3967\n",
      "Comparison loss = 0.1461\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.750% \n",
      "Comparison = 0.200%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.000% \n",
      "Comparison = 3.400%\u001b[0m\n",
      "RUN NO 6\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.6347\n",
      "Comparison loss = 5.7548\n",
      "Epoch no 2 : \n",
      "Classification loss = 43.9690\n",
      "Comparison loss = 4.9595\n",
      "Epoch no 3 : \n",
      "Classification loss = 42.0893\n",
      "Comparison loss = 5.2195\n",
      "Epoch no 4 : \n",
      "Classification loss = 40.5934\n",
      "Comparison loss = 4.9041\n",
      "Epoch no 5 : \n",
      "Classification loss = 38.7153\n",
      "Comparison loss = 3.4052\n",
      "Epoch no 6 : \n",
      "Classification loss = 36.4454\n",
      "Comparison loss = 2.8058\n",
      "Epoch no 7 : \n",
      "Classification loss = 34.4182\n",
      "Comparison loss = 2.3151\n",
      "Epoch no 8 : \n",
      "Classification loss = 33.2790\n",
      "Comparison loss = 1.8034\n",
      "Epoch no 9 : \n",
      "Classification loss = 32.7618\n",
      "Comparison loss = 1.7436\n",
      "Epoch no 10 : \n",
      "Classification loss = 32.4156\n",
      "Comparison loss = 1.4637\n",
      "Epoch no 11 : \n",
      "Classification loss = 31.8042\n",
      "Comparison loss = 1.1565\n",
      "Epoch no 12 : \n",
      "Classification loss = 31.2838\n",
      "Comparison loss = 1.1005\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.8743\n",
      "Comparison loss = 0.7920\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.5955\n",
      "Comparison loss = 0.7317\n",
      "Epoch no 15 : \n",
      "Classification loss = 30.2857\n",
      "Comparison loss = 0.7379\n",
      "Epoch no 16 : \n",
      "Classification loss = 30.2945\n",
      "Comparison loss = 0.5640\n",
      "Epoch no 17 : \n",
      "Classification loss = 30.0270\n",
      "Comparison loss = 0.5580\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.9584\n",
      "Comparison loss = 0.4786\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.8038\n",
      "Comparison loss = 0.4317\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.7436\n",
      "Comparison loss = 0.4175\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.6694\n",
      "Comparison loss = 0.3596\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.5763\n",
      "Comparison loss = 0.2831\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.5484\n",
      "Comparison loss = 0.2901\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.5097\n",
      "Comparison loss = 0.2771\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.5110\n",
      "Comparison loss = 0.2076\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 1.200% \n",
      "Comparison = 0.300%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.500% \n",
      "Comparison = 3.400%\u001b[0m\n",
      "RUN NO 7\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.6819\n",
      "Comparison loss = 5.4765\n",
      "Epoch no 2 : \n",
      "Classification loss = 44.0134\n",
      "Comparison loss = 4.9273\n",
      "Epoch no 3 : \n",
      "Classification loss = 41.7509\n",
      "Comparison loss = 5.2868\n",
      "Epoch no 4 : \n",
      "Classification loss = 40.2847\n",
      "Comparison loss = 4.4656\n",
      "Epoch no 5 : \n",
      "Classification loss = 37.9078\n",
      "Comparison loss = 3.4614\n",
      "Epoch no 6 : \n",
      "Classification loss = 36.1295\n",
      "Comparison loss = 2.7060\n",
      "Epoch no 7 : \n",
      "Classification loss = 34.3693\n",
      "Comparison loss = 2.2968\n",
      "Epoch no 8 : \n",
      "Classification loss = 33.3315\n",
      "Comparison loss = 2.6213\n",
      "Epoch no 9 : \n",
      "Classification loss = 32.2994\n",
      "Comparison loss = 1.6231\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.4414\n",
      "Comparison loss = 1.3250\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.9930\n",
      "Comparison loss = 1.0694\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.6284\n",
      "Comparison loss = 0.8852\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.3765\n",
      "Comparison loss = 0.8329\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.1582\n",
      "Comparison loss = 0.6779\n",
      "Epoch no 15 : \n",
      "Classification loss = 30.0375\n",
      "Comparison loss = 0.6369\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.8551\n",
      "Comparison loss = 0.5012\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.8316\n",
      "Comparison loss = 0.3971\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.7518\n",
      "Comparison loss = 0.4285\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.6543\n",
      "Comparison loss = 0.3447\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.6077\n",
      "Comparison loss = 0.3687\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.5766\n",
      "Comparison loss = 0.3059\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.5197\n",
      "Comparison loss = 0.2450\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4824\n",
      "Comparison loss = 0.2272\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4594\n",
      "Comparison loss = 0.1858\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.4395\n",
      "Comparison loss = 0.1809\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.950% \n",
      "Comparison = 0.300%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.700% \n",
      "Comparison = 3.000%\u001b[0m\n",
      "RUN NO 8\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.3468\n",
      "Comparison loss = 5.2078\n",
      "Epoch no 2 : \n",
      "Classification loss = 42.6431\n",
      "Comparison loss = 4.2436\n",
      "Epoch no 3 : \n",
      "Classification loss = 39.4405\n",
      "Comparison loss = 3.4454\n",
      "Epoch no 4 : \n",
      "Classification loss = 36.6830\n",
      "Comparison loss = 3.1276\n",
      "Epoch no 5 : \n",
      "Classification loss = 35.2453\n",
      "Comparison loss = 3.0748\n",
      "Epoch no 6 : \n",
      "Classification loss = 34.4194\n",
      "Comparison loss = 2.2104\n",
      "Epoch no 7 : \n",
      "Classification loss = 33.2523\n",
      "Comparison loss = 1.7372\n",
      "Epoch no 8 : \n",
      "Classification loss = 32.3573\n",
      "Comparison loss = 1.6872\n",
      "Epoch no 9 : \n",
      "Classification loss = 31.9832\n",
      "Comparison loss = 1.4150\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.3766\n",
      "Comparison loss = 0.9802\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.8271\n",
      "Comparison loss = 0.8538\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.5963\n",
      "Comparison loss = 0.8529\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.2696\n",
      "Comparison loss = 0.5131\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.0880\n",
      "Comparison loss = 0.5154\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.9847\n",
      "Comparison loss = 0.5713\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.9649\n",
      "Comparison loss = 0.4031\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.7995\n",
      "Comparison loss = 0.2113\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.6595\n",
      "Comparison loss = 0.1820\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.6319\n",
      "Comparison loss = 0.2509\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.5430\n",
      "Comparison loss = 0.1969\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.5255\n",
      "Comparison loss = 0.2003\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4467\n",
      "Comparison loss = 0.0966\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4118\n",
      "Comparison loss = 0.0923\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4038\n",
      "Comparison loss = 0.1166\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.4097\n",
      "Comparison loss = 0.0952\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.650% \n",
      "Comparison = 0.100%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.700% \n",
      "Comparison = 3.300%\u001b[0m\n",
      "RUN NO 9\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.4950\n",
      "Comparison loss = 5.5704\n",
      "Epoch no 2 : \n",
      "Classification loss = 43.0499\n",
      "Comparison loss = 4.3977\n",
      "Epoch no 3 : \n",
      "Classification loss = 40.4081\n",
      "Comparison loss = 4.0441\n",
      "Epoch no 4 : \n",
      "Classification loss = 37.9203\n",
      "Comparison loss = 2.9694\n",
      "Epoch no 5 : \n",
      "Classification loss = 35.4630\n",
      "Comparison loss = 2.1557\n",
      "Epoch no 6 : \n",
      "Classification loss = 33.5770\n",
      "Comparison loss = 1.5883\n",
      "Epoch no 7 : \n",
      "Classification loss = 32.7770\n",
      "Comparison loss = 1.8629\n",
      "Epoch no 8 : \n",
      "Classification loss = 32.4972\n",
      "Comparison loss = 1.6640\n",
      "Epoch no 9 : \n",
      "Classification loss = 32.1268\n",
      "Comparison loss = 1.1891\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.7990\n",
      "Comparison loss = 1.1671\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.9935\n",
      "Comparison loss = 0.9837\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.4489\n",
      "Comparison loss = 0.7911\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.2238\n",
      "Comparison loss = 0.5635\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.9610\n",
      "Comparison loss = 0.4617\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.8751\n",
      "Comparison loss = 0.4111\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.7131\n",
      "Comparison loss = 0.3088\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.5929\n",
      "Comparison loss = 0.2400\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.5055\n",
      "Comparison loss = 0.2107\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.4716\n",
      "Comparison loss = 0.1903\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.4244\n",
      "Comparison loss = 0.1685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch no 21 : \n",
      "Classification loss = 29.3905\n",
      "Comparison loss = 0.1094\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.3773\n",
      "Comparison loss = 0.0919\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.3693\n",
      "Comparison loss = 0.1149\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.3640\n",
      "Comparison loss = 0.0989\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3587\n",
      "Comparison loss = 0.0752\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.650% \n",
      "Comparison = 0.100%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.600% \n",
      "Comparison = 3.100%\u001b[0m\n",
      "RUN NO 10\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.6248\n",
      "Comparison loss = 5.8314\n",
      "Epoch no 2 : \n",
      "Classification loss = 43.7089\n",
      "Comparison loss = 4.8013\n",
      "Epoch no 3 : \n",
      "Classification loss = 41.3057\n",
      "Comparison loss = 4.4590\n",
      "Epoch no 4 : \n",
      "Classification loss = 39.2625\n",
      "Comparison loss = 3.4825\n",
      "Epoch no 5 : \n",
      "Classification loss = 37.1705\n",
      "Comparison loss = 3.1870\n",
      "Epoch no 6 : \n",
      "Classification loss = 35.5151\n",
      "Comparison loss = 2.8583\n",
      "Epoch no 7 : \n",
      "Classification loss = 34.2482\n",
      "Comparison loss = 3.1683\n",
      "Epoch no 8 : \n",
      "Classification loss = 33.4993\n",
      "Comparison loss = 2.0512\n",
      "Epoch no 9 : \n",
      "Classification loss = 33.3794\n",
      "Comparison loss = 2.1085\n",
      "Epoch no 10 : \n",
      "Classification loss = 32.0906\n",
      "Comparison loss = 1.3428\n",
      "Epoch no 11 : \n",
      "Classification loss = 31.6947\n",
      "Comparison loss = 1.3088\n",
      "Epoch no 12 : \n",
      "Classification loss = 31.2683\n",
      "Comparison loss = 1.0726\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.6948\n",
      "Comparison loss = 0.9019\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.4169\n",
      "Comparison loss = 0.8434\n",
      "Epoch no 15 : \n",
      "Classification loss = 30.3410\n",
      "Comparison loss = 0.6470\n",
      "Epoch no 16 : \n",
      "Classification loss = 30.0776\n",
      "Comparison loss = 0.4676\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.9930\n",
      "Comparison loss = 0.4274\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.8561\n",
      "Comparison loss = 0.3732\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.7744\n",
      "Comparison loss = 0.2732\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.6988\n",
      "Comparison loss = 0.2180\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.6455\n",
      "Comparison loss = 0.1860\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.5935\n",
      "Comparison loss = 0.1744\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.5631\n",
      "Comparison loss = 0.1676\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.5436\n",
      "Comparison loss = 0.1574\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.5195\n",
      "Comparison loss = 0.1518\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 1.250% \n",
      "Comparison = 0.400%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 6.250% \n",
      "Comparison = 4.600%\u001b[0m\n",
      "Final error for train batch : 0.26±0.1647\n",
      "Final error for test batch : 3.58±0.4590\n",
      "RUN NO 1\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.4480\n",
      "Comparison loss = 6.9640\n",
      "Epoch no 2 : \n",
      "Classification loss = 42.8740\n",
      "Comparison loss = 6.9252\n",
      "Epoch no 3 : \n",
      "Classification loss = 38.9666\n",
      "Comparison loss = 6.8846\n",
      "Epoch no 4 : \n",
      "Classification loss = 36.4901\n",
      "Comparison loss = 6.8210\n",
      "Epoch no 5 : \n",
      "Classification loss = 34.9039\n",
      "Comparison loss = 6.7025\n",
      "Epoch no 6 : \n",
      "Classification loss = 34.2614\n",
      "Comparison loss = 6.4776\n",
      "Epoch no 7 : \n",
      "Classification loss = 33.7914\n",
      "Comparison loss = 6.0650\n",
      "Epoch no 8 : \n",
      "Classification loss = 32.5726\n",
      "Comparison loss = 5.4735\n",
      "Epoch no 9 : \n",
      "Classification loss = 32.2730\n",
      "Comparison loss = 4.6852\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.7636\n",
      "Comparison loss = 3.7533\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.9208\n",
      "Comparison loss = 2.7014\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.4799\n",
      "Comparison loss = 1.9041\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.1911\n",
      "Comparison loss = 1.3850\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.9490\n",
      "Comparison loss = 0.9713\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.7876\n",
      "Comparison loss = 0.6516\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.7583\n",
      "Comparison loss = 0.6592\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.7793\n",
      "Comparison loss = 0.6098\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.6012\n",
      "Comparison loss = 0.4793\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.5922\n",
      "Comparison loss = 0.4405\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.5770\n",
      "Comparison loss = 0.4684\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4805\n",
      "Comparison loss = 0.2969\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4586\n",
      "Comparison loss = 0.2139\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4208\n",
      "Comparison loss = 0.1846\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.3979\n",
      "Comparison loss = 0.1813\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3856\n",
      "Comparison loss = 0.1734\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.700% \n",
      "Comparison = 0.200%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 3.950% \n",
      "Comparison = 3.200%\u001b[0m\n",
      "RUN NO 2\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.2972\n",
      "Comparison loss = 6.8189\n",
      "Epoch no 2 : \n",
      "Classification loss = 42.9126\n",
      "Comparison loss = 7.3411\n",
      "Epoch no 3 : \n",
      "Classification loss = 40.8933\n",
      "Comparison loss = 6.4010\n",
      "Epoch no 4 : \n",
      "Classification loss = 39.3218\n",
      "Comparison loss = 4.4832\n",
      "Epoch no 5 : \n",
      "Classification loss = 37.4394\n",
      "Comparison loss = 3.2879\n",
      "Epoch no 6 : \n",
      "Classification loss = 35.5493\n",
      "Comparison loss = 3.0412\n",
      "Epoch no 7 : \n",
      "Classification loss = 34.2063\n",
      "Comparison loss = 2.5453\n",
      "Epoch no 8 : \n",
      "Classification loss = 33.3050\n",
      "Comparison loss = 1.6247\n",
      "Epoch no 9 : \n",
      "Classification loss = 32.3903\n",
      "Comparison loss = 1.4740\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.5276\n",
      "Comparison loss = 1.2388\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.8296\n",
      "Comparison loss = 0.8597\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.5290\n",
      "Comparison loss = 0.6938\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.2449\n",
      "Comparison loss = 0.7521\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.1484\n",
      "Comparison loss = 0.4826\n",
      "Epoch no 15 : \n",
      "Classification loss = 30.0320\n",
      "Comparison loss = 0.4767\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.8540\n",
      "Comparison loss = 0.4094\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.8190\n",
      "Comparison loss = 0.3825\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.6477\n",
      "Comparison loss = 0.2490\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.5882\n",
      "Comparison loss = 0.2332\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.5438\n",
      "Comparison loss = 0.2175\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4602\n",
      "Comparison loss = 0.2044\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4204\n",
      "Comparison loss = 0.1987\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4049\n",
      "Comparison loss = 0.1928\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4026\n",
      "Comparison loss = 0.1876\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3897\n",
      "Comparison loss = 0.1825\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.750% \n",
      "Comparison = 0.200%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.250% \n",
      "Comparison = 3.400%\u001b[0m\n",
      "RUN NO 3\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.5529\n",
      "Comparison loss = 6.3910\n",
      "Epoch no 2 : \n",
      "Classification loss = 43.5930\n",
      "Comparison loss = 6.9440\n",
      "Epoch no 3 : \n",
      "Classification loss = 41.3394\n",
      "Comparison loss = 5.1814\n",
      "Epoch no 4 : \n",
      "Classification loss = 38.6878\n",
      "Comparison loss = 3.5239\n",
      "Epoch no 5 : \n",
      "Classification loss = 36.8312\n",
      "Comparison loss = 3.0153\n",
      "Epoch no 6 : \n",
      "Classification loss = 34.9067\n",
      "Comparison loss = 2.6850\n",
      "Epoch no 7 : \n",
      "Classification loss = 33.2789\n",
      "Comparison loss = 1.7848\n",
      "Epoch no 8 : \n",
      "Classification loss = 32.6294\n",
      "Comparison loss = 1.7975\n",
      "Epoch no 9 : \n",
      "Classification loss = 32.6243\n",
      "Comparison loss = 2.2158\n",
      "Epoch no 10 : \n",
      "Classification loss = 32.0308\n",
      "Comparison loss = 1.7166\n",
      "Epoch no 11 : \n",
      "Classification loss = 31.1560\n",
      "Comparison loss = 1.2340\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.8031\n",
      "Comparison loss = 1.2470\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.3232\n",
      "Comparison loss = 0.8117\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.1492\n",
      "Comparison loss = 0.7177\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.9147\n",
      "Comparison loss = 0.5316\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.8321\n",
      "Comparison loss = 0.5555\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.6982\n",
      "Comparison loss = 0.3695\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.5880\n",
      "Comparison loss = 0.3189\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.5490\n",
      "Comparison loss = 0.2662\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.5009\n",
      "Comparison loss = 0.2300\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4732\n",
      "Comparison loss = 0.2094\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4477\n",
      "Comparison loss = 0.1978\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4280\n",
      "Comparison loss = 0.1875\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4178\n",
      "Comparison loss = 0.1780\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.4059\n",
      "Comparison loss = 0.1698\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.750% \n",
      "Comparison = 0.300%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.950% \n",
      "Comparison = 4.100%\u001b[0m\n",
      "RUN NO 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch no 1 : \n",
      "Classification loss = 45.6152\n",
      "Comparison loss = 6.3885\n",
      "Epoch no 2 : \n",
      "Classification loss = 43.6203\n",
      "Comparison loss = 6.8495\n",
      "Epoch no 3 : \n",
      "Classification loss = 41.3565\n",
      "Comparison loss = 5.4456\n",
      "Epoch no 4 : \n",
      "Classification loss = 39.3892\n",
      "Comparison loss = 3.9104\n",
      "Epoch no 5 : \n",
      "Classification loss = 37.1878\n",
      "Comparison loss = 3.4546\n",
      "Epoch no 6 : \n",
      "Classification loss = 35.4394\n",
      "Comparison loss = 2.4308\n",
      "Epoch no 7 : \n",
      "Classification loss = 34.2731\n",
      "Comparison loss = 2.3129\n",
      "Epoch no 8 : \n",
      "Classification loss = 33.6293\n",
      "Comparison loss = 1.8935\n",
      "Epoch no 9 : \n",
      "Classification loss = 32.8188\n",
      "Comparison loss = 1.1736\n",
      "Epoch no 10 : \n",
      "Classification loss = 32.3863\n",
      "Comparison loss = 1.2932\n",
      "Epoch no 11 : \n",
      "Classification loss = 31.8907\n",
      "Comparison loss = 0.9786\n",
      "Epoch no 12 : \n",
      "Classification loss = 31.1641\n",
      "Comparison loss = 0.8003\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.7060\n",
      "Comparison loss = 0.8733\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.3658\n",
      "Comparison loss = 0.6274\n",
      "Epoch no 15 : \n",
      "Classification loss = 30.1754\n",
      "Comparison loss = 0.7752\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.9706\n",
      "Comparison loss = 0.5796\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.7796\n",
      "Comparison loss = 0.4297\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.6948\n",
      "Comparison loss = 0.3667\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.5974\n",
      "Comparison loss = 0.4072\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.5477\n",
      "Comparison loss = 0.2811\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4853\n",
      "Comparison loss = 0.2396\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4653\n",
      "Comparison loss = 0.2002\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4366\n",
      "Comparison loss = 0.2049\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4273\n",
      "Comparison loss = 0.1867\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.4107\n",
      "Comparison loss = 0.1790\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.800% \n",
      "Comparison = 0.200%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.100% \n",
      "Comparison = 3.000%\u001b[0m\n",
      "RUN NO 5\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.6785\n",
      "Comparison loss = 6.1167\n",
      "Epoch no 2 : \n",
      "Classification loss = 43.7281\n",
      "Comparison loss = 5.9129\n",
      "Epoch no 3 : \n",
      "Classification loss = 41.6524\n",
      "Comparison loss = 4.8769\n",
      "Epoch no 4 : \n",
      "Classification loss = 40.7095\n",
      "Comparison loss = 3.4761\n",
      "Epoch no 5 : \n",
      "Classification loss = 38.6691\n",
      "Comparison loss = 2.3627\n",
      "Epoch no 6 : \n",
      "Classification loss = 36.1709\n",
      "Comparison loss = 2.3036\n",
      "Epoch no 7 : \n",
      "Classification loss = 34.1284\n",
      "Comparison loss = 1.9816\n",
      "Epoch no 8 : \n",
      "Classification loss = 33.7284\n",
      "Comparison loss = 2.6813\n",
      "Epoch no 9 : \n",
      "Classification loss = 32.7610\n",
      "Comparison loss = 1.8029\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.4683\n",
      "Comparison loss = 1.1887\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.8919\n",
      "Comparison loss = 1.1069\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.6023\n",
      "Comparison loss = 0.8725\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.1810\n",
      "Comparison loss = 0.6914\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.0286\n",
      "Comparison loss = 0.6917\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.8785\n",
      "Comparison loss = 0.5566\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.7925\n",
      "Comparison loss = 0.4759\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.6808\n",
      "Comparison loss = 0.4066\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.6057\n",
      "Comparison loss = 0.3682\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.5759\n",
      "Comparison loss = 0.3354\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.5333\n",
      "Comparison loss = 0.2929\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.5102\n",
      "Comparison loss = 0.2686\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4720\n",
      "Comparison loss = 0.1656\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4488\n",
      "Comparison loss = 0.1480\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4365\n",
      "Comparison loss = 0.1410\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.4190\n",
      "Comparison loss = 0.1352\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.850% \n",
      "Comparison = 0.200%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 5.100% \n",
      "Comparison = 3.300%\u001b[0m\n",
      "RUN NO 6\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.8020\n",
      "Comparison loss = 6.6865\n",
      "Epoch no 2 : \n",
      "Classification loss = 44.3806\n",
      "Comparison loss = 5.7254\n",
      "Epoch no 3 : \n",
      "Classification loss = 42.4919\n",
      "Comparison loss = 4.7695\n",
      "Epoch no 4 : \n",
      "Classification loss = 41.1433\n",
      "Comparison loss = 4.4037\n",
      "Epoch no 5 : \n",
      "Classification loss = 39.4972\n",
      "Comparison loss = 3.1042\n",
      "Epoch no 6 : \n",
      "Classification loss = 37.4556\n",
      "Comparison loss = 2.9639\n",
      "Epoch no 7 : \n",
      "Classification loss = 35.6964\n",
      "Comparison loss = 2.1807\n",
      "Epoch no 8 : \n",
      "Classification loss = 34.1977\n",
      "Comparison loss = 1.7781\n",
      "Epoch no 9 : \n",
      "Classification loss = 33.5860\n",
      "Comparison loss = 2.4117\n",
      "Epoch no 10 : \n",
      "Classification loss = 32.9319\n",
      "Comparison loss = 1.6104\n",
      "Epoch no 11 : \n",
      "Classification loss = 31.9628\n",
      "Comparison loss = 1.1402\n",
      "Epoch no 12 : \n",
      "Classification loss = 31.1882\n",
      "Comparison loss = 1.1746\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.9699\n",
      "Comparison loss = 0.9408\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.4938\n",
      "Comparison loss = 0.8894\n",
      "Epoch no 15 : \n",
      "Classification loss = 30.2077\n",
      "Comparison loss = 0.7645\n",
      "Epoch no 16 : \n",
      "Classification loss = 30.0861\n",
      "Comparison loss = 0.6854\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.9414\n",
      "Comparison loss = 0.4301\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.7823\n",
      "Comparison loss = 0.4020\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.7039\n",
      "Comparison loss = 0.4131\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.6269\n",
      "Comparison loss = 0.3806\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.5629\n",
      "Comparison loss = 0.2765\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.5135\n",
      "Comparison loss = 0.2627\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4833\n",
      "Comparison loss = 0.2458\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4796\n",
      "Comparison loss = 0.2423\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.4640\n",
      "Comparison loss = 0.2341\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.950% \n",
      "Comparison = 0.400%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.850% \n",
      "Comparison = 3.500%\u001b[0m\n",
      "RUN NO 7\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.4455\n",
      "Comparison loss = 5.8331\n",
      "Epoch no 2 : \n",
      "Classification loss = 43.2736\n",
      "Comparison loss = 5.5166\n",
      "Epoch no 3 : \n",
      "Classification loss = 41.5563\n",
      "Comparison loss = 5.0324\n",
      "Epoch no 4 : \n",
      "Classification loss = 40.1012\n",
      "Comparison loss = 3.4564\n",
      "Epoch no 5 : \n",
      "Classification loss = 37.7330\n",
      "Comparison loss = 2.5593\n",
      "Epoch no 6 : \n",
      "Classification loss = 35.5065\n",
      "Comparison loss = 2.6615\n",
      "Epoch no 7 : \n",
      "Classification loss = 33.9258\n",
      "Comparison loss = 1.7372\n",
      "Epoch no 8 : \n",
      "Classification loss = 32.6962\n",
      "Comparison loss = 1.5781\n",
      "Epoch no 9 : \n",
      "Classification loss = 32.3733\n",
      "Comparison loss = 1.6810\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.9276\n",
      "Comparison loss = 1.1560\n",
      "Epoch no 11 : \n",
      "Classification loss = 31.2693\n",
      "Comparison loss = 0.7881\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.6290\n",
      "Comparison loss = 0.7665\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.2964\n",
      "Comparison loss = 0.6532\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.2455\n",
      "Comparison loss = 0.6181\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.8390\n",
      "Comparison loss = 0.3924\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.8565\n",
      "Comparison loss = 0.3554\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.8957\n",
      "Comparison loss = 0.5389\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.6628\n",
      "Comparison loss = 0.3286\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.6617\n",
      "Comparison loss = 0.2245\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.6408\n",
      "Comparison loss = 0.4018\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4964\n",
      "Comparison loss = 0.2077\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4907\n",
      "Comparison loss = 0.2205\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4387\n",
      "Comparison loss = 0.1662\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.3966\n",
      "Comparison loss = 0.0794\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3722\n",
      "Comparison loss = 0.0735\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.550% \n",
      "Comparison = 0.100%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.050% \n",
      "Comparison = 2.400%\u001b[0m\n",
      "RUN NO 8\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.3776\n",
      "Comparison loss = 5.5876\n",
      "Epoch no 2 : \n",
      "Classification loss = 42.6999\n",
      "Comparison loss = 4.0259\n",
      "Epoch no 3 : \n",
      "Classification loss = 39.8422\n",
      "Comparison loss = 3.5108\n",
      "Epoch no 4 : \n",
      "Classification loss = 37.5012\n",
      "Comparison loss = 2.9051\n",
      "Epoch no 5 : \n",
      "Classification loss = 35.3968\n",
      "Comparison loss = 2.2818\n",
      "Epoch no 6 : \n",
      "Classification loss = 33.5824\n",
      "Comparison loss = 1.7184\n",
      "Epoch no 7 : \n",
      "Classification loss = 32.3135\n",
      "Comparison loss = 1.4527\n",
      "Epoch no 8 : \n",
      "Classification loss = 31.7710\n",
      "Comparison loss = 1.5674\n",
      "Epoch no 9 : \n",
      "Classification loss = 31.3974\n",
      "Comparison loss = 1.2958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch no 10 : \n",
      "Classification loss = 30.6549\n",
      "Comparison loss = 0.8307\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.4356\n",
      "Comparison loss = 0.8943\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.1092\n",
      "Comparison loss = 0.7271\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.0741\n",
      "Comparison loss = 0.5767\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.8374\n",
      "Comparison loss = 0.4080\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.7025\n",
      "Comparison loss = 0.3560\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.6217\n",
      "Comparison loss = 0.2694\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.5806\n",
      "Comparison loss = 0.2434\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.5079\n",
      "Comparison loss = 0.1645\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.4617\n",
      "Comparison loss = 0.1953\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.4393\n",
      "Comparison loss = 0.1580\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4257\n",
      "Comparison loss = 0.0820\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4144\n",
      "Comparison loss = 0.0750\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.3984\n",
      "Comparison loss = 0.0709\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.3920\n",
      "Comparison loss = 0.0666\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3874\n",
      "Comparison loss = 0.0633\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.750% \n",
      "Comparison = 0.100%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.500% \n",
      "Comparison = 2.600%\u001b[0m\n",
      "RUN NO 9\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.6129\n",
      "Comparison loss = 5.5547\n",
      "Epoch no 2 : \n",
      "Classification loss = 43.6695\n",
      "Comparison loss = 4.5398\n",
      "Epoch no 3 : \n",
      "Classification loss = 41.3875\n",
      "Comparison loss = 4.2848\n",
      "Epoch no 4 : \n",
      "Classification loss = 39.3277\n",
      "Comparison loss = 3.5508\n",
      "Epoch no 5 : \n",
      "Classification loss = 37.3965\n",
      "Comparison loss = 3.0413\n",
      "Epoch no 6 : \n",
      "Classification loss = 35.4807\n",
      "Comparison loss = 2.3104\n",
      "Epoch no 7 : \n",
      "Classification loss = 33.9542\n",
      "Comparison loss = 1.7092\n",
      "Epoch no 8 : \n",
      "Classification loss = 32.7345\n",
      "Comparison loss = 1.5762\n",
      "Epoch no 9 : \n",
      "Classification loss = 32.4634\n",
      "Comparison loss = 2.5990\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.5463\n",
      "Comparison loss = 1.4625\n",
      "Epoch no 11 : \n",
      "Classification loss = 31.2645\n",
      "Comparison loss = 1.1340\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.6516\n",
      "Comparison loss = 0.8290\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.5221\n",
      "Comparison loss = 0.7562\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.2578\n",
      "Comparison loss = 0.6368\n",
      "Epoch no 15 : \n",
      "Classification loss = 30.1685\n",
      "Comparison loss = 0.5082\n",
      "Epoch no 16 : \n",
      "Classification loss = 30.0649\n",
      "Comparison loss = 0.5236\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.9072\n",
      "Comparison loss = 0.4026\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.8340\n",
      "Comparison loss = 0.3642\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.7552\n",
      "Comparison loss = 0.2887\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.7016\n",
      "Comparison loss = 0.2492\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.6313\n",
      "Comparison loss = 0.2293\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.6032\n",
      "Comparison loss = 0.2067\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.5732\n",
      "Comparison loss = 0.1754\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.5514\n",
      "Comparison loss = 0.1640\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.5310\n",
      "Comparison loss = 0.1574\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 1.400% \n",
      "Comparison = 0.300%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 5.300% \n",
      "Comparison = 3.500%\u001b[0m\n",
      "RUN NO 10\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.4897\n",
      "Comparison loss = 5.6905\n",
      "Epoch no 2 : \n",
      "Classification loss = 43.3092\n",
      "Comparison loss = 4.4763\n",
      "Epoch no 3 : \n",
      "Classification loss = 40.6240\n",
      "Comparison loss = 4.5293\n",
      "Epoch no 4 : \n",
      "Classification loss = 38.0134\n",
      "Comparison loss = 2.3969\n",
      "Epoch no 5 : \n",
      "Classification loss = 35.6906\n",
      "Comparison loss = 2.1438\n",
      "Epoch no 6 : \n",
      "Classification loss = 33.7806\n",
      "Comparison loss = 1.7935\n",
      "Epoch no 7 : \n",
      "Classification loss = 32.4310\n",
      "Comparison loss = 1.7897\n",
      "Epoch no 8 : \n",
      "Classification loss = 31.8919\n",
      "Comparison loss = 1.7915\n",
      "Epoch no 9 : \n",
      "Classification loss = 31.3100\n",
      "Comparison loss = 1.0644\n",
      "Epoch no 10 : \n",
      "Classification loss = 30.8171\n",
      "Comparison loss = 1.0757\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.5822\n",
      "Comparison loss = 0.8049\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.2849\n",
      "Comparison loss = 0.6303\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.1582\n",
      "Comparison loss = 0.6247\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.9363\n",
      "Comparison loss = 0.5183\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.8072\n",
      "Comparison loss = 0.3256\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.6941\n",
      "Comparison loss = 0.2467\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.6201\n",
      "Comparison loss = 0.1975\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.5803\n",
      "Comparison loss = 0.1420\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.5220\n",
      "Comparison loss = 0.0841\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.4782\n",
      "Comparison loss = 0.0356\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4499\n",
      "Comparison loss = 0.0419\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4283\n",
      "Comparison loss = 0.0378\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4082\n",
      "Comparison loss = 0.0228\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4012\n",
      "Comparison loss = 0.0200\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3937\n",
      "Comparison loss = 0.0178\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.750% \n",
      "Comparison = 0.000%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.200% \n",
      "Comparison = 3.400%\u001b[0m\n",
      "Final error for train batch : 0.20±0.1155\n",
      "Final error for test batch : 3.24±0.4835\n",
      "RUN NO 1\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.5425\n",
      "Comparison loss = 6.9518\n",
      "Epoch no 2 : \n",
      "Classification loss = 43.9612\n",
      "Comparison loss = 6.9964\n",
      "Epoch no 3 : \n",
      "Classification loss = 41.3595\n",
      "Comparison loss = 6.9020\n",
      "Epoch no 4 : \n",
      "Classification loss = 38.8401\n",
      "Comparison loss = 6.8821\n",
      "Epoch no 5 : \n",
      "Classification loss = 36.8777\n",
      "Comparison loss = 6.8947\n",
      "Epoch no 6 : \n",
      "Classification loss = 35.4286\n",
      "Comparison loss = 6.8938\n",
      "Epoch no 7 : \n",
      "Classification loss = 34.0030\n",
      "Comparison loss = 6.8998\n",
      "Epoch no 8 : \n",
      "Classification loss = 33.3272\n",
      "Comparison loss = 6.8785\n",
      "Epoch no 9 : \n",
      "Classification loss = 32.4919\n",
      "Comparison loss = 6.8780\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.6261\n",
      "Comparison loss = 6.8826\n",
      "Epoch no 11 : \n",
      "Classification loss = 31.0192\n",
      "Comparison loss = 6.8872\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.5413\n",
      "Comparison loss = 6.8815\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.3109\n",
      "Comparison loss = 6.8766\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.9751\n",
      "Comparison loss = 6.8793\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.9853\n",
      "Comparison loss = 6.8823\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.8527\n",
      "Comparison loss = 6.8795\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.7679\n",
      "Comparison loss = 6.8757\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.6747\n",
      "Comparison loss = 6.8772\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.6196\n",
      "Comparison loss = 6.8788\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.5518\n",
      "Comparison loss = 6.8756\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.5170\n",
      "Comparison loss = 6.8728\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4693\n",
      "Comparison loss = 6.8738\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4515\n",
      "Comparison loss = 6.8732\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4354\n",
      "Comparison loss = 6.8684\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.4213\n",
      "Comparison loss = 6.8666\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.900% \n",
      "Comparison = 44.900%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.650% \n",
      "Comparison = 47.400%\u001b[0m\n",
      "RUN NO 2\n",
      "Epoch no 1 : \n",
      "Classification loss = 44.8453\n",
      "Comparison loss = 6.8869\n",
      "Epoch no 2 : \n",
      "Classification loss = 41.5934\n",
      "Comparison loss = 6.8846\n",
      "Epoch no 3 : \n",
      "Classification loss = 39.0339\n",
      "Comparison loss = 6.9015\n",
      "Epoch no 4 : \n",
      "Classification loss = 36.7346\n",
      "Comparison loss = 6.8854\n",
      "Epoch no 5 : \n",
      "Classification loss = 34.6840\n",
      "Comparison loss = 6.8688\n",
      "Epoch no 6 : \n",
      "Classification loss = 33.2342\n",
      "Comparison loss = 6.8778\n",
      "Epoch no 7 : \n",
      "Classification loss = 31.9235\n",
      "Comparison loss = 6.8932\n",
      "Epoch no 8 : \n",
      "Classification loss = 30.9172\n",
      "Comparison loss = 6.8567\n",
      "Epoch no 9 : \n",
      "Classification loss = 30.7416\n",
      "Comparison loss = 6.8625\n",
      "Epoch no 10 : \n",
      "Classification loss = 30.4150\n",
      "Comparison loss = 6.8701\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.2554\n",
      "Comparison loss = 6.8652\n",
      "Epoch no 12 : \n",
      "Classification loss = 29.9594\n",
      "Comparison loss = 6.8413\n",
      "Epoch no 13 : \n",
      "Classification loss = 29.8756\n",
      "Comparison loss = 6.8488\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.7395\n",
      "Comparison loss = 6.8587\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.6015\n",
      "Comparison loss = 6.8158\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.5181\n",
      "Comparison loss = 6.8230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch no 17 : \n",
      "Classification loss = 29.4653\n",
      "Comparison loss = 6.8432\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.4193\n",
      "Comparison loss = 6.7776\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.3884\n",
      "Comparison loss = 6.7913\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.3782\n",
      "Comparison loss = 6.8250\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.3628\n",
      "Comparison loss = 6.7782\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.3538\n",
      "Comparison loss = 6.7780\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.3453\n",
      "Comparison loss = 6.8088\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.3400\n",
      "Comparison loss = 6.7630\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3349\n",
      "Comparison loss = 6.7269\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.500% \n",
      "Comparison = 44.900%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 3.650% \n",
      "Comparison = 47.400%\u001b[0m\n",
      "RUN NO 3\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.2164\n",
      "Comparison loss = 6.8765\n",
      "Epoch no 2 : \n",
      "Classification loss = 41.9348\n",
      "Comparison loss = 6.9493\n",
      "Epoch no 3 : \n",
      "Classification loss = 37.6654\n",
      "Comparison loss = 6.8159\n",
      "Epoch no 4 : \n",
      "Classification loss = 34.7856\n",
      "Comparison loss = 6.8316\n",
      "Epoch no 5 : \n",
      "Classification loss = 33.1217\n",
      "Comparison loss = 6.6840\n",
      "Epoch no 6 : \n",
      "Classification loss = 32.2340\n",
      "Comparison loss = 6.6992\n",
      "Epoch no 7 : \n",
      "Classification loss = 31.7113\n",
      "Comparison loss = 6.6878\n",
      "Epoch no 8 : \n",
      "Classification loss = 30.7492\n",
      "Comparison loss = 6.6768\n",
      "Epoch no 9 : \n",
      "Classification loss = 30.5892\n",
      "Comparison loss = 6.5966\n",
      "Epoch no 10 : \n",
      "Classification loss = 30.2082\n",
      "Comparison loss = 6.5824\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.0684\n",
      "Comparison loss = 6.5789\n",
      "Epoch no 12 : \n",
      "Classification loss = 29.8930\n",
      "Comparison loss = 6.4945\n",
      "Epoch no 13 : \n",
      "Classification loss = 29.7994\n",
      "Comparison loss = 6.4744\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.6858\n",
      "Comparison loss = 6.4908\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.6037\n",
      "Comparison loss = 6.3261\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.5408\n",
      "Comparison loss = 6.3636\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.5017\n",
      "Comparison loss = 6.6461\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.4571\n",
      "Comparison loss = 6.3953\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.4370\n",
      "Comparison loss = 6.3306\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.4181\n",
      "Comparison loss = 6.8299\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4102\n",
      "Comparison loss = 6.2402\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4058\n",
      "Comparison loss = 6.4536\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4009\n",
      "Comparison loss = 6.6494\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.3924\n",
      "Comparison loss = 6.2142\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3770\n",
      "Comparison loss = 6.4366\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.650% \n",
      "Comparison = 37.200%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.550% \n",
      "Comparison = 35.900%\u001b[0m\n",
      "RUN NO 4\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.4062\n",
      "Comparison loss = 7.0393\n",
      "Epoch no 2 : \n",
      "Classification loss = 43.2647\n",
      "Comparison loss = 6.9901\n",
      "Epoch no 3 : \n",
      "Classification loss = 40.8588\n",
      "Comparison loss = 6.5185\n",
      "Epoch no 4 : \n",
      "Classification loss = 38.1123\n",
      "Comparison loss = 6.4663\n",
      "Epoch no 5 : \n",
      "Classification loss = 35.7320\n",
      "Comparison loss = 6.4644\n",
      "Epoch no 6 : \n",
      "Classification loss = 35.2656\n",
      "Comparison loss = 6.3449\n",
      "Epoch no 7 : \n",
      "Classification loss = 34.1077\n",
      "Comparison loss = 6.2476\n",
      "Epoch no 8 : \n",
      "Classification loss = 33.7809\n",
      "Comparison loss = 6.2400\n",
      "Epoch no 9 : \n",
      "Classification loss = 32.8411\n",
      "Comparison loss = 6.2367\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.9311\n",
      "Comparison loss = 6.0473\n",
      "Epoch no 11 : \n",
      "Classification loss = 31.0151\n",
      "Comparison loss = 6.0555\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.5779\n",
      "Comparison loss = 5.9979\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.4817\n",
      "Comparison loss = 5.9039\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.1201\n",
      "Comparison loss = 5.9182\n",
      "Epoch no 15 : \n",
      "Classification loss = 30.0153\n",
      "Comparison loss = 5.8808\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.8135\n",
      "Comparison loss = 5.7586\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.7086\n",
      "Comparison loss = 5.8893\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.6299\n",
      "Comparison loss = 5.8462\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.5902\n",
      "Comparison loss = 5.6744\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.5414\n",
      "Comparison loss = 6.0190\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.5042\n",
      "Comparison loss = 5.8603\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4864\n",
      "Comparison loss = 5.7649\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4762\n",
      "Comparison loss = 6.0600\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4648\n",
      "Comparison loss = 5.6347\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.4522\n",
      "Comparison loss = 6.1253\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 1.000% \n",
      "Comparison = 24.800%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.250% \n",
      "Comparison = 25.900%\u001b[0m\n",
      "RUN NO 5\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.2807\n",
      "Comparison loss = 6.8443\n",
      "Epoch no 2 : \n",
      "Classification loss = 42.2120\n",
      "Comparison loss = 6.3123\n",
      "Epoch no 3 : \n",
      "Classification loss = 38.6379\n",
      "Comparison loss = 6.1033\n",
      "Epoch no 4 : \n",
      "Classification loss = 35.8247\n",
      "Comparison loss = 5.8017\n",
      "Epoch no 5 : \n",
      "Classification loss = 33.9345\n",
      "Comparison loss = 5.6421\n",
      "Epoch no 6 : \n",
      "Classification loss = 32.9755\n",
      "Comparison loss = 5.3263\n",
      "Epoch no 7 : \n",
      "Classification loss = 32.7469\n",
      "Comparison loss = 5.4068\n",
      "Epoch no 8 : \n",
      "Classification loss = 32.2912\n",
      "Comparison loss = 5.2151\n",
      "Epoch no 9 : \n",
      "Classification loss = 31.8737\n",
      "Comparison loss = 5.8734\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.4184\n",
      "Comparison loss = 5.9820\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.6325\n",
      "Comparison loss = 5.2993\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.0453\n",
      "Comparison loss = 6.0594\n",
      "Epoch no 13 : \n",
      "Classification loss = 29.9360\n",
      "Comparison loss = 5.2265\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.8557\n",
      "Comparison loss = 5.9461\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.9173\n",
      "Comparison loss = 5.0538\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.6688\n",
      "Comparison loss = 5.3636\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.6231\n",
      "Comparison loss = 5.4163\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.4820\n",
      "Comparison loss = 5.0255\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.4424\n",
      "Comparison loss = 5.2012\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.3995\n",
      "Comparison loss = 4.8509\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.3874\n",
      "Comparison loss = 5.3199\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.3781\n",
      "Comparison loss = 4.6730\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.3733\n",
      "Comparison loss = 4.9882\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.3693\n",
      "Comparison loss = 4.9930\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3630\n",
      "Comparison loss = 4.7342\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.650% \n",
      "Comparison = 10.300%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 3.850% \n",
      "Comparison = 11.700%\u001b[0m\n",
      "RUN NO 6\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.1767\n",
      "Comparison loss = 6.8845\n",
      "Epoch no 2 : \n",
      "Classification loss = 41.8331\n",
      "Comparison loss = 6.3628\n",
      "Epoch no 3 : \n",
      "Classification loss = 37.9273\n",
      "Comparison loss = 6.0104\n",
      "Epoch no 4 : \n",
      "Classification loss = 36.0785\n",
      "Comparison loss = 5.4029\n",
      "Epoch no 5 : \n",
      "Classification loss = 35.0318\n",
      "Comparison loss = 5.8079\n",
      "Epoch no 6 : \n",
      "Classification loss = 34.0307\n",
      "Comparison loss = 5.5285\n",
      "Epoch no 7 : \n",
      "Classification loss = 32.9756\n",
      "Comparison loss = 5.2583\n",
      "Epoch no 8 : \n",
      "Classification loss = 32.0186\n",
      "Comparison loss = 5.3552\n",
      "Epoch no 9 : \n",
      "Classification loss = 31.0913\n",
      "Comparison loss = 4.8391\n",
      "Epoch no 10 : \n",
      "Classification loss = 30.8890\n",
      "Comparison loss = 5.3223\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.4569\n",
      "Comparison loss = 4.7615\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.4281\n",
      "Comparison loss = 4.9008\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.4292\n",
      "Comparison loss = 5.2496\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.1582\n",
      "Comparison loss = 4.4898\n",
      "Epoch no 15 : \n",
      "Classification loss = 30.0442\n",
      "Comparison loss = 5.0872\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.9301\n",
      "Comparison loss = 4.7704\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.7255\n",
      "Comparison loss = 4.8198\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.6402\n",
      "Comparison loss = 4.7583\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.5607\n",
      "Comparison loss = 4.4763\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.5004\n",
      "Comparison loss = 5.0814\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4822\n",
      "Comparison loss = 4.3207\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4629\n",
      "Comparison loss = 4.6978\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4450\n",
      "Comparison loss = 4.8760\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4302\n",
      "Comparison loss = 4.3163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch no 25 : \n",
      "Classification loss = 29.4140\n",
      "Comparison loss = 4.8547\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.850% \n",
      "Comparison = 12.900%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.150% \n",
      "Comparison = 14.200%\u001b[0m\n",
      "RUN NO 7\n",
      "Epoch no 1 : \n",
      "Classification loss = 44.9818\n",
      "Comparison loss = 7.0682\n",
      "Epoch no 2 : \n",
      "Classification loss = 42.1109\n",
      "Comparison loss = 6.0367\n",
      "Epoch no 3 : \n",
      "Classification loss = 38.7061\n",
      "Comparison loss = 5.5946\n",
      "Epoch no 4 : \n",
      "Classification loss = 36.6282\n",
      "Comparison loss = 5.5191\n",
      "Epoch no 5 : \n",
      "Classification loss = 35.2363\n",
      "Comparison loss = 5.8463\n",
      "Epoch no 6 : \n",
      "Classification loss = 34.4207\n",
      "Comparison loss = 5.1087\n",
      "Epoch no 7 : \n",
      "Classification loss = 33.8867\n",
      "Comparison loss = 5.5065\n",
      "Epoch no 8 : \n",
      "Classification loss = 32.9313\n",
      "Comparison loss = 4.7399\n",
      "Epoch no 9 : \n",
      "Classification loss = 31.9458\n",
      "Comparison loss = 4.9050\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.1292\n",
      "Comparison loss = 5.3241\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.7576\n",
      "Comparison loss = 4.3192\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.5143\n",
      "Comparison loss = 5.0550\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.1184\n",
      "Comparison loss = 4.4418\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.0057\n",
      "Comparison loss = 4.8506\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.8733\n",
      "Comparison loss = 4.2916\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.6941\n",
      "Comparison loss = 4.3300\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.5766\n",
      "Comparison loss = 4.7337\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.5325\n",
      "Comparison loss = 4.0086\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.5055\n",
      "Comparison loss = 4.5319\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.4603\n",
      "Comparison loss = 4.1790\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4370\n",
      "Comparison loss = 4.3630\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4242\n",
      "Comparison loss = 4.1617\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4151\n",
      "Comparison loss = 4.0112\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4047\n",
      "Comparison loss = 4.5716\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3981\n",
      "Comparison loss = 3.8117\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.800% \n",
      "Comparison = 20.000%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.450% \n",
      "Comparison = 20.700%\u001b[0m\n",
      "RUN NO 8\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.2129\n",
      "Comparison loss = 7.4782\n",
      "Epoch no 2 : \n",
      "Classification loss = 42.6454\n",
      "Comparison loss = 6.0172\n",
      "Epoch no 3 : \n",
      "Classification loss = 40.3346\n",
      "Comparison loss = 7.2599\n",
      "Epoch no 4 : \n",
      "Classification loss = 38.2521\n",
      "Comparison loss = 5.3096\n",
      "Epoch no 5 : \n",
      "Classification loss = 36.0150\n",
      "Comparison loss = 6.1430\n",
      "Epoch no 6 : \n",
      "Classification loss = 34.2877\n",
      "Comparison loss = 4.4408\n",
      "Epoch no 7 : \n",
      "Classification loss = 32.6696\n",
      "Comparison loss = 4.9535\n",
      "Epoch no 8 : \n",
      "Classification loss = 31.7699\n",
      "Comparison loss = 4.3622\n",
      "Epoch no 9 : \n",
      "Classification loss = 30.9699\n",
      "Comparison loss = 4.5937\n",
      "Epoch no 10 : \n",
      "Classification loss = 30.6326\n",
      "Comparison loss = 3.9723\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.5973\n",
      "Comparison loss = 4.1494\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.2099\n",
      "Comparison loss = 4.1502\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.1133\n",
      "Comparison loss = 3.8997\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.8679\n",
      "Comparison loss = 3.9791\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.7920\n",
      "Comparison loss = 3.7938\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.6795\n",
      "Comparison loss = 4.0218\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.6757\n",
      "Comparison loss = 3.6516\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.5940\n",
      "Comparison loss = 3.7790\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.4795\n",
      "Comparison loss = 3.9326\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.4510\n",
      "Comparison loss = 3.5594\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4348\n",
      "Comparison loss = 3.8451\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4170\n",
      "Comparison loss = 3.7946\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4014\n",
      "Comparison loss = 3.6745\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.3935\n",
      "Comparison loss = 3.8804\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3888\n",
      "Comparison loss = 3.6769\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.700% \n",
      "Comparison = 24.900%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.500% \n",
      "Comparison = 25.700%\u001b[0m\n",
      "RUN NO 9\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.1727\n",
      "Comparison loss = 7.1018\n",
      "Epoch no 2 : \n",
      "Classification loss = 42.4620\n",
      "Comparison loss = 5.9459\n",
      "Epoch no 3 : \n",
      "Classification loss = 39.9308\n",
      "Comparison loss = 7.0338\n",
      "Epoch no 4 : \n",
      "Classification loss = 37.2113\n",
      "Comparison loss = 4.9371\n",
      "Epoch no 5 : \n",
      "Classification loss = 35.3036\n",
      "Comparison loss = 5.2606\n",
      "Epoch no 6 : \n",
      "Classification loss = 33.8445\n",
      "Comparison loss = 4.7798\n",
      "Epoch no 7 : \n",
      "Classification loss = 32.5237\n",
      "Comparison loss = 4.4649\n",
      "Epoch no 8 : \n",
      "Classification loss = 31.3510\n",
      "Comparison loss = 4.3002\n",
      "Epoch no 9 : \n",
      "Classification loss = 30.8672\n",
      "Comparison loss = 3.9637\n",
      "Epoch no 10 : \n",
      "Classification loss = 30.7365\n",
      "Comparison loss = 4.4145\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.4573\n",
      "Comparison loss = 3.7170\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.4932\n",
      "Comparison loss = 4.1517\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.1222\n",
      "Comparison loss = 3.7749\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.8765\n",
      "Comparison loss = 3.9365\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.8015\n",
      "Comparison loss = 3.6112\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.6632\n",
      "Comparison loss = 3.5653\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.5756\n",
      "Comparison loss = 3.9229\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.4921\n",
      "Comparison loss = 3.3391\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.4650\n",
      "Comparison loss = 3.7148\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.4413\n",
      "Comparison loss = 3.6891\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4114\n",
      "Comparison loss = 3.4752\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.3864\n",
      "Comparison loss = 3.7220\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.3760\n",
      "Comparison loss = 3.4537\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.3635\n",
      "Comparison loss = 3.7739\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3477\n",
      "Comparison loss = 3.5250\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.550% \n",
      "Comparison = 18.700%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 3.700% \n",
      "Comparison = 19.700%\u001b[0m\n",
      "RUN NO 10\n",
      "Epoch no 1 : \n",
      "Classification loss = 44.8214\n",
      "Comparison loss = 7.5318\n",
      "Epoch no 2 : \n",
      "Classification loss = 41.8305\n",
      "Comparison loss = 5.8681\n",
      "Epoch no 3 : \n",
      "Classification loss = 38.4324\n",
      "Comparison loss = 6.3788\n",
      "Epoch no 4 : \n",
      "Classification loss = 36.8064\n",
      "Comparison loss = 6.1021\n",
      "Epoch no 5 : \n",
      "Classification loss = 35.5078\n",
      "Comparison loss = 5.0962\n",
      "Epoch no 6 : \n",
      "Classification loss = 33.6678\n",
      "Comparison loss = 4.7663\n",
      "Epoch no 7 : \n",
      "Classification loss = 32.3095\n",
      "Comparison loss = 4.0371\n",
      "Epoch no 8 : \n",
      "Classification loss = 31.8287\n",
      "Comparison loss = 4.7103\n",
      "Epoch no 9 : \n",
      "Classification loss = 30.8244\n",
      "Comparison loss = 3.7117\n",
      "Epoch no 10 : \n",
      "Classification loss = 30.4372\n",
      "Comparison loss = 4.1050\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.3493\n",
      "Comparison loss = 3.5707\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.0930\n",
      "Comparison loss = 3.9904\n",
      "Epoch no 13 : \n",
      "Classification loss = 29.9888\n",
      "Comparison loss = 3.3494\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.8276\n",
      "Comparison loss = 3.6107\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.6963\n",
      "Comparison loss = 3.6031\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.6152\n",
      "Comparison loss = 3.3434\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.5720\n",
      "Comparison loss = 3.4954\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.4721\n",
      "Comparison loss = 3.2487\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.4472\n",
      "Comparison loss = 3.6071\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.4141\n",
      "Comparison loss = 3.1719\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.3928\n",
      "Comparison loss = 3.3149\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.3733\n",
      "Comparison loss = 3.6492\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.3573\n",
      "Comparison loss = 3.0594\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.3479\n",
      "Comparison loss = 3.5202\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3396\n",
      "Comparison loss = 3.4760\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.500% \n",
      "Comparison = 23.800%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.300% \n",
      "Comparison = 25.100%\u001b[0m\n",
      "Final error for train batch : 26.24±12.2663\n",
      "Final error for test batch : 27.37±12.5059\n",
      "RUN NO 1\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.3324\n",
      "Comparison loss = 6.9187\n",
      "Epoch no 2 : \n",
      "Classification loss = 42.1602\n",
      "Comparison loss = 6.8966\n",
      "Epoch no 3 : \n",
      "Classification loss = 38.0693\n",
      "Comparison loss = 6.8587\n",
      "Epoch no 4 : \n",
      "Classification loss = 34.7034\n",
      "Comparison loss = 6.7672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch no 5 : \n",
      "Classification loss = 33.0383\n",
      "Comparison loss = 6.5457\n",
      "Epoch no 6 : \n",
      "Classification loss = 32.3260\n",
      "Comparison loss = 6.0464\n",
      "Epoch no 7 : \n",
      "Classification loss = 31.7658\n",
      "Comparison loss = 5.2865\n",
      "Epoch no 8 : \n",
      "Classification loss = 31.1620\n",
      "Comparison loss = 4.4715\n",
      "Epoch no 9 : \n",
      "Classification loss = 30.4527\n",
      "Comparison loss = 3.5485\n",
      "Epoch no 10 : \n",
      "Classification loss = 30.4799\n",
      "Comparison loss = 2.8711\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.0300\n",
      "Comparison loss = 2.1022\n",
      "Epoch no 12 : \n",
      "Classification loss = 29.8434\n",
      "Comparison loss = 1.6920\n",
      "Epoch no 13 : \n",
      "Classification loss = 29.8198\n",
      "Comparison loss = 1.1608\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.8001\n",
      "Comparison loss = 0.8039\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.6342\n",
      "Comparison loss = 0.7269\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.5664\n",
      "Comparison loss = 0.4650\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.5123\n",
      "Comparison loss = 0.4752\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.4821\n",
      "Comparison loss = 0.2117\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.4388\n",
      "Comparison loss = 0.2416\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.4175\n",
      "Comparison loss = 0.2833\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.3830\n",
      "Comparison loss = 0.1864\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.3554\n",
      "Comparison loss = 0.1501\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.3423\n",
      "Comparison loss = 0.1314\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.3384\n",
      "Comparison loss = 0.1205\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3350\n",
      "Comparison loss = 0.0932\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.500% \n",
      "Comparison = 0.200%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.150% \n",
      "Comparison = 3.500%\u001b[0m\n",
      "RUN NO 2\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.8265\n",
      "Comparison loss = 7.9187\n",
      "Epoch no 2 : \n",
      "Classification loss = 44.4740\n",
      "Comparison loss = 6.0689\n",
      "Epoch no 3 : \n",
      "Classification loss = 42.2782\n",
      "Comparison loss = 6.0404\n",
      "Epoch no 4 : \n",
      "Classification loss = 40.5390\n",
      "Comparison loss = 5.2130\n",
      "Epoch no 5 : \n",
      "Classification loss = 38.3272\n",
      "Comparison loss = 4.4411\n",
      "Epoch no 6 : \n",
      "Classification loss = 36.7362\n",
      "Comparison loss = 2.7683\n",
      "Epoch no 7 : \n",
      "Classification loss = 35.1035\n",
      "Comparison loss = 2.8152\n",
      "Epoch no 8 : \n",
      "Classification loss = 33.3712\n",
      "Comparison loss = 2.0408\n",
      "Epoch no 9 : \n",
      "Classification loss = 31.9818\n",
      "Comparison loss = 1.5533\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.5582\n",
      "Comparison loss = 1.7540\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.9731\n",
      "Comparison loss = 1.1351\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.5652\n",
      "Comparison loss = 1.1865\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.2789\n",
      "Comparison loss = 0.7864\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.0564\n",
      "Comparison loss = 0.6209\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.8972\n",
      "Comparison loss = 0.5093\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.8016\n",
      "Comparison loss = 0.3942\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.7144\n",
      "Comparison loss = 0.3165\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.6454\n",
      "Comparison loss = 0.2682\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.5960\n",
      "Comparison loss = 0.2132\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.5678\n",
      "Comparison loss = 0.1785\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.5292\n",
      "Comparison loss = 0.1661\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.5090\n",
      "Comparison loss = 0.1584\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4943\n",
      "Comparison loss = 0.1513\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4831\n",
      "Comparison loss = 0.1454\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.4705\n",
      "Comparison loss = 0.1404\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 1.150% \n",
      "Comparison = 0.200%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.750% \n",
      "Comparison = 3.400%\u001b[0m\n",
      "RUN NO 3\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.5805\n",
      "Comparison loss = 5.6193\n",
      "Epoch no 2 : \n",
      "Classification loss = 43.8110\n",
      "Comparison loss = 5.2305\n",
      "Epoch no 3 : \n",
      "Classification loss = 42.1863\n",
      "Comparison loss = 6.1981\n",
      "Epoch no 4 : \n",
      "Classification loss = 40.4648\n",
      "Comparison loss = 3.9821\n",
      "Epoch no 5 : \n",
      "Classification loss = 38.2514\n",
      "Comparison loss = 3.4079\n",
      "Epoch no 6 : \n",
      "Classification loss = 35.6094\n",
      "Comparison loss = 2.6880\n",
      "Epoch no 7 : \n",
      "Classification loss = 33.8304\n",
      "Comparison loss = 2.2906\n",
      "Epoch no 8 : \n",
      "Classification loss = 33.0895\n",
      "Comparison loss = 2.0409\n",
      "Epoch no 9 : \n",
      "Classification loss = 33.2513\n",
      "Comparison loss = 2.7194\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.8935\n",
      "Comparison loss = 1.9320\n",
      "Epoch no 11 : \n",
      "Classification loss = 31.4757\n",
      "Comparison loss = 1.5998\n",
      "Epoch no 12 : \n",
      "Classification loss = 31.0078\n",
      "Comparison loss = 1.2553\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.7397\n",
      "Comparison loss = 1.0599\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.4786\n",
      "Comparison loss = 0.8993\n",
      "Epoch no 15 : \n",
      "Classification loss = 30.2290\n",
      "Comparison loss = 0.7125\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.9698\n",
      "Comparison loss = 0.5647\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.8680\n",
      "Comparison loss = 0.4105\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.7432\n",
      "Comparison loss = 0.3441\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.6771\n",
      "Comparison loss = 0.2543\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.5983\n",
      "Comparison loss = 0.2309\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.5578\n",
      "Comparison loss = 0.2071\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.5205\n",
      "Comparison loss = 0.1452\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4876\n",
      "Comparison loss = 0.1317\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4706\n",
      "Comparison loss = 0.1124\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.4576\n",
      "Comparison loss = 0.0855\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 1.050% \n",
      "Comparison = 0.200%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 5.150% \n",
      "Comparison = 3.300%\u001b[0m\n",
      "RUN NO 4\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.6058\n",
      "Comparison loss = 6.0554\n",
      "Epoch no 2 : \n",
      "Classification loss = 43.5961\n",
      "Comparison loss = 6.0375\n",
      "Epoch no 3 : \n",
      "Classification loss = 41.7010\n",
      "Comparison loss = 6.5367\n",
      "Epoch no 4 : \n",
      "Classification loss = 40.1241\n",
      "Comparison loss = 4.6999\n",
      "Epoch no 5 : \n",
      "Classification loss = 38.5171\n",
      "Comparison loss = 3.6002\n",
      "Epoch no 6 : \n",
      "Classification loss = 36.3499\n",
      "Comparison loss = 3.2664\n",
      "Epoch no 7 : \n",
      "Classification loss = 34.4333\n",
      "Comparison loss = 2.8426\n",
      "Epoch no 8 : \n",
      "Classification loss = 33.0277\n",
      "Comparison loss = 2.2288\n",
      "Epoch no 9 : \n",
      "Classification loss = 31.8969\n",
      "Comparison loss = 1.4432\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.3511\n",
      "Comparison loss = 1.5146\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.8816\n",
      "Comparison loss = 1.1048\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.4486\n",
      "Comparison loss = 0.9142\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.1756\n",
      "Comparison loss = 0.8704\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.9927\n",
      "Comparison loss = 0.5610\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.8245\n",
      "Comparison loss = 0.4400\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.6701\n",
      "Comparison loss = 0.4024\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.6031\n",
      "Comparison loss = 0.3201\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.5695\n",
      "Comparison loss = 0.2496\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.5180\n",
      "Comparison loss = 0.2009\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.4836\n",
      "Comparison loss = 0.1874\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4552\n",
      "Comparison loss = 0.1781\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4305\n",
      "Comparison loss = 0.1671\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4196\n",
      "Comparison loss = 0.1594\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4047\n",
      "Comparison loss = 0.1479\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3951\n",
      "Comparison loss = 0.1374\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.750% \n",
      "Comparison = 0.200%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 5.200% \n",
      "Comparison = 3.900%\u001b[0m\n",
      "RUN NO 5\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.7438\n",
      "Comparison loss = 5.8573\n",
      "Epoch no 2 : \n",
      "Classification loss = 44.3188\n",
      "Comparison loss = 5.3219\n",
      "Epoch no 3 : \n",
      "Classification loss = 41.8335\n",
      "Comparison loss = 5.7521\n",
      "Epoch no 4 : \n",
      "Classification loss = 39.3478\n",
      "Comparison loss = 4.4375\n",
      "Epoch no 5 : \n",
      "Classification loss = 37.2013\n",
      "Comparison loss = 2.9827\n",
      "Epoch no 6 : \n",
      "Classification loss = 34.9369\n",
      "Comparison loss = 2.2984\n",
      "Epoch no 7 : \n",
      "Classification loss = 33.5252\n",
      "Comparison loss = 1.8027\n",
      "Epoch no 8 : \n",
      "Classification loss = 32.9307\n",
      "Comparison loss = 1.6712\n",
      "Epoch no 9 : \n",
      "Classification loss = 32.4624\n",
      "Comparison loss = 1.5233\n",
      "Epoch no 10 : \n",
      "Classification loss = 32.3272\n",
      "Comparison loss = 1.5690\n",
      "Epoch no 11 : \n",
      "Classification loss = 31.6917\n",
      "Comparison loss = 1.0506\n",
      "Epoch no 12 : \n",
      "Classification loss = 31.0911\n",
      "Comparison loss = 0.8846\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.5593\n",
      "Comparison loss = 0.7956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch no 14 : \n",
      "Classification loss = 30.2670\n",
      "Comparison loss = 0.6853\n",
      "Epoch no 15 : \n",
      "Classification loss = 30.0613\n",
      "Comparison loss = 0.5048\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.9247\n",
      "Comparison loss = 0.3940\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.7814\n",
      "Comparison loss = 0.3089\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.6958\n",
      "Comparison loss = 0.2271\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.6385\n",
      "Comparison loss = 0.1970\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.5996\n",
      "Comparison loss = 0.1653\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.5463\n",
      "Comparison loss = 0.1674\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.5136\n",
      "Comparison loss = 0.1495\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4933\n",
      "Comparison loss = 0.1347\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4734\n",
      "Comparison loss = 0.1229\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.4589\n",
      "Comparison loss = 0.1157\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 1.100% \n",
      "Comparison = 0.300%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.950% \n",
      "Comparison = 3.000%\u001b[0m\n",
      "RUN NO 6\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.5900\n",
      "Comparison loss = 5.4651\n",
      "Epoch no 2 : \n",
      "Classification loss = 43.6920\n",
      "Comparison loss = 5.4891\n",
      "Epoch no 3 : \n",
      "Classification loss = 41.6437\n",
      "Comparison loss = 4.8076\n",
      "Epoch no 4 : \n",
      "Classification loss = 39.4068\n",
      "Comparison loss = 4.0458\n",
      "Epoch no 5 : \n",
      "Classification loss = 37.4444\n",
      "Comparison loss = 3.3793\n",
      "Epoch no 6 : \n",
      "Classification loss = 35.6844\n",
      "Comparison loss = 2.7102\n",
      "Epoch no 7 : \n",
      "Classification loss = 34.0292\n",
      "Comparison loss = 2.2844\n",
      "Epoch no 8 : \n",
      "Classification loss = 33.2927\n",
      "Comparison loss = 2.2750\n",
      "Epoch no 9 : \n",
      "Classification loss = 32.3216\n",
      "Comparison loss = 1.9999\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.4804\n",
      "Comparison loss = 1.3689\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.9996\n",
      "Comparison loss = 1.1555\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.4574\n",
      "Comparison loss = 0.8162\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.2411\n",
      "Comparison loss = 0.7055\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.9959\n",
      "Comparison loss = 0.6219\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.8135\n",
      "Comparison loss = 0.4842\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.6689\n",
      "Comparison loss = 0.3228\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.5650\n",
      "Comparison loss = 0.1726\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.4818\n",
      "Comparison loss = 0.1709\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.4598\n",
      "Comparison loss = 0.1508\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.4356\n",
      "Comparison loss = 0.0893\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4182\n",
      "Comparison loss = 0.0649\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4012\n",
      "Comparison loss = 0.0539\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.3959\n",
      "Comparison loss = 0.0311\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.3849\n",
      "Comparison loss = 0.0267\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3795\n",
      "Comparison loss = 0.0238\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.700% \n",
      "Comparison = 0.100%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.400% \n",
      "Comparison = 3.000%\u001b[0m\n",
      "RUN NO 7\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.5196\n",
      "Comparison loss = 5.4234\n",
      "Epoch no 2 : \n",
      "Classification loss = 43.2995\n",
      "Comparison loss = 4.4457\n",
      "Epoch no 3 : \n",
      "Classification loss = 40.3592\n",
      "Comparison loss = 3.4729\n",
      "Epoch no 4 : \n",
      "Classification loss = 37.6866\n",
      "Comparison loss = 3.1185\n",
      "Epoch no 5 : \n",
      "Classification loss = 35.4951\n",
      "Comparison loss = 2.5250\n",
      "Epoch no 6 : \n",
      "Classification loss = 33.9797\n",
      "Comparison loss = 2.0816\n",
      "Epoch no 7 : \n",
      "Classification loss = 33.2107\n",
      "Comparison loss = 1.5669\n",
      "Epoch no 8 : \n",
      "Classification loss = 32.5828\n",
      "Comparison loss = 1.4227\n",
      "Epoch no 9 : \n",
      "Classification loss = 32.3801\n",
      "Comparison loss = 1.3274\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.9333\n",
      "Comparison loss = 0.9918\n",
      "Epoch no 11 : \n",
      "Classification loss = 31.0442\n",
      "Comparison loss = 0.8531\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.6133\n",
      "Comparison loss = 0.7638\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.4635\n",
      "Comparison loss = 0.6627\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.1485\n",
      "Comparison loss = 0.5343\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.9395\n",
      "Comparison loss = 0.3880\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.9357\n",
      "Comparison loss = 0.3248\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.7152\n",
      "Comparison loss = 0.2391\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.6619\n",
      "Comparison loss = 0.2351\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.6231\n",
      "Comparison loss = 0.3901\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.5402\n",
      "Comparison loss = 0.1498\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.5000\n",
      "Comparison loss = 0.1195\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4442\n",
      "Comparison loss = 0.1478\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4009\n",
      "Comparison loss = 0.0764\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.3875\n",
      "Comparison loss = 0.0682\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3691\n",
      "Comparison loss = 0.0627\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.550% \n",
      "Comparison = 0.100%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.400% \n",
      "Comparison = 2.800%\u001b[0m\n",
      "RUN NO 8\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.4445\n",
      "Comparison loss = 5.5154\n",
      "Epoch no 2 : \n",
      "Classification loss = 43.0507\n",
      "Comparison loss = 4.9228\n",
      "Epoch no 3 : \n",
      "Classification loss = 40.1602\n",
      "Comparison loss = 4.1876\n",
      "Epoch no 4 : \n",
      "Classification loss = 37.3043\n",
      "Comparison loss = 3.4940\n",
      "Epoch no 5 : \n",
      "Classification loss = 35.4777\n",
      "Comparison loss = 2.9160\n",
      "Epoch no 6 : \n",
      "Classification loss = 34.3756\n",
      "Comparison loss = 2.2973\n",
      "Epoch no 7 : \n",
      "Classification loss = 33.5347\n",
      "Comparison loss = 1.7824\n",
      "Epoch no 8 : \n",
      "Classification loss = 32.8593\n",
      "Comparison loss = 1.3881\n",
      "Epoch no 9 : \n",
      "Classification loss = 32.0829\n",
      "Comparison loss = 1.5107\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.3882\n",
      "Comparison loss = 1.1551\n",
      "Epoch no 11 : \n",
      "Classification loss = 31.2010\n",
      "Comparison loss = 0.8314\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.7197\n",
      "Comparison loss = 0.8815\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.5008\n",
      "Comparison loss = 0.9983\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.1969\n",
      "Comparison loss = 0.4950\n",
      "Epoch no 15 : \n",
      "Classification loss = 30.0411\n",
      "Comparison loss = 0.4866\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.9296\n",
      "Comparison loss = 0.3795\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.8101\n",
      "Comparison loss = 0.2932\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.7314\n",
      "Comparison loss = 0.3297\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.6026\n",
      "Comparison loss = 0.1943\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.5315\n",
      "Comparison loss = 0.1869\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4853\n",
      "Comparison loss = 0.1638\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4390\n",
      "Comparison loss = 0.1258\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.3970\n",
      "Comparison loss = 0.1479\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4107\n",
      "Comparison loss = 0.1617\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.4000\n",
      "Comparison loss = 0.1290\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.700% \n",
      "Comparison = 0.300%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.950% \n",
      "Comparison = 3.500%\u001b[0m\n",
      "RUN NO 9\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.6502\n",
      "Comparison loss = 6.0094\n",
      "Epoch no 2 : \n",
      "Classification loss = 43.8005\n",
      "Comparison loss = 5.1429\n",
      "Epoch no 3 : \n",
      "Classification loss = 41.4455\n",
      "Comparison loss = 4.8119\n",
      "Epoch no 4 : \n",
      "Classification loss = 39.7806\n",
      "Comparison loss = 3.5730\n",
      "Epoch no 5 : \n",
      "Classification loss = 37.9237\n",
      "Comparison loss = 3.0367\n",
      "Epoch no 6 : \n",
      "Classification loss = 35.5171\n",
      "Comparison loss = 2.7174\n",
      "Epoch no 7 : \n",
      "Classification loss = 33.9166\n",
      "Comparison loss = 1.9943\n",
      "Epoch no 8 : \n",
      "Classification loss = 32.8159\n",
      "Comparison loss = 1.5495\n",
      "Epoch no 9 : \n",
      "Classification loss = 32.2513\n",
      "Comparison loss = 1.3814\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.5141\n",
      "Comparison loss = 0.9974\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.8121\n",
      "Comparison loss = 0.9317\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.7471\n",
      "Comparison loss = 1.0286\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.1921\n",
      "Comparison loss = 0.6606\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.0986\n",
      "Comparison loss = 0.7025\n",
      "Epoch no 15 : \n",
      "Classification loss = 30.0892\n",
      "Comparison loss = 0.5236\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.9650\n",
      "Comparison loss = 0.4860\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.8662\n",
      "Comparison loss = 0.3809\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.7371\n",
      "Comparison loss = 0.2129\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.6163\n",
      "Comparison loss = 0.2292\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.4982\n",
      "Comparison loss = 0.2270\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4720\n",
      "Comparison loss = 0.1673\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4479\n",
      "Comparison loss = 0.1636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch no 23 : \n",
      "Classification loss = 29.4101\n",
      "Comparison loss = 0.1530\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.3880\n",
      "Comparison loss = 0.1427\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3779\n",
      "Comparison loss = 0.1227\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.650% \n",
      "Comparison = 0.200%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.850% \n",
      "Comparison = 3.100%\u001b[0m\n",
      "RUN NO 10\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.2020\n",
      "Comparison loss = 5.5252\n",
      "Epoch no 2 : \n",
      "Classification loss = 42.7548\n",
      "Comparison loss = 4.4253\n",
      "Epoch no 3 : \n",
      "Classification loss = 40.7518\n",
      "Comparison loss = 3.6219\n",
      "Epoch no 4 : \n",
      "Classification loss = 38.3456\n",
      "Comparison loss = 3.1215\n",
      "Epoch no 5 : \n",
      "Classification loss = 35.9609\n",
      "Comparison loss = 2.5474\n",
      "Epoch no 6 : \n",
      "Classification loss = 34.2094\n",
      "Comparison loss = 2.2112\n",
      "Epoch no 7 : \n",
      "Classification loss = 33.0064\n",
      "Comparison loss = 1.6137\n",
      "Epoch no 8 : \n",
      "Classification loss = 32.4877\n",
      "Comparison loss = 2.0769\n",
      "Epoch no 9 : \n",
      "Classification loss = 31.9533\n",
      "Comparison loss = 2.0987\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.3506\n",
      "Comparison loss = 1.7412\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.7675\n",
      "Comparison loss = 1.1552\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.3190\n",
      "Comparison loss = 0.8452\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.1162\n",
      "Comparison loss = 0.6735\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.8671\n",
      "Comparison loss = 0.5243\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.7573\n",
      "Comparison loss = 0.4023\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.6517\n",
      "Comparison loss = 0.2888\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.5742\n",
      "Comparison loss = 0.3305\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.5332\n",
      "Comparison loss = 0.2681\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.4945\n",
      "Comparison loss = 0.2101\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.4794\n",
      "Comparison loss = 0.1987\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4698\n",
      "Comparison loss = 0.1969\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4611\n",
      "Comparison loss = 0.1850\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4541\n",
      "Comparison loss = 0.1784\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4421\n",
      "Comparison loss = 0.1712\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.4354\n",
      "Comparison loss = 0.1478\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.950% \n",
      "Comparison = 0.300%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.650% \n",
      "Comparison = 2.800%\u001b[0m\n",
      "Final error for train batch : 0.21±0.0738\n",
      "Final error for test batch : 3.23±0.3529\n",
      "RUN NO 1\n",
      "Epoch no 1 : \n",
      "Classification loss = 44.9832\n",
      "Comparison loss = 6.9333\n",
      "Epoch no 2 : \n",
      "Classification loss = 41.4724\n",
      "Comparison loss = 6.8785\n",
      "Epoch no 3 : \n",
      "Classification loss = 38.4732\n",
      "Comparison loss = 6.8073\n",
      "Epoch no 4 : \n",
      "Classification loss = 36.2613\n",
      "Comparison loss = 6.6538\n",
      "Epoch no 5 : \n",
      "Classification loss = 35.4097\n",
      "Comparison loss = 6.3571\n",
      "Epoch no 6 : \n",
      "Classification loss = 34.4849\n",
      "Comparison loss = 5.8949\n",
      "Epoch no 7 : \n",
      "Classification loss = 33.6594\n",
      "Comparison loss = 5.1464\n",
      "Epoch no 8 : \n",
      "Classification loss = 32.8784\n",
      "Comparison loss = 4.2746\n",
      "Epoch no 9 : \n",
      "Classification loss = 32.4228\n",
      "Comparison loss = 3.3807\n",
      "Epoch no 10 : \n",
      "Classification loss = 30.9529\n",
      "Comparison loss = 2.9148\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.9075\n",
      "Comparison loss = 3.0011\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.6850\n",
      "Comparison loss = 2.2729\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.4033\n",
      "Comparison loss = 1.9134\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.1142\n",
      "Comparison loss = 2.0768\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.9305\n",
      "Comparison loss = 0.8655\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.7708\n",
      "Comparison loss = 0.9428\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.6480\n",
      "Comparison loss = 0.5676\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.6009\n",
      "Comparison loss = 0.6473\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.5460\n",
      "Comparison loss = 0.3089\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.5164\n",
      "Comparison loss = 0.1924\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4903\n",
      "Comparison loss = 0.1636\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4785\n",
      "Comparison loss = 0.0930\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4302\n",
      "Comparison loss = 0.0607\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4138\n",
      "Comparison loss = 0.0498\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.4016\n",
      "Comparison loss = 0.0575\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.850% \n",
      "Comparison = 0.000%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 3.950% \n",
      "Comparison = 3.000%\u001b[0m\n",
      "RUN NO 2\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.4594\n",
      "Comparison loss = 7.8363\n",
      "Epoch no 2 : \n",
      "Classification loss = 43.4190\n",
      "Comparison loss = 9.3474\n",
      "Epoch no 3 : \n",
      "Classification loss = 41.8026\n",
      "Comparison loss = 6.4444\n",
      "Epoch no 4 : \n",
      "Classification loss = 40.3276\n",
      "Comparison loss = 4.5415\n",
      "Epoch no 5 : \n",
      "Classification loss = 38.4874\n",
      "Comparison loss = 3.4545\n",
      "Epoch no 6 : \n",
      "Classification loss = 36.4776\n",
      "Comparison loss = 3.0918\n",
      "Epoch no 7 : \n",
      "Classification loss = 34.6403\n",
      "Comparison loss = 2.2488\n",
      "Epoch no 8 : \n",
      "Classification loss = 33.7355\n",
      "Comparison loss = 1.8778\n",
      "Epoch no 9 : \n",
      "Classification loss = 32.8378\n",
      "Comparison loss = 1.8547\n",
      "Epoch no 10 : \n",
      "Classification loss = 32.2769\n",
      "Comparison loss = 1.5666\n",
      "Epoch no 11 : \n",
      "Classification loss = 31.6653\n",
      "Comparison loss = 1.2420\n",
      "Epoch no 12 : \n",
      "Classification loss = 31.1295\n",
      "Comparison loss = 1.2592\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.4757\n",
      "Comparison loss = 0.9297\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.2281\n",
      "Comparison loss = 0.7941\n",
      "Epoch no 15 : \n",
      "Classification loss = 30.0637\n",
      "Comparison loss = 0.7025\n",
      "Epoch no 16 : \n",
      "Classification loss = 30.0160\n",
      "Comparison loss = 0.8036\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.9046\n",
      "Comparison loss = 0.5911\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.8473\n",
      "Comparison loss = 0.5289\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.8269\n",
      "Comparison loss = 0.5874\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.6755\n",
      "Comparison loss = 0.3681\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.6856\n",
      "Comparison loss = 0.4493\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.6720\n",
      "Comparison loss = 0.3788\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.5967\n",
      "Comparison loss = 0.3897\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.5429\n",
      "Comparison loss = 0.3083\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.4936\n",
      "Comparison loss = 0.3012\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 1.250% \n",
      "Comparison = 0.500%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 5.100% \n",
      "Comparison = 4.100%\u001b[0m\n",
      "RUN NO 3\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.5342\n",
      "Comparison loss = 6.4754\n",
      "Epoch no 2 : \n",
      "Classification loss = 43.2877\n",
      "Comparison loss = 7.0555\n",
      "Epoch no 3 : \n",
      "Classification loss = 41.2805\n",
      "Comparison loss = 5.2848\n",
      "Epoch no 4 : \n",
      "Classification loss = 39.3962\n",
      "Comparison loss = 3.6325\n",
      "Epoch no 5 : \n",
      "Classification loss = 37.3170\n",
      "Comparison loss = 3.2171\n",
      "Epoch no 6 : \n",
      "Classification loss = 36.1441\n",
      "Comparison loss = 3.1695\n",
      "Epoch no 7 : \n",
      "Classification loss = 34.8595\n",
      "Comparison loss = 2.7666\n",
      "Epoch no 8 : \n",
      "Classification loss = 34.0488\n",
      "Comparison loss = 2.2911\n",
      "Epoch no 9 : \n",
      "Classification loss = 33.0843\n",
      "Comparison loss = 1.9037\n",
      "Epoch no 10 : \n",
      "Classification loss = 32.4267\n",
      "Comparison loss = 1.6201\n",
      "Epoch no 11 : \n",
      "Classification loss = 31.7480\n",
      "Comparison loss = 1.4006\n",
      "Epoch no 12 : \n",
      "Classification loss = 31.4714\n",
      "Comparison loss = 1.4357\n",
      "Epoch no 13 : \n",
      "Classification loss = 31.0194\n",
      "Comparison loss = 1.1022\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.6891\n",
      "Comparison loss = 1.0517\n",
      "Epoch no 15 : \n",
      "Classification loss = 30.3588\n",
      "Comparison loss = 0.8704\n",
      "Epoch no 16 : \n",
      "Classification loss = 30.3262\n",
      "Comparison loss = 0.8104\n",
      "Epoch no 17 : \n",
      "Classification loss = 30.1650\n",
      "Comparison loss = 0.8346\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.8930\n",
      "Comparison loss = 0.5502\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.8553\n",
      "Comparison loss = 0.4346\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.7665\n",
      "Comparison loss = 0.4056\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.6647\n",
      "Comparison loss = 0.3236\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.6289\n",
      "Comparison loss = 0.2367\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.5519\n",
      "Comparison loss = 0.1774\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.5208\n",
      "Comparison loss = 0.1536\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.4976\n",
      "Comparison loss = 0.1136\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 1.150% \n",
      "Comparison = 0.300%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 5.250% \n",
      "Comparison = 3.700%\u001b[0m\n",
      "RUN NO 4\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.3340\n",
      "Comparison loss = 5.8136\n",
      "Epoch no 2 : \n",
      "Classification loss = 42.9842\n",
      "Comparison loss = 6.0690\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch no 3 : \n",
      "Classification loss = 40.7419\n",
      "Comparison loss = 4.3076\n",
      "Epoch no 4 : \n",
      "Classification loss = 38.6638\n",
      "Comparison loss = 3.3573\n",
      "Epoch no 5 : \n",
      "Classification loss = 36.5479\n",
      "Comparison loss = 2.6612\n",
      "Epoch no 6 : \n",
      "Classification loss = 35.1461\n",
      "Comparison loss = 2.4128\n",
      "Epoch no 7 : \n",
      "Classification loss = 34.0414\n",
      "Comparison loss = 2.2699\n",
      "Epoch no 8 : \n",
      "Classification loss = 32.8086\n",
      "Comparison loss = 1.9535\n",
      "Epoch no 9 : \n",
      "Classification loss = 32.2711\n",
      "Comparison loss = 1.4601\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.5885\n",
      "Comparison loss = 1.1817\n",
      "Epoch no 11 : \n",
      "Classification loss = 31.3798\n",
      "Comparison loss = 1.3845\n",
      "Epoch no 12 : \n",
      "Classification loss = 31.1737\n",
      "Comparison loss = 1.2970\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.5866\n",
      "Comparison loss = 0.7958\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.2781\n",
      "Comparison loss = 0.6894\n",
      "Epoch no 15 : \n",
      "Classification loss = 30.0061\n",
      "Comparison loss = 0.5805\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.8824\n",
      "Comparison loss = 0.5275\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.7346\n",
      "Comparison loss = 0.4168\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.6442\n",
      "Comparison loss = 0.3015\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.5732\n",
      "Comparison loss = 0.2586\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.5228\n",
      "Comparison loss = 0.2223\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4995\n",
      "Comparison loss = 0.2046\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4766\n",
      "Comparison loss = 0.1910\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4579\n",
      "Comparison loss = 0.1726\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4386\n",
      "Comparison loss = 0.1277\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.4201\n",
      "Comparison loss = 0.1203\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.850% \n",
      "Comparison = 0.200%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.200% \n",
      "Comparison = 3.300%\u001b[0m\n",
      "RUN NO 5\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.6951\n",
      "Comparison loss = 6.5900\n",
      "Epoch no 2 : \n",
      "Classification loss = 43.8339\n",
      "Comparison loss = 5.7855\n",
      "Epoch no 3 : \n",
      "Classification loss = 41.0783\n",
      "Comparison loss = 4.7892\n",
      "Epoch no 4 : \n",
      "Classification loss = 38.8896\n",
      "Comparison loss = 3.8605\n",
      "Epoch no 5 : \n",
      "Classification loss = 36.8413\n",
      "Comparison loss = 2.9823\n",
      "Epoch no 6 : \n",
      "Classification loss = 34.8977\n",
      "Comparison loss = 2.4201\n",
      "Epoch no 7 : \n",
      "Classification loss = 34.1344\n",
      "Comparison loss = 2.2607\n",
      "Epoch no 8 : \n",
      "Classification loss = 33.5730\n",
      "Comparison loss = 2.1149\n",
      "Epoch no 9 : \n",
      "Classification loss = 33.3238\n",
      "Comparison loss = 1.9889\n",
      "Epoch no 10 : \n",
      "Classification loss = 32.4102\n",
      "Comparison loss = 1.3534\n",
      "Epoch no 11 : \n",
      "Classification loss = 31.4071\n",
      "Comparison loss = 1.1713\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.6031\n",
      "Comparison loss = 1.0257\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.3295\n",
      "Comparison loss = 0.7316\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.0555\n",
      "Comparison loss = 0.4857\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.9464\n",
      "Comparison loss = 0.4383\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.8417\n",
      "Comparison loss = 0.3868\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.7413\n",
      "Comparison loss = 0.3624\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.6679\n",
      "Comparison loss = 0.2757\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.5814\n",
      "Comparison loss = 0.1658\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.5289\n",
      "Comparison loss = 0.1419\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4860\n",
      "Comparison loss = 0.1030\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4616\n",
      "Comparison loss = 0.0977\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4360\n",
      "Comparison loss = 0.0939\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4136\n",
      "Comparison loss = 0.0908\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3934\n",
      "Comparison loss = 0.0883\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.650% \n",
      "Comparison = 0.200%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.200% \n",
      "Comparison = 3.700%\u001b[0m\n",
      "RUN NO 6\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.3298\n",
      "Comparison loss = 5.5883\n",
      "Epoch no 2 : \n",
      "Classification loss = 42.7202\n",
      "Comparison loss = 5.1580\n",
      "Epoch no 3 : \n",
      "Classification loss = 39.9278\n",
      "Comparison loss = 3.6561\n",
      "Epoch no 4 : \n",
      "Classification loss = 37.1770\n",
      "Comparison loss = 3.3393\n",
      "Epoch no 5 : \n",
      "Classification loss = 35.3844\n",
      "Comparison loss = 2.5383\n",
      "Epoch no 6 : \n",
      "Classification loss = 34.0586\n",
      "Comparison loss = 2.1134\n",
      "Epoch no 7 : \n",
      "Classification loss = 33.3261\n",
      "Comparison loss = 1.9569\n",
      "Epoch no 8 : \n",
      "Classification loss = 32.5343\n",
      "Comparison loss = 1.7508\n",
      "Epoch no 9 : \n",
      "Classification loss = 31.6286\n",
      "Comparison loss = 1.2032\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.1524\n",
      "Comparison loss = 1.1494\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.4489\n",
      "Comparison loss = 0.7377\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.2917\n",
      "Comparison loss = 0.7029\n",
      "Epoch no 13 : \n",
      "Classification loss = 29.9711\n",
      "Comparison loss = 0.5874\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.8855\n",
      "Comparison loss = 0.3798\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.7200\n",
      "Comparison loss = 0.3545\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.6156\n",
      "Comparison loss = 0.2592\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.5581\n",
      "Comparison loss = 0.2135\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.5277\n",
      "Comparison loss = 0.1455\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.4721\n",
      "Comparison loss = 0.0760\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.4491\n",
      "Comparison loss = 0.0566\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4334\n",
      "Comparison loss = 0.0545\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4205\n",
      "Comparison loss = 0.0562\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4170\n",
      "Comparison loss = 0.0473\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4108\n",
      "Comparison loss = 0.0467\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.4050\n",
      "Comparison loss = 0.0379\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.850% \n",
      "Comparison = 0.100%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 3.850% \n",
      "Comparison = 2.900%\u001b[0m\n",
      "RUN NO 7\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.7405\n",
      "Comparison loss = 6.4279\n",
      "Epoch no 2 : \n",
      "Classification loss = 43.7215\n",
      "Comparison loss = 5.0008\n",
      "Epoch no 3 : \n",
      "Classification loss = 40.9787\n",
      "Comparison loss = 4.6756\n",
      "Epoch no 4 : \n",
      "Classification loss = 38.2753\n",
      "Comparison loss = 3.5802\n",
      "Epoch no 5 : \n",
      "Classification loss = 35.7226\n",
      "Comparison loss = 2.6332\n",
      "Epoch no 6 : \n",
      "Classification loss = 34.6305\n",
      "Comparison loss = 2.3495\n",
      "Epoch no 7 : \n",
      "Classification loss = 34.3398\n",
      "Comparison loss = 1.9291\n",
      "Epoch no 8 : \n",
      "Classification loss = 33.8638\n",
      "Comparison loss = 2.0496\n",
      "Epoch no 9 : \n",
      "Classification loss = 33.4441\n",
      "Comparison loss = 1.6776\n",
      "Epoch no 10 : \n",
      "Classification loss = 32.6970\n",
      "Comparison loss = 1.5209\n",
      "Epoch no 11 : \n",
      "Classification loss = 31.5084\n",
      "Comparison loss = 1.1469\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.8515\n",
      "Comparison loss = 0.9620\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.5115\n",
      "Comparison loss = 0.9162\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.2431\n",
      "Comparison loss = 0.5726\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.9883\n",
      "Comparison loss = 0.4718\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.8922\n",
      "Comparison loss = 0.4593\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.7635\n",
      "Comparison loss = 0.3673\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.7293\n",
      "Comparison loss = 0.2911\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.5823\n",
      "Comparison loss = 0.2323\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.5203\n",
      "Comparison loss = 0.1937\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4822\n",
      "Comparison loss = 0.1863\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4564\n",
      "Comparison loss = 0.1812\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4436\n",
      "Comparison loss = 0.1750\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4346\n",
      "Comparison loss = 0.1702\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.4274\n",
      "Comparison loss = 0.1665\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.950% \n",
      "Comparison = 0.300%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 5.050% \n",
      "Comparison = 3.100%\u001b[0m\n",
      "RUN NO 8\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.5477\n",
      "Comparison loss = 6.2331\n",
      "Epoch no 2 : \n",
      "Classification loss = 43.3764\n",
      "Comparison loss = 5.0304\n",
      "Epoch no 3 : \n",
      "Classification loss = 40.8921\n",
      "Comparison loss = 4.0970\n",
      "Epoch no 4 : \n",
      "Classification loss = 38.0516\n",
      "Comparison loss = 3.5546\n",
      "Epoch no 5 : \n",
      "Classification loss = 35.9461\n",
      "Comparison loss = 2.6064\n",
      "Epoch no 6 : \n",
      "Classification loss = 34.6896\n",
      "Comparison loss = 2.6903\n",
      "Epoch no 7 : \n",
      "Classification loss = 34.0436\n",
      "Comparison loss = 2.1319\n",
      "Epoch no 8 : \n",
      "Classification loss = 33.1415\n",
      "Comparison loss = 2.1750\n",
      "Epoch no 9 : \n",
      "Classification loss = 31.6194\n",
      "Comparison loss = 1.2565\n",
      "Epoch no 10 : \n",
      "Classification loss = 30.9199\n",
      "Comparison loss = 1.1185\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.8342\n",
      "Comparison loss = 1.0166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch no 12 : \n",
      "Classification loss = 30.4389\n",
      "Comparison loss = 0.7232\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.1302\n",
      "Comparison loss = 0.4712\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.9322\n",
      "Comparison loss = 0.5085\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.8498\n",
      "Comparison loss = 0.3438\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.7483\n",
      "Comparison loss = 0.2432\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.6235\n",
      "Comparison loss = 0.2376\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.5486\n",
      "Comparison loss = 0.2518\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.5019\n",
      "Comparison loss = 0.2026\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.4604\n",
      "Comparison loss = 0.2013\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4595\n",
      "Comparison loss = 0.1316\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4267\n",
      "Comparison loss = 0.1099\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4061\n",
      "Comparison loss = 0.0974\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.3911\n",
      "Comparison loss = 0.0918\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3795\n",
      "Comparison loss = 0.0777\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.650% \n",
      "Comparison = 0.200%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 3.900% \n",
      "Comparison = 2.800%\u001b[0m\n",
      "RUN NO 9\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.1892\n",
      "Comparison loss = 5.9587\n",
      "Epoch no 2 : \n",
      "Classification loss = 42.0756\n",
      "Comparison loss = 4.4055\n",
      "Epoch no 3 : \n",
      "Classification loss = 38.8019\n",
      "Comparison loss = 4.1405\n",
      "Epoch no 4 : \n",
      "Classification loss = 36.6959\n",
      "Comparison loss = 2.8885\n",
      "Epoch no 5 : \n",
      "Classification loss = 34.9518\n",
      "Comparison loss = 2.1813\n",
      "Epoch no 6 : \n",
      "Classification loss = 33.4138\n",
      "Comparison loss = 1.8939\n",
      "Epoch no 7 : \n",
      "Classification loss = 33.1319\n",
      "Comparison loss = 2.0417\n",
      "Epoch no 8 : \n",
      "Classification loss = 32.2843\n",
      "Comparison loss = 1.5318\n",
      "Epoch no 9 : \n",
      "Classification loss = 31.2149\n",
      "Comparison loss = 0.9887\n",
      "Epoch no 10 : \n",
      "Classification loss = 30.7358\n",
      "Comparison loss = 1.0715\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.4283\n",
      "Comparison loss = 0.5882\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.1811\n",
      "Comparison loss = 0.4596\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.0094\n",
      "Comparison loss = 0.3896\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.7894\n",
      "Comparison loss = 0.2499\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.7404\n",
      "Comparison loss = 0.1964\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.6017\n",
      "Comparison loss = 0.1832\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.5650\n",
      "Comparison loss = 0.1325\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.5079\n",
      "Comparison loss = 0.1008\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.4759\n",
      "Comparison loss = 0.0856\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.4488\n",
      "Comparison loss = 0.0827\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4191\n",
      "Comparison loss = 0.0778\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.3999\n",
      "Comparison loss = 0.0704\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.3861\n",
      "Comparison loss = 0.0623\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.3745\n",
      "Comparison loss = 0.0156\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3581\n",
      "Comparison loss = 0.0053\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.500% \n",
      "Comparison = 0.000%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.550% \n",
      "Comparison = 3.300%\u001b[0m\n",
      "RUN NO 10\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.2159\n",
      "Comparison loss = 5.6468\n",
      "Epoch no 2 : \n",
      "Classification loss = 42.4451\n",
      "Comparison loss = 4.8306\n",
      "Epoch no 3 : \n",
      "Classification loss = 39.9903\n",
      "Comparison loss = 3.9666\n",
      "Epoch no 4 : \n",
      "Classification loss = 37.6536\n",
      "Comparison loss = 2.9731\n",
      "Epoch no 5 : \n",
      "Classification loss = 35.6607\n",
      "Comparison loss = 2.5297\n",
      "Epoch no 6 : \n",
      "Classification loss = 34.8020\n",
      "Comparison loss = 2.2445\n",
      "Epoch no 7 : \n",
      "Classification loss = 33.9333\n",
      "Comparison loss = 1.8278\n",
      "Epoch no 8 : \n",
      "Classification loss = 33.1109\n",
      "Comparison loss = 1.6411\n",
      "Epoch no 9 : \n",
      "Classification loss = 31.9475\n",
      "Comparison loss = 1.3105\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.1915\n",
      "Comparison loss = 1.0539\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.6545\n",
      "Comparison loss = 1.0339\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.2839\n",
      "Comparison loss = 0.7019\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.1802\n",
      "Comparison loss = 0.5331\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.9734\n",
      "Comparison loss = 0.3495\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.9060\n",
      "Comparison loss = 0.4025\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.7858\n",
      "Comparison loss = 0.3417\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.7252\n",
      "Comparison loss = 0.3307\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.5975\n",
      "Comparison loss = 0.2356\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.5273\n",
      "Comparison loss = 0.2247\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.4689\n",
      "Comparison loss = 0.1716\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4388\n",
      "Comparison loss = 0.1398\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4179\n",
      "Comparison loss = 0.1009\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4039\n",
      "Comparison loss = 0.0733\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.3870\n",
      "Comparison loss = 0.0855\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3665\n",
      "Comparison loss = 0.0655\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.550% \n",
      "Comparison = 0.100%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.050% \n",
      "Comparison = 2.700%\u001b[0m\n",
      "Final error for train batch : 0.19±0.1524\n",
      "Final error for test batch : 3.26±0.4526\n",
      "RUN NO 1\n",
      "Epoch no 1 : \n",
      "Classification loss = 44.9556\n",
      "Comparison loss = 6.8966\n",
      "Epoch no 2 : \n",
      "Classification loss = 41.5464\n",
      "Comparison loss = 6.8856\n",
      "Epoch no 3 : \n",
      "Classification loss = 38.0771\n",
      "Comparison loss = 6.9039\n",
      "Epoch no 4 : \n",
      "Classification loss = 35.2565\n",
      "Comparison loss = 6.8977\n",
      "Epoch no 5 : \n",
      "Classification loss = 33.7993\n",
      "Comparison loss = 6.8779\n",
      "Epoch no 6 : \n",
      "Classification loss = 32.8010\n",
      "Comparison loss = 6.8903\n",
      "Epoch no 7 : \n",
      "Classification loss = 32.7611\n",
      "Comparison loss = 6.9081\n",
      "Epoch no 8 : \n",
      "Classification loss = 32.3358\n",
      "Comparison loss = 6.8773\n",
      "Epoch no 9 : \n",
      "Classification loss = 31.5904\n",
      "Comparison loss = 6.8821\n",
      "Epoch no 10 : \n",
      "Classification loss = 30.9971\n",
      "Comparison loss = 6.8910\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.3208\n",
      "Comparison loss = 6.8954\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.1152\n",
      "Comparison loss = 6.8746\n",
      "Epoch no 13 : \n",
      "Classification loss = 29.8994\n",
      "Comparison loss = 6.8817\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.7677\n",
      "Comparison loss = 6.8907\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.6302\n",
      "Comparison loss = 6.8845\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.5604\n",
      "Comparison loss = 6.8749\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.4875\n",
      "Comparison loss = 6.8816\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.4570\n",
      "Comparison loss = 6.8880\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.4267\n",
      "Comparison loss = 6.8757\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.4091\n",
      "Comparison loss = 6.8747\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.3883\n",
      "Comparison loss = 6.8812\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.3761\n",
      "Comparison loss = 6.8780\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.3610\n",
      "Comparison loss = 6.8664\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.3571\n",
      "Comparison loss = 6.8698\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3543\n",
      "Comparison loss = 6.8700\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.600% \n",
      "Comparison = 44.900%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.500% \n",
      "Comparison = 47.400%\u001b[0m\n",
      "RUN NO 2\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.1116\n",
      "Comparison loss = 6.8784\n",
      "Epoch no 2 : \n",
      "Classification loss = 42.5154\n",
      "Comparison loss = 6.8855\n",
      "Epoch no 3 : \n",
      "Classification loss = 40.6936\n",
      "Comparison loss = 6.8956\n",
      "Epoch no 4 : \n",
      "Classification loss = 38.5350\n",
      "Comparison loss = 6.8807\n",
      "Epoch no 5 : \n",
      "Classification loss = 36.3081\n",
      "Comparison loss = 6.8558\n",
      "Epoch no 6 : \n",
      "Classification loss = 34.9085\n",
      "Comparison loss = 6.8638\n",
      "Epoch no 7 : \n",
      "Classification loss = 33.4108\n",
      "Comparison loss = 6.8747\n",
      "Epoch no 8 : \n",
      "Classification loss = 31.8558\n",
      "Comparison loss = 6.8426\n",
      "Epoch no 9 : \n",
      "Classification loss = 31.0535\n",
      "Comparison loss = 6.8336\n",
      "Epoch no 10 : \n",
      "Classification loss = 30.7838\n",
      "Comparison loss = 6.8330\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.8677\n",
      "Comparison loss = 6.8200\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.1890\n",
      "Comparison loss = 6.7787\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.0500\n",
      "Comparison loss = 6.7742\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.8091\n",
      "Comparison loss = 6.7132\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.7151\n",
      "Comparison loss = 6.7120\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.6021\n",
      "Comparison loss = 6.7869\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.5217\n",
      "Comparison loss = 6.5782\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.4643\n",
      "Comparison loss = 6.6274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch no 19 : \n",
      "Classification loss = 29.4334\n",
      "Comparison loss = 6.8443\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.4061\n",
      "Comparison loss = 6.4932\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.3903\n",
      "Comparison loss = 6.6228\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.3817\n",
      "Comparison loss = 6.7296\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.3730\n",
      "Comparison loss = 6.4118\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.3608\n",
      "Comparison loss = 6.6109\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3538\n",
      "Comparison loss = 6.4244\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.550% \n",
      "Comparison = 44.900%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.100% \n",
      "Comparison = 47.400%\u001b[0m\n",
      "RUN NO 3\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.4594\n",
      "Comparison loss = 6.9067\n",
      "Epoch no 2 : \n",
      "Classification loss = 42.9441\n",
      "Comparison loss = 7.0148\n",
      "Epoch no 3 : \n",
      "Classification loss = 39.8271\n",
      "Comparison loss = 6.6319\n",
      "Epoch no 4 : \n",
      "Classification loss = 37.3192\n",
      "Comparison loss = 6.7112\n",
      "Epoch no 5 : \n",
      "Classification loss = 35.1463\n",
      "Comparison loss = 6.4315\n",
      "Epoch no 6 : \n",
      "Classification loss = 33.5037\n",
      "Comparison loss = 6.4580\n",
      "Epoch no 7 : \n",
      "Classification loss = 32.0327\n",
      "Comparison loss = 6.3371\n",
      "Epoch no 8 : \n",
      "Classification loss = 31.6253\n",
      "Comparison loss = 6.3434\n",
      "Epoch no 9 : \n",
      "Classification loss = 31.3332\n",
      "Comparison loss = 6.1809\n",
      "Epoch no 10 : \n",
      "Classification loss = 30.9818\n",
      "Comparison loss = 6.1496\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.5023\n",
      "Comparison loss = 6.1516\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.1458\n",
      "Comparison loss = 5.9013\n",
      "Epoch no 13 : \n",
      "Classification loss = 29.9198\n",
      "Comparison loss = 5.8951\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.7956\n",
      "Comparison loss = 6.1510\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.6948\n",
      "Comparison loss = 5.9009\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.6357\n",
      "Comparison loss = 5.7694\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.5940\n",
      "Comparison loss = 6.3407\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.5606\n",
      "Comparison loss = 6.0842\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.5337\n",
      "Comparison loss = 5.7363\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.5036\n",
      "Comparison loss = 6.7496\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4852\n",
      "Comparison loss = 5.5710\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4464\n",
      "Comparison loss = 6.1673\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4207\n",
      "Comparison loss = 6.0512\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4021\n",
      "Comparison loss = 5.6692\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3957\n",
      "Comparison loss = 5.9246\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.750% \n",
      "Comparison = 35.900%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.200% \n",
      "Comparison = 34.200%\u001b[0m\n",
      "RUN NO 4\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.1619\n",
      "Comparison loss = 7.2428\n",
      "Epoch no 2 : \n",
      "Classification loss = 42.0400\n",
      "Comparison loss = 7.0099\n",
      "Epoch no 3 : \n",
      "Classification loss = 38.9705\n",
      "Comparison loss = 6.3788\n",
      "Epoch no 4 : \n",
      "Classification loss = 36.1239\n",
      "Comparison loss = 6.0389\n",
      "Epoch no 5 : \n",
      "Classification loss = 34.3363\n",
      "Comparison loss = 6.0563\n",
      "Epoch no 6 : \n",
      "Classification loss = 32.8444\n",
      "Comparison loss = 5.7281\n",
      "Epoch no 7 : \n",
      "Classification loss = 31.2902\n",
      "Comparison loss = 5.5945\n",
      "Epoch no 8 : \n",
      "Classification loss = 30.8210\n",
      "Comparison loss = 5.3551\n",
      "Epoch no 9 : \n",
      "Classification loss = 30.3002\n",
      "Comparison loss = 5.5463\n",
      "Epoch no 10 : \n",
      "Classification loss = 30.1463\n",
      "Comparison loss = 5.1000\n",
      "Epoch no 11 : \n",
      "Classification loss = 29.8773\n",
      "Comparison loss = 5.1995\n",
      "Epoch no 12 : \n",
      "Classification loss = 29.7649\n",
      "Comparison loss = 5.3340\n",
      "Epoch no 13 : \n",
      "Classification loss = 29.6627\n",
      "Comparison loss = 4.8573\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.5579\n",
      "Comparison loss = 5.1945\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.4906\n",
      "Comparison loss = 5.4008\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.4654\n",
      "Comparison loss = 4.7168\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.4424\n",
      "Comparison loss = 5.4997\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.4233\n",
      "Comparison loss = 5.5948\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.4069\n",
      "Comparison loss = 4.8092\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.3878\n",
      "Comparison loss = 5.9871\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.3698\n",
      "Comparison loss = 5.1272\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.3591\n",
      "Comparison loss = 5.6105\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.3457\n",
      "Comparison loss = 5.2857\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.3367\n",
      "Comparison loss = 4.8348\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3328\n",
      "Comparison loss = 5.9980\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.500% \n",
      "Comparison = 36.200%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.100% \n",
      "Comparison = 38.000%\u001b[0m\n",
      "RUN NO 5\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.2605\n",
      "Comparison loss = 7.2269\n",
      "Epoch no 2 : \n",
      "Classification loss = 42.8653\n",
      "Comparison loss = 6.8070\n",
      "Epoch no 3 : \n",
      "Classification loss = 40.8565\n",
      "Comparison loss = 7.4382\n",
      "Epoch no 4 : \n",
      "Classification loss = 38.5871\n",
      "Comparison loss = 5.4767\n",
      "Epoch no 5 : \n",
      "Classification loss = 35.8362\n",
      "Comparison loss = 5.9920\n",
      "Epoch no 6 : \n",
      "Classification loss = 33.7268\n",
      "Comparison loss = 4.9565\n",
      "Epoch no 7 : \n",
      "Classification loss = 32.9306\n",
      "Comparison loss = 5.5630\n",
      "Epoch no 8 : \n",
      "Classification loss = 32.5935\n",
      "Comparison loss = 4.6227\n",
      "Epoch no 9 : \n",
      "Classification loss = 31.7613\n",
      "Comparison loss = 5.0766\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.0456\n",
      "Comparison loss = 4.6153\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.5995\n",
      "Comparison loss = 4.9224\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.2656\n",
      "Comparison loss = 4.3888\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.1341\n",
      "Comparison loss = 4.5163\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.9114\n",
      "Comparison loss = 4.6679\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.7597\n",
      "Comparison loss = 4.1445\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.6572\n",
      "Comparison loss = 4.5551\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.6204\n",
      "Comparison loss = 4.4460\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.5452\n",
      "Comparison loss = 4.1559\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.5070\n",
      "Comparison loss = 4.6626\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.4808\n",
      "Comparison loss = 4.3417\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4659\n",
      "Comparison loss = 4.3728\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4512\n",
      "Comparison loss = 4.9012\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4323\n",
      "Comparison loss = 4.2464\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4182\n",
      "Comparison loss = 4.9887\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.4035\n",
      "Comparison loss = 4.7964\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.800% \n",
      "Comparison = 31.800%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.650% \n",
      "Comparison = 30.700%\u001b[0m\n",
      "RUN NO 6\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.1629\n",
      "Comparison loss = 7.8999\n",
      "Epoch no 2 : \n",
      "Classification loss = 41.9641\n",
      "Comparison loss = 7.1467\n",
      "Epoch no 3 : \n",
      "Classification loss = 38.5245\n",
      "Comparison loss = 6.3814\n",
      "Epoch no 4 : \n",
      "Classification loss = 35.9861\n",
      "Comparison loss = 5.1758\n",
      "Epoch no 5 : \n",
      "Classification loss = 34.0940\n",
      "Comparison loss = 5.7130\n",
      "Epoch no 6 : \n",
      "Classification loss = 33.1961\n",
      "Comparison loss = 4.3768\n",
      "Epoch no 7 : \n",
      "Classification loss = 32.7600\n",
      "Comparison loss = 4.9397\n",
      "Epoch no 8 : \n",
      "Classification loss = 32.0747\n",
      "Comparison loss = 4.1758\n",
      "Epoch no 9 : \n",
      "Classification loss = 31.4477\n",
      "Comparison loss = 4.6827\n",
      "Epoch no 10 : \n",
      "Classification loss = 30.9341\n",
      "Comparison loss = 3.9273\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.5766\n",
      "Comparison loss = 4.2376\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.3408\n",
      "Comparison loss = 4.0864\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.0437\n",
      "Comparison loss = 3.9617\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.9165\n",
      "Comparison loss = 4.0844\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.7723\n",
      "Comparison loss = 3.7385\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.6951\n",
      "Comparison loss = 4.2296\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.5983\n",
      "Comparison loss = 3.7623\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.5446\n",
      "Comparison loss = 3.7244\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.4736\n",
      "Comparison loss = 4.5583\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.4441\n",
      "Comparison loss = 3.5578\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4203\n",
      "Comparison loss = 4.0708\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4135\n",
      "Comparison loss = 4.9359\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4036\n",
      "Comparison loss = 3.5044\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4006\n",
      "Comparison loss = 4.9175\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3909\n",
      "Comparison loss = 4.6990\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.700% \n",
      "Comparison = 36.100%\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.150% \n",
      "Comparison = 37.900%\u001b[0m\n",
      "RUN NO 7\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.5079\n",
      "Comparison loss = 8.0365\n",
      "Epoch no 2 : \n",
      "Classification loss = 43.4864\n",
      "Comparison loss = 10.2046\n",
      "Epoch no 3 : \n",
      "Classification loss = 40.3795\n",
      "Comparison loss = 6.1501\n",
      "Epoch no 4 : \n",
      "Classification loss = 37.5375\n",
      "Comparison loss = 6.4061\n",
      "Epoch no 5 : \n",
      "Classification loss = 35.1549\n",
      "Comparison loss = 4.2984\n",
      "Epoch no 6 : \n",
      "Classification loss = 33.5409\n",
      "Comparison loss = 4.8383\n",
      "Epoch no 7 : \n",
      "Classification loss = 32.5482\n",
      "Comparison loss = 4.0326\n",
      "Epoch no 8 : \n",
      "Classification loss = 32.4973\n",
      "Comparison loss = 4.4507\n",
      "Epoch no 9 : \n",
      "Classification loss = 31.0812\n",
      "Comparison loss = 3.5989\n",
      "Epoch no 10 : \n",
      "Classification loss = 30.6468\n",
      "Comparison loss = 3.8825\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.3317\n",
      "Comparison loss = 3.8067\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.1710\n",
      "Comparison loss = 3.4884\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.0434\n",
      "Comparison loss = 3.6474\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.8684\n",
      "Comparison loss = 3.3828\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.7826\n",
      "Comparison loss = 3.7531\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.6803\n",
      "Comparison loss = 3.2867\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.5974\n",
      "Comparison loss = 3.3601\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.5191\n",
      "Comparison loss = 3.8881\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.4898\n",
      "Comparison loss = 3.0637\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.4624\n",
      "Comparison loss = 3.6117\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4293\n",
      "Comparison loss = 4.0521\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4095\n",
      "Comparison loss = 3.0694\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.3972\n",
      "Comparison loss = 4.1679\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.3892\n",
      "Comparison loss = 4.1338\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3826\n",
      "Comparison loss = 3.4082\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.700% \n",
      "Comparison = 18.600%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.350% \n",
      "Comparison = 19.900%\u001b[0m\n",
      "RUN NO 8\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.2088\n",
      "Comparison loss = 7.6649\n",
      "Epoch no 2 : \n",
      "Classification loss = 42.7481\n",
      "Comparison loss = 5.7289\n",
      "Epoch no 3 : \n",
      "Classification loss = 39.9157\n",
      "Comparison loss = 4.9539\n",
      "Epoch no 4 : \n",
      "Classification loss = 37.4055\n",
      "Comparison loss = 5.4067\n",
      "Epoch no 5 : \n",
      "Classification loss = 35.3406\n",
      "Comparison loss = 5.1652\n",
      "Epoch no 6 : \n",
      "Classification loss = 33.9965\n",
      "Comparison loss = 4.1711\n",
      "Epoch no 7 : \n",
      "Classification loss = 32.8764\n",
      "Comparison loss = 5.8423\n",
      "Epoch no 8 : \n",
      "Classification loss = 32.2429\n",
      "Comparison loss = 3.6188\n",
      "Epoch no 9 : \n",
      "Classification loss = 31.4455\n",
      "Comparison loss = 5.0553\n",
      "Epoch no 10 : \n",
      "Classification loss = 30.8363\n",
      "Comparison loss = 4.4581\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.6381\n",
      "Comparison loss = 4.0770\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.3983\n",
      "Comparison loss = 4.3273\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.0433\n",
      "Comparison loss = 3.4773\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.8843\n",
      "Comparison loss = 4.7564\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.8061\n",
      "Comparison loss = 3.1351\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.6918\n",
      "Comparison loss = 4.1144\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.5962\n",
      "Comparison loss = 3.7854\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.5304\n",
      "Comparison loss = 3.5416\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.4828\n",
      "Comparison loss = 3.7801\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.4448\n",
      "Comparison loss = 3.1651\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4306\n",
      "Comparison loss = 4.2447\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4144\n",
      "Comparison loss = 3.0067\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4012\n",
      "Comparison loss = 3.6444\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.3903\n",
      "Comparison loss = 3.9759\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3825\n",
      "Comparison loss = 3.0279\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.700% \n",
      "Comparison = 15.900%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.300% \n",
      "Comparison = 17.000%\u001b[0m\n",
      "RUN NO 9\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.3824\n",
      "Comparison loss = 7.4563\n",
      "Epoch no 2 : \n",
      "Classification loss = 42.5632\n",
      "Comparison loss = 5.4608\n",
      "Epoch no 3 : \n",
      "Classification loss = 39.6446\n",
      "Comparison loss = 4.8940\n",
      "Epoch no 4 : \n",
      "Classification loss = 37.7906\n",
      "Comparison loss = 4.3832\n",
      "Epoch no 5 : \n",
      "Classification loss = 35.8048\n",
      "Comparison loss = 5.0350\n",
      "Epoch no 6 : \n",
      "Classification loss = 34.2183\n",
      "Comparison loss = 4.2713\n",
      "Epoch no 7 : \n",
      "Classification loss = 33.1176\n",
      "Comparison loss = 4.4161\n",
      "Epoch no 8 : \n",
      "Classification loss = 32.5195\n",
      "Comparison loss = 4.2696\n",
      "Epoch no 9 : \n",
      "Classification loss = 32.0294\n",
      "Comparison loss = 3.5184\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.3351\n",
      "Comparison loss = 4.8080\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.7380\n",
      "Comparison loss = 3.2852\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.4618\n",
      "Comparison loss = 3.9369\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.1199\n",
      "Comparison loss = 4.2648\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.0089\n",
      "Comparison loss = 3.1875\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.8181\n",
      "Comparison loss = 4.3497\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.7777\n",
      "Comparison loss = 3.3708\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.6445\n",
      "Comparison loss = 4.0487\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.5711\n",
      "Comparison loss = 3.5640\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.5311\n",
      "Comparison loss = 3.2878\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.5135\n",
      "Comparison loss = 4.6006\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4747\n",
      "Comparison loss = 2.8582\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4349\n",
      "Comparison loss = 4.1326\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4110\n",
      "Comparison loss = 3.8400\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4018\n",
      "Comparison loss = 3.3995\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3980\n",
      "Comparison loss = 4.0347\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.800% \n",
      "Comparison = 18.800%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.200% \n",
      "Comparison = 19.700%\u001b[0m\n",
      "RUN NO 10\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.1756\n",
      "Comparison loss = 8.1278\n",
      "Epoch no 2 : \n",
      "Classification loss = 42.5810\n",
      "Comparison loss = 5.4915\n",
      "Epoch no 3 : \n",
      "Classification loss = 40.0252\n",
      "Comparison loss = 7.0398\n",
      "Epoch no 4 : \n",
      "Classification loss = 37.5140\n",
      "Comparison loss = 6.6746\n",
      "Epoch no 5 : \n",
      "Classification loss = 35.6163\n",
      "Comparison loss = 4.6532\n",
      "Epoch no 6 : \n",
      "Classification loss = 33.8427\n",
      "Comparison loss = 4.8717\n",
      "Epoch no 7 : \n",
      "Classification loss = 33.5365\n",
      "Comparison loss = 4.1996\n",
      "Epoch no 8 : \n",
      "Classification loss = 32.6126\n",
      "Comparison loss = 5.0539\n",
      "Epoch no 9 : \n",
      "Classification loss = 32.0182\n",
      "Comparison loss = 3.2502\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.4386\n",
      "Comparison loss = 4.1541\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.9196\n",
      "Comparison loss = 3.3331\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.7130\n",
      "Comparison loss = 4.1471\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.2201\n",
      "Comparison loss = 3.0247\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.0652\n",
      "Comparison loss = 3.5093\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.8668\n",
      "Comparison loss = 3.5740\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.7096\n",
      "Comparison loss = 2.9808\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.6374\n",
      "Comparison loss = 3.4572\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.5470\n",
      "Comparison loss = 2.9351\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.5079\n",
      "Comparison loss = 3.5321\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.4662\n",
      "Comparison loss = 2.9255\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4353\n",
      "Comparison loss = 2.9931\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4141\n",
      "Comparison loss = 3.8019\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4062\n",
      "Comparison loss = 2.6122\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.3838\n",
      "Comparison loss = 3.5011\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3767\n",
      "Comparison loss = 3.6348\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.650% \n",
      "Comparison = 22.700%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.600% \n",
      "Comparison = 24.100%\u001b[0m\n",
      "Final error for train batch : 30.58±10.8620\n",
      "Final error for test batch : 31.63±11.2319\n",
      "RUN NO 1\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.3977\n",
      "Comparison loss = 6.8998\n",
      "Epoch no 2 : \n",
      "Classification loss = 43.0690\n",
      "Comparison loss = 6.8911\n",
      "Epoch no 3 : \n",
      "Classification loss = 40.7236\n",
      "Comparison loss = 6.8643\n",
      "Epoch no 4 : \n",
      "Classification loss = 38.3268\n",
      "Comparison loss = 6.7909\n",
      "Epoch no 5 : \n",
      "Classification loss = 35.4759\n",
      "Comparison loss = 6.5321\n",
      "Epoch no 6 : \n",
      "Classification loss = 33.5822\n",
      "Comparison loss = 5.8133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch no 7 : \n",
      "Classification loss = 33.2373\n",
      "Comparison loss = 5.2809\n",
      "Epoch no 8 : \n",
      "Classification loss = 32.5707\n",
      "Comparison loss = 4.6366\n",
      "Epoch no 9 : \n",
      "Classification loss = 32.3580\n",
      "Comparison loss = 4.5758\n",
      "Epoch no 10 : \n",
      "Classification loss = 32.1128\n",
      "Comparison loss = 3.9857\n",
      "Epoch no 11 : \n",
      "Classification loss = 31.7587\n",
      "Comparison loss = 2.9293\n",
      "Epoch no 12 : \n",
      "Classification loss = 31.0834\n",
      "Comparison loss = 2.1146\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.7202\n",
      "Comparison loss = 2.9038\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.2502\n",
      "Comparison loss = 1.5834\n",
      "Epoch no 15 : \n",
      "Classification loss = 30.0688\n",
      "Comparison loss = 1.4869\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.8198\n",
      "Comparison loss = 1.3209\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.7635\n",
      "Comparison loss = 0.9430\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.6231\n",
      "Comparison loss = 0.5397\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.5855\n",
      "Comparison loss = 0.5239\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.5466\n",
      "Comparison loss = 0.2919\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.5156\n",
      "Comparison loss = 0.1576\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4947\n",
      "Comparison loss = 0.1161\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4711\n",
      "Comparison loss = 0.1430\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4492\n",
      "Comparison loss = 0.1145\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.4311\n",
      "Comparison loss = 0.1094\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.950% \n",
      "Comparison = 0.200%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.750% \n",
      "Comparison = 3.700%\u001b[0m\n",
      "RUN NO 2\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.7567\n",
      "Comparison loss = 9.9886\n",
      "Epoch no 2 : \n",
      "Classification loss = 44.4460\n",
      "Comparison loss = 7.0707\n",
      "Epoch no 3 : \n",
      "Classification loss = 42.2507\n",
      "Comparison loss = 6.0216\n",
      "Epoch no 4 : \n",
      "Classification loss = 40.5578\n",
      "Comparison loss = 4.9111\n",
      "Epoch no 5 : \n",
      "Classification loss = 38.2147\n",
      "Comparison loss = 3.6748\n",
      "Epoch no 6 : \n",
      "Classification loss = 36.2540\n",
      "Comparison loss = 2.8709\n",
      "Epoch no 7 : \n",
      "Classification loss = 34.6998\n",
      "Comparison loss = 2.7769\n",
      "Epoch no 8 : \n",
      "Classification loss = 33.4413\n",
      "Comparison loss = 2.3683\n",
      "Epoch no 9 : \n",
      "Classification loss = 32.9318\n",
      "Comparison loss = 1.9497\n",
      "Epoch no 10 : \n",
      "Classification loss = 32.4973\n",
      "Comparison loss = 1.9358\n",
      "Epoch no 11 : \n",
      "Classification loss = 31.6210\n",
      "Comparison loss = 1.3653\n",
      "Epoch no 12 : \n",
      "Classification loss = 31.3736\n",
      "Comparison loss = 1.3365\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.6991\n",
      "Comparison loss = 0.8805\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.5737\n",
      "Comparison loss = 0.8750\n",
      "Epoch no 15 : \n",
      "Classification loss = 30.2756\n",
      "Comparison loss = 0.8882\n",
      "Epoch no 16 : \n",
      "Classification loss = 30.2876\n",
      "Comparison loss = 0.8640\n",
      "Epoch no 17 : \n",
      "Classification loss = 30.2576\n",
      "Comparison loss = 0.8974\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.9144\n",
      "Comparison loss = 0.5511\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.8455\n",
      "Comparison loss = 0.4431\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.7332\n",
      "Comparison loss = 0.3286\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.6643\n",
      "Comparison loss = 0.2502\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.6560\n",
      "Comparison loss = 0.2410\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.5406\n",
      "Comparison loss = 0.1562\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.5130\n",
      "Comparison loss = 0.1354\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.5098\n",
      "Comparison loss = 0.1040\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 1.200% \n",
      "Comparison = 0.200%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.700% \n",
      "Comparison = 2.900%\u001b[0m\n",
      "RUN NO 3\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.5533\n",
      "Comparison loss = 7.8483\n",
      "Epoch no 2 : \n",
      "Classification loss = 43.6470\n",
      "Comparison loss = 5.6477\n",
      "Epoch no 3 : \n",
      "Classification loss = 41.7911\n",
      "Comparison loss = 4.8974\n",
      "Epoch no 4 : \n",
      "Classification loss = 39.4251\n",
      "Comparison loss = 3.6520\n",
      "Epoch no 5 : \n",
      "Classification loss = 36.4436\n",
      "Comparison loss = 2.7258\n",
      "Epoch no 6 : \n",
      "Classification loss = 34.0845\n",
      "Comparison loss = 2.2814\n",
      "Epoch no 7 : \n",
      "Classification loss = 32.9507\n",
      "Comparison loss = 1.8164\n",
      "Epoch no 8 : \n",
      "Classification loss = 32.1105\n",
      "Comparison loss = 1.6362\n",
      "Epoch no 9 : \n",
      "Classification loss = 31.9340\n",
      "Comparison loss = 1.7152\n",
      "Epoch no 10 : \n",
      "Classification loss = 32.2230\n",
      "Comparison loss = 2.0188\n",
      "Epoch no 11 : \n",
      "Classification loss = 31.1084\n",
      "Comparison loss = 1.2073\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.7729\n",
      "Comparison loss = 1.0355\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.3328\n",
      "Comparison loss = 0.8714\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.0903\n",
      "Comparison loss = 0.6831\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.9167\n",
      "Comparison loss = 0.5691\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.8084\n",
      "Comparison loss = 0.3432\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.6896\n",
      "Comparison loss = 0.2857\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.5913\n",
      "Comparison loss = 0.1821\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.5630\n",
      "Comparison loss = 0.1793\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.5431\n",
      "Comparison loss = 0.1093\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.5520\n",
      "Comparison loss = 0.2332\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.5350\n",
      "Comparison loss = 0.2331\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.5122\n",
      "Comparison loss = 0.1382\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4862\n",
      "Comparison loss = 0.1749\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.4554\n",
      "Comparison loss = 0.1470\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 1.100% \n",
      "Comparison = 0.200%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.000% \n",
      "Comparison = 2.400%\u001b[0m\n",
      "RUN NO 4\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.7456\n",
      "Comparison loss = 7.0773\n",
      "Epoch no 2 : \n",
      "Classification loss = 44.4669\n",
      "Comparison loss = 6.3518\n",
      "Epoch no 3 : \n",
      "Classification loss = 41.6351\n",
      "Comparison loss = 4.5476\n",
      "Epoch no 4 : \n",
      "Classification loss = 39.0603\n",
      "Comparison loss = 3.9081\n",
      "Epoch no 5 : \n",
      "Classification loss = 36.9233\n",
      "Comparison loss = 2.9742\n",
      "Epoch no 6 : \n",
      "Classification loss = 35.0086\n",
      "Comparison loss = 2.5478\n",
      "Epoch no 7 : \n",
      "Classification loss = 33.8313\n",
      "Comparison loss = 2.4176\n",
      "Epoch no 8 : \n",
      "Classification loss = 33.0683\n",
      "Comparison loss = 1.9676\n",
      "Epoch no 9 : \n",
      "Classification loss = 32.7908\n",
      "Comparison loss = 1.8874\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.7656\n",
      "Comparison loss = 1.4172\n",
      "Epoch no 11 : \n",
      "Classification loss = 31.2294\n",
      "Comparison loss = 1.2714\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.7728\n",
      "Comparison loss = 0.9243\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.4116\n",
      "Comparison loss = 0.6369\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.1305\n",
      "Comparison loss = 0.5267\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.9848\n",
      "Comparison loss = 0.4582\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.8183\n",
      "Comparison loss = 0.3684\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.7617\n",
      "Comparison loss = 0.3794\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.6413\n",
      "Comparison loss = 0.3224\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.6256\n",
      "Comparison loss = 0.2401\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.5757\n",
      "Comparison loss = 0.1999\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.5530\n",
      "Comparison loss = 0.1677\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.5091\n",
      "Comparison loss = 0.1429\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4861\n",
      "Comparison loss = 0.1991\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4754\n",
      "Comparison loss = 0.1166\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.4641\n",
      "Comparison loss = 0.0937\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 1.000% \n",
      "Comparison = 0.200%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 5.100% \n",
      "Comparison = 3.000%\u001b[0m\n",
      "RUN NO 5\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.2576\n",
      "Comparison loss = 5.8992\n",
      "Epoch no 2 : \n",
      "Classification loss = 42.6125\n",
      "Comparison loss = 5.1194\n",
      "Epoch no 3 : \n",
      "Classification loss = 40.0321\n",
      "Comparison loss = 4.1264\n",
      "Epoch no 4 : \n",
      "Classification loss = 37.4649\n",
      "Comparison loss = 2.6669\n",
      "Epoch no 5 : \n",
      "Classification loss = 35.0831\n",
      "Comparison loss = 2.3725\n",
      "Epoch no 6 : \n",
      "Classification loss = 33.5638\n",
      "Comparison loss = 2.2154\n",
      "Epoch no 7 : \n",
      "Classification loss = 32.8995\n",
      "Comparison loss = 2.2090\n",
      "Epoch no 8 : \n",
      "Classification loss = 32.1972\n",
      "Comparison loss = 1.5727\n",
      "Epoch no 9 : \n",
      "Classification loss = 31.7497\n",
      "Comparison loss = 1.1786\n",
      "Epoch no 10 : \n",
      "Classification loss = 30.9274\n",
      "Comparison loss = 0.9983\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.6814\n",
      "Comparison loss = 0.8485\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.2779\n",
      "Comparison loss = 0.7049\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.0685\n",
      "Comparison loss = 0.5922\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.9158\n",
      "Comparison loss = 0.4839\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.8176\n",
      "Comparison loss = 0.2994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch no 16 : \n",
      "Classification loss = 29.7304\n",
      "Comparison loss = 0.2009\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.6097\n",
      "Comparison loss = 0.1563\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.5711\n",
      "Comparison loss = 0.1211\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.5379\n",
      "Comparison loss = 0.1553\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.4815\n",
      "Comparison loss = 0.1096\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4554\n",
      "Comparison loss = 0.1022\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4323\n",
      "Comparison loss = 0.0799\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4110\n",
      "Comparison loss = 0.1352\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.3961\n",
      "Comparison loss = 0.0568\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3890\n",
      "Comparison loss = 0.0548\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.700% \n",
      "Comparison = 0.100%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.950% \n",
      "Comparison = 3.600%\u001b[0m\n",
      "RUN NO 6\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.4978\n",
      "Comparison loss = 5.4538\n",
      "Epoch no 2 : \n",
      "Classification loss = 43.7616\n",
      "Comparison loss = 6.0024\n",
      "Epoch no 3 : \n",
      "Classification loss = 42.2506\n",
      "Comparison loss = 4.8176\n",
      "Epoch no 4 : \n",
      "Classification loss = 40.7378\n",
      "Comparison loss = 3.4515\n",
      "Epoch no 5 : \n",
      "Classification loss = 38.3550\n",
      "Comparison loss = 3.4635\n",
      "Epoch no 6 : \n",
      "Classification loss = 35.9535\n",
      "Comparison loss = 3.0941\n",
      "Epoch no 7 : \n",
      "Classification loss = 34.9536\n",
      "Comparison loss = 2.8281\n",
      "Epoch no 8 : \n",
      "Classification loss = 34.2366\n",
      "Comparison loss = 2.2726\n",
      "Epoch no 9 : \n",
      "Classification loss = 33.6870\n",
      "Comparison loss = 1.9498\n",
      "Epoch no 10 : \n",
      "Classification loss = 33.1226\n",
      "Comparison loss = 1.6356\n",
      "Epoch no 11 : \n",
      "Classification loss = 32.0464\n",
      "Comparison loss = 1.7098\n",
      "Epoch no 12 : \n",
      "Classification loss = 31.1459\n",
      "Comparison loss = 1.2321\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.8208\n",
      "Comparison loss = 0.8391\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.6786\n",
      "Comparison loss = 1.1167\n",
      "Epoch no 15 : \n",
      "Classification loss = 30.6114\n",
      "Comparison loss = 1.3817\n",
      "Epoch no 16 : \n",
      "Classification loss = 30.6464\n",
      "Comparison loss = 1.0446\n",
      "Epoch no 17 : \n",
      "Classification loss = 30.3173\n",
      "Comparison loss = 0.9209\n",
      "Epoch no 18 : \n",
      "Classification loss = 30.0984\n",
      "Comparison loss = 0.6560\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.8681\n",
      "Comparison loss = 0.5663\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.7464\n",
      "Comparison loss = 0.3003\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.6305\n",
      "Comparison loss = 0.2347\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.5422\n",
      "Comparison loss = 0.2494\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.5046\n",
      "Comparison loss = 0.1758\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4928\n",
      "Comparison loss = 0.1387\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.4658\n",
      "Comparison loss = 0.1326\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 1.000% \n",
      "Comparison = 0.300%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 5.050% \n",
      "Comparison = 3.200%\u001b[0m\n",
      "RUN NO 7\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.5030\n",
      "Comparison loss = 6.5664\n",
      "Epoch no 2 : \n",
      "Classification loss = 43.0468\n",
      "Comparison loss = 4.8201\n",
      "Epoch no 3 : \n",
      "Classification loss = 40.0764\n",
      "Comparison loss = 3.6410\n",
      "Epoch no 4 : \n",
      "Classification loss = 37.7499\n",
      "Comparison loss = 2.9861\n",
      "Epoch no 5 : \n",
      "Classification loss = 35.9485\n",
      "Comparison loss = 2.6506\n",
      "Epoch no 6 : \n",
      "Classification loss = 34.1154\n",
      "Comparison loss = 1.9838\n",
      "Epoch no 7 : \n",
      "Classification loss = 32.4877\n",
      "Comparison loss = 1.5027\n",
      "Epoch no 8 : \n",
      "Classification loss = 31.4685\n",
      "Comparison loss = 1.1432\n",
      "Epoch no 9 : \n",
      "Classification loss = 31.0952\n",
      "Comparison loss = 1.5320\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.4368\n",
      "Comparison loss = 1.9730\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.8114\n",
      "Comparison loss = 1.2677\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.5124\n",
      "Comparison loss = 0.9106\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.1609\n",
      "Comparison loss = 0.5940\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.8595\n",
      "Comparison loss = 0.3335\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.7764\n",
      "Comparison loss = 0.2813\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.6680\n",
      "Comparison loss = 0.2428\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.5721\n",
      "Comparison loss = 0.1855\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.5111\n",
      "Comparison loss = 0.1193\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.4796\n",
      "Comparison loss = 0.1363\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.4592\n",
      "Comparison loss = 0.0962\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4396\n",
      "Comparison loss = 0.0651\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4232\n",
      "Comparison loss = 0.0435\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4056\n",
      "Comparison loss = 0.0395\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.3984\n",
      "Comparison loss = 0.0382\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3922\n",
      "Comparison loss = 0.0373\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.750% \n",
      "Comparison = 0.100%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 3.750% \n",
      "Comparison = 2.600%\u001b[0m\n",
      "RUN NO 8\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.5208\n",
      "Comparison loss = 5.8498\n",
      "Epoch no 2 : \n",
      "Classification loss = 43.2922\n",
      "Comparison loss = 4.9212\n",
      "Epoch no 3 : \n",
      "Classification loss = 40.3877\n",
      "Comparison loss = 4.6591\n",
      "Epoch no 4 : \n",
      "Classification loss = 37.4095\n",
      "Comparison loss = 2.7723\n",
      "Epoch no 5 : \n",
      "Classification loss = 35.2002\n",
      "Comparison loss = 2.4297\n",
      "Epoch no 6 : \n",
      "Classification loss = 33.7827\n",
      "Comparison loss = 2.0904\n",
      "Epoch no 7 : \n",
      "Classification loss = 32.7401\n",
      "Comparison loss = 1.5759\n",
      "Epoch no 8 : \n",
      "Classification loss = 31.5007\n",
      "Comparison loss = 1.1874\n",
      "Epoch no 9 : \n",
      "Classification loss = 30.9377\n",
      "Comparison loss = 0.8043\n",
      "Epoch no 10 : \n",
      "Classification loss = 30.7728\n",
      "Comparison loss = 1.0154\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.3767\n",
      "Comparison loss = 0.6324\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.1799\n",
      "Comparison loss = 0.5772\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.0219\n",
      "Comparison loss = 0.4060\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.9097\n",
      "Comparison loss = 0.3615\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.8134\n",
      "Comparison loss = 0.3674\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.6497\n",
      "Comparison loss = 0.2763\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.6081\n",
      "Comparison loss = 0.1906\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.5201\n",
      "Comparison loss = 0.2128\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.4593\n",
      "Comparison loss = 0.0986\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.4626\n",
      "Comparison loss = 0.1801\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4212\n",
      "Comparison loss = 0.0636\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4204\n",
      "Comparison loss = 0.0617\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.3981\n",
      "Comparison loss = 0.0603\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.3851\n",
      "Comparison loss = 0.0564\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3652\n",
      "Comparison loss = 0.0534\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.600% \n",
      "Comparison = 0.100%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.650% \n",
      "Comparison = 3.700%\u001b[0m\n",
      "RUN NO 9\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.3963\n",
      "Comparison loss = 6.0952\n",
      "Epoch no 2 : \n",
      "Classification loss = 43.3766\n",
      "Comparison loss = 4.4693\n",
      "Epoch no 3 : \n",
      "Classification loss = 40.7281\n",
      "Comparison loss = 4.2825\n",
      "Epoch no 4 : \n",
      "Classification loss = 38.2029\n",
      "Comparison loss = 3.6088\n",
      "Epoch no 5 : \n",
      "Classification loss = 36.4911\n",
      "Comparison loss = 2.7779\n",
      "Epoch no 6 : \n",
      "Classification loss = 35.0566\n",
      "Comparison loss = 2.5960\n",
      "Epoch no 7 : \n",
      "Classification loss = 34.0744\n",
      "Comparison loss = 2.0041\n",
      "Epoch no 8 : \n",
      "Classification loss = 33.8643\n",
      "Comparison loss = 2.2989\n",
      "Epoch no 9 : \n",
      "Classification loss = 33.2978\n",
      "Comparison loss = 2.2090\n",
      "Epoch no 10 : \n",
      "Classification loss = 32.3671\n",
      "Comparison loss = 1.4831\n",
      "Epoch no 11 : \n",
      "Classification loss = 31.6846\n",
      "Comparison loss = 1.1295\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.9117\n",
      "Comparison loss = 0.9398\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.9223\n",
      "Comparison loss = 1.2692\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.2696\n",
      "Comparison loss = 0.7261\n",
      "Epoch no 15 : \n",
      "Classification loss = 30.1711\n",
      "Comparison loss = 0.5394\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.8865\n",
      "Comparison loss = 0.3252\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.7320\n",
      "Comparison loss = 0.2313\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.6136\n",
      "Comparison loss = 0.1800\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.5479\n",
      "Comparison loss = 0.1475\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.5093\n",
      "Comparison loss = 0.1127\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4714\n",
      "Comparison loss = 0.0688\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4476\n",
      "Comparison loss = 0.0531\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4325\n",
      "Comparison loss = 0.0437\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4153\n",
      "Comparison loss = 0.0416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch no 25 : \n",
      "Classification loss = 29.4021\n",
      "Comparison loss = 0.0411\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.700% \n",
      "Comparison = 0.100%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.600% \n",
      "Comparison = 3.100%\u001b[0m\n",
      "RUN NO 10\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.2884\n",
      "Comparison loss = 6.0043\n",
      "Epoch no 2 : \n",
      "Classification loss = 42.2562\n",
      "Comparison loss = 4.6454\n",
      "Epoch no 3 : \n",
      "Classification loss = 38.5379\n",
      "Comparison loss = 3.8371\n",
      "Epoch no 4 : \n",
      "Classification loss = 36.1345\n",
      "Comparison loss = 2.9693\n",
      "Epoch no 5 : \n",
      "Classification loss = 35.0794\n",
      "Comparison loss = 2.5024\n",
      "Epoch no 6 : \n",
      "Classification loss = 33.6630\n",
      "Comparison loss = 1.8510\n",
      "Epoch no 7 : \n",
      "Classification loss = 32.6243\n",
      "Comparison loss = 1.4891\n",
      "Epoch no 8 : \n",
      "Classification loss = 31.8972\n",
      "Comparison loss = 1.5410\n",
      "Epoch no 9 : \n",
      "Classification loss = 31.2848\n",
      "Comparison loss = 1.5746\n",
      "Epoch no 10 : \n",
      "Classification loss = 30.7539\n",
      "Comparison loss = 0.7142\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.5017\n",
      "Comparison loss = 0.6473\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.1461\n",
      "Comparison loss = 0.5009\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.0662\n",
      "Comparison loss = 0.3727\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.9208\n",
      "Comparison loss = 0.3412\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.7597\n",
      "Comparison loss = 0.1983\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.6793\n",
      "Comparison loss = 0.1597\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.6003\n",
      "Comparison loss = 0.1236\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.5406\n",
      "Comparison loss = 0.1278\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.5013\n",
      "Comparison loss = 0.1150\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.4637\n",
      "Comparison loss = 0.1030\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4343\n",
      "Comparison loss = 0.0848\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4196\n",
      "Comparison loss = 0.0524\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4082\n",
      "Comparison loss = 0.0333\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4015\n",
      "Comparison loss = 0.0072\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3971\n",
      "Comparison loss = 0.0047\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.800% \n",
      "Comparison = 0.000%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.400% \n",
      "Comparison = 2.800%\u001b[0m\n",
      "Final error for train batch : 0.15±0.0850\n",
      "Final error for test batch : 3.10±0.4546\n",
      "RUN NO 1\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.1412\n",
      "Comparison loss = 6.9193\n",
      "Epoch no 2 : \n",
      "Classification loss = 42.5057\n",
      "Comparison loss = 6.8884\n",
      "Epoch no 3 : \n",
      "Classification loss = 40.0323\n",
      "Comparison loss = 6.7771\n",
      "Epoch no 4 : \n",
      "Classification loss = 37.2234\n",
      "Comparison loss = 6.5635\n",
      "Epoch no 5 : \n",
      "Classification loss = 35.4479\n",
      "Comparison loss = 6.0301\n",
      "Epoch no 6 : \n",
      "Classification loss = 34.1891\n",
      "Comparison loss = 5.1562\n",
      "Epoch no 7 : \n",
      "Classification loss = 33.5036\n",
      "Comparison loss = 3.9947\n",
      "Epoch no 8 : \n",
      "Classification loss = 33.5475\n",
      "Comparison loss = 4.0493\n",
      "Epoch no 9 : \n",
      "Classification loss = 32.3697\n",
      "Comparison loss = 4.7930\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.9252\n",
      "Comparison loss = 3.6894\n",
      "Epoch no 11 : \n",
      "Classification loss = 31.6792\n",
      "Comparison loss = 3.7351\n",
      "Epoch no 12 : \n",
      "Classification loss = 31.0502\n",
      "Comparison loss = 2.6237\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.7462\n",
      "Comparison loss = 2.3030\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.3463\n",
      "Comparison loss = 1.4020\n",
      "Epoch no 15 : \n",
      "Classification loss = 30.1218\n",
      "Comparison loss = 1.0984\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.9828\n",
      "Comparison loss = 0.7764\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.8237\n",
      "Comparison loss = 0.6486\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.7589\n",
      "Comparison loss = 0.5271\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.6819\n",
      "Comparison loss = 0.3480\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.6522\n",
      "Comparison loss = 0.3720\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.6068\n",
      "Comparison loss = 0.3155\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.5782\n",
      "Comparison loss = 0.2310\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.5416\n",
      "Comparison loss = 0.2339\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.5160\n",
      "Comparison loss = 0.2247\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.5006\n",
      "Comparison loss = 0.1939\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 1.150% \n",
      "Comparison = 0.300%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.650% \n",
      "Comparison = 3.400%\u001b[0m\n",
      "RUN NO 2\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.6580\n",
      "Comparison loss = 10.0508\n",
      "Epoch no 2 : \n",
      "Classification loss = 44.1008\n",
      "Comparison loss = 9.0625\n",
      "Epoch no 3 : \n",
      "Classification loss = 42.0717\n",
      "Comparison loss = 4.4953\n",
      "Epoch no 4 : \n",
      "Classification loss = 40.5010\n",
      "Comparison loss = 3.4604\n",
      "Epoch no 5 : \n",
      "Classification loss = 38.4038\n",
      "Comparison loss = 3.1964\n",
      "Epoch no 6 : \n",
      "Classification loss = 36.7633\n",
      "Comparison loss = 3.1299\n",
      "Epoch no 7 : \n",
      "Classification loss = 35.2920\n",
      "Comparison loss = 2.7231\n",
      "Epoch no 8 : \n",
      "Classification loss = 33.5196\n",
      "Comparison loss = 2.4114\n",
      "Epoch no 9 : \n",
      "Classification loss = 32.8388\n",
      "Comparison loss = 2.0017\n",
      "Epoch no 10 : \n",
      "Classification loss = 32.2801\n",
      "Comparison loss = 1.7493\n",
      "Epoch no 11 : \n",
      "Classification loss = 31.8929\n",
      "Comparison loss = 1.4969\n",
      "Epoch no 12 : \n",
      "Classification loss = 31.3836\n",
      "Comparison loss = 1.2499\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.8182\n",
      "Comparison loss = 1.0109\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.5793\n",
      "Comparison loss = 0.8511\n",
      "Epoch no 15 : \n",
      "Classification loss = 30.3063\n",
      "Comparison loss = 0.8847\n",
      "Epoch no 16 : \n",
      "Classification loss = 30.1376\n",
      "Comparison loss = 0.7349\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.9517\n",
      "Comparison loss = 0.5895\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.9204\n",
      "Comparison loss = 0.5977\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.7796\n",
      "Comparison loss = 0.5085\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.7705\n",
      "Comparison loss = 0.3859\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.7007\n",
      "Comparison loss = 0.4362\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.6412\n",
      "Comparison loss = 0.3629\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.6069\n",
      "Comparison loss = 0.2969\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.5522\n",
      "Comparison loss = 0.3044\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.5045\n",
      "Comparison loss = 0.1519\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 1.200% \n",
      "Comparison = 0.200%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.250% \n",
      "Comparison = 3.400%\u001b[0m\n",
      "RUN NO 3\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.7538\n",
      "Comparison loss = 8.3813\n",
      "Epoch no 2 : \n",
      "Classification loss = 44.4772\n",
      "Comparison loss = 8.7309\n",
      "Epoch no 3 : \n",
      "Classification loss = 41.7904\n",
      "Comparison loss = 4.5939\n",
      "Epoch no 4 : \n",
      "Classification loss = 38.9254\n",
      "Comparison loss = 3.7038\n",
      "Epoch no 5 : \n",
      "Classification loss = 36.9731\n",
      "Comparison loss = 3.3249\n",
      "Epoch no 6 : \n",
      "Classification loss = 35.6895\n",
      "Comparison loss = 3.0419\n",
      "Epoch no 7 : \n",
      "Classification loss = 34.6640\n",
      "Comparison loss = 2.6997\n",
      "Epoch no 8 : \n",
      "Classification loss = 33.3528\n",
      "Comparison loss = 2.0731\n",
      "Epoch no 9 : \n",
      "Classification loss = 31.9542\n",
      "Comparison loss = 1.6473\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.3277\n",
      "Comparison loss = 1.4470\n",
      "Epoch no 11 : \n",
      "Classification loss = 31.0142\n",
      "Comparison loss = 1.5080\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.5025\n",
      "Comparison loss = 0.9289\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.3131\n",
      "Comparison loss = 0.7883\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.1149\n",
      "Comparison loss = 0.5053\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.8263\n",
      "Comparison loss = 0.4781\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.7342\n",
      "Comparison loss = 0.3573\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.6861\n",
      "Comparison loss = 0.2480\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.6088\n",
      "Comparison loss = 0.1984\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.5720\n",
      "Comparison loss = 0.1722\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.5339\n",
      "Comparison loss = 0.1292\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4998\n",
      "Comparison loss = 0.0929\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4789\n",
      "Comparison loss = 0.0894\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4665\n",
      "Comparison loss = 0.0864\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4591\n",
      "Comparison loss = 0.0902\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.4509\n",
      "Comparison loss = 0.0844\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 1.050% \n",
      "Comparison = 0.200%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 5.150% \n",
      "Comparison = 3.200%\u001b[0m\n",
      "RUN NO 4\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.7280\n",
      "Comparison loss = 7.7502\n",
      "Epoch no 2 : \n",
      "Classification loss = 44.1980\n",
      "Comparison loss = 7.0480\n",
      "Epoch no 3 : \n",
      "Classification loss = 41.7689\n",
      "Comparison loss = 4.3386\n",
      "Epoch no 4 : \n",
      "Classification loss = 39.2332\n",
      "Comparison loss = 3.6459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch no 5 : \n",
      "Classification loss = 37.0330\n",
      "Comparison loss = 3.0332\n",
      "Epoch no 6 : \n",
      "Classification loss = 35.2209\n",
      "Comparison loss = 2.6603\n",
      "Epoch no 7 : \n",
      "Classification loss = 33.7105\n",
      "Comparison loss = 2.2450\n",
      "Epoch no 8 : \n",
      "Classification loss = 33.2110\n",
      "Comparison loss = 2.4361\n",
      "Epoch no 9 : \n",
      "Classification loss = 32.5834\n",
      "Comparison loss = 1.9392\n",
      "Epoch no 10 : \n",
      "Classification loss = 32.1617\n",
      "Comparison loss = 1.5487\n",
      "Epoch no 11 : \n",
      "Classification loss = 31.5689\n",
      "Comparison loss = 1.2310\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.8964\n",
      "Comparison loss = 1.0758\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.5849\n",
      "Comparison loss = 0.9309\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.6586\n",
      "Comparison loss = 1.1530\n",
      "Epoch no 15 : \n",
      "Classification loss = 30.1855\n",
      "Comparison loss = 0.7391\n",
      "Epoch no 16 : \n",
      "Classification loss = 30.0715\n",
      "Comparison loss = 0.6606\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.9274\n",
      "Comparison loss = 0.6453\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.8414\n",
      "Comparison loss = 0.5128\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.7396\n",
      "Comparison loss = 0.4733\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.6684\n",
      "Comparison loss = 0.4359\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.5736\n",
      "Comparison loss = 0.2668\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.5493\n",
      "Comparison loss = 0.2611\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.5173\n",
      "Comparison loss = 0.1570\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4879\n",
      "Comparison loss = 0.1402\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.5260\n",
      "Comparison loss = 0.5490\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 2.100% \n",
      "Comparison = 1.600%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 6.850% \n",
      "Comparison = 4.300%\u001b[0m\n",
      "RUN NO 5\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.3937\n",
      "Comparison loss = 6.1159\n",
      "Epoch no 2 : \n",
      "Classification loss = 42.7450\n",
      "Comparison loss = 4.9847\n",
      "Epoch no 3 : \n",
      "Classification loss = 39.4400\n",
      "Comparison loss = 3.7747\n",
      "Epoch no 4 : \n",
      "Classification loss = 36.8303\n",
      "Comparison loss = 2.7157\n",
      "Epoch no 5 : \n",
      "Classification loss = 35.4173\n",
      "Comparison loss = 2.5810\n",
      "Epoch no 6 : \n",
      "Classification loss = 34.3888\n",
      "Comparison loss = 2.6050\n",
      "Epoch no 7 : \n",
      "Classification loss = 33.5529\n",
      "Comparison loss = 2.5836\n",
      "Epoch no 8 : \n",
      "Classification loss = 33.5339\n",
      "Comparison loss = 2.5816\n",
      "Epoch no 9 : \n",
      "Classification loss = 32.9934\n",
      "Comparison loss = 2.1243\n",
      "Epoch no 10 : \n",
      "Classification loss = 32.2043\n",
      "Comparison loss = 1.6299\n",
      "Epoch no 11 : \n",
      "Classification loss = 31.4360\n",
      "Comparison loss = 1.2118\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.7776\n",
      "Comparison loss = 0.8697\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.3994\n",
      "Comparison loss = 0.7827\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.3136\n",
      "Comparison loss = 0.8029\n",
      "Epoch no 15 : \n",
      "Classification loss = 30.0933\n",
      "Comparison loss = 0.6995\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.9700\n",
      "Comparison loss = 0.5450\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.8709\n",
      "Comparison loss = 0.5037\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.7878\n",
      "Comparison loss = 0.4720\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.7230\n",
      "Comparison loss = 0.3436\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.6450\n",
      "Comparison loss = 0.2423\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.6016\n",
      "Comparison loss = 0.1556\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.5598\n",
      "Comparison loss = 0.1537\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.5430\n",
      "Comparison loss = 0.1254\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.5243\n",
      "Comparison loss = 0.1131\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.5081\n",
      "Comparison loss = 0.1050\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 1.150% \n",
      "Comparison = 0.300%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 5.450% \n",
      "Comparison = 3.600%\u001b[0m\n",
      "RUN NO 6\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.1149\n",
      "Comparison loss = 5.4287\n",
      "Epoch no 2 : \n",
      "Classification loss = 42.3666\n",
      "Comparison loss = 4.7572\n",
      "Epoch no 3 : \n",
      "Classification loss = 40.1298\n",
      "Comparison loss = 3.7229\n",
      "Epoch no 4 : \n",
      "Classification loss = 37.7196\n",
      "Comparison loss = 3.3395\n",
      "Epoch no 5 : \n",
      "Classification loss = 36.2529\n",
      "Comparison loss = 2.7690\n",
      "Epoch no 6 : \n",
      "Classification loss = 34.4724\n",
      "Comparison loss = 2.3832\n",
      "Epoch no 7 : \n",
      "Classification loss = 33.0558\n",
      "Comparison loss = 2.1752\n",
      "Epoch no 8 : \n",
      "Classification loss = 32.5706\n",
      "Comparison loss = 1.5990\n",
      "Epoch no 9 : \n",
      "Classification loss = 32.0789\n",
      "Comparison loss = 1.5012\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.4120\n",
      "Comparison loss = 1.1103\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.7812\n",
      "Comparison loss = 1.0300\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.4911\n",
      "Comparison loss = 0.8169\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.2375\n",
      "Comparison loss = 0.7350\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.0103\n",
      "Comparison loss = 0.6133\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.8415\n",
      "Comparison loss = 0.3713\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.7505\n",
      "Comparison loss = 0.2920\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.5921\n",
      "Comparison loss = 0.1579\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.5219\n",
      "Comparison loss = 0.1269\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.5271\n",
      "Comparison loss = 0.1429\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.4824\n",
      "Comparison loss = 0.0673\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4377\n",
      "Comparison loss = 0.0435\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4015\n",
      "Comparison loss = 0.0325\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.3753\n",
      "Comparison loss = 0.0075\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.3576\n",
      "Comparison loss = 0.0064\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3357\n",
      "Comparison loss = 0.0151\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.450% \n",
      "Comparison = 0.100%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 3.950% \n",
      "Comparison = 2.500%\u001b[0m\n",
      "RUN NO 7\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.5892\n",
      "Comparison loss = 6.3680\n",
      "Epoch no 2 : \n",
      "Classification loss = 43.3384\n",
      "Comparison loss = 5.1410\n",
      "Epoch no 3 : \n",
      "Classification loss = 39.8982\n",
      "Comparison loss = 4.1442\n",
      "Epoch no 4 : \n",
      "Classification loss = 37.6356\n",
      "Comparison loss = 2.9589\n",
      "Epoch no 5 : \n",
      "Classification loss = 35.5081\n",
      "Comparison loss = 2.5526\n",
      "Epoch no 6 : \n",
      "Classification loss = 34.0976\n",
      "Comparison loss = 2.3036\n",
      "Epoch no 7 : \n",
      "Classification loss = 33.1305\n",
      "Comparison loss = 2.0349\n",
      "Epoch no 8 : \n",
      "Classification loss = 32.4180\n",
      "Comparison loss = 1.5213\n",
      "Epoch no 9 : \n",
      "Classification loss = 31.9944\n",
      "Comparison loss = 1.2490\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.2258\n",
      "Comparison loss = 1.1255\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.6891\n",
      "Comparison loss = 1.0042\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.8425\n",
      "Comparison loss = 1.5054\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.4035\n",
      "Comparison loss = 0.8819\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.2806\n",
      "Comparison loss = 0.8715\n",
      "Epoch no 15 : \n",
      "Classification loss = 30.0365\n",
      "Comparison loss = 0.6326\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.9751\n",
      "Comparison loss = 0.4972\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.7789\n",
      "Comparison loss = 0.3914\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.6737\n",
      "Comparison loss = 0.3521\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.6253\n",
      "Comparison loss = 0.2097\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.5623\n",
      "Comparison loss = 0.1071\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.5192\n",
      "Comparison loss = 0.0979\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4846\n",
      "Comparison loss = 0.0792\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4544\n",
      "Comparison loss = 0.0650\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4347\n",
      "Comparison loss = 0.0350\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.4201\n",
      "Comparison loss = 0.0071\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.800% \n",
      "Comparison = 0.200%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.600% \n",
      "Comparison = 2.900%\u001b[0m\n",
      "RUN NO 8\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.5553\n",
      "Comparison loss = 6.1747\n",
      "Epoch no 2 : \n",
      "Classification loss = 43.5692\n",
      "Comparison loss = 5.0699\n",
      "Epoch no 3 : \n",
      "Classification loss = 40.9829\n",
      "Comparison loss = 4.3730\n",
      "Epoch no 4 : \n",
      "Classification loss = 38.4731\n",
      "Comparison loss = 3.1723\n",
      "Epoch no 5 : \n",
      "Classification loss = 35.8632\n",
      "Comparison loss = 2.6340\n",
      "Epoch no 6 : \n",
      "Classification loss = 33.6631\n",
      "Comparison loss = 2.0566\n",
      "Epoch no 7 : \n",
      "Classification loss = 32.1948\n",
      "Comparison loss = 1.5562\n",
      "Epoch no 8 : \n",
      "Classification loss = 31.3837\n",
      "Comparison loss = 1.5318\n",
      "Epoch no 9 : \n",
      "Classification loss = 31.4918\n",
      "Comparison loss = 1.5947\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.0875\n",
      "Comparison loss = 1.2133\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.4400\n",
      "Comparison loss = 0.9367\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.3084\n",
      "Comparison loss = 0.6674\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.1720\n",
      "Comparison loss = 0.7355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch no 14 : \n",
      "Classification loss = 30.1875\n",
      "Comparison loss = 0.9766\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.9483\n",
      "Comparison loss = 0.4433\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.8189\n",
      "Comparison loss = 0.3512\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.7573\n",
      "Comparison loss = 0.2983\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.6800\n",
      "Comparison loss = 0.4178\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.6233\n",
      "Comparison loss = 0.2627\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.5645\n",
      "Comparison loss = 0.1241\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.5325\n",
      "Comparison loss = 0.1169\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.5148\n",
      "Comparison loss = 0.0665\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4916\n",
      "Comparison loss = 0.1052\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4776\n",
      "Comparison loss = 0.0300\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.4569\n",
      "Comparison loss = 0.0036\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 1.000% \n",
      "Comparison = 0.000%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.200% \n",
      "Comparison = 3.100%\u001b[0m\n",
      "RUN NO 9\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.4076\n",
      "Comparison loss = 5.8661\n",
      "Epoch no 2 : \n",
      "Classification loss = 43.1440\n",
      "Comparison loss = 5.0184\n",
      "Epoch no 3 : \n",
      "Classification loss = 41.3306\n",
      "Comparison loss = 4.3087\n",
      "Epoch no 4 : \n",
      "Classification loss = 38.5879\n",
      "Comparison loss = 3.0734\n",
      "Epoch no 5 : \n",
      "Classification loss = 36.4218\n",
      "Comparison loss = 3.2482\n",
      "Epoch no 6 : \n",
      "Classification loss = 35.5218\n",
      "Comparison loss = 2.6019\n",
      "Epoch no 7 : \n",
      "Classification loss = 34.8089\n",
      "Comparison loss = 2.2146\n",
      "Epoch no 8 : \n",
      "Classification loss = 33.7644\n",
      "Comparison loss = 1.8388\n",
      "Epoch no 9 : \n",
      "Classification loss = 32.4631\n",
      "Comparison loss = 1.4428\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.8916\n",
      "Comparison loss = 1.6244\n",
      "Epoch no 11 : \n",
      "Classification loss = 31.5926\n",
      "Comparison loss = 1.2430\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.9633\n",
      "Comparison loss = 1.1220\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.4628\n",
      "Comparison loss = 0.8525\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.2233\n",
      "Comparison loss = 0.7075\n",
      "Epoch no 15 : \n",
      "Classification loss = 30.0225\n",
      "Comparison loss = 0.6257\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.8306\n",
      "Comparison loss = 0.2949\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.7361\n",
      "Comparison loss = 0.1661\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.6391\n",
      "Comparison loss = 0.1170\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.6085\n",
      "Comparison loss = 0.1646\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.5558\n",
      "Comparison loss = 0.1818\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.5394\n",
      "Comparison loss = 0.0259\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.5215\n",
      "Comparison loss = 0.0560\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4944\n",
      "Comparison loss = 0.0441\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4482\n",
      "Comparison loss = 0.0046\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.4409\n",
      "Comparison loss = 0.0179\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.950% \n",
      "Comparison = 0.000%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 3.900% \n",
      "Comparison = 2.800%\u001b[0m\n",
      "RUN NO 10\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.1838\n",
      "Comparison loss = 6.2499\n",
      "Epoch no 2 : \n",
      "Classification loss = 42.3964\n",
      "Comparison loss = 4.4962\n",
      "Epoch no 3 : \n",
      "Classification loss = 39.6256\n",
      "Comparison loss = 4.2147\n",
      "Epoch no 4 : \n",
      "Classification loss = 37.7438\n",
      "Comparison loss = 3.6631\n",
      "Epoch no 5 : \n",
      "Classification loss = 36.4310\n",
      "Comparison loss = 3.0171\n",
      "Epoch no 6 : \n",
      "Classification loss = 35.6525\n",
      "Comparison loss = 3.2345\n",
      "Epoch no 7 : \n",
      "Classification loss = 34.3285\n",
      "Comparison loss = 2.5935\n",
      "Epoch no 8 : \n",
      "Classification loss = 33.7858\n",
      "Comparison loss = 2.0744\n",
      "Epoch no 9 : \n",
      "Classification loss = 32.0968\n",
      "Comparison loss = 1.5715\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.5136\n",
      "Comparison loss = 1.2493\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.8349\n",
      "Comparison loss = 0.9336\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.7133\n",
      "Comparison loss = 0.8850\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.2413\n",
      "Comparison loss = 0.5004\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.1171\n",
      "Comparison loss = 0.3220\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.8248\n",
      "Comparison loss = 0.2667\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.7477\n",
      "Comparison loss = 0.2063\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.6394\n",
      "Comparison loss = 0.1924\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.5873\n",
      "Comparison loss = 0.1320\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.5231\n",
      "Comparison loss = 0.1273\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.4776\n",
      "Comparison loss = 0.0780\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4381\n",
      "Comparison loss = 0.0498\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4151\n",
      "Comparison loss = 0.0413\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.3966\n",
      "Comparison loss = 0.0405\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.3831\n",
      "Comparison loss = 0.0402\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3699\n",
      "Comparison loss = 0.0399\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.550% \n",
      "Comparison = 0.100%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.350% \n",
      "Comparison = 3.300%\u001b[0m\n",
      "Final error for train batch : 0.30±0.4690\n",
      "Final error for test batch : 3.25±0.4927\n",
      "RUN NO 1\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.3624\n",
      "Comparison loss = 6.9079\n",
      "Epoch no 2 : \n",
      "Classification loss = 42.8370\n",
      "Comparison loss = 6.9516\n",
      "Epoch no 3 : \n",
      "Classification loss = 39.8356\n",
      "Comparison loss = 6.9485\n",
      "Epoch no 4 : \n",
      "Classification loss = 37.4528\n",
      "Comparison loss = 6.9282\n",
      "Epoch no 5 : \n",
      "Classification loss = 35.7445\n",
      "Comparison loss = 6.8757\n",
      "Epoch no 6 : \n",
      "Classification loss = 34.6955\n",
      "Comparison loss = 6.8953\n",
      "Epoch no 7 : \n",
      "Classification loss = 33.3412\n",
      "Comparison loss = 6.8895\n",
      "Epoch no 8 : \n",
      "Classification loss = 32.7259\n",
      "Comparison loss = 6.8993\n",
      "Epoch no 9 : \n",
      "Classification loss = 32.5043\n",
      "Comparison loss = 6.8840\n",
      "Epoch no 10 : \n",
      "Classification loss = 32.8582\n",
      "Comparison loss = 6.8772\n",
      "Epoch no 11 : \n",
      "Classification loss = 31.3532\n",
      "Comparison loss = 6.8813\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.8198\n",
      "Comparison loss = 6.8851\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.3614\n",
      "Comparison loss = 6.8855\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.1251\n",
      "Comparison loss = 6.8802\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.8870\n",
      "Comparison loss = 6.8798\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.7936\n",
      "Comparison loss = 6.8823\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.6521\n",
      "Comparison loss = 6.8836\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.5754\n",
      "Comparison loss = 6.8816\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.5678\n",
      "Comparison loss = 6.8804\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.5334\n",
      "Comparison loss = 6.8817\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4864\n",
      "Comparison loss = 6.8828\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4940\n",
      "Comparison loss = 6.8818\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4306\n",
      "Comparison loss = 6.8809\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4237\n",
      "Comparison loss = 6.8817\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.4073\n",
      "Comparison loss = 6.8824\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.800% \n",
      "Comparison = 44.900%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 5.150% \n",
      "Comparison = 47.400%\u001b[0m\n",
      "RUN NO 2\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.4163\n",
      "Comparison loss = 6.8860\n",
      "Epoch no 2 : \n",
      "Classification loss = 42.5845\n",
      "Comparison loss = 6.8914\n",
      "Epoch no 3 : \n",
      "Classification loss = 39.2417\n",
      "Comparison loss = 6.9043\n",
      "Epoch no 4 : \n",
      "Classification loss = 36.4625\n",
      "Comparison loss = 6.8970\n",
      "Epoch no 5 : \n",
      "Classification loss = 35.2407\n",
      "Comparison loss = 6.8754\n",
      "Epoch no 6 : \n",
      "Classification loss = 34.1529\n",
      "Comparison loss = 6.8850\n",
      "Epoch no 7 : \n",
      "Classification loss = 33.5078\n",
      "Comparison loss = 6.8917\n",
      "Epoch no 8 : \n",
      "Classification loss = 32.7283\n",
      "Comparison loss = 6.8892\n",
      "Epoch no 9 : \n",
      "Classification loss = 31.8735\n",
      "Comparison loss = 6.8769\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.5901\n",
      "Comparison loss = 6.8808\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.7147\n",
      "Comparison loss = 6.8859\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.5235\n",
      "Comparison loss = 6.8857\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.0530\n",
      "Comparison loss = 6.8788\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.8973\n",
      "Comparison loss = 6.8803\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.7663\n",
      "Comparison loss = 6.8841\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.6381\n",
      "Comparison loss = 6.8836\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.5462\n",
      "Comparison loss = 6.8795\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.5020\n",
      "Comparison loss = 6.8807\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.4752\n",
      "Comparison loss = 6.8832\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.4466\n",
      "Comparison loss = 6.8813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch no 21 : \n",
      "Classification loss = 29.4285\n",
      "Comparison loss = 6.8782\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4145\n",
      "Comparison loss = 6.8788\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4049\n",
      "Comparison loss = 6.8757\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.3976\n",
      "Comparison loss = 6.8630\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3937\n",
      "Comparison loss = 6.8478\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.800% \n",
      "Comparison = 44.900%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.100% \n",
      "Comparison = 47.400%\u001b[0m\n",
      "RUN NO 3\n",
      "Epoch no 1 : \n",
      "Classification loss = 44.9800\n",
      "Comparison loss = 6.8693\n",
      "Epoch no 2 : \n",
      "Classification loss = 41.5022\n",
      "Comparison loss = 6.8815\n",
      "Epoch no 3 : \n",
      "Classification loss = 38.7120\n",
      "Comparison loss = 6.8810\n",
      "Epoch no 4 : \n",
      "Classification loss = 36.5890\n",
      "Comparison loss = 6.8473\n",
      "Epoch no 5 : \n",
      "Classification loss = 35.3419\n",
      "Comparison loss = 6.8359\n",
      "Epoch no 6 : \n",
      "Classification loss = 34.7686\n",
      "Comparison loss = 6.8203\n",
      "Epoch no 7 : \n",
      "Classification loss = 34.4670\n",
      "Comparison loss = 6.8325\n",
      "Epoch no 8 : \n",
      "Classification loss = 33.0831\n",
      "Comparison loss = 6.7463\n",
      "Epoch no 9 : \n",
      "Classification loss = 31.9029\n",
      "Comparison loss = 6.7226\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.0995\n",
      "Comparison loss = 6.7032\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.6360\n",
      "Comparison loss = 6.6595\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.2286\n",
      "Comparison loss = 6.6168\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.0388\n",
      "Comparison loss = 6.4393\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.8406\n",
      "Comparison loss = 7.1010\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.7093\n",
      "Comparison loss = 6.7098\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.6272\n",
      "Comparison loss = 6.6527\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.5391\n",
      "Comparison loss = 6.8417\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.4906\n",
      "Comparison loss = 6.8488\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.4511\n",
      "Comparison loss = 6.4491\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.4316\n",
      "Comparison loss = 6.6061\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4075\n",
      "Comparison loss = 6.3127\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.3943\n",
      "Comparison loss = 6.3717\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.3812\n",
      "Comparison loss = 6.2034\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.3652\n",
      "Comparison loss = 6.1378\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3600\n",
      "Comparison loss = 6.2032\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.600% \n",
      "Comparison = 9.000%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 3.700% \n",
      "Comparison = 11.100%\u001b[0m\n",
      "RUN NO 4\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.1560\n",
      "Comparison loss = 7.0383\n",
      "Epoch no 2 : \n",
      "Classification loss = 41.7097\n",
      "Comparison loss = 6.5939\n",
      "Epoch no 3 : \n",
      "Classification loss = 38.6740\n",
      "Comparison loss = 6.3858\n",
      "Epoch no 4 : \n",
      "Classification loss = 37.1438\n",
      "Comparison loss = 6.3321\n",
      "Epoch no 5 : \n",
      "Classification loss = 36.0077\n",
      "Comparison loss = 6.4858\n",
      "Epoch no 6 : \n",
      "Classification loss = 35.6213\n",
      "Comparison loss = 6.1143\n",
      "Epoch no 7 : \n",
      "Classification loss = 34.6819\n",
      "Comparison loss = 6.4951\n",
      "Epoch no 8 : \n",
      "Classification loss = 32.9979\n",
      "Comparison loss = 6.1984\n",
      "Epoch no 9 : \n",
      "Classification loss = 32.2721\n",
      "Comparison loss = 5.9157\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.1098\n",
      "Comparison loss = 6.3667\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.6664\n",
      "Comparison loss = 5.5726\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.2317\n",
      "Comparison loss = 6.0048\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.0365\n",
      "Comparison loss = 5.8059\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.8801\n",
      "Comparison loss = 5.4328\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.7458\n",
      "Comparison loss = 6.1568\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.6986\n",
      "Comparison loss = 5.5533\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.6632\n",
      "Comparison loss = 5.9157\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.5398\n",
      "Comparison loss = 6.3431\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.5559\n",
      "Comparison loss = 5.4591\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.4768\n",
      "Comparison loss = 6.9223\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4517\n",
      "Comparison loss = 5.3202\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4288\n",
      "Comparison loss = 6.1712\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4110\n",
      "Comparison loss = 5.5797\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4025\n",
      "Comparison loss = 5.4988\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3919\n",
      "Comparison loss = 5.6983\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.750% \n",
      "Comparison = 38.000%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.250% \n",
      "Comparison = 36.300%\u001b[0m\n",
      "RUN NO 5\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.6474\n",
      "Comparison loss = 7.6880\n",
      "Epoch no 2 : \n",
      "Classification loss = 43.7119\n",
      "Comparison loss = 6.9341\n",
      "Epoch no 3 : \n",
      "Classification loss = 40.4631\n",
      "Comparison loss = 7.4494\n",
      "Epoch no 4 : \n",
      "Classification loss = 38.1057\n",
      "Comparison loss = 6.2650\n",
      "Epoch no 5 : \n",
      "Classification loss = 36.2437\n",
      "Comparison loss = 6.4822\n",
      "Epoch no 6 : \n",
      "Classification loss = 34.8413\n",
      "Comparison loss = 5.6423\n",
      "Epoch no 7 : \n",
      "Classification loss = 33.1945\n",
      "Comparison loss = 5.8764\n",
      "Epoch no 8 : \n",
      "Classification loss = 32.0048\n",
      "Comparison loss = 5.5127\n",
      "Epoch no 9 : \n",
      "Classification loss = 31.6521\n",
      "Comparison loss = 5.7620\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.2025\n",
      "Comparison loss = 5.0886\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.6253\n",
      "Comparison loss = 5.3396\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.3934\n",
      "Comparison loss = 5.2366\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.1674\n",
      "Comparison loss = 4.7647\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.9083\n",
      "Comparison loss = 5.2956\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.7861\n",
      "Comparison loss = 5.3035\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.6838\n",
      "Comparison loss = 4.5667\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.6574\n",
      "Comparison loss = 5.9338\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.5709\n",
      "Comparison loss = 5.8178\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.5416\n",
      "Comparison loss = 4.7067\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.4914\n",
      "Comparison loss = 6.9325\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4789\n",
      "Comparison loss = 5.1718\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4434\n",
      "Comparison loss = 6.4531\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4302\n",
      "Comparison loss = 5.7003\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4180\n",
      "Comparison loss = 5.4156\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.4067\n",
      "Comparison loss = 5.9312\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.750% \n",
      "Comparison = 41.300%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.450% \n",
      "Comparison = 43.800%\u001b[0m\n",
      "RUN NO 6\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.2530\n",
      "Comparison loss = 7.4184\n",
      "Epoch no 2 : \n",
      "Classification loss = 42.2438\n",
      "Comparison loss = 8.3366\n",
      "Epoch no 3 : \n",
      "Classification loss = 39.3740\n",
      "Comparison loss = 6.0150\n",
      "Epoch no 4 : \n",
      "Classification loss = 36.9326\n",
      "Comparison loss = 6.5781\n",
      "Epoch no 5 : \n",
      "Classification loss = 35.4900\n",
      "Comparison loss = 5.4223\n",
      "Epoch no 6 : \n",
      "Classification loss = 33.9410\n",
      "Comparison loss = 5.7121\n",
      "Epoch no 7 : \n",
      "Classification loss = 33.4251\n",
      "Comparison loss = 5.4652\n",
      "Epoch no 8 : \n",
      "Classification loss = 33.0531\n",
      "Comparison loss = 5.2973\n",
      "Epoch no 9 : \n",
      "Classification loss = 31.9102\n",
      "Comparison loss = 4.9522\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.3634\n",
      "Comparison loss = 4.7353\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.7134\n",
      "Comparison loss = 5.0371\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.4950\n",
      "Comparison loss = 4.4549\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.2639\n",
      "Comparison loss = 4.5290\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.0405\n",
      "Comparison loss = 5.0430\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.9432\n",
      "Comparison loss = 4.3697\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.7447\n",
      "Comparison loss = 4.4218\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.6692\n",
      "Comparison loss = 5.8631\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.5925\n",
      "Comparison loss = 4.8299\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.5476\n",
      "Comparison loss = 4.7440\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.5141\n",
      "Comparison loss = 6.7644\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4890\n",
      "Comparison loss = 4.4126\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4662\n",
      "Comparison loss = 5.9764\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4514\n",
      "Comparison loss = 5.2802\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4339\n",
      "Comparison loss = 4.6699\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.4150\n",
      "Comparison loss = 5.7603\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.800% \n",
      "Comparison = 35.500%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.350% \n",
      "Comparison = 33.300%\u001b[0m\n",
      "RUN NO 7\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.4862\n",
      "Comparison loss = 8.2854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch no 2 : \n",
      "Classification loss = 43.2130\n",
      "Comparison loss = 7.0572\n",
      "Epoch no 3 : \n",
      "Classification loss = 40.1135\n",
      "Comparison loss = 7.8331\n",
      "Epoch no 4 : \n",
      "Classification loss = 37.3777\n",
      "Comparison loss = 5.9417\n",
      "Epoch no 5 : \n",
      "Classification loss = 35.9571\n",
      "Comparison loss = 6.0409\n",
      "Epoch no 6 : \n",
      "Classification loss = 35.0812\n",
      "Comparison loss = 4.9195\n",
      "Epoch no 7 : \n",
      "Classification loss = 33.9465\n",
      "Comparison loss = 5.0759\n",
      "Epoch no 8 : \n",
      "Classification loss = 33.2354\n",
      "Comparison loss = 4.6600\n",
      "Epoch no 9 : \n",
      "Classification loss = 32.3445\n",
      "Comparison loss = 4.7563\n",
      "Epoch no 10 : \n",
      "Classification loss = 32.1031\n",
      "Comparison loss = 4.1114\n",
      "Epoch no 11 : \n",
      "Classification loss = 31.6415\n",
      "Comparison loss = 4.3792\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.9944\n",
      "Comparison loss = 4.0782\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.4119\n",
      "Comparison loss = 4.0197\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.2490\n",
      "Comparison loss = 4.2224\n",
      "Epoch no 15 : \n",
      "Classification loss = 30.0228\n",
      "Comparison loss = 3.9274\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.7752\n",
      "Comparison loss = 4.1385\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.7249\n",
      "Comparison loss = 4.9788\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.6153\n",
      "Comparison loss = 4.2054\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.5229\n",
      "Comparison loss = 4.7981\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.4864\n",
      "Comparison loss = 6.0750\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4280\n",
      "Comparison loss = 4.2805\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4079\n",
      "Comparison loss = 7.0382\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.3969\n",
      "Comparison loss = 4.5624\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.3855\n",
      "Comparison loss = 5.4897\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3722\n",
      "Comparison loss = 5.1673\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.650% \n",
      "Comparison = 37.100%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.300% \n",
      "Comparison = 39.900%\u001b[0m\n",
      "RUN NO 8\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.3418\n",
      "Comparison loss = 7.9976\n",
      "Epoch no 2 : \n",
      "Classification loss = 42.5085\n",
      "Comparison loss = 10.4287\n",
      "Epoch no 3 : \n",
      "Classification loss = 39.6640\n",
      "Comparison loss = 6.0872\n",
      "Epoch no 4 : \n",
      "Classification loss = 37.9398\n",
      "Comparison loss = 7.8537\n",
      "Epoch no 5 : \n",
      "Classification loss = 36.3211\n",
      "Comparison loss = 4.9081\n",
      "Epoch no 6 : \n",
      "Classification loss = 35.4102\n",
      "Comparison loss = 6.2458\n",
      "Epoch no 7 : \n",
      "Classification loss = 34.6314\n",
      "Comparison loss = 4.9073\n",
      "Epoch no 8 : \n",
      "Classification loss = 34.1836\n",
      "Comparison loss = 5.4422\n",
      "Epoch no 9 : \n",
      "Classification loss = 33.9250\n",
      "Comparison loss = 4.3673\n",
      "Epoch no 10 : \n",
      "Classification loss = 32.2910\n",
      "Comparison loss = 4.7639\n",
      "Epoch no 11 : \n",
      "Classification loss = 31.8984\n",
      "Comparison loss = 4.2603\n",
      "Epoch no 12 : \n",
      "Classification loss = 31.1740\n",
      "Comparison loss = 4.6910\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.6223\n",
      "Comparison loss = 3.9386\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.3772\n",
      "Comparison loss = 4.1542\n",
      "Epoch no 15 : \n",
      "Classification loss = 30.0836\n",
      "Comparison loss = 4.3835\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.9660\n",
      "Comparison loss = 3.6237\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.8212\n",
      "Comparison loss = 4.2687\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.6862\n",
      "Comparison loss = 4.0877\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.6327\n",
      "Comparison loss = 3.6857\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.5666\n",
      "Comparison loss = 4.7338\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.5179\n",
      "Comparison loss = 4.0560\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4839\n",
      "Comparison loss = 4.2480\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4634\n",
      "Comparison loss = 5.4122\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4542\n",
      "Comparison loss = 3.9686\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.4475\n",
      "Comparison loss = 6.0395\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 1.000% \n",
      "Comparison = 8.400%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.350% \n",
      "Comparison = 10.700%\u001b[0m\n",
      "RUN NO 9\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.2856\n",
      "Comparison loss = 6.8078\n",
      "Epoch no 2 : \n",
      "Classification loss = 42.2728\n",
      "Comparison loss = 6.5757\n",
      "Epoch no 3 : \n",
      "Classification loss = 38.8225\n",
      "Comparison loss = 6.9897\n",
      "Epoch no 4 : \n",
      "Classification loss = 36.0362\n",
      "Comparison loss = 5.0960\n",
      "Epoch no 5 : \n",
      "Classification loss = 34.2869\n",
      "Comparison loss = 5.9592\n",
      "Epoch no 6 : \n",
      "Classification loss = 32.6391\n",
      "Comparison loss = 3.8909\n",
      "Epoch no 7 : \n",
      "Classification loss = 31.3172\n",
      "Comparison loss = 4.9268\n",
      "Epoch no 8 : \n",
      "Classification loss = 30.7555\n",
      "Comparison loss = 3.8608\n",
      "Epoch no 9 : \n",
      "Classification loss = 30.5546\n",
      "Comparison loss = 4.7079\n",
      "Epoch no 10 : \n",
      "Classification loss = 30.3274\n",
      "Comparison loss = 3.5406\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.1222\n",
      "Comparison loss = 4.0764\n",
      "Epoch no 12 : \n",
      "Classification loss = 29.8863\n",
      "Comparison loss = 3.8507\n",
      "Epoch no 13 : \n",
      "Classification loss = 29.7935\n",
      "Comparison loss = 3.4755\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.6853\n",
      "Comparison loss = 3.8880\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.6192\n",
      "Comparison loss = 3.3586\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.6638\n",
      "Comparison loss = 3.9491\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.6010\n",
      "Comparison loss = 3.7658\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.5400\n",
      "Comparison loss = 3.3602\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.4658\n",
      "Comparison loss = 4.7527\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.4372\n",
      "Comparison loss = 3.7315\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.3927\n",
      "Comparison loss = 3.7176\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.3893\n",
      "Comparison loss = 5.6312\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.3811\n",
      "Comparison loss = 3.3446\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.3744\n",
      "Comparison loss = 4.9576\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3531\n",
      "Comparison loss = 4.8501\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.550% \n",
      "Comparison = 28.700%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.500% \n",
      "Comparison = 30.000%\u001b[0m\n",
      "RUN NO 10\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.7588\n",
      "Comparison loss = 8.8610\n",
      "Epoch no 2 : \n",
      "Classification loss = 43.9316\n",
      "Comparison loss = 11.8659\n",
      "Epoch no 3 : \n",
      "Classification loss = 41.6898\n",
      "Comparison loss = 6.5240\n",
      "Epoch no 4 : \n",
      "Classification loss = 39.0631\n",
      "Comparison loss = 7.8283\n",
      "Epoch no 5 : \n",
      "Classification loss = 36.3272\n",
      "Comparison loss = 4.6009\n",
      "Epoch no 6 : \n",
      "Classification loss = 33.9881\n",
      "Comparison loss = 5.7831\n",
      "Epoch no 7 : \n",
      "Classification loss = 32.7585\n",
      "Comparison loss = 4.2904\n",
      "Epoch no 8 : \n",
      "Classification loss = 32.5005\n",
      "Comparison loss = 5.0207\n",
      "Epoch no 9 : \n",
      "Classification loss = 31.9648\n",
      "Comparison loss = 3.9150\n",
      "Epoch no 10 : \n",
      "Classification loss = 30.8598\n",
      "Comparison loss = 4.1181\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.5611\n",
      "Comparison loss = 3.7558\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.1958\n",
      "Comparison loss = 3.5900\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.1312\n",
      "Comparison loss = 3.6786\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.9799\n",
      "Comparison loss = 3.2937\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.8299\n",
      "Comparison loss = 3.8070\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.8072\n",
      "Comparison loss = 3.1827\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.6507\n",
      "Comparison loss = 3.2679\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.6027\n",
      "Comparison loss = 4.0744\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.6178\n",
      "Comparison loss = 2.9965\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.5220\n",
      "Comparison loss = 3.6555\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4796\n",
      "Comparison loss = 4.5075\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4571\n",
      "Comparison loss = 2.9614\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4117\n",
      "Comparison loss = 4.4813\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.3983\n",
      "Comparison loss = 4.6035\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3799\n",
      "Comparison loss = 3.2549\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.650% \n",
      "Comparison = 20.400%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.200% \n",
      "Comparison = 21.800%\u001b[0m\n",
      "Final error for train batch : 30.82±13.7883\n",
      "Final error for test batch : 32.17±13.7210\n",
      "RUN NO 1\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.2411\n",
      "Comparison loss = 6.9344\n",
      "Epoch no 2 : \n",
      "Classification loss = 41.9807\n",
      "Comparison loss = 6.8925\n",
      "Epoch no 3 : \n",
      "Classification loss = 37.8038\n",
      "Comparison loss = 6.8822\n",
      "Epoch no 4 : \n",
      "Classification loss = 35.4682\n",
      "Comparison loss = 6.7804\n",
      "Epoch no 5 : \n",
      "Classification loss = 33.9563\n",
      "Comparison loss = 6.5518\n",
      "Epoch no 6 : \n",
      "Classification loss = 33.0850\n",
      "Comparison loss = 5.8354\n",
      "Epoch no 7 : \n",
      "Classification loss = 32.2264\n",
      "Comparison loss = 5.0633\n",
      "Epoch no 8 : \n",
      "Classification loss = 31.4492\n",
      "Comparison loss = 4.1231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch no 9 : \n",
      "Classification loss = 31.1420\n",
      "Comparison loss = 4.1245\n",
      "Epoch no 10 : \n",
      "Classification loss = 30.5471\n",
      "Comparison loss = 4.2014\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.4578\n",
      "Comparison loss = 3.1562\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.1184\n",
      "Comparison loss = 2.7885\n",
      "Epoch no 13 : \n",
      "Classification loss = 29.9766\n",
      "Comparison loss = 1.8832\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.7971\n",
      "Comparison loss = 0.9753\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.7518\n",
      "Comparison loss = 0.9532\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.6276\n",
      "Comparison loss = 0.6430\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.5715\n",
      "Comparison loss = 0.4181\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.6350\n",
      "Comparison loss = 0.6856\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.5094\n",
      "Comparison loss = 0.3595\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.4938\n",
      "Comparison loss = 0.2377\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4489\n",
      "Comparison loss = 0.1310\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4076\n",
      "Comparison loss = 0.1226\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.3945\n",
      "Comparison loss = 0.1155\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.3824\n",
      "Comparison loss = 0.1030\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.4506\n",
      "Comparison loss = 0.3325\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 2.550% \n",
      "Comparison = 1.900%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 6.500% \n",
      "Comparison = 4.500%\u001b[0m\n",
      "RUN NO 2\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.9357\n",
      "Comparison loss = 8.4424\n",
      "Epoch no 2 : \n",
      "Classification loss = 45.0917\n",
      "Comparison loss = 7.4659\n",
      "Epoch no 3 : \n",
      "Classification loss = 43.2580\n",
      "Comparison loss = 6.0656\n",
      "Epoch no 4 : \n",
      "Classification loss = 41.7705\n",
      "Comparison loss = 4.7987\n",
      "Epoch no 5 : \n",
      "Classification loss = 40.2310\n",
      "Comparison loss = 3.5779\n",
      "Epoch no 6 : \n",
      "Classification loss = 37.9749\n",
      "Comparison loss = 3.0179\n",
      "Epoch no 7 : \n",
      "Classification loss = 35.5664\n",
      "Comparison loss = 2.6464\n",
      "Epoch no 8 : \n",
      "Classification loss = 33.9445\n",
      "Comparison loss = 2.3382\n",
      "Epoch no 9 : \n",
      "Classification loss = 33.2845\n",
      "Comparison loss = 2.2976\n",
      "Epoch no 10 : \n",
      "Classification loss = 33.1488\n",
      "Comparison loss = 2.2429\n",
      "Epoch no 11 : \n",
      "Classification loss = 32.4623\n",
      "Comparison loss = 1.6008\n",
      "Epoch no 12 : \n",
      "Classification loss = 32.0507\n",
      "Comparison loss = 1.6171\n",
      "Epoch no 13 : \n",
      "Classification loss = 31.3266\n",
      "Comparison loss = 1.2561\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.8335\n",
      "Comparison loss = 0.8424\n",
      "Epoch no 15 : \n",
      "Classification loss = 30.5181\n",
      "Comparison loss = 0.8397\n",
      "Epoch no 16 : \n",
      "Classification loss = 30.2344\n",
      "Comparison loss = 0.5968\n",
      "Epoch no 17 : \n",
      "Classification loss = 30.0864\n",
      "Comparison loss = 0.4724\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.9224\n",
      "Comparison loss = 0.3264\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.8149\n",
      "Comparison loss = 0.3086\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.7423\n",
      "Comparison loss = 0.3043\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.6114\n",
      "Comparison loss = 0.2076\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.5602\n",
      "Comparison loss = 0.2001\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.5077\n",
      "Comparison loss = 0.1993\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4758\n",
      "Comparison loss = 0.1979\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.4544\n",
      "Comparison loss = 0.1932\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 1.000% \n",
      "Comparison = 0.400%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 5.100% \n",
      "Comparison = 3.800%\u001b[0m\n",
      "RUN NO 3\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.6194\n",
      "Comparison loss = 6.3934\n",
      "Epoch no 2 : \n",
      "Classification loss = 43.7663\n",
      "Comparison loss = 6.5728\n",
      "Epoch no 3 : \n",
      "Classification loss = 41.8185\n",
      "Comparison loss = 4.5343\n",
      "Epoch no 4 : \n",
      "Classification loss = 40.1172\n",
      "Comparison loss = 4.2873\n",
      "Epoch no 5 : \n",
      "Classification loss = 37.8835\n",
      "Comparison loss = 3.4974\n",
      "Epoch no 6 : \n",
      "Classification loss = 35.5417\n",
      "Comparison loss = 3.0775\n",
      "Epoch no 7 : \n",
      "Classification loss = 34.7656\n",
      "Comparison loss = 2.6929\n",
      "Epoch no 8 : \n",
      "Classification loss = 34.1145\n",
      "Comparison loss = 2.5310\n",
      "Epoch no 9 : \n",
      "Classification loss = 33.3763\n",
      "Comparison loss = 2.0864\n",
      "Epoch no 10 : \n",
      "Classification loss = 32.0543\n",
      "Comparison loss = 1.4377\n",
      "Epoch no 11 : \n",
      "Classification loss = 31.2124\n",
      "Comparison loss = 1.1474\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.8431\n",
      "Comparison loss = 1.0734\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.5301\n",
      "Comparison loss = 0.8348\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.2805\n",
      "Comparison loss = 0.7316\n",
      "Epoch no 15 : \n",
      "Classification loss = 30.3458\n",
      "Comparison loss = 0.6316\n",
      "Epoch no 16 : \n",
      "Classification loss = 30.0599\n",
      "Comparison loss = 0.5171\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.9899\n",
      "Comparison loss = 0.5239\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.9197\n",
      "Comparison loss = 0.4633\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.8239\n",
      "Comparison loss = 0.5344\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.8119\n",
      "Comparison loss = 0.3987\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.8610\n",
      "Comparison loss = 0.6421\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.7336\n",
      "Comparison loss = 0.5465\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.7368\n",
      "Comparison loss = 0.3120\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.6208\n",
      "Comparison loss = 0.1838\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.5264\n",
      "Comparison loss = 0.1491\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 1.200% \n",
      "Comparison = 0.300%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 5.300% \n",
      "Comparison = 3.700%\u001b[0m\n",
      "RUN NO 4\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.3872\n",
      "Comparison loss = 5.3550\n",
      "Epoch no 2 : \n",
      "Classification loss = 42.7568\n",
      "Comparison loss = 5.0398\n",
      "Epoch no 3 : \n",
      "Classification loss = 40.2217\n",
      "Comparison loss = 3.6902\n",
      "Epoch no 4 : \n",
      "Classification loss = 37.4172\n",
      "Comparison loss = 2.9350\n",
      "Epoch no 5 : \n",
      "Classification loss = 34.9421\n",
      "Comparison loss = 2.4501\n",
      "Epoch no 6 : \n",
      "Classification loss = 33.8062\n",
      "Comparison loss = 2.2981\n",
      "Epoch no 7 : \n",
      "Classification loss = 33.2322\n",
      "Comparison loss = 2.2781\n",
      "Epoch no 8 : \n",
      "Classification loss = 32.4245\n",
      "Comparison loss = 1.7352\n",
      "Epoch no 9 : \n",
      "Classification loss = 31.6837\n",
      "Comparison loss = 1.3951\n",
      "Epoch no 10 : \n",
      "Classification loss = 30.9097\n",
      "Comparison loss = 1.1593\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.8278\n",
      "Comparison loss = 1.2606\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.4760\n",
      "Comparison loss = 0.8510\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.2286\n",
      "Comparison loss = 0.6425\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.0196\n",
      "Comparison loss = 0.6239\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.8207\n",
      "Comparison loss = 0.5636\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.7023\n",
      "Comparison loss = 0.3601\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.6356\n",
      "Comparison loss = 0.2921\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.5713\n",
      "Comparison loss = 0.2103\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.5266\n",
      "Comparison loss = 0.1927\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.4997\n",
      "Comparison loss = 0.1807\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4667\n",
      "Comparison loss = 0.1977\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4416\n",
      "Comparison loss = 0.1355\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4257\n",
      "Comparison loss = 0.0880\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4189\n",
      "Comparison loss = 0.0860\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.4154\n",
      "Comparison loss = 0.0842\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.900% \n",
      "Comparison = 0.200%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.000% \n",
      "Comparison = 3.200%\u001b[0m\n",
      "RUN NO 5\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.4889\n",
      "Comparison loss = 5.5895\n",
      "Epoch no 2 : \n",
      "Classification loss = 43.3456\n",
      "Comparison loss = 4.8749\n",
      "Epoch no 3 : \n",
      "Classification loss = 40.3398\n",
      "Comparison loss = 4.1524\n",
      "Epoch no 4 : \n",
      "Classification loss = 37.5947\n",
      "Comparison loss = 3.2458\n",
      "Epoch no 5 : \n",
      "Classification loss = 35.0468\n",
      "Comparison loss = 2.4019\n",
      "Epoch no 6 : \n",
      "Classification loss = 33.2808\n",
      "Comparison loss = 1.8715\n",
      "Epoch no 7 : \n",
      "Classification loss = 32.1188\n",
      "Comparison loss = 1.6037\n",
      "Epoch no 8 : \n",
      "Classification loss = 31.8838\n",
      "Comparison loss = 1.9275\n",
      "Epoch no 9 : \n",
      "Classification loss = 31.1540\n",
      "Comparison loss = 1.5473\n",
      "Epoch no 10 : \n",
      "Classification loss = 30.7714\n",
      "Comparison loss = 1.2077\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.3720\n",
      "Comparison loss = 0.8993\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.1487\n",
      "Comparison loss = 0.8906\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.0181\n",
      "Comparison loss = 0.6317\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.8624\n",
      "Comparison loss = 0.5542\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.7480\n",
      "Comparison loss = 0.4313\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.6085\n",
      "Comparison loss = 0.3528\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.6033\n",
      "Comparison loss = 0.3078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch no 18 : \n",
      "Classification loss = 29.5360\n",
      "Comparison loss = 0.2236\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.5087\n",
      "Comparison loss = 0.2013\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.4673\n",
      "Comparison loss = 0.1820\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4329\n",
      "Comparison loss = 0.1798\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4071\n",
      "Comparison loss = 0.1721\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.3900\n",
      "Comparison loss = 0.1663\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.3806\n",
      "Comparison loss = 0.1620\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3748\n",
      "Comparison loss = 0.1585\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.650% \n",
      "Comparison = 0.300%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.100% \n",
      "Comparison = 2.800%\u001b[0m\n",
      "RUN NO 6\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.4422\n",
      "Comparison loss = 5.8254\n",
      "Epoch no 2 : \n",
      "Classification loss = 42.8826\n",
      "Comparison loss = 4.6077\n",
      "Epoch no 3 : \n",
      "Classification loss = 40.0024\n",
      "Comparison loss = 3.7866\n",
      "Epoch no 4 : \n",
      "Classification loss = 37.3722\n",
      "Comparison loss = 2.6143\n",
      "Epoch no 5 : \n",
      "Classification loss = 34.9839\n",
      "Comparison loss = 2.1975\n",
      "Epoch no 6 : \n",
      "Classification loss = 33.2622\n",
      "Comparison loss = 1.6499\n",
      "Epoch no 7 : \n",
      "Classification loss = 32.0784\n",
      "Comparison loss = 1.5490\n",
      "Epoch no 8 : \n",
      "Classification loss = 31.6968\n",
      "Comparison loss = 1.7558\n",
      "Epoch no 9 : \n",
      "Classification loss = 31.2002\n",
      "Comparison loss = 1.3495\n",
      "Epoch no 10 : \n",
      "Classification loss = 30.6233\n",
      "Comparison loss = 1.0411\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.2966\n",
      "Comparison loss = 0.8297\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.1792\n",
      "Comparison loss = 0.6113\n",
      "Epoch no 13 : \n",
      "Classification loss = 29.9357\n",
      "Comparison loss = 0.3722\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.8270\n",
      "Comparison loss = 0.2718\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.7464\n",
      "Comparison loss = 0.3968\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.6339\n",
      "Comparison loss = 0.2543\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.5969\n",
      "Comparison loss = 0.1681\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.5586\n",
      "Comparison loss = 0.1469\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.5211\n",
      "Comparison loss = 0.1584\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.4790\n",
      "Comparison loss = 0.1146\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4616\n",
      "Comparison loss = 0.1094\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4531\n",
      "Comparison loss = 0.1051\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4434\n",
      "Comparison loss = 0.1015\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4303\n",
      "Comparison loss = 0.0972\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.4218\n",
      "Comparison loss = 0.0863\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.900% \n",
      "Comparison = 0.200%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.850% \n",
      "Comparison = 3.400%\u001b[0m\n",
      "RUN NO 7\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.4175\n",
      "Comparison loss = 5.5212\n",
      "Epoch no 2 : \n",
      "Classification loss = 43.0630\n",
      "Comparison loss = 4.6268\n",
      "Epoch no 3 : \n",
      "Classification loss = 39.8803\n",
      "Comparison loss = 3.3137\n",
      "Epoch no 4 : \n",
      "Classification loss = 37.0265\n",
      "Comparison loss = 2.7536\n",
      "Epoch no 5 : \n",
      "Classification loss = 35.1863\n",
      "Comparison loss = 2.6753\n",
      "Epoch no 6 : \n",
      "Classification loss = 33.6428\n",
      "Comparison loss = 2.0269\n",
      "Epoch no 7 : \n",
      "Classification loss = 32.3317\n",
      "Comparison loss = 1.3796\n",
      "Epoch no 8 : \n",
      "Classification loss = 31.2978\n",
      "Comparison loss = 0.8496\n",
      "Epoch no 9 : \n",
      "Classification loss = 30.8337\n",
      "Comparison loss = 0.8870\n",
      "Epoch no 10 : \n",
      "Classification loss = 30.4704\n",
      "Comparison loss = 0.8854\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.2339\n",
      "Comparison loss = 0.6084\n",
      "Epoch no 12 : \n",
      "Classification loss = 29.9713\n",
      "Comparison loss = 0.5580\n",
      "Epoch no 13 : \n",
      "Classification loss = 29.7962\n",
      "Comparison loss = 0.4918\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.6812\n",
      "Comparison loss = 0.3349\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.5576\n",
      "Comparison loss = 0.3006\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.5074\n",
      "Comparison loss = 0.3218\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.4514\n",
      "Comparison loss = 0.1796\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.4252\n",
      "Comparison loss = 0.1696\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.3989\n",
      "Comparison loss = 0.1458\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.3886\n",
      "Comparison loss = 0.1198\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.3871\n",
      "Comparison loss = 0.0718\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.3825\n",
      "Comparison loss = 0.0690\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.3654\n",
      "Comparison loss = 0.0669\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.3550\n",
      "Comparison loss = 0.0647\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3463\n",
      "Comparison loss = 0.0959\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.600% \n",
      "Comparison = 0.100%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.300% \n",
      "Comparison = 3.200%\u001b[0m\n",
      "RUN NO 8\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.4966\n",
      "Comparison loss = 6.3015\n",
      "Epoch no 2 : \n",
      "Classification loss = 43.6492\n",
      "Comparison loss = 5.4934\n",
      "Epoch no 3 : \n",
      "Classification loss = 41.8772\n",
      "Comparison loss = 4.5438\n",
      "Epoch no 4 : \n",
      "Classification loss = 39.6995\n",
      "Comparison loss = 3.4606\n",
      "Epoch no 5 : \n",
      "Classification loss = 37.3474\n",
      "Comparison loss = 3.2874\n",
      "Epoch no 6 : \n",
      "Classification loss = 35.2622\n",
      "Comparison loss = 2.6021\n",
      "Epoch no 7 : \n",
      "Classification loss = 34.6476\n",
      "Comparison loss = 2.4971\n",
      "Epoch no 8 : \n",
      "Classification loss = 33.4544\n",
      "Comparison loss = 2.0150\n",
      "Epoch no 9 : \n",
      "Classification loss = 32.7568\n",
      "Comparison loss = 1.5139\n",
      "Epoch no 10 : \n",
      "Classification loss = 32.6053\n",
      "Comparison loss = 1.8534\n",
      "Epoch no 11 : \n",
      "Classification loss = 32.1506\n",
      "Comparison loss = 1.2339\n",
      "Epoch no 12 : \n",
      "Classification loss = 32.0604\n",
      "Comparison loss = 1.0783\n",
      "Epoch no 13 : \n",
      "Classification loss = 31.9013\n",
      "Comparison loss = 1.2205\n",
      "Epoch no 14 : \n",
      "Classification loss = 31.8379\n",
      "Comparison loss = 1.0765\n",
      "Epoch no 15 : \n",
      "Classification loss = 31.5595\n",
      "Comparison loss = 0.8118\n",
      "Epoch no 16 : \n",
      "Classification loss = 31.2591\n",
      "Comparison loss = 0.7368\n",
      "Epoch no 17 : \n",
      "Classification loss = 30.5476\n",
      "Comparison loss = 0.6120\n",
      "Epoch no 18 : \n",
      "Classification loss = 30.0997\n",
      "Comparison loss = 0.3732\n",
      "Epoch no 19 : \n",
      "Classification loss = 30.0266\n",
      "Comparison loss = 0.6753\n",
      "Epoch no 20 : \n",
      "Classification loss = 30.1307\n",
      "Comparison loss = 1.3555\n",
      "Epoch no 21 : \n",
      "Classification loss = 30.0156\n",
      "Comparison loss = 0.4687\n",
      "Epoch no 22 : \n",
      "Classification loss = 30.0555\n",
      "Comparison loss = 0.6605\n",
      "Epoch no 23 : \n",
      "Classification loss = 30.1967\n",
      "Comparison loss = 0.8488\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.8701\n",
      "Comparison loss = 0.4456\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.7794\n",
      "Comparison loss = 0.3897\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 1.650% \n",
      "Comparison = 0.600%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.900% \n",
      "Comparison = 3.100%\u001b[0m\n",
      "RUN NO 9\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.4170\n",
      "Comparison loss = 6.5100\n",
      "Epoch no 2 : \n",
      "Classification loss = 42.9211\n",
      "Comparison loss = 4.8728\n",
      "Epoch no 3 : \n",
      "Classification loss = 39.8045\n",
      "Comparison loss = 3.7402\n",
      "Epoch no 4 : \n",
      "Classification loss = 37.1671\n",
      "Comparison loss = 2.9930\n",
      "Epoch no 5 : \n",
      "Classification loss = 35.7601\n",
      "Comparison loss = 2.7072\n",
      "Epoch no 6 : \n",
      "Classification loss = 34.4374\n",
      "Comparison loss = 2.3889\n",
      "Epoch no 7 : \n",
      "Classification loss = 33.2722\n",
      "Comparison loss = 2.1157\n",
      "Epoch no 8 : \n",
      "Classification loss = 32.5482\n",
      "Comparison loss = 1.5952\n",
      "Epoch no 9 : \n",
      "Classification loss = 32.1945\n",
      "Comparison loss = 1.3374\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.2709\n",
      "Comparison loss = 1.0356\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.7790\n",
      "Comparison loss = 0.9782\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.5590\n",
      "Comparison loss = 1.0585\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.1416\n",
      "Comparison loss = 0.6160\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.0051\n",
      "Comparison loss = 0.5771\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.9303\n",
      "Comparison loss = 0.6256\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.8688\n",
      "Comparison loss = 0.3253\n",
      "Epoch no 17 : \n",
      "Classification loss = 30.0078\n",
      "Comparison loss = 0.6181\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.8405\n",
      "Comparison loss = 0.5756\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.7845\n",
      "Comparison loss = 0.2786\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.7089\n",
      "Comparison loss = 0.2728\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.6128\n",
      "Comparison loss = 0.1422\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.5821\n",
      "Comparison loss = 0.1248\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4969\n",
      "Comparison loss = 0.1139\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4388\n",
      "Comparison loss = 0.0433\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.4166\n",
      "Comparison loss = 0.0061\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.700% \n",
      "Comparison = 0.100%\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.100% \n",
      "Comparison = 3.100%\u001b[0m\n",
      "RUN NO 10\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.1877\n",
      "Comparison loss = 6.3648\n",
      "Epoch no 2 : \n",
      "Classification loss = 42.7599\n",
      "Comparison loss = 5.1774\n",
      "Epoch no 3 : \n",
      "Classification loss = 40.8307\n",
      "Comparison loss = 4.3702\n",
      "Epoch no 4 : \n",
      "Classification loss = 38.5324\n",
      "Comparison loss = 3.9493\n",
      "Epoch no 5 : \n",
      "Classification loss = 35.9202\n",
      "Comparison loss = 2.7901\n",
      "Epoch no 6 : \n",
      "Classification loss = 34.3366\n",
      "Comparison loss = 2.3155\n",
      "Epoch no 7 : \n",
      "Classification loss = 32.8398\n",
      "Comparison loss = 1.8442\n",
      "Epoch no 8 : \n",
      "Classification loss = 31.8490\n",
      "Comparison loss = 1.3265\n",
      "Epoch no 9 : \n",
      "Classification loss = 31.3452\n",
      "Comparison loss = 1.2028\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.5473\n",
      "Comparison loss = 2.3734\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.9925\n",
      "Comparison loss = 1.3454\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.7330\n",
      "Comparison loss = 1.1436\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.4563\n",
      "Comparison loss = 0.8367\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.1865\n",
      "Comparison loss = 0.6657\n",
      "Epoch no 15 : \n",
      "Classification loss = 30.0146\n",
      "Comparison loss = 0.5916\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.9109\n",
      "Comparison loss = 0.5249\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.9163\n",
      "Comparison loss = 0.5379\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.8034\n",
      "Comparison loss = 0.4217\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.7135\n",
      "Comparison loss = 0.3454\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.6427\n",
      "Comparison loss = 0.3001\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.5957\n",
      "Comparison loss = 0.3201\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.5516\n",
      "Comparison loss = 0.2445\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.5021\n",
      "Comparison loss = 0.1948\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4769\n",
      "Comparison loss = 0.1836\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.4619\n",
      "Comparison loss = 0.1724\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 1.050% \n",
      "Comparison = 0.200%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.950% \n",
      "Comparison = 3.200%\u001b[0m\n",
      "Final error for train batch : 0.43±0.5376\n",
      "Final error for test batch : 3.40±0.4853\n",
      "RUN NO 1\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.3160\n",
      "Comparison loss = 6.9069\n",
      "Epoch no 2 : \n",
      "Classification loss = 42.6593\n",
      "Comparison loss = 6.8891\n",
      "Epoch no 3 : \n",
      "Classification loss = 39.9024\n",
      "Comparison loss = 6.8805\n",
      "Epoch no 4 : \n",
      "Classification loss = 37.1119\n",
      "Comparison loss = 6.8066\n",
      "Epoch no 5 : \n",
      "Classification loss = 35.5335\n",
      "Comparison loss = 6.5148\n",
      "Epoch no 6 : \n",
      "Classification loss = 34.3362\n",
      "Comparison loss = 5.6888\n",
      "Epoch no 7 : \n",
      "Classification loss = 33.1243\n",
      "Comparison loss = 4.6119\n",
      "Epoch no 8 : \n",
      "Classification loss = 32.5572\n",
      "Comparison loss = 3.6979\n",
      "Epoch no 9 : \n",
      "Classification loss = 32.7017\n",
      "Comparison loss = 4.0056\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.6721\n",
      "Comparison loss = 2.7686\n",
      "Epoch no 11 : \n",
      "Classification loss = 31.4779\n",
      "Comparison loss = 2.1995\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.7488\n",
      "Comparison loss = 1.5850\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.6045\n",
      "Comparison loss = 2.3709\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.2188\n",
      "Comparison loss = 4.6162\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.9497\n",
      "Comparison loss = 1.4454\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.8306\n",
      "Comparison loss = 1.7917\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.7155\n",
      "Comparison loss = 0.8822\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.6324\n",
      "Comparison loss = 0.3380\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.5758\n",
      "Comparison loss = 0.2499\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.5170\n",
      "Comparison loss = 0.0922\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4948\n",
      "Comparison loss = 0.0131\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4766\n",
      "Comparison loss = 0.0060\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4654\n",
      "Comparison loss = 0.1002\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4466\n",
      "Comparison loss = 0.0376\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.4361\n",
      "Comparison loss = 0.0029\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.950% \n",
      "Comparison = 0.000%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.550% \n",
      "Comparison = 3.400%\u001b[0m\n",
      "RUN NO 2\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.5189\n",
      "Comparison loss = 11.0691\n",
      "Epoch no 2 : \n",
      "Classification loss = 43.7387\n",
      "Comparison loss = 10.0143\n",
      "Epoch no 3 : \n",
      "Classification loss = 42.1280\n",
      "Comparison loss = 4.7348\n",
      "Epoch no 4 : \n",
      "Classification loss = 40.8140\n",
      "Comparison loss = 3.3883\n",
      "Epoch no 5 : \n",
      "Classification loss = 38.8651\n",
      "Comparison loss = 3.2072\n",
      "Epoch no 6 : \n",
      "Classification loss = 37.2062\n",
      "Comparison loss = 2.8190\n",
      "Epoch no 7 : \n",
      "Classification loss = 35.2007\n",
      "Comparison loss = 2.4083\n",
      "Epoch no 8 : \n",
      "Classification loss = 33.7040\n",
      "Comparison loss = 2.0662\n",
      "Epoch no 9 : \n",
      "Classification loss = 32.7283\n",
      "Comparison loss = 1.7531\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.7363\n",
      "Comparison loss = 1.6606\n",
      "Epoch no 11 : \n",
      "Classification loss = 31.1294\n",
      "Comparison loss = 1.3475\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.8456\n",
      "Comparison loss = 1.2424\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.6521\n",
      "Comparison loss = 1.2351\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.2067\n",
      "Comparison loss = 0.8361\n",
      "Epoch no 15 : \n",
      "Classification loss = 30.2086\n",
      "Comparison loss = 0.7880\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.8459\n",
      "Comparison loss = 0.4913\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.7662\n",
      "Comparison loss = 0.3994\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.6766\n",
      "Comparison loss = 0.3896\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.6288\n",
      "Comparison loss = 0.2856\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.5768\n",
      "Comparison loss = 0.2297\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.5462\n",
      "Comparison loss = 0.1572\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.5136\n",
      "Comparison loss = 0.1102\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4959\n",
      "Comparison loss = 0.1038\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4771\n",
      "Comparison loss = 0.1668\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.4698\n",
      "Comparison loss = 0.0977\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 1.100% \n",
      "Comparison = 0.300%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.700% \n",
      "Comparison = 3.600%\u001b[0m\n",
      "RUN NO 3\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.6973\n",
      "Comparison loss = 7.9929\n",
      "Epoch no 2 : \n",
      "Classification loss = 44.4156\n",
      "Comparison loss = 5.6130\n",
      "Epoch no 3 : \n",
      "Classification loss = 42.3810\n",
      "Comparison loss = 4.8427\n",
      "Epoch no 4 : \n",
      "Classification loss = 40.8199\n",
      "Comparison loss = 4.6656\n",
      "Epoch no 5 : \n",
      "Classification loss = 39.1082\n",
      "Comparison loss = 4.1428\n",
      "Epoch no 6 : \n",
      "Classification loss = 37.3622\n",
      "Comparison loss = 3.5908\n",
      "Epoch no 7 : \n",
      "Classification loss = 35.9237\n",
      "Comparison loss = 3.1417\n",
      "Epoch no 8 : \n",
      "Classification loss = 35.1862\n",
      "Comparison loss = 2.7227\n",
      "Epoch no 9 : \n",
      "Classification loss = 34.2514\n",
      "Comparison loss = 2.1238\n",
      "Epoch no 10 : \n",
      "Classification loss = 33.1437\n",
      "Comparison loss = 1.9310\n",
      "Epoch no 11 : \n",
      "Classification loss = 32.5893\n",
      "Comparison loss = 2.0288\n",
      "Epoch no 12 : \n",
      "Classification loss = 32.9170\n",
      "Comparison loss = 1.9762\n",
      "Epoch no 13 : \n",
      "Classification loss = 32.5008\n",
      "Comparison loss = 1.6887\n",
      "Epoch no 14 : \n",
      "Classification loss = 32.2393\n",
      "Comparison loss = 1.5416\n",
      "Epoch no 15 : \n",
      "Classification loss = 31.8617\n",
      "Comparison loss = 1.1797\n",
      "Epoch no 16 : \n",
      "Classification loss = 31.3798\n",
      "Comparison loss = 0.9412\n",
      "Epoch no 17 : \n",
      "Classification loss = 30.6178\n",
      "Comparison loss = 0.8946\n",
      "Epoch no 18 : \n",
      "Classification loss = 30.5697\n",
      "Comparison loss = 0.8811\n",
      "Epoch no 19 : \n",
      "Classification loss = 30.1171\n",
      "Comparison loss = 0.6516\n",
      "Epoch no 20 : \n",
      "Classification loss = 30.0031\n",
      "Comparison loss = 0.5904\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.8601\n",
      "Comparison loss = 0.5167\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.7714\n",
      "Comparison loss = 0.4294\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.6632\n",
      "Comparison loss = 0.3146\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.6091\n",
      "Comparison loss = 0.2784\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.5181\n",
      "Comparison loss = 0.2261\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 1.200% \n",
      "Comparison = 0.400%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 5.050% \n",
      "Comparison = 2.900%\u001b[0m\n",
      "RUN NO 4\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.7199\n",
      "Comparison loss = 7.1589\n",
      "Epoch no 2 : \n",
      "Classification loss = 44.0651\n",
      "Comparison loss = 6.5471\n",
      "Epoch no 3 : \n",
      "Classification loss = 41.3707\n",
      "Comparison loss = 4.2823\n",
      "Epoch no 4 : \n",
      "Classification loss = 38.8507\n",
      "Comparison loss = 3.7389\n",
      "Epoch no 5 : \n",
      "Classification loss = 36.5433\n",
      "Comparison loss = 3.0814\n",
      "Epoch no 6 : \n",
      "Classification loss = 35.1513\n",
      "Comparison loss = 2.5840\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch no 7 : \n",
      "Classification loss = 34.3209\n",
      "Comparison loss = 2.2632\n",
      "Epoch no 8 : \n",
      "Classification loss = 33.1133\n",
      "Comparison loss = 2.1432\n",
      "Epoch no 9 : \n",
      "Classification loss = 32.5067\n",
      "Comparison loss = 1.6959\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.7870\n",
      "Comparison loss = 2.0903\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.9792\n",
      "Comparison loss = 1.2113\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.5985\n",
      "Comparison loss = 1.0074\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.2617\n",
      "Comparison loss = 0.7648\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.0680\n",
      "Comparison loss = 0.6106\n",
      "Epoch no 15 : \n",
      "Classification loss = 30.0839\n",
      "Comparison loss = 0.7076\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.9516\n",
      "Comparison loss = 0.6266\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.8872\n",
      "Comparison loss = 0.4752\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.7265\n",
      "Comparison loss = 0.3553\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.6681\n",
      "Comparison loss = 0.3061\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.6097\n",
      "Comparison loss = 0.2776\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.5778\n",
      "Comparison loss = 0.3099\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.5731\n",
      "Comparison loss = 0.2275\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.5253\n",
      "Comparison loss = 0.1840\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.5072\n",
      "Comparison loss = 0.1767\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.4841\n",
      "Comparison loss = 0.1483\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 1.150% \n",
      "Comparison = 0.300%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.350% \n",
      "Comparison = 3.000%\u001b[0m\n",
      "RUN NO 5\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.3635\n",
      "Comparison loss = 5.9379\n",
      "Epoch no 2 : \n",
      "Classification loss = 43.1245\n",
      "Comparison loss = 4.8743\n",
      "Epoch no 3 : \n",
      "Classification loss = 40.6562\n",
      "Comparison loss = 4.9255\n",
      "Epoch no 4 : \n",
      "Classification loss = 38.3784\n",
      "Comparison loss = 3.3045\n",
      "Epoch no 5 : \n",
      "Classification loss = 36.4620\n",
      "Comparison loss = 3.2709\n",
      "Epoch no 6 : \n",
      "Classification loss = 34.8320\n",
      "Comparison loss = 2.7004\n",
      "Epoch no 7 : \n",
      "Classification loss = 33.4748\n",
      "Comparison loss = 2.0045\n",
      "Epoch no 8 : \n",
      "Classification loss = 32.7089\n",
      "Comparison loss = 1.7377\n",
      "Epoch no 9 : \n",
      "Classification loss = 31.8911\n",
      "Comparison loss = 1.2837\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.1406\n",
      "Comparison loss = 1.0576\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.6811\n",
      "Comparison loss = 0.8697\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.4917\n",
      "Comparison loss = 0.8157\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.2274\n",
      "Comparison loss = 0.7151\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.1057\n",
      "Comparison loss = 0.7389\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.9086\n",
      "Comparison loss = 0.5419\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.8316\n",
      "Comparison loss = 0.3592\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.7444\n",
      "Comparison loss = 0.2505\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.6515\n",
      "Comparison loss = 0.2080\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.5731\n",
      "Comparison loss = 0.1339\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.5159\n",
      "Comparison loss = 0.1204\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4743\n",
      "Comparison loss = 0.0973\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4398\n",
      "Comparison loss = 0.0197\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4374\n",
      "Comparison loss = 0.0048\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4302\n",
      "Comparison loss = 0.0045\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.4197\n",
      "Comparison loss = 0.0025\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.900% \n",
      "Comparison = 0.000%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.300% \n",
      "Comparison = 2.800%\u001b[0m\n",
      "RUN NO 6\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.4861\n",
      "Comparison loss = 6.1387\n",
      "Epoch no 2 : \n",
      "Classification loss = 43.1656\n",
      "Comparison loss = 5.0893\n",
      "Epoch no 3 : \n",
      "Classification loss = 39.8386\n",
      "Comparison loss = 3.6226\n",
      "Epoch no 4 : \n",
      "Classification loss = 36.9850\n",
      "Comparison loss = 3.0761\n",
      "Epoch no 5 : \n",
      "Classification loss = 34.7039\n",
      "Comparison loss = 2.5729\n",
      "Epoch no 6 : \n",
      "Classification loss = 33.2833\n",
      "Comparison loss = 1.9593\n",
      "Epoch no 7 : \n",
      "Classification loss = 32.2748\n",
      "Comparison loss = 1.7262\n",
      "Epoch no 8 : \n",
      "Classification loss = 31.3122\n",
      "Comparison loss = 1.3090\n",
      "Epoch no 9 : \n",
      "Classification loss = 30.9138\n",
      "Comparison loss = 1.1576\n",
      "Epoch no 10 : \n",
      "Classification loss = 30.6917\n",
      "Comparison loss = 0.9136\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.3885\n",
      "Comparison loss = 1.0074\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.2141\n",
      "Comparison loss = 0.6925\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.1572\n",
      "Comparison loss = 0.7804\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.9739\n",
      "Comparison loss = 0.4676\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.9870\n",
      "Comparison loss = 0.8463\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.8161\n",
      "Comparison loss = 0.4762\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.7541\n",
      "Comparison loss = 0.3652\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.6451\n",
      "Comparison loss = 0.2478\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.5901\n",
      "Comparison loss = 0.4306\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.4837\n",
      "Comparison loss = 0.1131\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4460\n",
      "Comparison loss = 0.0962\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4325\n",
      "Comparison loss = 0.0510\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4186\n",
      "Comparison loss = 0.0453\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4017\n",
      "Comparison loss = 0.0436\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3875\n",
      "Comparison loss = 0.0423\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.700% \n",
      "Comparison = 0.200%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.300% \n",
      "Comparison = 3.500%\u001b[0m\n",
      "RUN NO 7\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.6448\n",
      "Comparison loss = 6.4424\n",
      "Epoch no 2 : \n",
      "Classification loss = 43.7537\n",
      "Comparison loss = 5.0857\n",
      "Epoch no 3 : \n",
      "Classification loss = 41.0130\n",
      "Comparison loss = 4.1987\n",
      "Epoch no 4 : \n",
      "Classification loss = 38.9515\n",
      "Comparison loss = 3.2678\n",
      "Epoch no 5 : \n",
      "Classification loss = 37.0664\n",
      "Comparison loss = 3.2678\n",
      "Epoch no 6 : \n",
      "Classification loss = 35.2022\n",
      "Comparison loss = 2.5846\n",
      "Epoch no 7 : \n",
      "Classification loss = 33.8513\n",
      "Comparison loss = 2.0235\n",
      "Epoch no 8 : \n",
      "Classification loss = 32.8881\n",
      "Comparison loss = 2.3481\n",
      "Epoch no 9 : \n",
      "Classification loss = 32.0982\n",
      "Comparison loss = 2.3483\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.2945\n",
      "Comparison loss = 1.6336\n",
      "Epoch no 11 : \n",
      "Classification loss = 31.0145\n",
      "Comparison loss = 1.3378\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.4813\n",
      "Comparison loss = 1.0363\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.2633\n",
      "Comparison loss = 0.6562\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.1197\n",
      "Comparison loss = 0.7007\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.9262\n",
      "Comparison loss = 0.3984\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.7656\n",
      "Comparison loss = 0.3021\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.6506\n",
      "Comparison loss = 0.2186\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.6007\n",
      "Comparison loss = 0.2220\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.5515\n",
      "Comparison loss = 0.1679\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.5158\n",
      "Comparison loss = 0.1199\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4954\n",
      "Comparison loss = 0.0755\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4718\n",
      "Comparison loss = 0.0417\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4601\n",
      "Comparison loss = 0.0413\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4484\n",
      "Comparison loss = 0.0420\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.4432\n",
      "Comparison loss = 0.0458\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.950% \n",
      "Comparison = 0.300%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.950% \n",
      "Comparison = 3.200%\u001b[0m\n",
      "RUN NO 8\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.5316\n",
      "Comparison loss = 6.1562\n",
      "Epoch no 2 : \n",
      "Classification loss = 43.4327\n",
      "Comparison loss = 4.8749\n",
      "Epoch no 3 : \n",
      "Classification loss = 40.5170\n",
      "Comparison loss = 3.8646\n",
      "Epoch no 4 : \n",
      "Classification loss = 37.7529\n",
      "Comparison loss = 2.9113\n",
      "Epoch no 5 : \n",
      "Classification loss = 35.4465\n",
      "Comparison loss = 2.3544\n",
      "Epoch no 6 : \n",
      "Classification loss = 33.6547\n",
      "Comparison loss = 2.2592\n",
      "Epoch no 7 : \n",
      "Classification loss = 32.8709\n",
      "Comparison loss = 1.9840\n",
      "Epoch no 8 : \n",
      "Classification loss = 32.2469\n",
      "Comparison loss = 1.4071\n",
      "Epoch no 9 : \n",
      "Classification loss = 31.5087\n",
      "Comparison loss = 1.0258\n",
      "Epoch no 10 : \n",
      "Classification loss = 30.6590\n",
      "Comparison loss = 0.7564\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.3008\n",
      "Comparison loss = 0.9334\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.4558\n",
      "Comparison loss = 0.6528\n",
      "Epoch no 13 : \n",
      "Classification loss = 29.9538\n",
      "Comparison loss = 0.5453\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.8484\n",
      "Comparison loss = 0.4987\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.7486\n",
      "Comparison loss = 0.3889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch no 16 : \n",
      "Classification loss = 29.7179\n",
      "Comparison loss = 0.2656\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.6050\n",
      "Comparison loss = 0.2685\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.5706\n",
      "Comparison loss = 0.2247\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.5354\n",
      "Comparison loss = 0.1929\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.4766\n",
      "Comparison loss = 0.1323\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4255\n",
      "Comparison loss = 0.1002\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4092\n",
      "Comparison loss = 0.0908\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.3949\n",
      "Comparison loss = 0.0867\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.3811\n",
      "Comparison loss = 0.0643\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3759\n",
      "Comparison loss = 0.0421\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.650% \n",
      "Comparison = 0.200%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 3.950% \n",
      "Comparison = 2.500%\u001b[0m\n",
      "RUN NO 9\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.2724\n",
      "Comparison loss = 5.8371\n",
      "Epoch no 2 : \n",
      "Classification loss = 42.4637\n",
      "Comparison loss = 4.3692\n",
      "Epoch no 3 : \n",
      "Classification loss = 38.9658\n",
      "Comparison loss = 3.3935\n",
      "Epoch no 4 : \n",
      "Classification loss = 36.5273\n",
      "Comparison loss = 2.4527\n",
      "Epoch no 5 : \n",
      "Classification loss = 35.2091\n",
      "Comparison loss = 2.4005\n",
      "Epoch no 6 : \n",
      "Classification loss = 34.6403\n",
      "Comparison loss = 2.3472\n",
      "Epoch no 7 : \n",
      "Classification loss = 34.1678\n",
      "Comparison loss = 2.0719\n",
      "Epoch no 8 : \n",
      "Classification loss = 33.5196\n",
      "Comparison loss = 1.6316\n",
      "Epoch no 9 : \n",
      "Classification loss = 32.9253\n",
      "Comparison loss = 1.2650\n",
      "Epoch no 10 : \n",
      "Classification loss = 32.1116\n",
      "Comparison loss = 1.0247\n",
      "Epoch no 11 : \n",
      "Classification loss = 31.0714\n",
      "Comparison loss = 0.8267\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.4357\n",
      "Comparison loss = 0.6525\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.1338\n",
      "Comparison loss = 0.5919\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.0778\n",
      "Comparison loss = 0.6768\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.9120\n",
      "Comparison loss = 0.5137\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.7263\n",
      "Comparison loss = 0.3425\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.6430\n",
      "Comparison loss = 0.2692\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.5824\n",
      "Comparison loss = 0.2433\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.5258\n",
      "Comparison loss = 0.1568\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.4765\n",
      "Comparison loss = 0.1407\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4514\n",
      "Comparison loss = 0.1265\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4219\n",
      "Comparison loss = 0.0734\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4089\n",
      "Comparison loss = 0.0412\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4018\n",
      "Comparison loss = 0.0405\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3962\n",
      "Comparison loss = 0.0401\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.750% \n",
      "Comparison = 0.100%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.650% \n",
      "Comparison = 3.000%\u001b[0m\n",
      "RUN NO 10\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.4488\n",
      "Comparison loss = 5.9994\n",
      "Epoch no 2 : \n",
      "Classification loss = 42.7531\n",
      "Comparison loss = 4.8934\n",
      "Epoch no 3 : \n",
      "Classification loss = 40.1382\n",
      "Comparison loss = 4.2809\n",
      "Epoch no 4 : \n",
      "Classification loss = 37.1782\n",
      "Comparison loss = 2.6953\n",
      "Epoch no 5 : \n",
      "Classification loss = 35.4594\n",
      "Comparison loss = 2.5665\n",
      "Epoch no 6 : \n",
      "Classification loss = 34.3233\n",
      "Comparison loss = 2.1893\n",
      "Epoch no 7 : \n",
      "Classification loss = 33.1006\n",
      "Comparison loss = 1.5678\n",
      "Epoch no 8 : \n",
      "Classification loss = 32.6222\n",
      "Comparison loss = 1.9298\n",
      "Epoch no 9 : \n",
      "Classification loss = 32.2541\n",
      "Comparison loss = 1.4061\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.6579\n",
      "Comparison loss = 1.1816\n",
      "Epoch no 11 : \n",
      "Classification loss = 31.1213\n",
      "Comparison loss = 1.1204\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.9216\n",
      "Comparison loss = 1.0297\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.3812\n",
      "Comparison loss = 0.6748\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.1219\n",
      "Comparison loss = 0.5969\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.9694\n",
      "Comparison loss = 0.5533\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.8731\n",
      "Comparison loss = 0.5921\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.6763\n",
      "Comparison loss = 0.2106\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.6154\n",
      "Comparison loss = 0.2307\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.5770\n",
      "Comparison loss = 0.2293\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.5009\n",
      "Comparison loss = 0.0983\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4662\n",
      "Comparison loss = 0.0814\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4296\n",
      "Comparison loss = 0.0812\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4186\n",
      "Comparison loss = 0.0553\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4127\n",
      "Comparison loss = 0.0559\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.4122\n",
      "Comparison loss = 0.0465\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.900% \n",
      "Comparison = 0.100%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.850% \n",
      "Comparison = 3.600%\u001b[0m\n",
      "Final error for train batch : 0.19±0.1370\n",
      "Final error for test batch : 3.15±0.3719\n",
      "RUN NO 1\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.3001\n",
      "Comparison loss = 6.8792\n",
      "Epoch no 2 : \n",
      "Classification loss = 42.3998\n",
      "Comparison loss = 6.9169\n",
      "Epoch no 3 : \n",
      "Classification loss = 39.4715\n",
      "Comparison loss = 6.9266\n",
      "Epoch no 4 : \n",
      "Classification loss = 36.8308\n",
      "Comparison loss = 6.9088\n",
      "Epoch no 5 : \n",
      "Classification loss = 34.8965\n",
      "Comparison loss = 6.8743\n",
      "Epoch no 6 : \n",
      "Classification loss = 33.3768\n",
      "Comparison loss = 6.8867\n",
      "Epoch no 7 : \n",
      "Classification loss = 32.5001\n",
      "Comparison loss = 6.8893\n",
      "Epoch no 8 : \n",
      "Classification loss = 31.9347\n",
      "Comparison loss = 6.8947\n",
      "Epoch no 9 : \n",
      "Classification loss = 30.8623\n",
      "Comparison loss = 6.8803\n",
      "Epoch no 10 : \n",
      "Classification loss = 30.4868\n",
      "Comparison loss = 6.8783\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.2776\n",
      "Comparison loss = 6.8828\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.0311\n",
      "Comparison loss = 6.8867\n",
      "Epoch no 13 : \n",
      "Classification loss = 29.8560\n",
      "Comparison loss = 6.8829\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.6976\n",
      "Comparison loss = 6.8790\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.6357\n",
      "Comparison loss = 6.8814\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.5019\n",
      "Comparison loss = 6.8842\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.4574\n",
      "Comparison loss = 6.8827\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.3872\n",
      "Comparison loss = 6.8801\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.3589\n",
      "Comparison loss = 6.8814\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.3457\n",
      "Comparison loss = 6.8833\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.3370\n",
      "Comparison loss = 6.8822\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.3318\n",
      "Comparison loss = 6.8806\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.3271\n",
      "Comparison loss = 6.8818\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.3149\n",
      "Comparison loss = 6.8830\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3032\n",
      "Comparison loss = 6.8817\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.300% \n",
      "Comparison = 44.900%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 3.950% \n",
      "Comparison = 47.400%\u001b[0m\n",
      "RUN NO 2\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.5003\n",
      "Comparison loss = 6.9013\n",
      "Epoch no 2 : \n",
      "Classification loss = 43.3404\n",
      "Comparison loss = 6.8752\n",
      "Epoch no 3 : \n",
      "Classification loss = 41.3200\n",
      "Comparison loss = 6.8854\n",
      "Epoch no 4 : \n",
      "Classification loss = 38.4844\n",
      "Comparison loss = 6.8969\n",
      "Epoch no 5 : \n",
      "Classification loss = 36.2666\n",
      "Comparison loss = 6.8805\n",
      "Epoch no 6 : \n",
      "Classification loss = 34.3531\n",
      "Comparison loss = 6.8789\n",
      "Epoch no 7 : \n",
      "Classification loss = 32.9356\n",
      "Comparison loss = 6.8868\n",
      "Epoch no 8 : \n",
      "Classification loss = 32.4121\n",
      "Comparison loss = 6.8910\n",
      "Epoch no 9 : \n",
      "Classification loss = 32.0481\n",
      "Comparison loss = 6.8779\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.3943\n",
      "Comparison loss = 6.8804\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.7988\n",
      "Comparison loss = 6.8872\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.4777\n",
      "Comparison loss = 6.8859\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.2540\n",
      "Comparison loss = 6.8778\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.9650\n",
      "Comparison loss = 6.8819\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.8704\n",
      "Comparison loss = 6.8871\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.7476\n",
      "Comparison loss = 6.8818\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.6264\n",
      "Comparison loss = 6.8789\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.5707\n",
      "Comparison loss = 6.8837\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.5039\n",
      "Comparison loss = 6.8855\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.4608\n",
      "Comparison loss = 6.8792\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4294\n",
      "Comparison loss = 6.8804\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4166\n",
      "Comparison loss = 6.8847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch no 23 : \n",
      "Classification loss = 29.4069\n",
      "Comparison loss = 6.8808\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.3995\n",
      "Comparison loss = 6.8759\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3938\n",
      "Comparison loss = 6.8756\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.750% \n",
      "Comparison = 44.900%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.350% \n",
      "Comparison = 47.400%\u001b[0m\n",
      "RUN NO 3\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.3608\n",
      "Comparison loss = 6.8817\n",
      "Epoch no 2 : \n",
      "Classification loss = 42.6063\n",
      "Comparison loss = 6.8787\n",
      "Epoch no 3 : \n",
      "Classification loss = 39.7328\n",
      "Comparison loss = 6.8859\n",
      "Epoch no 4 : \n",
      "Classification loss = 37.6226\n",
      "Comparison loss = 6.8799\n",
      "Epoch no 5 : \n",
      "Classification loss = 35.6984\n",
      "Comparison loss = 6.8556\n",
      "Epoch no 6 : \n",
      "Classification loss = 34.0990\n",
      "Comparison loss = 6.8508\n",
      "Epoch no 7 : \n",
      "Classification loss = 33.1176\n",
      "Comparison loss = 6.8277\n",
      "Epoch no 8 : \n",
      "Classification loss = 32.5597\n",
      "Comparison loss = 6.7672\n",
      "Epoch no 9 : \n",
      "Classification loss = 31.9979\n",
      "Comparison loss = 6.7331\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.4167\n",
      "Comparison loss = 6.5164\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.7072\n",
      "Comparison loss = 6.2827\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.4942\n",
      "Comparison loss = 6.2516\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.1247\n",
      "Comparison loss = 8.3082\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.8816\n",
      "Comparison loss = 6.4295\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.7710\n",
      "Comparison loss = 8.2907\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.6240\n",
      "Comparison loss = 6.7298\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.5593\n",
      "Comparison loss = 6.9537\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.4752\n",
      "Comparison loss = 6.7620\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.4417\n",
      "Comparison loss = 6.2930\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.4221\n",
      "Comparison loss = 6.4388\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4102\n",
      "Comparison loss = 6.2272\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.3976\n",
      "Comparison loss = 6.2456\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.3875\n",
      "Comparison loss = 6.0189\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.3779\n",
      "Comparison loss = 5.8747\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3657\n",
      "Comparison loss = 6.0456\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.600% \n",
      "Comparison = 6.900%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 3.950% \n",
      "Comparison = 9.500%\u001b[0m\n",
      "RUN NO 4\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.4376\n",
      "Comparison loss = 6.9724\n",
      "Epoch no 2 : \n",
      "Classification loss = 42.7763\n",
      "Comparison loss = 6.7555\n",
      "Epoch no 3 : \n",
      "Classification loss = 39.5636\n",
      "Comparison loss = 6.6178\n",
      "Epoch no 4 : \n",
      "Classification loss = 36.9197\n",
      "Comparison loss = 6.1687\n",
      "Epoch no 5 : \n",
      "Classification loss = 35.2103\n",
      "Comparison loss = 6.5837\n",
      "Epoch no 6 : \n",
      "Classification loss = 34.4359\n",
      "Comparison loss = 6.2715\n",
      "Epoch no 7 : \n",
      "Classification loss = 33.5832\n",
      "Comparison loss = 6.1094\n",
      "Epoch no 8 : \n",
      "Classification loss = 32.8951\n",
      "Comparison loss = 6.7600\n",
      "Epoch no 9 : \n",
      "Classification loss = 32.5778\n",
      "Comparison loss = 6.0002\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.8055\n",
      "Comparison loss = 7.0737\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.9586\n",
      "Comparison loss = 5.8388\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.4220\n",
      "Comparison loss = 6.2626\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.2749\n",
      "Comparison loss = 6.0566\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.9979\n",
      "Comparison loss = 5.5218\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.8326\n",
      "Comparison loss = 6.4887\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.7667\n",
      "Comparison loss = 5.6857\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.6341\n",
      "Comparison loss = 6.2786\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.5774\n",
      "Comparison loss = 6.3000\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.5274\n",
      "Comparison loss = 5.5666\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.4818\n",
      "Comparison loss = 7.1163\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4336\n",
      "Comparison loss = 5.3363\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4030\n",
      "Comparison loss = 6.7726\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.3878\n",
      "Comparison loss = 5.5503\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.3773\n",
      "Comparison loss = 6.4372\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3675\n",
      "Comparison loss = 5.4485\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.600% \n",
      "Comparison = 39.300%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 3.750% \n",
      "Comparison = 38.200%\u001b[0m\n",
      "RUN NO 5\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.4914\n",
      "Comparison loss = 7.5172\n",
      "Epoch no 2 : \n",
      "Classification loss = 43.0030\n",
      "Comparison loss = 7.0666\n",
      "Epoch no 3 : \n",
      "Classification loss = 40.7179\n",
      "Comparison loss = 6.5397\n",
      "Epoch no 4 : \n",
      "Classification loss = 38.7635\n",
      "Comparison loss = 6.2201\n",
      "Epoch no 5 : \n",
      "Classification loss = 36.3099\n",
      "Comparison loss = 6.4280\n",
      "Epoch no 6 : \n",
      "Classification loss = 34.7418\n",
      "Comparison loss = 5.8172\n",
      "Epoch no 7 : \n",
      "Classification loss = 33.7165\n",
      "Comparison loss = 6.0531\n",
      "Epoch no 8 : \n",
      "Classification loss = 32.5208\n",
      "Comparison loss = 5.5715\n",
      "Epoch no 9 : \n",
      "Classification loss = 31.6096\n",
      "Comparison loss = 5.6465\n",
      "Epoch no 10 : \n",
      "Classification loss = 30.7776\n",
      "Comparison loss = 5.9244\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.7419\n",
      "Comparison loss = 5.4545\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.3625\n",
      "Comparison loss = 5.4738\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.0918\n",
      "Comparison loss = 6.7535\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.0035\n",
      "Comparison loss = 5.4601\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.8437\n",
      "Comparison loss = 6.8502\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.7397\n",
      "Comparison loss = 5.2417\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.6436\n",
      "Comparison loss = 5.5462\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.5616\n",
      "Comparison loss = 6.1672\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.4970\n",
      "Comparison loss = 4.8972\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.4405\n",
      "Comparison loss = 6.2861\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4214\n",
      "Comparison loss = 5.1073\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.3927\n",
      "Comparison loss = 6.0827\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.3792\n",
      "Comparison loss = 5.0738\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.3652\n",
      "Comparison loss = 4.9426\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3575\n",
      "Comparison loss = 6.3511\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.550% \n",
      "Comparison = 33.800%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.350% \n",
      "Comparison = 36.200%\u001b[0m\n",
      "RUN NO 6\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.4220\n",
      "Comparison loss = 7.4987\n",
      "Epoch no 2 : \n",
      "Classification loss = 43.2224\n",
      "Comparison loss = 6.7146\n",
      "Epoch no 3 : \n",
      "Classification loss = 41.3436\n",
      "Comparison loss = 8.2647\n",
      "Epoch no 4 : \n",
      "Classification loss = 38.9014\n",
      "Comparison loss = 6.6465\n",
      "Epoch no 5 : \n",
      "Classification loss = 36.9432\n",
      "Comparison loss = 6.0613\n",
      "Epoch no 6 : \n",
      "Classification loss = 35.5881\n",
      "Comparison loss = 5.8995\n",
      "Epoch no 7 : \n",
      "Classification loss = 34.4887\n",
      "Comparison loss = 6.2122\n",
      "Epoch no 8 : \n",
      "Classification loss = 33.7861\n",
      "Comparison loss = 5.6118\n",
      "Epoch no 9 : \n",
      "Classification loss = 33.8895\n",
      "Comparison loss = 5.6476\n",
      "Epoch no 10 : \n",
      "Classification loss = 32.1105\n",
      "Comparison loss = 5.1875\n",
      "Epoch no 11 : \n",
      "Classification loss = 31.8583\n",
      "Comparison loss = 5.4702\n",
      "Epoch no 12 : \n",
      "Classification loss = 31.4008\n",
      "Comparison loss = 5.1397\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.8978\n",
      "Comparison loss = 4.8636\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.5911\n",
      "Comparison loss = 4.6681\n",
      "Epoch no 15 : \n",
      "Classification loss = 30.3900\n",
      "Comparison loss = 6.6096\n",
      "Epoch no 16 : \n",
      "Classification loss = 30.1517\n",
      "Comparison loss = 6.8459\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.9800\n",
      "Comparison loss = 5.9487\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.8441\n",
      "Comparison loss = 5.6360\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.8008\n",
      "Comparison loss = 4.7644\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.7330\n",
      "Comparison loss = 6.3315\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.6597\n",
      "Comparison loss = 4.4983\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.5976\n",
      "Comparison loss = 5.7787\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.5742\n",
      "Comparison loss = 5.0462\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.5526\n",
      "Comparison loss = 5.3352\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.5548\n",
      "Comparison loss = 4.7078\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 1.500% \n",
      "Comparison = 29.400%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.650% \n",
      "Comparison = 29.200%\u001b[0m\n",
      "RUN NO 7\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.3750\n",
      "Comparison loss = 8.1106\n",
      "Epoch no 2 : \n",
      "Classification loss = 42.7498\n",
      "Comparison loss = 8.3545\n",
      "Epoch no 3 : \n",
      "Classification loss = 39.9916\n",
      "Comparison loss = 6.0116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch no 4 : \n",
      "Classification loss = 36.9779\n",
      "Comparison loss = 6.7151\n",
      "Epoch no 5 : \n",
      "Classification loss = 35.0835\n",
      "Comparison loss = 6.0475\n",
      "Epoch no 6 : \n",
      "Classification loss = 34.2991\n",
      "Comparison loss = 6.3409\n",
      "Epoch no 7 : \n",
      "Classification loss = 33.3382\n",
      "Comparison loss = 5.2492\n",
      "Epoch no 8 : \n",
      "Classification loss = 32.3264\n",
      "Comparison loss = 5.5898\n",
      "Epoch no 9 : \n",
      "Classification loss = 31.5875\n",
      "Comparison loss = 5.3144\n",
      "Epoch no 10 : \n",
      "Classification loss = 30.7147\n",
      "Comparison loss = 4.9185\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.2988\n",
      "Comparison loss = 4.9749\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.0201\n",
      "Comparison loss = 4.7094\n",
      "Epoch no 13 : \n",
      "Classification loss = 29.9934\n",
      "Comparison loss = 4.3240\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.7179\n",
      "Comparison loss = 5.8009\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.7113\n",
      "Comparison loss = 6.0532\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.5297\n",
      "Comparison loss = 4.7137\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.4981\n",
      "Comparison loss = 6.7187\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.4289\n",
      "Comparison loss = 4.7506\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.3987\n",
      "Comparison loss = 6.6411\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.3867\n",
      "Comparison loss = 4.2396\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.3809\n",
      "Comparison loss = 5.6377\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.3773\n",
      "Comparison loss = 4.7090\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.3743\n",
      "Comparison loss = 5.0864\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.3713\n",
      "Comparison loss = 4.3461\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3641\n",
      "Comparison loss = 4.1320\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.650% \n",
      "Comparison = 23.000%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 3.900% \n",
      "Comparison = 23.700%\u001b[0m\n",
      "RUN NO 8\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.3774\n",
      "Comparison loss = 6.9763\n",
      "Epoch no 2 : \n",
      "Classification loss = 42.5374\n",
      "Comparison loss = 5.9916\n",
      "Epoch no 3 : \n",
      "Classification loss = 39.8059\n",
      "Comparison loss = 5.1499\n",
      "Epoch no 4 : \n",
      "Classification loss = 37.4205\n",
      "Comparison loss = 5.0612\n",
      "Epoch no 5 : \n",
      "Classification loss = 36.1496\n",
      "Comparison loss = 6.1797\n",
      "Epoch no 6 : \n",
      "Classification loss = 34.8570\n",
      "Comparison loss = 4.7554\n",
      "Epoch no 7 : \n",
      "Classification loss = 33.5360\n",
      "Comparison loss = 4.7817\n",
      "Epoch no 8 : \n",
      "Classification loss = 32.1381\n",
      "Comparison loss = 6.8516\n",
      "Epoch no 9 : \n",
      "Classification loss = 31.3437\n",
      "Comparison loss = 4.3606\n",
      "Epoch no 10 : \n",
      "Classification loss = 30.7670\n",
      "Comparison loss = 6.3365\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.4612\n",
      "Comparison loss = 4.8790\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.2764\n",
      "Comparison loss = 5.8453\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.0728\n",
      "Comparison loss = 4.1558\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.8758\n",
      "Comparison loss = 4.8054\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.7286\n",
      "Comparison loss = 4.7476\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.6576\n",
      "Comparison loss = 4.1664\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.5650\n",
      "Comparison loss = 4.6115\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.5129\n",
      "Comparison loss = 3.8679\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.4623\n",
      "Comparison loss = 4.5462\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.4458\n",
      "Comparison loss = 4.5100\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4276\n",
      "Comparison loss = 3.7527\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4213\n",
      "Comparison loss = 5.6252\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4082\n",
      "Comparison loss = 4.4089\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4009\n",
      "Comparison loss = 4.0659\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3883\n",
      "Comparison loss = 6.9850\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.750% \n",
      "Comparison = 32.200%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.750% \n",
      "Comparison = 33.400%\u001b[0m\n",
      "RUN NO 9\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.5539\n",
      "Comparison loss = 8.3907\n",
      "Epoch no 2 : \n",
      "Classification loss = 43.4174\n",
      "Comparison loss = 8.1720\n",
      "Epoch no 3 : \n",
      "Classification loss = 40.7285\n",
      "Comparison loss = 7.4798\n",
      "Epoch no 4 : \n",
      "Classification loss = 38.6231\n",
      "Comparison loss = 6.7982\n",
      "Epoch no 5 : \n",
      "Classification loss = 36.3412\n",
      "Comparison loss = 5.1806\n",
      "Epoch no 6 : \n",
      "Classification loss = 34.3257\n",
      "Comparison loss = 5.4037\n",
      "Epoch no 7 : \n",
      "Classification loss = 32.4930\n",
      "Comparison loss = 4.8476\n",
      "Epoch no 8 : \n",
      "Classification loss = 31.4570\n",
      "Comparison loss = 4.7886\n",
      "Epoch no 9 : \n",
      "Classification loss = 30.9348\n",
      "Comparison loss = 4.2107\n",
      "Epoch no 10 : \n",
      "Classification loss = 30.7561\n",
      "Comparison loss = 4.1440\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.4311\n",
      "Comparison loss = 3.7184\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.4385\n",
      "Comparison loss = 3.4767\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.0977\n",
      "Comparison loss = 3.6166\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.9464\n",
      "Comparison loss = 4.2226\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.8441\n",
      "Comparison loss = 3.4058\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.7773\n",
      "Comparison loss = 3.8062\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.6738\n",
      "Comparison loss = 8.4369\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.5923\n",
      "Comparison loss = 4.5003\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.5347\n",
      "Comparison loss = 6.2712\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.4980\n",
      "Comparison loss = 7.1987\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4826\n",
      "Comparison loss = 5.7645\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4582\n",
      "Comparison loss = 4.5122\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4443\n",
      "Comparison loss = 4.5407\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4385\n",
      "Comparison loss = 4.8484\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.4330\n",
      "Comparison loss = 4.4261\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.950% \n",
      "Comparison = 5.800%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.600% \n",
      "Comparison = 8.300%\u001b[0m\n",
      "RUN NO 10\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.0636\n",
      "Comparison loss = 6.4473\n",
      "Epoch no 2 : \n",
      "Classification loss = 42.0010\n",
      "Comparison loss = 5.7947\n",
      "Epoch no 3 : \n",
      "Classification loss = 39.5343\n",
      "Comparison loss = 6.7226\n",
      "Epoch no 4 : \n",
      "Classification loss = 36.6764\n",
      "Comparison loss = 4.7298\n",
      "Epoch no 5 : \n",
      "Classification loss = 34.3045\n",
      "Comparison loss = 5.4140\n",
      "Epoch no 6 : \n",
      "Classification loss = 33.1453\n",
      "Comparison loss = 4.3628\n",
      "Epoch no 7 : \n",
      "Classification loss = 32.5304\n",
      "Comparison loss = 5.1312\n",
      "Epoch no 8 : \n",
      "Classification loss = 32.0757\n",
      "Comparison loss = 3.7926\n",
      "Epoch no 9 : \n",
      "Classification loss = 31.3543\n",
      "Comparison loss = 4.2578\n",
      "Epoch no 10 : \n",
      "Classification loss = 30.6463\n",
      "Comparison loss = 4.9331\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.2276\n",
      "Comparison loss = 3.5064\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.2232\n",
      "Comparison loss = 5.1687\n",
      "Epoch no 13 : \n",
      "Classification loss = 29.9722\n",
      "Comparison loss = 4.9861\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.8121\n",
      "Comparison loss = 4.2990\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.7237\n",
      "Comparison loss = 4.9745\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.5734\n",
      "Comparison loss = 3.6998\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.5218\n",
      "Comparison loss = 5.3100\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.4800\n",
      "Comparison loss = 3.3381\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.4119\n",
      "Comparison loss = 4.4809\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.3903\n",
      "Comparison loss = 4.4224\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.3626\n",
      "Comparison loss = 3.8467\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.3532\n",
      "Comparison loss = 4.3127\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.3473\n",
      "Comparison loss = 3.3597\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.3430\n",
      "Comparison loss = 4.6918\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3362\n",
      "Comparison loss = 3.3631\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.500% \n",
      "Comparison = 27.700%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 3.800% \n",
      "Comparison = 27.600%\u001b[0m\n",
      "Final error for train batch : 28.79±13.7802\n",
      "Final error for test batch : 30.09±13.5807\n"
     ]
    }
   ],
   "source": [
    "train_class = t.empty(NB_RUN)\n",
    "train_comp = t.empty(NB_RUN)\n",
    "test_class = t.empty(NB_RUN)\n",
    "test_comp = t.empty(NB_RUN)\n",
    "\n",
    "nb_rows = all_models.shape[0]\n",
    "nb_cols = all_models.shape[1]\n",
    "\n",
    "train_error_storage = np.zeros((nb_rows, nb_cols))\n",
    "test_error_storage = np.zeros((nb_rows, nb_cols))\n",
    "\n",
    "# Can add a for loop for the learning rates (only 1e-3 and 1e-2)\n",
    "for k in range(nb_rows):\n",
    "    for l in range(nb_cols):\n",
    "        for i in range(NB_RUN):\n",
    "            model_cl = Classification() #same model here\n",
    "            model_co = all_models[k, l]\n",
    "            print(\"RUN NO {}\".format(i+1))\n",
    "            training(model_cl, model_co, 1e-3) # lr fixed for the moment\n",
    "\n",
    "            e1, e2 = test_models(model_cl, model_co, train_input, train_classes, train_target)\n",
    "            e3, e4 = test_models(model_cl, model_co, test_input, test_classes, test_target, False)\n",
    "            train_class[i] = (e1)\n",
    "            train_comp[i] = (e2)\n",
    "            test_class[i] = (e3)\n",
    "            test_comp[i] = (e4)\n",
    "\n",
    "        print(\"Final error for train batch : {:0.2f}\\u00B1{:0.4f}\".format(t.mean(train_comp)*100,t.std(train_comp)*100))\n",
    "        print(\"Final error for test batch : {:0.2f}\\u00B1{:0.4f}\".format(t.mean(test_comp)*100,t.std(test_comp)*100))\n",
    "        \n",
    "        train_error = t.mean(train_comp) * 100\n",
    "        test_error = t.mean(test_comp) * 100\n",
    "\n",
    "        train_error_storage[k, l] = train_error\n",
    "        test_error_storage[k, l] = test_error\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Grid: nb of conv layers vs activation fct [comparison model]\n",
    "ax = sns.heatmap(test_error_storage[:,0:2], cmap = 'Blues',\n",
    "                 xticklabels = ['ReLU', 'Leaky ReLU'], yticklabels = ['2', '3', '4', '5', '6'])\n",
    "ax.set_xlabel('Activation function')\n",
    "ax.set_ylabel('Number of convolutional layers')\n",
    "ax.set_title('Test error [%]')\n",
    "#plt.savefig('layers_vs_actfct_test.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Grid: nb of conv layers vs activation fct [comparison model]\n",
    "ax = sns.heatmap(train_error_storage[:, 0:2], cmap = 'Blues',\n",
    "                 xticklabels = ['ReLU', 'Leaky ReLU'], yticklabels = ['2', '3', '4', '5', '6'])\n",
    "ax.set_xlabel('Activation function')\n",
    "ax.set_ylabel('Number of convolutional layers')\n",
    "ax.set_title('Train error [%]')\n",
    "#plt.savefig('layers_vs_actfct_train.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplots(figsize=(10,4))\n",
    "plt.subplot(1,2,1)\n",
    "ax = sns.heatmap(train_error_storage[:, 0:2], cmap = 'Blues',\n",
    "                 xticklabels = ['ReLU', 'Leaky ReLU'], yticklabels = ['2', '3', '4', '5', '6'])\n",
    "ax.set_xlabel('Activation function')\n",
    "ax.set_ylabel('Number of convolutional layers')\n",
    "ax.set_title('Train error [%]')\n",
    "plt.subplot(1,2,2)\n",
    "ax = sns.heatmap(test_error_storage[:,0:2], cmap = 'Blues',\n",
    "                 xticklabels = ['ReLU', 'Leaky ReLU'], yticklabels = ['2', '3', '4', '5', '6'])\n",
    "ax.set_xlabel('Activation function')\n",
    "ax.set_ylabel('Number of convolutional layers')\n",
    "ax.set_title('Test error [%]')\n",
    "plt.savefig('layers_vs_actfct_train_and_test.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save variables\n",
    "with open('errors_part_2.pkl', 'wb') as f:  \n",
    "    pickle.dump([train_error_storage, test_error_storage], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.23000003,  0.38      ,  2.0400002 ],\n",
       "       [ 0.26000002,  0.2       , 26.23999977],\n",
       "       [ 0.21000001,  0.19000001, 30.57999992],\n",
       "       [ 0.15000001,  0.30000001, 30.81999969],\n",
       "       [ 0.42999998,  0.19000001, 28.79000092]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_error_storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.50999975,  3.3099997 ,  5.1500001 ],\n",
       "       [ 3.57999992,  3.24000001, 27.36999702],\n",
       "       [ 3.23000002,  3.25999999, 31.62999725],\n",
       "       [ 3.0999999 ,  3.25      , 32.17000198],\n",
       "       [ 3.4000001 ,  3.1500001 , 30.09000206]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_error_storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Second run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN NO 1\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.0491\n",
      "Comparison loss = 6.9237\n",
      "Epoch no 2 : \n",
      "Classification loss = 42.1864\n",
      "Comparison loss = 6.9335\n",
      "Epoch no 3 : \n",
      "Classification loss = 39.5160\n",
      "Comparison loss = 6.8968\n",
      "Epoch no 4 : \n",
      "Classification loss = 36.8699\n",
      "Comparison loss = 6.8937\n",
      "Epoch no 5 : \n",
      "Classification loss = 35.4184\n",
      "Comparison loss = 6.8736\n",
      "Epoch no 6 : \n",
      "Classification loss = 34.1828\n",
      "Comparison loss = 6.6857\n",
      "Epoch no 7 : \n",
      "Classification loss = 33.0198\n",
      "Comparison loss = 6.3614\n",
      "Epoch no 8 : \n",
      "Classification loss = 32.8021\n",
      "Comparison loss = 5.9372\n",
      "Epoch no 9 : \n",
      "Classification loss = 32.4858\n",
      "Comparison loss = 6.7660\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.4204\n",
      "Comparison loss = 5.7988\n",
      "Epoch no 11 : \n",
      "Classification loss = 31.1892\n",
      "Comparison loss = 5.1220\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.7366\n",
      "Comparison loss = 5.1096\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.3785\n",
      "Comparison loss = 4.3906\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.1454\n",
      "Comparison loss = 3.3858\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.9857\n",
      "Comparison loss = 2.1447\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.8175\n",
      "Comparison loss = 1.3499\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.7349\n",
      "Comparison loss = 1.6769\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.6556\n",
      "Comparison loss = 1.0279\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.6109\n",
      "Comparison loss = 0.9278\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.6537\n",
      "Comparison loss = 1.2699\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.5936\n",
      "Comparison loss = 0.5856\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.5423\n",
      "Comparison loss = 0.3091\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4772\n",
      "Comparison loss = 0.2423\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4363\n",
      "Comparison loss = 0.1673\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.4186\n",
      "Comparison loss = 0.1133\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.750% \n",
      "Comparison = 0.200%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.800% \n",
      "Comparison = 3.000%\u001b[0m\n",
      "RUN NO 2\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.2240\n",
      "Comparison loss = 6.9081\n",
      "Epoch no 2 : \n",
      "Classification loss = 42.4332\n",
      "Comparison loss = 6.9333\n",
      "Epoch no 3 : \n",
      "Classification loss = 39.1865\n",
      "Comparison loss = 6.8749\n",
      "Epoch no 4 : \n",
      "Classification loss = 35.9373\n",
      "Comparison loss = 6.8709\n",
      "Epoch no 5 : \n",
      "Classification loss = 34.2991\n",
      "Comparison loss = 6.5707\n",
      "Epoch no 6 : \n",
      "Classification loss = 33.8795\n",
      "Comparison loss = 5.9022\n",
      "Epoch no 7 : \n",
      "Classification loss = 33.0447\n",
      "Comparison loss = 6.0724\n",
      "Epoch no 8 : \n",
      "Classification loss = 31.9688\n",
      "Comparison loss = 5.5295\n",
      "Epoch no 9 : \n",
      "Classification loss = 31.3876\n",
      "Comparison loss = 6.6821\n",
      "Epoch no 10 : \n",
      "Classification loss = 30.5536\n",
      "Comparison loss = 6.7263\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.3077\n",
      "Comparison loss = 6.1616\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.0071\n",
      "Comparison loss = 5.8136\n",
      "Epoch no 13 : \n",
      "Classification loss = 29.8460\n",
      "Comparison loss = 3.9397\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.7488\n",
      "Comparison loss = 2.7186\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.6541\n",
      "Comparison loss = 1.5184\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.7562\n",
      "Comparison loss = 3.1135\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.7292\n",
      "Comparison loss = 1.9115\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.8744\n",
      "Comparison loss = 3.4053\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.7705\n",
      "Comparison loss = 2.5588\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.6281\n",
      "Comparison loss = 1.6803\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.5321\n",
      "Comparison loss = 0.7603\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4968\n",
      "Comparison loss = 0.2948\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4490\n",
      "Comparison loss = 0.3229\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4275\n",
      "Comparison loss = 0.3079\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.4172\n",
      "Comparison loss = 0.1315\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.900% \n",
      "Comparison = 0.200%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.600% \n",
      "Comparison = 3.100%\u001b[0m\n",
      "RUN NO 3\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.4439\n",
      "Comparison loss = 6.9042\n",
      "Epoch no 2 : \n",
      "Classification loss = 43.2938\n",
      "Comparison loss = 6.9343\n",
      "Epoch no 3 : \n",
      "Classification loss = 40.4728\n",
      "Comparison loss = 6.8777\n",
      "Epoch no 4 : \n",
      "Classification loss = 37.5124\n",
      "Comparison loss = 6.8841\n",
      "Epoch no 5 : \n",
      "Classification loss = 35.5545\n",
      "Comparison loss = 6.8587\n",
      "Epoch no 6 : \n",
      "Classification loss = 34.1233\n",
      "Comparison loss = 6.4530\n",
      "Epoch no 7 : \n",
      "Classification loss = 33.1336\n",
      "Comparison loss = 5.4555\n",
      "Epoch no 8 : \n",
      "Classification loss = 33.5095\n",
      "Comparison loss = 5.8188\n",
      "Epoch no 9 : \n",
      "Classification loss = 32.7119\n",
      "Comparison loss = 6.8909\n",
      "Epoch no 10 : \n",
      "Classification loss = 32.0203\n",
      "Comparison loss = 6.8917\n",
      "Epoch no 11 : \n",
      "Classification loss = 31.0430\n",
      "Comparison loss = 6.6938\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.4905\n",
      "Comparison loss = 6.4544\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.2411\n",
      "Comparison loss = 6.8765\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.0184\n",
      "Comparison loss = 6.5665\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.9123\n",
      "Comparison loss = 5.2644\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.7846\n",
      "Comparison loss = 3.1892\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.7507\n",
      "Comparison loss = 2.0204\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.7835\n",
      "Comparison loss = 3.6138\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.9603\n",
      "Comparison loss = 3.2534\n",
      "Epoch no 20 : \n",
      "Classification loss = 30.0989\n",
      "Comparison loss = 3.5177\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.8517\n",
      "Comparison loss = 1.7303\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.7850\n",
      "Comparison loss = 1.1064\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.6939\n",
      "Comparison loss = 1.0448\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.6191\n",
      "Comparison loss = 0.8584\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.7721\n",
      "Comparison loss = 1.3433\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 3.000% \n",
      "Comparison = 1.500%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 6.500% \n",
      "Comparison = 4.000%\u001b[0m\n",
      "RUN NO 4\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.4633\n",
      "Comparison loss = 6.9768\n",
      "Epoch no 2 : \n",
      "Classification loss = 42.9707\n",
      "Comparison loss = 6.9299\n",
      "Epoch no 3 : \n",
      "Classification loss = 39.2609\n",
      "Comparison loss = 6.8891\n",
      "Epoch no 4 : \n",
      "Classification loss = 36.6658\n",
      "Comparison loss = 6.8796\n",
      "Epoch no 5 : \n",
      "Classification loss = 35.4863\n",
      "Comparison loss = 6.8550\n",
      "Epoch no 6 : \n",
      "Classification loss = 34.9998\n",
      "Comparison loss = 6.6055\n",
      "Epoch no 7 : \n",
      "Classification loss = 34.2597\n",
      "Comparison loss = 5.8338\n",
      "Epoch no 8 : \n",
      "Classification loss = 33.2277\n",
      "Comparison loss = 5.7782\n",
      "Epoch no 9 : \n",
      "Classification loss = 31.9244\n",
      "Comparison loss = 5.7139\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.5347\n",
      "Comparison loss = 6.8522\n",
      "Epoch no 11 : \n",
      "Classification loss = 31.1700\n",
      "Comparison loss = 6.9466\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.5973\n",
      "Comparison loss = 6.9547\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.4963\n",
      "Comparison loss = 6.9169\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.1827\n",
      "Comparison loss = 6.7498\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.9987\n",
      "Comparison loss = 5.8644\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.7978\n",
      "Comparison loss = 3.4676\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.7202\n",
      "Comparison loss = 4.1184\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.7042\n",
      "Comparison loss = 3.7112\n",
      "Epoch no 19 : \n",
      "Classification loss = 30.0295\n",
      "Comparison loss = 4.1249\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.7465\n",
      "Comparison loss = 2.6277\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.6973\n",
      "Comparison loss = 1.4586\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.5709\n",
      "Comparison loss = 0.8915\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.5120\n",
      "Comparison loss = 0.4674\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.5358\n",
      "Comparison loss = 0.5479\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.5051\n",
      "Comparison loss = 0.6536\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 1.050% \n",
      "Comparison = 0.600%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.500% \n",
      "Comparison = 3.000%\u001b[0m\n",
      "RUN NO 5\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.4186\n",
      "Comparison loss = 6.9444\n",
      "Epoch no 2 : \n",
      "Classification loss = 42.8667\n",
      "Comparison loss = 6.9546\n",
      "Epoch no 3 : \n",
      "Classification loss = 40.3566\n",
      "Comparison loss = 6.8998\n",
      "Epoch no 4 : \n",
      "Classification loss = 38.4410\n",
      "Comparison loss = 6.9090\n",
      "Epoch no 5 : \n",
      "Classification loss = 36.8324\n",
      "Comparison loss = 6.8818\n",
      "Epoch no 6 : \n",
      "Classification loss = 34.7630\n",
      "Comparison loss = 6.7256\n",
      "Epoch no 7 : \n",
      "Classification loss = 33.3150\n",
      "Comparison loss = 6.0952\n",
      "Epoch no 8 : \n",
      "Classification loss = 32.2330\n",
      "Comparison loss = 6.1728\n",
      "Epoch no 9 : \n",
      "Classification loss = 31.7476\n",
      "Comparison loss = 4.6946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch no 10 : \n",
      "Classification loss = 31.3518\n",
      "Comparison loss = 4.8976\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.7940\n",
      "Comparison loss = 3.9129\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.4885\n",
      "Comparison loss = 2.8202\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.1767\n",
      "Comparison loss = 3.4247\n",
      "Epoch no 14 : \n",
      "Classification loss = 30.0942\n",
      "Comparison loss = 6.7419\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.8967\n",
      "Comparison loss = 6.1618\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.7558\n",
      "Comparison loss = 5.2960\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.6374\n",
      "Comparison loss = 3.6410\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.5868\n",
      "Comparison loss = 3.6302\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.4882\n",
      "Comparison loss = 2.6109\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.4645\n",
      "Comparison loss = 1.5019\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.4370\n",
      "Comparison loss = 0.5732\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.4171\n",
      "Comparison loss = 0.6588\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.3900\n",
      "Comparison loss = 0.2668\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.3870\n",
      "Comparison loss = 0.1637\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3864\n",
      "Comparison loss = 0.1722\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.750% \n",
      "Comparison = 0.200%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.500% \n",
      "Comparison = 3.200%\u001b[0m\n",
      "RUN NO 6\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.2917\n",
      "Comparison loss = 6.9119\n",
      "Epoch no 2 : \n",
      "Classification loss = 42.7312\n",
      "Comparison loss = 6.9164\n",
      "Epoch no 3 : \n",
      "Classification loss = 39.9319\n",
      "Comparison loss = 6.8857\n",
      "Epoch no 4 : \n",
      "Classification loss = 36.7101\n",
      "Comparison loss = 6.8918\n",
      "Epoch no 5 : \n",
      "Classification loss = 35.2116\n",
      "Comparison loss = 6.8704\n",
      "Epoch no 6 : \n",
      "Classification loss = 34.1447\n",
      "Comparison loss = 6.4985\n",
      "Epoch no 7 : \n",
      "Classification loss = 32.9512\n",
      "Comparison loss = 5.3820\n",
      "Epoch no 8 : \n",
      "Classification loss = 31.6167\n",
      "Comparison loss = 6.0237\n",
      "Epoch no 9 : \n",
      "Classification loss = 31.3132\n",
      "Comparison loss = 5.1711\n",
      "Epoch no 10 : \n",
      "Classification loss = 30.5885\n",
      "Comparison loss = 5.7743\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.3231\n",
      "Comparison loss = 3.6919\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.0989\n",
      "Comparison loss = 5.1537\n",
      "Epoch no 13 : \n",
      "Classification loss = 29.9655\n",
      "Comparison loss = 3.7573\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.9032\n",
      "Comparison loss = 5.0415\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.7303\n",
      "Comparison loss = 3.5746\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.7021\n",
      "Comparison loss = 3.5046\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.6371\n",
      "Comparison loss = 2.7454\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.6058\n",
      "Comparison loss = 1.2020\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.5744\n",
      "Comparison loss = 0.6245\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.6789\n",
      "Comparison loss = 1.0361\n",
      "Epoch no 21 : \n",
      "Classification loss = 30.0973\n",
      "Comparison loss = 1.3130\n",
      "Epoch no 22 : \n",
      "Classification loss = 30.2236\n",
      "Comparison loss = 1.2532\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.8843\n",
      "Comparison loss = 0.9671\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.8026\n",
      "Comparison loss = 0.6760\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.9063\n",
      "Comparison loss = 0.5826\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 1.750% \n",
      "Comparison = 0.700%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 6.250% \n",
      "Comparison = 4.200%\u001b[0m\n",
      "RUN NO 7\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.1685\n",
      "Comparison loss = 6.9527\n",
      "Epoch no 2 : \n",
      "Classification loss = 42.3472\n",
      "Comparison loss = 6.9694\n",
      "Epoch no 3 : \n",
      "Classification loss = 39.3457\n",
      "Comparison loss = 6.9006\n",
      "Epoch no 4 : \n",
      "Classification loss = 36.4782\n",
      "Comparison loss = 6.9105\n",
      "Epoch no 5 : \n",
      "Classification loss = 34.9559\n",
      "Comparison loss = 6.8564\n",
      "Epoch no 6 : \n",
      "Classification loss = 34.3009\n",
      "Comparison loss = 6.5133\n",
      "Epoch no 7 : \n",
      "Classification loss = 33.5548\n",
      "Comparison loss = 5.7802\n",
      "Epoch no 8 : \n",
      "Classification loss = 32.5532\n",
      "Comparison loss = 5.5880\n",
      "Epoch no 9 : \n",
      "Classification loss = 32.3185\n",
      "Comparison loss = 7.3956\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.7742\n",
      "Comparison loss = 6.9338\n",
      "Epoch no 11 : \n",
      "Classification loss = 31.0519\n",
      "Comparison loss = 6.9838\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.4104\n",
      "Comparison loss = 6.9170\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.1511\n",
      "Comparison loss = 6.5469\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.9639\n",
      "Comparison loss = 5.4540\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.7710\n",
      "Comparison loss = 5.3211\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.7112\n",
      "Comparison loss = 6.9080\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.6100\n",
      "Comparison loss = 6.8328\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.5394\n",
      "Comparison loss = 6.2325\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.4918\n",
      "Comparison loss = 3.4513\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.4679\n",
      "Comparison loss = 2.0384\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.5214\n",
      "Comparison loss = 0.7418\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.5107\n",
      "Comparison loss = 0.6019\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4690\n",
      "Comparison loss = 0.6892\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4551\n",
      "Comparison loss = 0.6944\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.4423\n",
      "Comparison loss = 0.3350\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.950% \n",
      "Comparison = 0.300%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.800% \n",
      "Comparison = 3.200%\u001b[0m\n",
      "RUN NO 8\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.1491\n",
      "Comparison loss = 6.9165\n",
      "Epoch no 2 : \n",
      "Classification loss = 42.9879\n",
      "Comparison loss = 6.9427\n",
      "Epoch no 3 : \n",
      "Classification loss = 40.1668\n",
      "Comparison loss = 6.8809\n",
      "Epoch no 4 : \n",
      "Classification loss = 37.2664\n",
      "Comparison loss = 6.8904\n",
      "Epoch no 5 : \n",
      "Classification loss = 35.2434\n",
      "Comparison loss = 6.8780\n",
      "Epoch no 6 : \n",
      "Classification loss = 34.0339\n",
      "Comparison loss = 6.7187\n",
      "Epoch no 7 : \n",
      "Classification loss = 32.9250\n",
      "Comparison loss = 5.6525\n",
      "Epoch no 8 : \n",
      "Classification loss = 32.3997\n",
      "Comparison loss = 5.9463\n",
      "Epoch no 9 : \n",
      "Classification loss = 31.9402\n",
      "Comparison loss = 6.1200\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.3403\n",
      "Comparison loss = 6.9082\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.6285\n",
      "Comparison loss = 6.8560\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.2356\n",
      "Comparison loss = 6.4839\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.0614\n",
      "Comparison loss = 6.3459\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.8984\n",
      "Comparison loss = 6.4750\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.7910\n",
      "Comparison loss = 5.6699\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.7026\n",
      "Comparison loss = 6.6437\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.5995\n",
      "Comparison loss = 4.6073\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.5392\n",
      "Comparison loss = 2.0754\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.5573\n",
      "Comparison loss = 1.8316\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.6967\n",
      "Comparison loss = 3.0338\n",
      "Epoch no 21 : \n",
      "Classification loss = 30.1525\n",
      "Comparison loss = 4.8192\n",
      "Epoch no 22 : \n",
      "Classification loss = 30.7565\n",
      "Comparison loss = 4.7364\n",
      "Epoch no 23 : \n",
      "Classification loss = 30.4112\n",
      "Comparison loss = 4.2415\n",
      "Epoch no 24 : \n",
      "Classification loss = 30.0969\n",
      "Comparison loss = 1.9458\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.8026\n",
      "Comparison loss = 1.0038\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 1.750% \n",
      "Comparison = 1.200%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 5.700% \n",
      "Comparison = 4.400%\u001b[0m\n",
      "RUN NO 9\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.2772\n",
      "Comparison loss = 6.9950\n",
      "Epoch no 2 : \n",
      "Classification loss = 42.6287\n",
      "Comparison loss = 6.9828\n",
      "Epoch no 3 : \n",
      "Classification loss = 39.5203\n",
      "Comparison loss = 6.9144\n",
      "Epoch no 4 : \n",
      "Classification loss = 36.5282\n",
      "Comparison loss = 6.9215\n",
      "Epoch no 5 : \n",
      "Classification loss = 33.9323\n",
      "Comparison loss = 6.8482\n",
      "Epoch no 6 : \n",
      "Classification loss = 32.3528\n",
      "Comparison loss = 6.6557\n",
      "Epoch no 7 : \n",
      "Classification loss = 31.8333\n",
      "Comparison loss = 6.1332\n",
      "Epoch no 8 : \n",
      "Classification loss = 31.0178\n",
      "Comparison loss = 5.6840\n",
      "Epoch no 9 : \n",
      "Classification loss = 30.7828\n",
      "Comparison loss = 6.9622\n",
      "Epoch no 10 : \n",
      "Classification loss = 30.3724\n",
      "Comparison loss = 6.9873\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.0653\n",
      "Comparison loss = 6.9638\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.0305\n",
      "Comparison loss = 6.8876\n",
      "Epoch no 13 : \n",
      "Classification loss = 29.7849\n",
      "Comparison loss = 6.7510\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.7461\n",
      "Comparison loss = 6.6977\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.6668\n",
      "Comparison loss = 5.4400\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.5746\n",
      "Comparison loss = 3.7843\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.5890\n",
      "Comparison loss = 3.8370\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.5044\n",
      "Comparison loss = 2.5177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch no 19 : \n",
      "Classification loss = 29.5781\n",
      "Comparison loss = 1.0018\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.5095\n",
      "Comparison loss = 1.0879\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.8326\n",
      "Comparison loss = 0.7556\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.5339\n",
      "Comparison loss = 0.3760\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.4673\n",
      "Comparison loss = 0.2775\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.4232\n",
      "Comparison loss = 0.2230\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3706\n",
      "Comparison loss = 0.0393\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.600% \n",
      "Comparison = 0.100%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.450% \n",
      "Comparison = 3.600%\u001b[0m\n",
      "RUN NO 10\n",
      "Epoch no 1 : \n",
      "Classification loss = 45.1358\n",
      "Comparison loss = 6.9185\n",
      "Epoch no 2 : \n",
      "Classification loss = 42.0900\n",
      "Comparison loss = 6.8794\n",
      "Epoch no 3 : \n",
      "Classification loss = 38.5974\n",
      "Comparison loss = 6.8989\n",
      "Epoch no 4 : \n",
      "Classification loss = 36.2069\n",
      "Comparison loss = 6.8963\n",
      "Epoch no 5 : \n",
      "Classification loss = 34.9885\n",
      "Comparison loss = 6.8855\n",
      "Epoch no 6 : \n",
      "Classification loss = 34.0133\n",
      "Comparison loss = 6.7940\n",
      "Epoch no 7 : \n",
      "Classification loss = 32.9379\n",
      "Comparison loss = 5.6694\n",
      "Epoch no 8 : \n",
      "Classification loss = 31.7746\n",
      "Comparison loss = 5.8220\n",
      "Epoch no 9 : \n",
      "Classification loss = 31.3994\n",
      "Comparison loss = 5.6108\n",
      "Epoch no 10 : \n",
      "Classification loss = 31.1761\n",
      "Comparison loss = 4.8057\n",
      "Epoch no 11 : \n",
      "Classification loss = 30.5001\n",
      "Comparison loss = 4.6645\n",
      "Epoch no 12 : \n",
      "Classification loss = 30.4320\n",
      "Comparison loss = 8.1587\n",
      "Epoch no 13 : \n",
      "Classification loss = 30.1450\n",
      "Comparison loss = 5.4447\n",
      "Epoch no 14 : \n",
      "Classification loss = 29.8634\n",
      "Comparison loss = 5.6276\n",
      "Epoch no 15 : \n",
      "Classification loss = 29.7036\n",
      "Comparison loss = 4.6858\n",
      "Epoch no 16 : \n",
      "Classification loss = 29.6144\n",
      "Comparison loss = 3.7033\n",
      "Epoch no 17 : \n",
      "Classification loss = 29.5332\n",
      "Comparison loss = 1.9958\n",
      "Epoch no 18 : \n",
      "Classification loss = 29.4915\n",
      "Comparison loss = 0.6768\n",
      "Epoch no 19 : \n",
      "Classification loss = 29.4469\n",
      "Comparison loss = 0.4653\n",
      "Epoch no 20 : \n",
      "Classification loss = 29.3970\n",
      "Comparison loss = 0.5507\n",
      "Epoch no 21 : \n",
      "Classification loss = 29.3803\n",
      "Comparison loss = 0.1897\n",
      "Epoch no 22 : \n",
      "Classification loss = 29.3698\n",
      "Comparison loss = 0.1449\n",
      "Epoch no 23 : \n",
      "Classification loss = 29.3611\n",
      "Comparison loss = 0.1620\n",
      "Epoch no 24 : \n",
      "Classification loss = 29.3578\n",
      "Comparison loss = 0.1357\n",
      "Epoch no 25 : \n",
      "Classification loss = 29.3557\n",
      "Comparison loss = 0.1555\n",
      "\u001b[3;37;41mError in training: \n",
      "Classification = 0.600% \n",
      "Comparison = 0.200%\u001b[0m\n",
      "\u001b[3;37;41mError in testing: \n",
      "Classification = 4.700% \n",
      "Comparison = 3.300%\u001b[0m\n",
      "Final error for train batch : 0.52±0.4826\n",
      "Final error for test batch : 3.50±0.5207\n"
     ]
    }
   ],
   "source": [
    "train_class = t.empty(NB_RUN)\n",
    "train_comp = t.empty(NB_RUN)\n",
    "test_class = t.empty(NB_RUN)\n",
    "test_comp = t.empty(NB_RUN)\n",
    "\n",
    "for i in range(NB_RUN):\n",
    "    model_cl = Classification()\n",
    "    model_co = Comparison_10()\n",
    "    print(\"RUN NO {}\".format(i+1))\n",
    "    training(model_cl, model_co, 1e-3)\n",
    "\n",
    "    e1, e2 = test_models(model_cl, model_co, train_input, train_classes, train_target)\n",
    "    e3, e4 = test_models(model_cl, model_co, test_input, test_classes, test_target, False)\n",
    "    train_class[i] = (e1)\n",
    "    train_comp[i] = (e2)\n",
    "    test_class[i] = (e3)\n",
    "    test_comp[i] = (e4)\n",
    "    \n",
    "print(\"Final error for train batch : {:0.2f}\\u00B1{:0.4f}\".format(t.mean(train_comp)*100,t.std(train_comp)*100))\n",
    "print(\"Final error for test batch : {:0.2f}\\u00B1{:0.4f}\".format(t.mean(test_comp)*100,t.std(test_comp)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final error for train batch : 0.22±0.1317\n",
      "Final error for test batch : 2.92±0.4517\n"
     ]
    }
   ],
   "source": [
    "print(\"Final error for train batch : {:0.2f}\\u00B1{:0.4f}\".format(t.mean(train_comp)*100,t.std(train_comp)*100))\n",
    "print(\"Final error for test batch : {:0.2f}\\u00B1{:0.4f}\".format(t.mean(test_comp)*100,t.std(test_comp)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results**\n",
    "\n",
    "Model  | Conv layers | lr  | Avg training err | Std training | Avg testing err | Std testing\n",
    "---    | ---         | --- | ---              | ---          | ---             | --- \n",
    "1  | 3 | 1e-3 | 0.22 | 0.13 | **2.92** | 0.45\n",
    "2  | 4 | 1e-3 | 0.29 | 0.12 | 3.30 | 0.38\n",
    "3  | 4 | 1e-3 | 0.26 | 0.14 | 2.94 | 0.54 \n",
    "4  | 5 | 1e-3 | 0.22 | 0.19 | 3.22 | 0.45 \n",
    "5  | 6 | 1e-3 | 0.19 | 0.16 | 3.12 | 0.48\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Note: \n",
    "- for model 2: 20-40-80-160-2\n",
    "- for model 3: 20-40-80-40-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
