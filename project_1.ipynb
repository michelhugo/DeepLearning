{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from torch import Tensor\n",
    "from torch import optim\n",
    "\n",
    "import dlc_practical_prologue as prologue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input, train_target, train_classes, test_input, test_target, test_classes = prologue.generate_pair_sets(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input, train_target = Variable(train_input), Variable(train_target)\n",
    "test_input, test_target = Variable(test_input), Variable(test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_input: torch.Size([1000, 2, 14, 14]) \n",
      " train_target: torch.Size([1000]) \n",
      " train_classes: torch.Size([1000, 2]) \n",
      " test_input: torch.Size([1000, 2, 14, 14]) \n",
      " test_target: torch.Size([1000]) \n",
      " test_classes: torch.Size([1000, 2])\n"
     ]
    }
   ],
   "source": [
    "#Sanity check\n",
    "print('train_input: {} \\n train_target: {} \\n train_classes: {} \\n test_input: {} \\n test_target: {} \\n test_classes: {}'.format(train_input.size(),\n",
    "                                                                   train_target.size(),\n",
    "                                                                   train_classes.size(),\n",
    "                                                                   test_input.size(),\n",
    "                                                                   test_target.size(),\n",
    "                                                                   test_classes.size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "nb_pairs = 1000\n",
    "nb_epochs = 25\n",
    "nb_hidden = 50\n",
    "mini_batch_size = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model\n",
    "\n",
    "The *train_input* variable is 1000x2x14x14.\n",
    "The model should receive as input a 14x14 image. Hence, the providing train and test sets account for 2000 images each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_input(input_):\n",
    "    '''\n",
    "    Tensor manipulation prior training our model \n",
    "    From 1000x2x14x14 to 2000x1x14x14\n",
    "    '''\n",
    "    channel_1 = input_[:,0,:,:] #get 1st channel\n",
    "    channel_2 = input_[:,1,:,:] #get 2nd channel\n",
    "    channel_concat = torch.cat((channel_1, channel_2), 0)\n",
    "    \n",
    "    return channel_concat.view(channel_concat.size(0), 1, \n",
    "                             channel_concat.size(1), channel_concat.size(2))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_classes(classes_):\n",
    "    '''\n",
    "    Assign each image its class/label [0,..., 9]. \n",
    "    From Nx2 to 2Nx1\n",
    "    '''\n",
    "    labels_1 = classes_[:,0]\n",
    "    labels_2 = classes_[:,1]\n",
    "    \n",
    "    return torch.cat((labels_1, labels_2), 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, input_, classes_, criterion, learning_rate, nb_e):\n",
    "    '''\n",
    "    Given a model, aims to perform the training step.\n",
    "    criterion: suggested either nn.MSELoss() or nn.CrossEntropyLoss() \n",
    "    learning_rate: parameter for the sgd\n",
    "    nb_e: epochs number\n",
    "    '''\n",
    "     \n",
    "    train_in = format_input(input_)\n",
    "    labels = format_classes(classes_)\n",
    "    \n",
    "    optimizer = optim.SGD(model.parameters(), lr = learning_rate)\n",
    "\n",
    "    for e in range(nb_e):\n",
    "        sum_loss = 0\n",
    "        for b in range(0, train_in.size(0), mini_batch_size):\n",
    "            #output = model(train_input.narrow(0, b, mini_batch_size))\n",
    "            #loss = criterion(output, train_target.narrow(0, b, mini_batch_size))\n",
    "            \n",
    "            output = model(train_in[b:b+mini_batch_size])\n",
    "            loss = criterion(output, labels[b:b+mini_batch_size].long())\n",
    "            \n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            sum_loss += loss.item()\n",
    "            optimizer.step()\n",
    "        \n",
    "            #to print every 2000 mini_batch\n",
    "            #if i % 2000 == 1999:\n",
    "                #print('[%d, %5d] loss: %.3f' %\n",
    "                #  (epoch + 1, i + 1, running_loss / 2000))\n",
    "                #running_loss = 0.0\n",
    "    \n",
    "        print('[epoch {:d}] loss: {:0.2f}'.format(e+1, sum_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_nb_errors(model, input_, classes_):\n",
    "    \n",
    "    input_f = format_input(input_)\n",
    "    labels_f = format_classes(classes_)\n",
    "    \n",
    "    nb_data_errors = 0\n",
    "\n",
    "    for b in range(0, input_f.size(0), mini_batch_size):\n",
    "        output = model(input_f.narrow(0, b, mini_batch_size))\n",
    "        _, predicted_classes = torch.max(output.data, 1) #max proba\n",
    "        for k in range(mini_batch_size):\n",
    "            if labels_f.data[b + k] != predicted_classes[k]:\n",
    "                nb_data_errors = nb_data_errors + 1\n",
    "\n",
    "    return nb_data_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, nb_hidden):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.fc1 = nn.Linear(256, nb_hidden) #64\n",
    "        self.fc2 = nn.Linear(nb_hidden, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), kernel_size=2)) #3 #stride=3\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), kernel_size=2)) #stride=2\n",
    "        x = F.relu(self.fc1(x.view(-1, 256)))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] loss: 230.12\n",
      "[epoch 2] loss: 33.99\n",
      "[epoch 3] loss: 18.88\n",
      "[epoch 4] loss: 12.71\n",
      "[epoch 5] loss: 7.94\n",
      "[epoch 6] loss: 5.43\n",
      "[epoch 7] loss: 5.18\n",
      "[epoch 8] loss: 2.64\n",
      "[epoch 9] loss: 1.61\n",
      "[epoch 10] loss: 1.22\n",
      "[epoch 11] loss: 0.84\n",
      "[epoch 12] loss: 0.66\n",
      "[epoch 13] loss: 0.54\n",
      "[epoch 14] loss: 0.41\n",
      "[epoch 15] loss: 0.31\n",
      "[epoch 16] loss: 0.24\n",
      "[epoch 17] loss: 0.21\n",
      "[epoch 18] loss: 0.18\n",
      "[epoch 19] loss: 0.16\n",
      "[epoch 20] loss: 0.14\n",
      "[epoch 21] loss: 0.13\n",
      "[epoch 22] loss: 0.12\n",
      "[epoch 23] loss: 0.11\n",
      "[epoch 24] loss: 0.10\n",
      "[epoch 25] loss: 0.09\n",
      "train_error 0.00% test_error 5.90%\n",
      "[epoch 1] loss: 620.53\n",
      "[epoch 2] loss: 181.70\n",
      "[epoch 3] loss: 171.53\n",
      "[epoch 4] loss: 117.44\n",
      "[epoch 5] loss: 83.44\n",
      "[epoch 6] loss: 58.68\n",
      "[epoch 7] loss: 40.47\n",
      "[epoch 8] loss: 29.66\n",
      "[epoch 9] loss: 23.60\n",
      "[epoch 10] loss: 20.14\n",
      "[epoch 11] loss: 16.59\n",
      "[epoch 12] loss: 15.07\n",
      "[epoch 13] loss: 12.21\n",
      "[epoch 14] loss: 10.17\n",
      "[epoch 15] loss: 13.35\n",
      "[epoch 16] loss: 8.99\n",
      "[epoch 17] loss: 17.51\n",
      "[epoch 18] loss: 6.12\n",
      "[epoch 19] loss: 3.84\n",
      "[epoch 20] loss: 4.31\n",
      "[epoch 21] loss: 2.57\n",
      "[epoch 22] loss: 3.00\n",
      "[epoch 23] loss: 1.74\n",
      "[epoch 24] loss: 1.83\n",
      "[epoch 25] loss: 1.55\n",
      "train_error 0.70% test_error 9.40%\n",
      "[epoch 1] loss: 236.95\n",
      "[epoch 2] loss: 30.65\n",
      "[epoch 3] loss: 17.46\n",
      "[epoch 4] loss: 9.98\n",
      "[epoch 5] loss: 6.01\n",
      "[epoch 6] loss: 5.30\n",
      "[epoch 7] loss: 2.76\n",
      "[epoch 8] loss: 1.53\n",
      "[epoch 9] loss: 0.94\n",
      "[epoch 10] loss: 0.64\n",
      "[epoch 11] loss: 0.49\n",
      "[epoch 12] loss: 0.39\n",
      "[epoch 13] loss: 0.33\n",
      "[epoch 14] loss: 0.28\n",
      "[epoch 15] loss: 0.24\n",
      "[epoch 16] loss: 0.21\n",
      "[epoch 17] loss: 0.19\n",
      "[epoch 18] loss: 0.17\n",
      "[epoch 19] loss: 0.16\n",
      "[epoch 20] loss: 0.14\n",
      "[epoch 21] loss: 0.13\n",
      "[epoch 22] loss: 0.12\n",
      "[epoch 23] loss: 0.11\n",
      "[epoch 24] loss: 0.10\n",
      "[epoch 25] loss: 0.10\n",
      "train_error 0.00% test_error 4.65%\n",
      "[epoch 1] loss: 817.23\n",
      "[epoch 2] loss: 88.56\n",
      "[epoch 3] loss: 36.50\n",
      "[epoch 4] loss: 23.45\n",
      "[epoch 5] loss: 17.12\n",
      "[epoch 6] loss: 12.38\n",
      "[epoch 7] loss: 9.37\n",
      "[epoch 8] loss: 7.41\n",
      "[epoch 9] loss: 5.61\n",
      "[epoch 10] loss: 4.24\n",
      "[epoch 11] loss: 2.90\n",
      "[epoch 12] loss: 1.96\n",
      "[epoch 13] loss: 1.50\n",
      "[epoch 14] loss: 1.03\n",
      "[epoch 15] loss: 0.74\n",
      "[epoch 16] loss: 0.57\n",
      "[epoch 17] loss: 0.44\n",
      "[epoch 18] loss: 0.35\n",
      "[epoch 19] loss: 0.29\n",
      "[epoch 20] loss: 0.25\n",
      "[epoch 21] loss: 0.22\n",
      "[epoch 22] loss: 0.20\n",
      "[epoch 23] loss: 0.18\n",
      "[epoch 24] loss: 0.16\n",
      "[epoch 25] loss: 0.15\n",
      "train_error 0.00% test_error 6.60%\n",
      "[epoch 1] loss: 308.12\n",
      "[epoch 2] loss: 35.33\n",
      "[epoch 3] loss: 18.11\n",
      "[epoch 4] loss: 11.79\n",
      "[epoch 5] loss: 8.06\n",
      "[epoch 6] loss: 5.41\n",
      "[epoch 7] loss: 3.63\n",
      "[epoch 8] loss: 2.13\n",
      "[epoch 9] loss: 1.36\n",
      "[epoch 10] loss: 0.83\n",
      "[epoch 11] loss: 0.59\n",
      "[epoch 12] loss: 0.41\n",
      "[epoch 13] loss: 0.32\n",
      "[epoch 14] loss: 0.27\n",
      "[epoch 15] loss: 0.23\n",
      "[epoch 16] loss: 0.20\n",
      "[epoch 17] loss: 0.18\n",
      "[epoch 18] loss: 0.16\n",
      "[epoch 19] loss: 0.15\n",
      "[epoch 20] loss: 0.14\n",
      "[epoch 21] loss: 0.12\n",
      "[epoch 22] loss: 0.12\n",
      "[epoch 23] loss: 0.11\n",
      "[epoch 24] loss: 0.10\n",
      "[epoch 25] loss: 0.09\n",
      "train_error 0.00% test_error 4.85%\n",
      "[epoch 1] loss: 489.88\n",
      "[epoch 2] loss: 40.65\n",
      "[epoch 3] loss: 22.26\n",
      "[epoch 4] loss: 15.95\n",
      "[epoch 5] loss: 11.10\n",
      "[epoch 6] loss: 8.53\n",
      "[epoch 7] loss: 5.20\n",
      "[epoch 8] loss: 3.35\n",
      "[epoch 9] loss: 2.09\n",
      "[epoch 10] loss: 1.47\n",
      "[epoch 11] loss: 1.34\n",
      "[epoch 12] loss: 0.90\n",
      "[epoch 13] loss: 0.67\n",
      "[epoch 14] loss: 0.48\n",
      "[epoch 15] loss: 0.37\n",
      "[epoch 16] loss: 0.30\n",
      "[epoch 17] loss: 0.25\n",
      "[epoch 18] loss: 0.22\n",
      "[epoch 19] loss: 0.19\n",
      "[epoch 20] loss: 0.17\n",
      "[epoch 21] loss: 0.16\n",
      "[epoch 22] loss: 0.14\n",
      "[epoch 23] loss: 0.13\n",
      "[epoch 24] loss: 0.12\n",
      "[epoch 25] loss: 0.11\n",
      "train_error 0.00% test_error 5.70%\n",
      "[epoch 1] loss: 562.13\n",
      "[epoch 2] loss: 44.59\n",
      "[epoch 3] loss: 25.69\n",
      "[epoch 4] loss: 18.36\n",
      "[epoch 5] loss: 13.64\n",
      "[epoch 6] loss: 9.94\n",
      "[epoch 7] loss: 7.43\n",
      "[epoch 8] loss: 5.30\n",
      "[epoch 9] loss: 3.62\n",
      "[epoch 10] loss: 2.72\n",
      "[epoch 11] loss: 2.32\n",
      "[epoch 12] loss: 1.50\n",
      "[epoch 13] loss: 1.06\n",
      "[epoch 14] loss: 0.89\n",
      "[epoch 15] loss: 0.64\n",
      "[epoch 16] loss: 0.49\n",
      "[epoch 17] loss: 0.38\n",
      "[epoch 18] loss: 0.32\n",
      "[epoch 19] loss: 0.28\n",
      "[epoch 20] loss: 0.24\n",
      "[epoch 21] loss: 0.22\n",
      "[epoch 22] loss: 0.19\n",
      "[epoch 23] loss: 0.17\n",
      "[epoch 24] loss: 0.16\n",
      "[epoch 25] loss: 0.15\n",
      "train_error 0.00% test_error 6.75%\n",
      "[epoch 1] loss: 397.86\n",
      "[epoch 2] loss: 43.75\n",
      "[epoch 3] loss: 25.25\n",
      "[epoch 4] loss: 17.39\n",
      "[epoch 5] loss: 12.79\n",
      "[epoch 6] loss: 8.09\n",
      "[epoch 7] loss: 5.30\n",
      "[epoch 8] loss: 3.95\n",
      "[epoch 9] loss: 2.70\n",
      "[epoch 10] loss: 1.79\n",
      "[epoch 11] loss: 1.30\n",
      "[epoch 12] loss: 0.85\n",
      "[epoch 13] loss: 0.64\n",
      "[epoch 14] loss: 0.50\n",
      "[epoch 15] loss: 0.41\n",
      "[epoch 16] loss: 0.34\n",
      "[epoch 17] loss: 0.29\n",
      "[epoch 18] loss: 0.25\n",
      "[epoch 19] loss: 0.22\n",
      "[epoch 20] loss: 0.20\n",
      "[epoch 21] loss: 0.17\n",
      "[epoch 22] loss: 0.16\n",
      "[epoch 23] loss: 0.15\n",
      "[epoch 24] loss: 0.13\n",
      "[epoch 25] loss: 0.12\n",
      "train_error 0.00% test_error 5.20%\n",
      "[epoch 1] loss: 984.49\n",
      "[epoch 2] loss: 134.77\n",
      "[epoch 3] loss: 82.49\n",
      "[epoch 4] loss: 61.80\n",
      "[epoch 5] loss: 48.58\n",
      "[epoch 6] loss: 41.41\n",
      "[epoch 7] loss: 37.52\n",
      "[epoch 8] loss: 34.43\n",
      "[epoch 9] loss: 31.44\n",
      "[epoch 10] loss: 27.98\n",
      "[epoch 11] loss: 25.12\n",
      "[epoch 12] loss: 23.46\n",
      "[epoch 13] loss: 21.98\n",
      "[epoch 14] loss: 18.43\n",
      "[epoch 15] loss: 16.31\n",
      "[epoch 16] loss: 13.87\n",
      "[epoch 17] loss: 12.57\n",
      "[epoch 18] loss: 11.76\n",
      "[epoch 19] loss: 11.34\n",
      "[epoch 20] loss: 10.33\n",
      "[epoch 21] loss: 12.74\n",
      "[epoch 22] loss: 7.84\n",
      "[epoch 23] loss: 6.80\n",
      "[epoch 24] loss: 7.21\n",
      "[epoch 25] loss: 8.32\n",
      "train_error 3.40% test_error 13.60%\n",
      "[epoch 1] loss: 675.58\n",
      "[epoch 2] loss: 89.02\n",
      "[epoch 3] loss: 44.84\n",
      "[epoch 4] loss: 29.59\n",
      "[epoch 5] loss: 21.36\n",
      "[epoch 6] loss: 17.13\n",
      "[epoch 7] loss: 13.31\n",
      "[epoch 8] loss: 10.58\n",
      "[epoch 9] loss: 9.50\n",
      "[epoch 10] loss: 8.05\n",
      "[epoch 11] loss: 5.09\n",
      "[epoch 12] loss: 4.58\n",
      "[epoch 13] loss: 3.22\n",
      "[epoch 14] loss: 2.75\n",
      "[epoch 15] loss: 1.98\n",
      "[epoch 16] loss: 2.08\n",
      "[epoch 17] loss: 1.61\n",
      "[epoch 18] loss: 1.20\n",
      "[epoch 19] loss: 1.37\n",
      "[epoch 20] loss: 1.08\n",
      "[epoch 21] loss: 0.60\n",
      "[epoch 22] loss: 0.36\n",
      "[epoch 23] loss: 0.26\n",
      "[epoch 24] loss: 0.22\n",
      "[epoch 25] loss: 0.19\n",
      "train_error 0.00% test_error 6.55%\n"
     ]
    }
   ],
   "source": [
    "# Here we just assess the performance of the process for recognising digits\n",
    "#(NOT assessing whether a number is higher than the other one!)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Run the training 10 times\n",
    "for i in range(10):\n",
    "    model = Net(nb_hidden)\n",
    "    train_model(model, train_input, train_classes, criterion, 1e-2, nb_epochs)\n",
    "\n",
    "    print('train_error {:.02f}% test_error {:.02f}%'.format(\n",
    "            compute_nb_errors(model, train_input, train_classes) / (2*train_input.size(0)) * 100,\n",
    "            compute_nb_errors(model, test_input, test_classes) / (2*test_input.size(0)) * 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: *cross entropy* preferred for classification (see [here](https://stackoverflow.com/questions/36515202/why-is-the-cross-entropy-method-preferred-over-mean-squared-error-in-what-cases))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll assess whether a digit is higher or not than another one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merci Hugo\n",
    "def format_model_output(model_output):\n",
    "    out = torch.empty(nb_pairs, dtype = torch.int32)\n",
    "    for i in range(nb_pairs):\n",
    "        _,max1 = torch.max(model_output[i], 0)\n",
    "        _,max2 = torch.max(model_output[i + nb_pairs], 0)\n",
    "        if max1 <= max2:\n",
    "            out[i] = 1\n",
    "        else:\n",
    "            out[i] = 0\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_target_error(model, input_, targets_):\n",
    "    input_f = format_input(input_)\n",
    "    output = model(input_f)\n",
    "    output = format_model_output(output)\n",
    "    \n",
    "    error = 0\n",
    "    \n",
    "    for i in range(nb_pairs):\n",
    "        if output[i].item() != targets_[i]:\n",
    "            error = error + 1\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] loss: 374.74\n",
      "[epoch 2] loss: 39.88\n",
      "[epoch 3] loss: 21.92\n",
      "[epoch 4] loss: 15.73\n",
      "[epoch 5] loss: 11.40\n",
      "[epoch 6] loss: 8.23\n",
      "[epoch 7] loss: 5.98\n",
      "[epoch 8] loss: 4.32\n",
      "[epoch 9] loss: 3.02\n",
      "[epoch 10] loss: 2.11\n",
      "[epoch 11] loss: 1.44\n",
      "[epoch 12] loss: 1.07\n",
      "[epoch 13] loss: 0.81\n",
      "[epoch 14] loss: 0.62\n",
      "[epoch 15] loss: 0.49\n",
      "[epoch 16] loss: 0.40\n",
      "[epoch 17] loss: 0.34\n",
      "[epoch 18] loss: 0.29\n",
      "[epoch 19] loss: 0.26\n",
      "[epoch 20] loss: 0.23\n",
      "[epoch 21] loss: 0.21\n",
      "[epoch 22] loss: 0.19\n",
      "[epoch 23] loss: 0.17\n",
      "[epoch 24] loss: 0.16\n",
      "[epoch 25] loss: 0.15\n",
      "Training error: 0.0% Testing error: 5.4%\n",
      "[epoch 1] loss: 694.63\n",
      "[epoch 2] loss: 45.22\n",
      "[epoch 3] loss: 25.88\n",
      "[epoch 4] loss: 18.04\n",
      "[epoch 5] loss: 13.23\n",
      "[epoch 6] loss: 9.78\n",
      "[epoch 7] loss: 6.81\n",
      "[epoch 8] loss: 4.90\n",
      "[epoch 9] loss: 3.32\n",
      "[epoch 10] loss: 2.91\n",
      "[epoch 11] loss: 2.07\n",
      "[epoch 12] loss: 1.61\n",
      "[epoch 13] loss: 1.17\n",
      "[epoch 14] loss: 1.00\n",
      "[epoch 15] loss: 0.75\n",
      "[epoch 16] loss: 0.57\n",
      "[epoch 17] loss: 0.41\n",
      "[epoch 18] loss: 0.33\n",
      "[epoch 19] loss: 0.28\n",
      "[epoch 20] loss: 0.25\n",
      "[epoch 21] loss: 0.22\n",
      "[epoch 22] loss: 0.20\n",
      "[epoch 23] loss: 0.18\n",
      "[epoch 24] loss: 0.17\n",
      "[epoch 25] loss: 0.15\n",
      "Training error: 0.0% Testing error: 3.5000000000000004%\n",
      "[epoch 1] loss: 151412.17\n",
      "[epoch 2] loss: 292.13\n",
      "[epoch 3] loss: 179.96\n",
      "[epoch 4] loss: 177.80\n",
      "[epoch 5] loss: 176.03\n",
      "[epoch 6] loss: 174.07\n",
      "[epoch 7] loss: 171.86\n",
      "[epoch 8] loss: 169.95\n",
      "[epoch 9] loss: 167.07\n",
      "[epoch 10] loss: 164.31\n",
      "[epoch 11] loss: 161.21\n",
      "[epoch 12] loss: 157.76\n",
      "[epoch 13] loss: 153.92\n",
      "[epoch 14] loss: 149.54\n",
      "[epoch 15] loss: 144.82\n",
      "[epoch 16] loss: 139.89\n",
      "[epoch 17] loss: 134.70\n",
      "[epoch 18] loss: 129.32\n",
      "[epoch 19] loss: 123.72\n",
      "[epoch 20] loss: 118.37\n",
      "[epoch 21] loss: 113.22\n",
      "[epoch 22] loss: 108.98\n",
      "[epoch 23] loss: 105.05\n",
      "[epoch 24] loss: 101.04\n",
      "[epoch 25] loss: 97.63\n",
      "Training error: 21.9% Testing error: 21.7%\n",
      "[epoch 1] loss: 452.62\n",
      "[epoch 2] loss: 29.76\n",
      "[epoch 3] loss: 16.92\n",
      "[epoch 4] loss: 10.40\n",
      "[epoch 5] loss: 6.81\n",
      "[epoch 6] loss: 4.26\n",
      "[epoch 7] loss: 2.75\n",
      "[epoch 8] loss: 1.92\n",
      "[epoch 9] loss: 1.43\n",
      "[epoch 10] loss: 1.08\n",
      "[epoch 11] loss: 0.87\n",
      "[epoch 12] loss: 0.66\n",
      "[epoch 13] loss: 0.53\n",
      "[epoch 14] loss: 0.41\n",
      "[epoch 15] loss: 0.34\n",
      "[epoch 16] loss: 0.29\n",
      "[epoch 17] loss: 0.25\n",
      "[epoch 18] loss: 0.22\n",
      "[epoch 19] loss: 0.19\n",
      "[epoch 20] loss: 0.17\n",
      "[epoch 21] loss: 0.16\n",
      "[epoch 22] loss: 0.14\n",
      "[epoch 23] loss: 0.13\n",
      "[epoch 24] loss: 0.12\n",
      "[epoch 25] loss: 0.11\n",
      "Training error: 0.0% Testing error: 2.7%\n",
      "[epoch 1] loss: 364.21\n",
      "[epoch 2] loss: 42.32\n",
      "[epoch 3] loss: 26.33\n",
      "[epoch 4] loss: 18.18\n",
      "[epoch 5] loss: 13.65\n",
      "[epoch 6] loss: 9.73\n",
      "[epoch 7] loss: 7.43\n",
      "[epoch 8] loss: 4.69\n",
      "[epoch 9] loss: 3.01\n",
      "[epoch 10] loss: 2.09\n",
      "[epoch 11] loss: 1.78\n",
      "[epoch 12] loss: 1.27\n",
      "[epoch 13] loss: 0.91\n",
      "[epoch 14] loss: 0.69\n",
      "[epoch 15] loss: 0.54\n",
      "[epoch 16] loss: 0.43\n",
      "[epoch 17] loss: 0.34\n",
      "[epoch 18] loss: 0.28\n",
      "[epoch 19] loss: 0.24\n",
      "[epoch 20] loss: 0.21\n",
      "[epoch 21] loss: 0.19\n",
      "[epoch 22] loss: 0.17\n",
      "[epoch 23] loss: 0.15\n",
      "[epoch 24] loss: 0.14\n",
      "[epoch 25] loss: 0.13\n",
      "Training error: 0.0% Testing error: 4.9%\n",
      "[epoch 1] loss: 210.50\n",
      "[epoch 2] loss: 26.99\n",
      "[epoch 3] loss: 16.17\n",
      "[epoch 4] loss: 9.67\n",
      "[epoch 5] loss: 6.05\n",
      "[epoch 6] loss: 3.67\n",
      "[epoch 7] loss: 2.32\n",
      "[epoch 8] loss: 1.51\n",
      "[epoch 9] loss: 1.06\n",
      "[epoch 10] loss: 0.90\n",
      "[epoch 11] loss: 0.52\n",
      "[epoch 12] loss: 0.36\n",
      "[epoch 13] loss: 0.28\n",
      "[epoch 14] loss: 0.23\n",
      "[epoch 15] loss: 0.19\n",
      "[epoch 16] loss: 0.17\n",
      "[epoch 17] loss: 0.15\n",
      "[epoch 18] loss: 0.14\n",
      "[epoch 19] loss: 0.12\n",
      "[epoch 20] loss: 0.11\n",
      "[epoch 21] loss: 0.10\n",
      "[epoch 22] loss: 0.10\n",
      "[epoch 23] loss: 0.09\n",
      "[epoch 24] loss: 0.08\n",
      "[epoch 25] loss: 0.08\n",
      "Training error: 0.0% Testing error: 3.5000000000000004%\n",
      "[epoch 1] loss: 469.46\n",
      "[epoch 2] loss: 44.27\n",
      "[epoch 3] loss: 20.72\n",
      "[epoch 4] loss: 13.62\n",
      "[epoch 5] loss: 8.93\n",
      "[epoch 6] loss: 6.66\n",
      "[epoch 7] loss: 4.00\n",
      "[epoch 8] loss: 2.75\n",
      "[epoch 9] loss: 2.05\n",
      "[epoch 10] loss: 1.20\n",
      "[epoch 11] loss: 0.84\n",
      "[epoch 12] loss: 0.59\n",
      "[epoch 13] loss: 0.44\n",
      "[epoch 14] loss: 0.35\n",
      "[epoch 15] loss: 0.30\n",
      "[epoch 16] loss: 0.26\n",
      "[epoch 17] loss: 0.23\n",
      "[epoch 18] loss: 0.20\n",
      "[epoch 19] loss: 0.18\n",
      "[epoch 20] loss: 0.17\n",
      "[epoch 21] loss: 0.15\n",
      "[epoch 22] loss: 0.14\n",
      "[epoch 23] loss: 0.13\n",
      "[epoch 24] loss: 0.12\n",
      "[epoch 25] loss: 0.11\n",
      "Training error: 0.0% Testing error: 3.0%\n",
      "[epoch 1] loss: 384.80\n",
      "[epoch 2] loss: 34.09\n",
      "[epoch 3] loss: 19.01\n",
      "[epoch 4] loss: 13.43\n",
      "[epoch 5] loss: 9.56\n",
      "[epoch 6] loss: 6.80\n",
      "[epoch 7] loss: 4.63\n",
      "[epoch 8] loss: 3.47\n",
      "[epoch 9] loss: 2.60\n",
      "[epoch 10] loss: 1.70\n",
      "[epoch 11] loss: 5.94\n",
      "[epoch 12] loss: 1.86\n",
      "[epoch 13] loss: 1.05\n",
      "[epoch 14] loss: 0.82\n",
      "[epoch 15] loss: 0.61\n",
      "[epoch 16] loss: 0.39\n",
      "[epoch 17] loss: 0.30\n",
      "[epoch 18] loss: 0.23\n",
      "[epoch 19] loss: 0.19\n",
      "[epoch 20] loss: 0.17\n",
      "[epoch 21] loss: 0.15\n",
      "[epoch 22] loss: 0.14\n",
      "[epoch 23] loss: 0.13\n",
      "[epoch 24] loss: 0.12\n",
      "[epoch 25] loss: 0.11\n",
      "Training error: 0.0% Testing error: 3.5000000000000004%\n",
      "[epoch 1] loss: 346.33\n",
      "[epoch 2] loss: 38.77\n",
      "[epoch 3] loss: 18.92\n",
      "[epoch 4] loss: 11.85\n",
      "[epoch 5] loss: 7.89\n",
      "[epoch 6] loss: 5.43\n",
      "[epoch 7] loss: 3.65\n",
      "[epoch 8] loss: 2.31\n",
      "[epoch 9] loss: 1.55\n",
      "[epoch 10] loss: 1.09\n",
      "[epoch 11] loss: 0.83\n",
      "[epoch 12] loss: 0.49\n",
      "[epoch 13] loss: 0.36\n",
      "[epoch 14] loss: 0.29\n",
      "[epoch 15] loss: 0.25\n",
      "[epoch 16] loss: 0.22\n",
      "[epoch 17] loss: 0.19\n",
      "[epoch 18] loss: 0.17\n",
      "[epoch 19] loss: 0.16\n",
      "[epoch 20] loss: 0.14\n",
      "[epoch 21] loss: 0.13\n",
      "[epoch 22] loss: 0.12\n",
      "[epoch 23] loss: 0.11\n",
      "[epoch 24] loss: 0.10\n",
      "[epoch 25] loss: 0.10\n",
      "Training error: 0.0% Testing error: 3.5999999999999996%\n",
      "[epoch 1] loss: 285.93\n",
      "[epoch 2] loss: 38.22\n",
      "[epoch 3] loss: 19.87\n",
      "[epoch 4] loss: 12.74\n",
      "[epoch 5] loss: 8.16\n",
      "[epoch 6] loss: 5.15\n",
      "[epoch 7] loss: 5.38\n",
      "[epoch 8] loss: 3.12\n",
      "[epoch 9] loss: 1.81\n",
      "[epoch 10] loss: 1.07\n",
      "[epoch 11] loss: 0.68\n",
      "[epoch 12] loss: 0.55\n",
      "[epoch 13] loss: 0.41\n",
      "[epoch 14] loss: 0.34\n",
      "[epoch 15] loss: 0.29\n",
      "[epoch 16] loss: 0.25\n",
      "[epoch 17] loss: 0.22\n",
      "[epoch 18] loss: 0.20\n",
      "[epoch 19] loss: 0.18\n",
      "[epoch 20] loss: 0.17\n",
      "[epoch 21] loss: 0.15\n",
      "[epoch 22] loss: 0.14\n",
      "[epoch 23] loss: 0.13\n",
      "[epoch 24] loss: 0.12\n",
      "[epoch 25] loss: 0.11\n",
      "Training error: 0.0% Testing error: 2.1999999999999997%\n"
     ]
    }
   ],
   "source": [
    "# we run the training k times\n",
    "for k in range(10):\n",
    "    model = Net(nb_hidden)\n",
    "    train_model(model, train_input, train_classes, criterion, 1e-2, nb_epochs)    \n",
    "        \n",
    "    print('Training error: {}% Testing error: {}%'.format(\n",
    "        compute_target_error(model, train_input, train_target) / nb_pairs * 100,\n",
    "        compute_target_error(model, test_input, test_target) / nb_pairs * 100))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune params manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] loss: 251.51\n",
      "[epoch 2] loss: 126.19\n",
      "[epoch 3] loss: 97.92\n",
      "[epoch 4] loss: 80.89\n",
      "[epoch 5] loss: 69.45\n",
      "[epoch 6] loss: 61.35\n",
      "[epoch 7] loss: 55.15\n",
      "[epoch 8] loss: 50.23\n",
      "[epoch 9] loss: 46.28\n",
      "[epoch 10] loss: 42.96\n",
      "[epoch 11] loss: 40.07\n",
      "[epoch 12] loss: 37.54\n",
      "[epoch 13] loss: 35.35\n",
      "[epoch 14] loss: 33.41\n",
      "[epoch 15] loss: 31.67\n",
      "[epoch 16] loss: 30.10\n",
      "[epoch 17] loss: 28.69\n",
      "[epoch 18] loss: 27.41\n",
      "[epoch 19] loss: 26.21\n",
      "[epoch 20] loss: 25.14\n",
      "[epoch 21] loss: 24.15\n",
      "[epoch 22] loss: 23.24\n",
      "[epoch 23] loss: 22.39\n",
      "[epoch 24] loss: 21.59\n",
      "[epoch 25] loss: 20.85\n",
      "Training error: 4.8% Testing error: 9.1%\n",
      "[epoch 1] loss: 261.51\n",
      "[epoch 2] loss: 129.98\n",
      "[epoch 3] loss: 97.59\n",
      "[epoch 4] loss: 79.94\n",
      "[epoch 5] loss: 68.55\n",
      "[epoch 6] loss: 60.50\n",
      "[epoch 7] loss: 54.31\n",
      "[epoch 8] loss: 49.46\n",
      "[epoch 9] loss: 45.54\n",
      "[epoch 10] loss: 42.31\n",
      "[epoch 11] loss: 39.53\n",
      "[epoch 12] loss: 37.15\n",
      "[epoch 13] loss: 35.05\n",
      "[epoch 14] loss: 33.19\n",
      "[epoch 15] loss: 31.54\n",
      "[epoch 16] loss: 30.05\n",
      "[epoch 17] loss: 28.70\n",
      "[epoch 18] loss: 27.50\n",
      "[epoch 19] loss: 26.39\n",
      "[epoch 20] loss: 25.38\n",
      "[epoch 21] loss: 24.44\n",
      "[epoch 22] loss: 23.59\n",
      "[epoch 23] loss: 22.78\n",
      "[epoch 24] loss: 22.04\n",
      "[epoch 25] loss: 21.33\n",
      "Training error: 5.6000000000000005% Testing error: 7.7%\n",
      "[epoch 1] loss: 264.58\n",
      "[epoch 2] loss: 128.66\n",
      "[epoch 3] loss: 92.43\n",
      "[epoch 4] loss: 73.93\n",
      "[epoch 5] loss: 62.58\n",
      "[epoch 6] loss: 54.91\n",
      "[epoch 7] loss: 49.22\n",
      "[epoch 8] loss: 44.83\n",
      "[epoch 9] loss: 41.27\n",
      "[epoch 10] loss: 38.34\n",
      "[epoch 11] loss: 35.86\n",
      "[epoch 12] loss: 33.75\n",
      "[epoch 13] loss: 31.92\n",
      "[epoch 14] loss: 30.30\n",
      "[epoch 15] loss: 28.82\n",
      "[epoch 16] loss: 27.52\n",
      "[epoch 17] loss: 26.33\n",
      "[epoch 18] loss: 25.25\n",
      "[epoch 19] loss: 24.25\n",
      "[epoch 20] loss: 23.32\n",
      "[epoch 21] loss: 22.45\n",
      "[epoch 22] loss: 21.62\n",
      "[epoch 23] loss: 20.85\n",
      "[epoch 24] loss: 20.12\n",
      "[epoch 25] loss: 19.44\n",
      "Training error: 4.6% Testing error: 7.8%\n",
      "[epoch 1] loss: 213.63\n",
      "[epoch 2] loss: 121.51\n",
      "[epoch 3] loss: 93.87\n",
      "[epoch 4] loss: 77.19\n",
      "[epoch 5] loss: 65.68\n",
      "[epoch 6] loss: 57.37\n",
      "[epoch 7] loss: 51.06\n",
      "[epoch 8] loss: 46.11\n",
      "[epoch 9] loss: 42.05\n",
      "[epoch 10] loss: 38.74\n",
      "[epoch 11] loss: 35.98\n",
      "[epoch 12] loss: 33.66\n",
      "[epoch 13] loss: 31.66\n",
      "[epoch 14] loss: 29.90\n",
      "[epoch 15] loss: 28.35\n",
      "[epoch 16] loss: 26.98\n",
      "[epoch 17] loss: 25.75\n",
      "[epoch 18] loss: 24.64\n",
      "[epoch 19] loss: 23.62\n",
      "[epoch 20] loss: 22.70\n",
      "[epoch 21] loss: 21.84\n",
      "[epoch 22] loss: 21.05\n",
      "[epoch 23] loss: 20.31\n",
      "[epoch 24] loss: 19.62\n",
      "[epoch 25] loss: 18.98\n",
      "Training error: 3.4000000000000004% Testing error: 6.9%\n",
      "[epoch 1] loss: 230.96\n",
      "[epoch 2] loss: 118.49\n",
      "[epoch 3] loss: 89.87\n",
      "[epoch 4] loss: 73.37\n",
      "[epoch 5] loss: 62.78\n",
      "[epoch 6] loss: 55.30\n",
      "[epoch 7] loss: 49.60\n",
      "[epoch 8] loss: 45.09\n",
      "[epoch 9] loss: 41.40\n",
      "[epoch 10] loss: 38.36\n",
      "[epoch 11] loss: 35.84\n",
      "[epoch 12] loss: 33.66\n",
      "[epoch 13] loss: 31.75\n",
      "[epoch 14] loss: 30.06\n",
      "[epoch 15] loss: 28.57\n",
      "[epoch 16] loss: 27.21\n",
      "[epoch 17] loss: 25.96\n",
      "[epoch 18] loss: 24.82\n",
      "[epoch 19] loss: 23.80\n",
      "[epoch 20] loss: 22.86\n",
      "[epoch 21] loss: 22.00\n",
      "[epoch 22] loss: 21.21\n",
      "[epoch 23] loss: 20.46\n",
      "[epoch 24] loss: 19.76\n",
      "[epoch 25] loss: 19.11\n",
      "Training error: 4.6% Testing error: 7.9%\n",
      "Average training error: 4.6 Std training error: 0.7874007874011811 \n",
      " Average testing error: 7.88 Std testing error: 0.788669766125214\n"
     ]
    }
   ],
   "source": [
    "it = 5\n",
    "number_hidden = 50\n",
    "\n",
    "train_error_storage = []\n",
    "test_error_storage = []\n",
    "\n",
    "for k in range(it):\n",
    "    model = Net(number_hidden)\n",
    "    train_model(model, train_input, train_classes, criterion, 1e-4, nb_epochs)    \n",
    "        \n",
    "    train_err = compute_target_error(model, train_input, train_target) / nb_pairs * 100\n",
    "    test_err = compute_target_error(model, test_input, test_target) / nb_pairs * 100\n",
    "        \n",
    "    train_error_storage.append(train_err)\n",
    "    test_error_storage.append(test_err)\n",
    "    \n",
    "    print('Training error: {}% Testing error: {}%'.format(\n",
    "        train_err,\n",
    "        test_err))\n",
    "\n",
    "print('\\nAverage training error: {} Std training error: {} \\nAverage testing error: {} Std testing error: {}'.format(\n",
    "    sum(train_error_storage) / len(train_error_storage), statistics.stdev(train_error_storage),\n",
    "    sum(test_error_storage) / len(test_error_storage), statistics.stdev(test_error_storage)\n",
    "))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.6"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results**\n",
    "\n",
    "Model | nb hidden | lr | iter | Avg training err | Std training | Avg testing err | Std testing\n",
    "--- | --- | --- | --- | --- | --- | --- | ---\n",
    "1 | 50 | 1e-2 | 5 | 1.32 | 2.950 | 5.26 | 3.33\n",
    "1 | 50 | 1e-3 | 5 | 0.26 | 0.089 | 4.68 | 0.43\n",
    "1 | 50 | 1e-4 | 5 | 4.60 | 0.787 | 7.88 | 0.79\n",
    "1 | x | x | x | x | x | x | x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] loss: 212.49\n",
      "[epoch 2] loss: 160.93\n",
      "[epoch 3] loss: 155.40\n",
      "[epoch 4] loss: 151.41\n",
      "[epoch 5] loss: 147.77\n",
      "[epoch 6] loss: 144.13\n",
      "[epoch 7] loss: 140.57\n",
      "[epoch 8] loss: 136.96\n",
      "[epoch 9] loss: 133.05\n",
      "[epoch 10] loss: 128.93\n",
      "[epoch 11] loss: 124.97\n",
      "[epoch 12] loss: 120.79\n",
      "[epoch 13] loss: 116.69\n",
      "[epoch 14] loss: 112.72\n",
      "[epoch 15] loss: 108.91\n",
      "[epoch 16] loss: 105.33\n",
      "[epoch 17] loss: 101.85\n",
      "[epoch 18] loss: 98.43\n",
      "[epoch 19] loss: 95.20\n",
      "[epoch 20] loss: 92.16\n",
      "[epoch 21] loss: 89.31\n",
      "[epoch 22] loss: 86.54\n",
      "[epoch 23] loss: 83.76\n",
      "[epoch 24] loss: 81.02\n",
      "[epoch 25] loss: 78.34\n",
      "[epoch 1] loss: 241.37\n",
      "[epoch 2] loss: 168.24\n",
      "[epoch 3] loss: 158.55\n",
      "[epoch 4] loss: 150.55\n",
      "[epoch 5] loss: 144.41\n",
      "[epoch 6] loss: 139.31\n",
      "[epoch 7] loss: 134.91\n",
      "[epoch 8] loss: 131.14\n",
      "[epoch 9] loss: 127.89\n",
      "[epoch 10] loss: 124.96\n",
      "[epoch 11] loss: 122.46\n",
      "[epoch 12] loss: 120.26\n",
      "[epoch 13] loss: 117.91\n",
      "[epoch 14] loss: 115.62\n",
      "[epoch 15] loss: 113.43\n",
      "[epoch 16] loss: 111.39\n",
      "[epoch 17] loss: 109.22\n",
      "[epoch 18] loss: 107.21\n",
      "[epoch 19] loss: 105.28\n",
      "[epoch 20] loss: 103.35\n",
      "[epoch 21] loss: 101.44\n",
      "[epoch 22] loss: 99.58\n",
      "[epoch 23] loss: 97.78\n",
      "[epoch 24] loss: 96.08\n",
      "[epoch 25] loss: 94.41\n",
      "[epoch 1] loss: 256.56\n",
      "[epoch 2] loss: 177.24\n",
      "[epoch 3] loss: 169.71\n",
      "[epoch 4] loss: 162.01\n",
      "[epoch 5] loss: 154.62\n",
      "[epoch 6] loss: 147.79\n",
      "[epoch 7] loss: 141.19\n",
      "[epoch 8] loss: 134.65\n",
      "[epoch 9] loss: 128.17\n",
      "[epoch 10] loss: 122.12\n",
      "[epoch 11] loss: 115.66\n",
      "[epoch 12] loss: 108.00\n",
      "[epoch 13] loss: 98.82\n",
      "[epoch 14] loss: 91.74\n",
      "[epoch 15] loss: 84.68\n",
      "[epoch 16] loss: 77.95\n",
      "[epoch 17] loss: 71.60\n",
      "[epoch 18] loss: 65.90\n",
      "[epoch 19] loss: 60.61\n",
      "[epoch 20] loss: 56.17\n",
      "[epoch 21] loss: 52.30\n",
      "[epoch 22] loss: 48.81\n",
      "[epoch 23] loss: 45.80\n",
      "[epoch 24] loss: 43.19\n",
      "[epoch 25] loss: 40.91\n",
      "[epoch 1] loss: 202.27\n",
      "[epoch 2] loss: 168.92\n",
      "[epoch 3] loss: 164.35\n",
      "[epoch 4] loss: 160.65\n",
      "[epoch 5] loss: 157.47\n",
      "[epoch 6] loss: 154.59\n",
      "[epoch 7] loss: 151.94\n",
      "[epoch 8] loss: 149.50\n",
      "[epoch 9] loss: 147.20\n",
      "[epoch 10] loss: 144.80\n",
      "[epoch 11] loss: 141.93\n",
      "[epoch 12] loss: 138.94\n",
      "[epoch 13] loss: 135.59\n",
      "[epoch 14] loss: 132.30\n",
      "[epoch 15] loss: 129.21\n",
      "[epoch 16] loss: 126.36\n",
      "[epoch 17] loss: 123.71\n",
      "[epoch 18] loss: 121.16\n",
      "[epoch 19] loss: 118.73\n",
      "[epoch 20] loss: 116.41\n",
      "[epoch 21] loss: 114.14\n",
      "[epoch 22] loss: 111.96\n",
      "[epoch 23] loss: 109.86\n",
      "[epoch 24] loss: 107.84\n",
      "[epoch 25] loss: 105.84\n",
      "[epoch 1] loss: 215.82\n",
      "[epoch 2] loss: 159.27\n",
      "[epoch 3] loss: 148.66\n",
      "[epoch 4] loss: 140.06\n",
      "[epoch 5] loss: 132.99\n",
      "[epoch 6] loss: 125.63\n",
      "[epoch 7] loss: 118.90\n",
      "[epoch 8] loss: 112.49\n",
      "[epoch 9] loss: 106.32\n",
      "[epoch 10] loss: 99.87\n",
      "[epoch 11] loss: 93.06\n",
      "[epoch 12] loss: 86.28\n",
      "[epoch 13] loss: 79.45\n",
      "[epoch 14] loss: 73.20\n",
      "[epoch 15] loss: 67.29\n",
      "[epoch 16] loss: 61.90\n",
      "[epoch 17] loss: 57.19\n",
      "[epoch 18] loss: 52.94\n",
      "[epoch 19] loss: 49.33\n",
      "[epoch 20] loss: 46.18\n",
      "[epoch 21] loss: 43.47\n",
      "[epoch 22] loss: 41.07\n",
      "[epoch 23] loss: 38.95\n",
      "[epoch 24] loss: 37.09\n",
      "[epoch 25] loss: 35.38\n",
      "[epoch 1] loss: 191.80\n",
      "[epoch 2] loss: 148.12\n",
      "[epoch 3] loss: 136.99\n",
      "[epoch 4] loss: 112.99\n",
      "[epoch 5] loss: 83.85\n",
      "[epoch 6] loss: 61.32\n",
      "[epoch 7] loss: 48.80\n",
      "[epoch 8] loss: 40.40\n",
      "[epoch 9] loss: 34.41\n",
      "[epoch 10] loss: 30.41\n",
      "[epoch 11] loss: 26.81\n",
      "[epoch 12] loss: 23.94\n",
      "[epoch 13] loss: 21.44\n",
      "[epoch 14] loss: 19.29\n",
      "[epoch 15] loss: 17.39\n",
      "[epoch 16] loss: 15.73\n",
      "[epoch 17] loss: 14.23\n",
      "[epoch 18] loss: 12.95\n",
      "[epoch 19] loss: 11.84\n",
      "[epoch 20] loss: 10.83\n",
      "[epoch 21] loss: 10.06\n",
      "[epoch 22] loss: 9.29\n",
      "[epoch 23] loss: 8.54\n",
      "[epoch 24] loss: 7.89\n",
      "[epoch 25] loss: 7.35\n",
      "[epoch 1] loss: 200.94\n",
      "[epoch 2] loss: 174.25\n",
      "[epoch 3] loss: 171.14\n",
      "[epoch 4] loss: 169.49\n",
      "[epoch 5] loss: 167.70\n",
      "[epoch 6] loss: 165.62\n",
      "[epoch 7] loss: 163.36\n",
      "[epoch 8] loss: 159.27\n",
      "[epoch 9] loss: 146.07\n",
      "[epoch 10] loss: 124.33\n",
      "[epoch 11] loss: 103.37\n",
      "[epoch 12] loss: 85.23\n",
      "[epoch 13] loss: 74.26\n",
      "[epoch 14] loss: 67.52\n",
      "[epoch 15] loss: 62.79\n",
      "[epoch 16] loss: 41.61\n",
      "[epoch 17] loss: 31.88\n",
      "[epoch 18] loss: 26.82\n",
      "[epoch 19] loss: 23.65\n",
      "[epoch 20] loss: 21.10\n",
      "[epoch 21] loss: 19.06\n",
      "[epoch 22] loss: 17.33\n",
      "[epoch 23] loss: 15.93\n",
      "[epoch 24] loss: 14.70\n",
      "[epoch 25] loss: 13.56\n",
      "[epoch 1] loss: 211.01\n",
      "[epoch 2] loss: 177.61\n",
      "[epoch 3] loss: 165.34\n",
      "[epoch 4] loss: 156.98\n",
      "[epoch 5] loss: 151.65\n",
      "[epoch 6] loss: 148.07\n",
      "[epoch 7] loss: 136.01\n",
      "[epoch 8] loss: 119.68\n",
      "[epoch 9] loss: 106.24\n",
      "[epoch 10] loss: 100.13\n",
      "[epoch 11] loss: 96.60\n",
      "[epoch 12] loss: 92.86\n",
      "[epoch 13] loss: 89.70\n",
      "[epoch 14] loss: 87.35\n",
      "[epoch 15] loss: 85.53\n",
      "[epoch 16] loss: 83.16\n",
      "[epoch 17] loss: 77.87\n",
      "[epoch 18] loss: 69.28\n",
      "[epoch 19] loss: 63.40\n",
      "[epoch 20] loss: 59.79\n",
      "[epoch 21] loss: 55.05\n",
      "[epoch 22] loss: 38.31\n",
      "[epoch 23] loss: 30.10\n",
      "[epoch 24] loss: 25.26\n",
      "[epoch 25] loss: 21.14\n",
      "[epoch 1] loss: 210.30\n",
      "[epoch 2] loss: 181.14\n",
      "[epoch 3] loss: 182.11\n",
      "[epoch 4] loss: 161.69\n",
      "[epoch 5] loss: 145.52\n",
      "[epoch 6] loss: 121.15\n",
      "[epoch 7] loss: 101.68\n",
      "[epoch 8] loss: 86.44\n",
      "[epoch 9] loss: 64.05\n",
      "[epoch 10] loss: 47.61\n",
      "[epoch 11] loss: 38.62\n",
      "[epoch 12] loss: 32.29\n",
      "[epoch 13] loss: 27.16\n",
      "[epoch 14] loss: 23.76\n",
      "[epoch 15] loss: 20.56\n",
      "[epoch 16] loss: 18.11\n",
      "[epoch 17] loss: 16.39\n",
      "[epoch 18] loss: 14.64\n",
      "[epoch 19] loss: 13.25\n",
      "[epoch 20] loss: 11.93\n",
      "[epoch 21] loss: 10.80\n",
      "[epoch 22] loss: 9.85\n",
      "[epoch 23] loss: 8.87\n",
      "[epoch 24] loss: 8.18\n",
      "[epoch 25] loss: 7.42\n",
      "[epoch 1] loss: 220.75\n",
      "[epoch 2] loss: 176.53\n",
      "[epoch 3] loss: 171.23\n",
      "[epoch 4] loss: 161.01\n",
      "[epoch 5] loss: 150.30\n",
      "[epoch 6] loss: 140.21\n",
      "[epoch 7] loss: 119.42\n",
      "[epoch 8] loss: 105.10\n",
      "[epoch 9] loss: 94.70\n",
      "[epoch 10] loss: 85.36\n",
      "[epoch 11] loss: 74.64\n",
      "[epoch 12] loss: 66.37\n",
      "[epoch 13] loss: 56.34\n",
      "[epoch 14] loss: 41.83\n",
      "[epoch 15] loss: 34.55\n",
      "[epoch 16] loss: 29.03\n",
      "[epoch 17] loss: 25.02\n",
      "[epoch 18] loss: 22.01\n",
      "[epoch 19] loss: 19.58\n",
      "[epoch 20] loss: 17.72\n",
      "[epoch 21] loss: 16.11\n",
      "[epoch 22] loss: 14.52\n",
      "[epoch 23] loss: 13.24\n",
      "[epoch 24] loss: 12.01\n",
      "[epoch 25] loss: 10.89\n",
      "[epoch 1] loss: 10640.24\n",
      "[epoch 2] loss: 184.52\n",
      "[epoch 3] loss: 184.39\n",
      "[epoch 4] loss: 184.28\n",
      "[epoch 5] loss: 184.19\n",
      "[epoch 6] loss: 184.11\n",
      "[epoch 7] loss: 184.05\n",
      "[epoch 8] loss: 183.99\n",
      "[epoch 9] loss: 183.95\n",
      "[epoch 10] loss: 183.91\n",
      "[epoch 11] loss: 183.87\n",
      "[epoch 12] loss: 183.85\n",
      "[epoch 13] loss: 183.82\n",
      "[epoch 14] loss: 183.80\n",
      "[epoch 15] loss: 183.79\n",
      "[epoch 16] loss: 183.77\n",
      "[epoch 17] loss: 183.76\n",
      "[epoch 18] loss: 183.75\n",
      "[epoch 19] loss: 183.74\n",
      "[epoch 20] loss: 183.73\n",
      "[epoch 21] loss: 183.73\n",
      "[epoch 22] loss: 183.72\n",
      "[epoch 23] loss: 183.72\n",
      "[epoch 24] loss: 183.71\n",
      "[epoch 25] loss: 183.71\n",
      "[epoch 1] loss: 483.59\n",
      "[epoch 2] loss: 73.22\n",
      "[epoch 3] loss: 37.37\n",
      "[epoch 4] loss: 24.08\n",
      "[epoch 5] loss: 16.14\n",
      "[epoch 6] loss: 11.09\n",
      "[epoch 7] loss: 7.14\n",
      "[epoch 8] loss: 4.78\n",
      "[epoch 9] loss: 3.02\n",
      "[epoch 10] loss: 2.19\n",
      "[epoch 11] loss: 1.64\n",
      "[epoch 12] loss: 1.34\n",
      "[epoch 13] loss: 0.90\n",
      "[epoch 14] loss: 0.72\n",
      "[epoch 15] loss: 0.59\n",
      "[epoch 16] loss: 0.50\n",
      "[epoch 17] loss: 0.45\n",
      "[epoch 18] loss: 0.40\n",
      "[epoch 19] loss: 0.37\n",
      "[epoch 20] loss: 0.34\n",
      "[epoch 21] loss: 0.32\n",
      "[epoch 22] loss: 0.30\n",
      "[epoch 23] loss: 0.27\n",
      "[epoch 24] loss: 0.25\n",
      "[epoch 25] loss: 0.23\n",
      "[epoch 1] loss: 631.49\n",
      "[epoch 2] loss: 184.63\n",
      "[epoch 3] loss: 184.49\n",
      "[epoch 4] loss: 184.37\n",
      "[epoch 5] loss: 184.26\n",
      "[epoch 6] loss: 184.18\n",
      "[epoch 7] loss: 184.10\n",
      "[epoch 8] loss: 184.04\n",
      "[epoch 9] loss: 183.99\n",
      "[epoch 10] loss: 183.94\n",
      "[epoch 11] loss: 183.91\n",
      "[epoch 12] loss: 183.87\n",
      "[epoch 13] loss: 183.85\n",
      "[epoch 14] loss: 183.82\n",
      "[epoch 15] loss: 183.80\n",
      "[epoch 16] loss: 183.79\n",
      "[epoch 17] loss: 183.77\n",
      "[epoch 18] loss: 183.76\n",
      "[epoch 19] loss: 183.75\n",
      "[epoch 20] loss: 183.74\n",
      "[epoch 21] loss: 183.74\n",
      "[epoch 22] loss: 183.73\n",
      "[epoch 23] loss: 183.72\n",
      "[epoch 24] loss: 183.72\n",
      "[epoch 25] loss: 183.71\n",
      "[epoch 1] loss: 192803.49\n",
      "[epoch 2] loss: 183.17\n",
      "[epoch 3] loss: 182.73\n",
      "[epoch 4] loss: 182.29\n",
      "[epoch 5] loss: 181.68\n",
      "[epoch 6] loss: 180.86\n",
      "[epoch 7] loss: 179.95\n",
      "[epoch 8] loss: 178.88\n",
      "[epoch 9] loss: 177.73\n",
      "[epoch 10] loss: 176.47\n",
      "[epoch 11] loss: 175.10\n",
      "[epoch 12] loss: 173.73\n",
      "[epoch 13] loss: 172.43\n",
      "[epoch 14] loss: 171.25\n",
      "[epoch 15] loss: 170.28\n",
      "[epoch 16] loss: 169.44\n",
      "[epoch 17] loss: 168.67\n",
      "[epoch 18] loss: 167.99\n",
      "[epoch 19] loss: 167.40\n",
      "[epoch 20] loss: 166.87\n",
      "[epoch 21] loss: 166.38\n",
      "[epoch 22] loss: 165.92\n",
      "[epoch 23] loss: 165.51\n",
      "[epoch 24] loss: 165.14\n",
      "[epoch 25] loss: 164.79\n",
      "[epoch 1] loss: 693.06\n",
      "[epoch 2] loss: 133.52\n",
      "[epoch 3] loss: 104.36\n",
      "[epoch 4] loss: 65.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 5] loss: 38.87\n",
      "[epoch 6] loss: 25.00\n",
      "[epoch 7] loss: 17.17\n",
      "[epoch 8] loss: 13.57\n",
      "[epoch 9] loss: 8.25\n",
      "[epoch 10] loss: 6.38\n",
      "[epoch 11] loss: 5.70\n",
      "[epoch 12] loss: 3.15\n",
      "[epoch 13] loss: 1.80\n",
      "[epoch 14] loss: 1.22\n",
      "[epoch 15] loss: 0.88\n",
      "[epoch 16] loss: 0.64\n",
      "[epoch 17] loss: 0.52\n",
      "[epoch 18] loss: 0.46\n",
      "[epoch 19] loss: 0.41\n",
      "[epoch 20] loss: 0.38\n",
      "[epoch 21] loss: 0.36\n",
      "[epoch 22] loss: 0.31\n",
      "[epoch 23] loss: 0.31\n",
      "[epoch 24] loss: 0.28\n",
      "[epoch 25] loss: 0.29\n",
      "[epoch 1] loss: 293.57\n",
      "[epoch 2] loss: 119.45\n",
      "[epoch 3] loss: 89.07\n",
      "[epoch 4] loss: 72.78\n",
      "[epoch 5] loss: 61.83\n",
      "[epoch 6] loss: 54.17\n",
      "[epoch 7] loss: 48.44\n",
      "[epoch 8] loss: 43.91\n",
      "[epoch 9] loss: 40.27\n",
      "[epoch 10] loss: 37.30\n",
      "[epoch 11] loss: 34.76\n",
      "[epoch 12] loss: 32.61\n",
      "[epoch 13] loss: 30.82\n",
      "[epoch 14] loss: 29.25\n",
      "[epoch 15] loss: 27.88\n",
      "[epoch 16] loss: 26.66\n",
      "[epoch 17] loss: 25.55\n",
      "[epoch 18] loss: 24.55\n",
      "[epoch 19] loss: 23.65\n",
      "[epoch 20] loss: 22.80\n",
      "[epoch 21] loss: 22.03\n",
      "[epoch 22] loss: 21.30\n",
      "[epoch 23] loss: 20.63\n",
      "[epoch 24] loss: 19.99\n",
      "[epoch 25] loss: 19.39\n",
      "[epoch 1] loss: 233.95\n",
      "[epoch 2] loss: 112.64\n",
      "[epoch 3] loss: 86.40\n",
      "[epoch 4] loss: 72.90\n",
      "[epoch 5] loss: 63.95\n",
      "[epoch 6] loss: 57.32\n",
      "[epoch 7] loss: 51.97\n",
      "[epoch 8] loss: 47.64\n",
      "[epoch 9] loss: 44.17\n",
      "[epoch 10] loss: 41.24\n",
      "[epoch 11] loss: 38.73\n",
      "[epoch 12] loss: 36.55\n",
      "[epoch 13] loss: 34.66\n",
      "[epoch 14] loss: 33.01\n",
      "[epoch 15] loss: 31.49\n",
      "[epoch 16] loss: 30.15\n",
      "[epoch 17] loss: 28.91\n",
      "[epoch 18] loss: 27.77\n",
      "[epoch 19] loss: 26.72\n",
      "[epoch 20] loss: 25.77\n",
      "[epoch 21] loss: 24.90\n",
      "[epoch 22] loss: 24.09\n",
      "[epoch 23] loss: 23.33\n",
      "[epoch 24] loss: 22.62\n",
      "[epoch 25] loss: 21.94\n",
      "[epoch 1] loss: 252.84\n",
      "[epoch 2] loss: 118.67\n",
      "[epoch 3] loss: 88.62\n",
      "[epoch 4] loss: 72.61\n",
      "[epoch 5] loss: 62.49\n",
      "[epoch 6] loss: 55.47\n",
      "[epoch 7] loss: 50.30\n",
      "[epoch 8] loss: 46.28\n",
      "[epoch 9] loss: 42.99\n",
      "[epoch 10] loss: 40.27\n",
      "[epoch 11] loss: 37.97\n",
      "[epoch 12] loss: 35.99\n",
      "[epoch 13] loss: 34.27\n",
      "[epoch 14] loss: 32.72\n",
      "[epoch 15] loss: 31.27\n",
      "[epoch 16] loss: 29.97\n",
      "[epoch 17] loss: 28.81\n",
      "[epoch 18] loss: 27.75\n",
      "[epoch 19] loss: 26.76\n",
      "[epoch 20] loss: 25.83\n",
      "[epoch 21] loss: 24.98\n",
      "[epoch 22] loss: 24.17\n",
      "[epoch 23] loss: 23.43\n",
      "[epoch 24] loss: 22.75\n",
      "[epoch 25] loss: 22.10\n",
      "[epoch 1] loss: 241.49\n",
      "[epoch 2] loss: 126.65\n",
      "[epoch 3] loss: 96.22\n",
      "[epoch 4] loss: 79.06\n",
      "[epoch 5] loss: 67.76\n",
      "[epoch 6] loss: 59.91\n",
      "[epoch 7] loss: 53.98\n",
      "[epoch 8] loss: 49.29\n",
      "[epoch 9] loss: 45.53\n",
      "[epoch 10] loss: 42.42\n",
      "[epoch 11] loss: 39.78\n",
      "[epoch 12] loss: 37.49\n",
      "[epoch 13] loss: 35.46\n",
      "[epoch 14] loss: 33.66\n",
      "[epoch 15] loss: 32.03\n",
      "[epoch 16] loss: 30.58\n",
      "[epoch 17] loss: 29.27\n",
      "[epoch 18] loss: 28.07\n",
      "[epoch 19] loss: 26.98\n",
      "[epoch 20] loss: 25.95\n",
      "[epoch 21] loss: 25.00\n",
      "[epoch 22] loss: 24.11\n",
      "[epoch 23] loss: 23.28\n",
      "[epoch 24] loss: 22.49\n",
      "[epoch 25] loss: 21.78\n",
      "[epoch 1] loss: 256.55\n",
      "[epoch 2] loss: 115.58\n",
      "[epoch 3] loss: 90.97\n",
      "[epoch 4] loss: 76.19\n",
      "[epoch 5] loss: 65.90\n",
      "[epoch 6] loss: 58.55\n",
      "[epoch 7] loss: 52.89\n",
      "[epoch 8] loss: 48.33\n",
      "[epoch 9] loss: 44.72\n",
      "[epoch 10] loss: 41.69\n",
      "[epoch 11] loss: 39.12\n",
      "[epoch 12] loss: 36.88\n",
      "[epoch 13] loss: 34.93\n",
      "[epoch 14] loss: 33.20\n",
      "[epoch 15] loss: 31.65\n",
      "[epoch 16] loss: 30.29\n",
      "[epoch 17] loss: 29.03\n",
      "[epoch 18] loss: 27.88\n",
      "[epoch 19] loss: 26.84\n",
      "[epoch 20] loss: 25.89\n",
      "[epoch 21] loss: 25.01\n",
      "[epoch 22] loss: 24.19\n",
      "[epoch 23] loss: 23.41\n",
      "[epoch 24] loss: 22.68\n",
      "[epoch 25] loss: 22.01\n",
      "[epoch 1] loss: 144.59\n",
      "[epoch 2] loss: 50.29\n",
      "[epoch 3] loss: 33.54\n",
      "[epoch 4] loss: 25.17\n",
      "[epoch 5] loss: 19.91\n",
      "[epoch 6] loss: 16.15\n",
      "[epoch 7] loss: 13.65\n",
      "[epoch 8] loss: 11.66\n",
      "[epoch 9] loss: 10.05\n",
      "[epoch 10] loss: 8.74\n",
      "[epoch 11] loss: 7.65\n",
      "[epoch 12] loss: 6.79\n",
      "[epoch 13] loss: 6.03\n",
      "[epoch 14] loss: 5.43\n",
      "[epoch 15] loss: 4.90\n",
      "[epoch 16] loss: 4.42\n",
      "[epoch 17] loss: 4.02\n",
      "[epoch 18] loss: 3.68\n",
      "[epoch 19] loss: 3.35\n",
      "[epoch 20] loss: 3.09\n",
      "[epoch 21] loss: 2.86\n",
      "[epoch 22] loss: 2.62\n",
      "[epoch 23] loss: 2.44\n",
      "[epoch 24] loss: 2.26\n",
      "[epoch 25] loss: 2.11\n",
      "[epoch 1] loss: 183.64\n",
      "[epoch 2] loss: 54.99\n",
      "[epoch 3] loss: 35.83\n",
      "[epoch 4] loss: 26.46\n",
      "[epoch 5] loss: 20.89\n",
      "[epoch 6] loss: 16.77\n",
      "[epoch 7] loss: 13.89\n",
      "[epoch 8] loss: 11.47\n",
      "[epoch 9] loss: 9.59\n",
      "[epoch 10] loss: 8.11\n",
      "[epoch 11] loss: 6.96\n",
      "[epoch 12] loss: 5.95\n",
      "[epoch 13] loss: 5.16\n",
      "[epoch 14] loss: 4.51\n",
      "[epoch 15] loss: 3.96\n",
      "[epoch 16] loss: 3.51\n",
      "[epoch 17] loss: 3.14\n",
      "[epoch 18] loss: 2.83\n",
      "[epoch 19] loss: 2.57\n",
      "[epoch 20] loss: 2.35\n",
      "[epoch 21] loss: 2.15\n",
      "[epoch 22] loss: 1.99\n",
      "[epoch 23] loss: 1.84\n",
      "[epoch 24] loss: 1.70\n",
      "[epoch 25] loss: 1.58\n",
      "[epoch 1] loss: 166.42\n",
      "[epoch 2] loss: 69.33\n",
      "[epoch 3] loss: 40.49\n",
      "[epoch 4] loss: 28.89\n",
      "[epoch 5] loss: 22.32\n",
      "[epoch 6] loss: 18.15\n",
      "[epoch 7] loss: 14.99\n",
      "[epoch 8] loss: 12.61\n",
      "[epoch 9] loss: 10.80\n",
      "[epoch 10] loss: 9.31\n",
      "[epoch 11] loss: 8.04\n",
      "[epoch 12] loss: 6.99\n",
      "[epoch 13] loss: 6.14\n",
      "[epoch 14] loss: 5.40\n",
      "[epoch 15] loss: 4.76\n",
      "[epoch 16] loss: 4.22\n",
      "[epoch 17] loss: 3.77\n",
      "[epoch 18] loss: 3.38\n",
      "[epoch 19] loss: 3.05\n",
      "[epoch 20] loss: 2.75\n",
      "[epoch 21] loss: 2.50\n",
      "[epoch 22] loss: 2.27\n",
      "[epoch 23] loss: 2.08\n",
      "[epoch 24] loss: 1.91\n",
      "[epoch 25] loss: 1.76\n",
      "[epoch 1] loss: 206.71\n",
      "[epoch 2] loss: 73.82\n",
      "[epoch 3] loss: 43.49\n",
      "[epoch 4] loss: 32.01\n",
      "[epoch 5] loss: 25.07\n",
      "[epoch 6] loss: 20.32\n",
      "[epoch 7] loss: 17.05\n",
      "[epoch 8] loss: 14.35\n",
      "[epoch 9] loss: 12.35\n",
      "[epoch 10] loss: 10.71\n",
      "[epoch 11] loss: 9.36\n",
      "[epoch 12] loss: 8.22\n",
      "[epoch 13] loss: 7.27\n",
      "[epoch 14] loss: 6.52\n",
      "[epoch 15] loss: 5.88\n",
      "[epoch 16] loss: 5.34\n",
      "[epoch 17] loss: 4.79\n",
      "[epoch 18] loss: 4.38\n",
      "[epoch 19] loss: 3.97\n",
      "[epoch 20] loss: 3.62\n",
      "[epoch 21] loss: 3.33\n",
      "[epoch 22] loss: 3.06\n",
      "[epoch 23] loss: 2.81\n",
      "[epoch 24] loss: 2.61\n",
      "[epoch 25] loss: 2.43\n",
      "[epoch 1] loss: 182.50\n",
      "[epoch 2] loss: 62.74\n",
      "[epoch 3] loss: 41.48\n",
      "[epoch 4] loss: 30.39\n",
      "[epoch 5] loss: 23.97\n",
      "[epoch 6] loss: 19.71\n",
      "[epoch 7] loss: 16.37\n",
      "[epoch 8] loss: 13.92\n",
      "[epoch 9] loss: 11.79\n",
      "[epoch 10] loss: 10.21\n",
      "[epoch 11] loss: 8.76\n",
      "[epoch 12] loss: 7.47\n",
      "[epoch 13] loss: 6.61\n",
      "[epoch 14] loss: 5.84\n",
      "[epoch 15] loss: 5.08\n",
      "[epoch 16] loss: 4.55\n",
      "[epoch 17] loss: 4.03\n",
      "[epoch 18] loss: 3.58\n",
      "[epoch 19] loss: 3.24\n",
      "[epoch 20] loss: 2.90\n",
      "[epoch 21] loss: 2.64\n",
      "[epoch 22] loss: 2.39\n",
      "[epoch 23] loss: 2.19\n",
      "[epoch 24] loss: 2.02\n",
      "[epoch 25] loss: 1.87\n",
      "[epoch 1] loss: 353.69\n",
      "[epoch 2] loss: 31.74\n",
      "[epoch 3] loss: 18.44\n",
      "[epoch 4] loss: 11.48\n",
      "[epoch 5] loss: 7.67\n",
      "[epoch 6] loss: 4.79\n",
      "[epoch 7] loss: 2.96\n",
      "[epoch 8] loss: 1.65\n",
      "[epoch 9] loss: 1.13\n",
      "[epoch 10] loss: 0.67\n",
      "[epoch 11] loss: 0.52\n",
      "[epoch 12] loss: 0.42\n",
      "[epoch 13] loss: 0.35\n",
      "[epoch 14] loss: 0.29\n",
      "[epoch 15] loss: 0.26\n",
      "[epoch 16] loss: 0.22\n",
      "[epoch 17] loss: 0.20\n",
      "[epoch 18] loss: 0.18\n",
      "[epoch 19] loss: 0.16\n",
      "[epoch 20] loss: 0.15\n",
      "[epoch 21] loss: 0.14\n",
      "[epoch 22] loss: 0.12\n",
      "[epoch 23] loss: 0.12\n",
      "[epoch 24] loss: 0.11\n",
      "[epoch 25] loss: 0.10\n",
      "[epoch 1] loss: 636.65\n",
      "[epoch 2] loss: 89.81\n",
      "[epoch 3] loss: 35.72\n",
      "[epoch 4] loss: 23.50\n",
      "[epoch 5] loss: 17.16\n",
      "[epoch 6] loss: 13.21\n",
      "[epoch 7] loss: 10.01\n",
      "[epoch 8] loss: 8.05\n",
      "[epoch 9] loss: 5.69\n",
      "[epoch 10] loss: 4.60\n",
      "[epoch 11] loss: 3.23\n",
      "[epoch 12] loss: 2.43\n",
      "[epoch 13] loss: 1.49\n",
      "[epoch 14] loss: 1.05\n",
      "[epoch 15] loss: 0.72\n",
      "[epoch 16] loss: 0.53\n",
      "[epoch 17] loss: 0.40\n",
      "[epoch 18] loss: 0.33\n",
      "[epoch 19] loss: 0.28\n",
      "[epoch 20] loss: 0.25\n",
      "[epoch 21] loss: 0.22\n",
      "[epoch 22] loss: 0.20\n",
      "[epoch 23] loss: 0.18\n",
      "[epoch 24] loss: 0.16\n",
      "[epoch 25] loss: 0.15\n",
      "[epoch 1] loss: 1022.75\n",
      "[epoch 2] loss: 102.02\n",
      "[epoch 3] loss: 61.86\n",
      "[epoch 4] loss: 41.22\n",
      "[epoch 5] loss: 29.17\n",
      "[epoch 6] loss: 21.27\n",
      "[epoch 7] loss: 16.26\n",
      "[epoch 8] loss: 13.05\n",
      "[epoch 9] loss: 10.27\n",
      "[epoch 10] loss: 8.31\n",
      "[epoch 11] loss: 6.93\n",
      "[epoch 12] loss: 5.13\n",
      "[epoch 13] loss: 4.65\n",
      "[epoch 14] loss: 3.26\n",
      "[epoch 15] loss: 2.39\n",
      "[epoch 16] loss: 1.71\n",
      "[epoch 17] loss: 1.28\n",
      "[epoch 18] loss: 0.96\n",
      "[epoch 19] loss: 0.78\n",
      "[epoch 20] loss: 0.62\n",
      "[epoch 21] loss: 0.52\n",
      "[epoch 22] loss: 0.43\n",
      "[epoch 23] loss: 0.37\n",
      "[epoch 24] loss: 0.32\n",
      "[epoch 25] loss: 0.29\n",
      "[epoch 1] loss: 289.84\n",
      "[epoch 2] loss: 41.46\n",
      "[epoch 3] loss: 24.02\n",
      "[epoch 4] loss: 16.58\n",
      "[epoch 5] loss: 11.59\n",
      "[epoch 6] loss: 8.28\n",
      "[epoch 7] loss: 6.02\n",
      "[epoch 8] loss: 7.23\n",
      "[epoch 9] loss: 3.71\n",
      "[epoch 10] loss: 2.87\n",
      "[epoch 11] loss: 2.10\n",
      "[epoch 12] loss: 1.72\n",
      "[epoch 13] loss: 1.36\n",
      "[epoch 14] loss: 0.94\n",
      "[epoch 15] loss: 0.72\n",
      "[epoch 16] loss: 0.59\n",
      "[epoch 17] loss: 0.44\n",
      "[epoch 18] loss: 0.35\n",
      "[epoch 19] loss: 0.28\n",
      "[epoch 20] loss: 0.24\n",
      "[epoch 21] loss: 0.21\n",
      "[epoch 22] loss: 0.19\n",
      "[epoch 23] loss: 0.17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 24] loss: 0.15\n",
      "[epoch 25] loss: 0.14\n",
      "[epoch 1] loss: 325.25\n",
      "[epoch 2] loss: 41.84\n",
      "[epoch 3] loss: 25.54\n",
      "[epoch 4] loss: 17.54\n",
      "[epoch 5] loss: 12.51\n",
      "[epoch 6] loss: 9.39\n",
      "[epoch 7] loss: 6.41\n",
      "[epoch 8] loss: 4.92\n",
      "[epoch 9] loss: 3.80\n",
      "[epoch 10] loss: 2.59\n",
      "[epoch 11] loss: 1.92\n",
      "[epoch 12] loss: 1.44\n",
      "[epoch 13] loss: 1.00\n",
      "[epoch 14] loss: 0.81\n",
      "[epoch 15] loss: 0.56\n",
      "[epoch 16] loss: 0.41\n",
      "[epoch 17] loss: 0.31\n",
      "[epoch 18] loss: 0.27\n",
      "[epoch 19] loss: 0.23\n",
      "[epoch 20] loss: 0.20\n",
      "[epoch 21] loss: 0.18\n",
      "[epoch 22] loss: 0.16\n",
      "[epoch 23] loss: 0.15\n",
      "[epoch 24] loss: 0.14\n",
      "[epoch 25] loss: 0.12\n",
      "[epoch 1] loss: 280.43\n",
      "[epoch 2] loss: 118.25\n",
      "[epoch 3] loss: 86.20\n",
      "[epoch 4] loss: 70.08\n",
      "[epoch 5] loss: 59.85\n",
      "[epoch 6] loss: 52.40\n",
      "[epoch 7] loss: 46.78\n",
      "[epoch 8] loss: 42.34\n",
      "[epoch 9] loss: 38.74\n",
      "[epoch 10] loss: 35.77\n",
      "[epoch 11] loss: 33.26\n",
      "[epoch 12] loss: 31.08\n",
      "[epoch 13] loss: 29.21\n",
      "[epoch 14] loss: 27.56\n",
      "[epoch 15] loss: 26.08\n",
      "[epoch 16] loss: 24.75\n",
      "[epoch 17] loss: 23.54\n",
      "[epoch 18] loss: 22.44\n",
      "[epoch 19] loss: 21.43\n",
      "[epoch 20] loss: 20.49\n",
      "[epoch 21] loss: 19.62\n",
      "[epoch 22] loss: 18.82\n",
      "[epoch 23] loss: 18.08\n",
      "[epoch 24] loss: 17.38\n",
      "[epoch 25] loss: 16.75\n",
      "[epoch 1] loss: 245.37\n",
      "[epoch 2] loss: 96.18\n",
      "[epoch 3] loss: 72.12\n",
      "[epoch 4] loss: 60.06\n",
      "[epoch 5] loss: 52.15\n",
      "[epoch 6] loss: 46.37\n",
      "[epoch 7] loss: 42.02\n",
      "[epoch 8] loss: 38.58\n",
      "[epoch 9] loss: 35.75\n",
      "[epoch 10] loss: 33.37\n",
      "[epoch 11] loss: 31.31\n",
      "[epoch 12] loss: 29.52\n",
      "[epoch 13] loss: 27.94\n",
      "[epoch 14] loss: 26.56\n",
      "[epoch 15] loss: 25.32\n",
      "[epoch 16] loss: 24.16\n",
      "[epoch 17] loss: 23.11\n",
      "[epoch 18] loss: 22.14\n",
      "[epoch 19] loss: 21.26\n",
      "[epoch 20] loss: 20.44\n",
      "[epoch 21] loss: 19.67\n",
      "[epoch 22] loss: 18.96\n",
      "[epoch 23] loss: 18.28\n",
      "[epoch 24] loss: 17.64\n",
      "[epoch 25] loss: 17.04\n",
      "[epoch 1] loss: 275.64\n",
      "[epoch 2] loss: 110.08\n",
      "[epoch 3] loss: 78.52\n",
      "[epoch 4] loss: 62.90\n",
      "[epoch 5] loss: 53.38\n",
      "[epoch 6] loss: 46.87\n",
      "[epoch 7] loss: 42.00\n",
      "[epoch 8] loss: 38.21\n",
      "[epoch 9] loss: 35.11\n",
      "[epoch 10] loss: 32.56\n",
      "[epoch 11] loss: 30.39\n",
      "[epoch 12] loss: 28.52\n",
      "[epoch 13] loss: 26.88\n",
      "[epoch 14] loss: 25.45\n",
      "[epoch 15] loss: 24.17\n",
      "[epoch 16] loss: 23.04\n",
      "[epoch 17] loss: 22.02\n",
      "[epoch 18] loss: 21.10\n",
      "[epoch 19] loss: 20.25\n",
      "[epoch 20] loss: 19.47\n",
      "[epoch 21] loss: 18.75\n",
      "[epoch 22] loss: 18.08\n",
      "[epoch 23] loss: 17.47\n",
      "[epoch 24] loss: 16.89\n",
      "[epoch 25] loss: 16.36\n",
      "[epoch 1] loss: 214.05\n",
      "[epoch 2] loss: 105.46\n",
      "[epoch 3] loss: 77.21\n",
      "[epoch 4] loss: 62.36\n",
      "[epoch 5] loss: 52.96\n",
      "[epoch 6] loss: 46.42\n",
      "[epoch 7] loss: 41.57\n",
      "[epoch 8] loss: 37.81\n",
      "[epoch 9] loss: 34.75\n",
      "[epoch 10] loss: 32.26\n",
      "[epoch 11] loss: 30.16\n",
      "[epoch 12] loss: 28.34\n",
      "[epoch 13] loss: 26.75\n",
      "[epoch 14] loss: 25.34\n",
      "[epoch 15] loss: 24.09\n",
      "[epoch 16] loss: 22.95\n",
      "[epoch 17] loss: 21.94\n",
      "[epoch 18] loss: 21.03\n",
      "[epoch 19] loss: 20.17\n",
      "[epoch 20] loss: 19.38\n",
      "[epoch 21] loss: 18.65\n",
      "[epoch 22] loss: 17.99\n",
      "[epoch 23] loss: 17.36\n",
      "[epoch 24] loss: 16.75\n",
      "[epoch 25] loss: 16.19\n",
      "[epoch 1] loss: 249.41\n",
      "[epoch 2] loss: 112.39\n",
      "[epoch 3] loss: 81.48\n",
      "[epoch 4] loss: 65.77\n",
      "[epoch 5] loss: 55.92\n",
      "[epoch 6] loss: 49.13\n",
      "[epoch 7] loss: 44.00\n",
      "[epoch 8] loss: 39.94\n",
      "[epoch 9] loss: 36.62\n",
      "[epoch 10] loss: 33.86\n",
      "[epoch 11] loss: 31.49\n",
      "[epoch 12] loss: 29.43\n",
      "[epoch 13] loss: 27.64\n",
      "[epoch 14] loss: 26.07\n",
      "[epoch 15] loss: 24.70\n",
      "[epoch 16] loss: 23.45\n",
      "[epoch 17] loss: 22.31\n",
      "[epoch 18] loss: 21.30\n",
      "[epoch 19] loss: 20.38\n",
      "[epoch 20] loss: 19.54\n",
      "[epoch 21] loss: 18.76\n",
      "[epoch 22] loss: 18.03\n",
      "[epoch 23] loss: 17.35\n",
      "[epoch 24] loss: 16.72\n",
      "[epoch 25] loss: 16.14\n",
      "[epoch 1] loss: 174.48\n",
      "[epoch 2] loss: 43.46\n",
      "[epoch 3] loss: 28.32\n",
      "[epoch 4] loss: 20.73\n",
      "[epoch 5] loss: 15.99\n",
      "[epoch 6] loss: 12.68\n",
      "[epoch 7] loss: 10.44\n",
      "[epoch 8] loss: 8.68\n",
      "[epoch 9] loss: 7.33\n",
      "[epoch 10] loss: 6.29\n",
      "[epoch 11] loss: 5.44\n",
      "[epoch 12] loss: 4.76\n",
      "[epoch 13] loss: 4.15\n",
      "[epoch 14] loss: 3.63\n",
      "[epoch 15] loss: 3.22\n",
      "[epoch 16] loss: 2.87\n",
      "[epoch 17] loss: 2.58\n",
      "[epoch 18] loss: 2.34\n",
      "[epoch 19] loss: 2.13\n",
      "[epoch 20] loss: 1.95\n",
      "[epoch 21] loss: 1.80\n",
      "[epoch 22] loss: 1.66\n",
      "[epoch 23] loss: 1.53\n",
      "[epoch 24] loss: 1.42\n",
      "[epoch 25] loss: 1.33\n",
      "[epoch 1] loss: 164.53\n",
      "[epoch 2] loss: 45.15\n",
      "[epoch 3] loss: 30.47\n",
      "[epoch 4] loss: 23.45\n",
      "[epoch 5] loss: 18.63\n",
      "[epoch 6] loss: 15.40\n",
      "[epoch 7] loss: 12.95\n",
      "[epoch 8] loss: 11.05\n",
      "[epoch 9] loss: 9.51\n",
      "[epoch 10] loss: 8.23\n",
      "[epoch 11] loss: 7.20\n",
      "[epoch 12] loss: 6.31\n",
      "[epoch 13] loss: 5.53\n",
      "[epoch 14] loss: 4.89\n",
      "[epoch 15] loss: 4.35\n",
      "[epoch 16] loss: 3.88\n",
      "[epoch 17] loss: 3.48\n",
      "[epoch 18] loss: 3.12\n",
      "[epoch 19] loss: 2.81\n",
      "[epoch 20] loss: 2.54\n",
      "[epoch 21] loss: 2.32\n",
      "[epoch 22] loss: 2.12\n",
      "[epoch 23] loss: 1.95\n",
      "[epoch 24] loss: 1.81\n",
      "[epoch 25] loss: 1.67\n",
      "[epoch 1] loss: 150.28\n",
      "[epoch 2] loss: 40.01\n",
      "[epoch 3] loss: 25.99\n",
      "[epoch 4] loss: 19.20\n",
      "[epoch 5] loss: 14.94\n",
      "[epoch 6] loss: 12.07\n",
      "[epoch 7] loss: 9.85\n",
      "[epoch 8] loss: 8.15\n",
      "[epoch 9] loss: 6.80\n",
      "[epoch 10] loss: 5.83\n",
      "[epoch 11] loss: 5.02\n",
      "[epoch 12] loss: 4.37\n",
      "[epoch 13] loss: 3.85\n",
      "[epoch 14] loss: 3.40\n",
      "[epoch 15] loss: 3.04\n",
      "[epoch 16] loss: 2.72\n",
      "[epoch 17] loss: 2.45\n",
      "[epoch 18] loss: 2.23\n",
      "[epoch 19] loss: 2.02\n",
      "[epoch 20] loss: 1.85\n",
      "[epoch 21] loss: 1.70\n",
      "[epoch 22] loss: 1.57\n",
      "[epoch 23] loss: 1.45\n",
      "[epoch 24] loss: 1.34\n",
      "[epoch 25] loss: 1.26\n",
      "[epoch 1] loss: 203.02\n",
      "[epoch 2] loss: 45.46\n",
      "[epoch 3] loss: 30.81\n",
      "[epoch 4] loss: 23.39\n",
      "[epoch 5] loss: 18.63\n",
      "[epoch 6] loss: 15.03\n",
      "[epoch 7] loss: 12.50\n",
      "[epoch 8] loss: 10.62\n",
      "[epoch 9] loss: 9.05\n",
      "[epoch 10] loss: 7.88\n",
      "[epoch 11] loss: 6.79\n",
      "[epoch 12] loss: 5.93\n",
      "[epoch 13] loss: 5.24\n",
      "[epoch 14] loss: 4.62\n",
      "[epoch 15] loss: 4.13\n",
      "[epoch 16] loss: 3.70\n",
      "[epoch 17] loss: 3.34\n",
      "[epoch 18] loss: 3.03\n",
      "[epoch 19] loss: 2.77\n",
      "[epoch 20] loss: 2.53\n",
      "[epoch 21] loss: 2.32\n",
      "[epoch 22] loss: 2.14\n",
      "[epoch 23] loss: 1.98\n",
      "[epoch 24] loss: 1.84\n",
      "[epoch 25] loss: 1.71\n",
      "[epoch 1] loss: 155.44\n",
      "[epoch 2] loss: 49.52\n",
      "[epoch 3] loss: 33.95\n",
      "[epoch 4] loss: 26.14\n",
      "[epoch 5] loss: 21.15\n",
      "[epoch 6] loss: 17.57\n",
      "[epoch 7] loss: 14.91\n",
      "[epoch 8] loss: 12.82\n",
      "[epoch 9] loss: 11.09\n",
      "[epoch 10] loss: 9.74\n",
      "[epoch 11] loss: 8.61\n",
      "[epoch 12] loss: 7.54\n",
      "[epoch 13] loss: 6.67\n",
      "[epoch 14] loss: 5.94\n",
      "[epoch 15] loss: 5.32\n",
      "[epoch 16] loss: 4.77\n",
      "[epoch 17] loss: 4.29\n",
      "[epoch 18] loss: 3.88\n",
      "[epoch 19] loss: 3.50\n",
      "[epoch 20] loss: 3.19\n",
      "[epoch 21] loss: 2.87\n",
      "[epoch 22] loss: 2.64\n",
      "[epoch 23] loss: 2.40\n",
      "[epoch 24] loss: 2.22\n",
      "[epoch 25] loss: 2.02\n",
      "[epoch 1] loss: 478.92\n",
      "[epoch 2] loss: 37.86\n",
      "[epoch 3] loss: 20.01\n",
      "[epoch 4] loss: 13.22\n",
      "[epoch 5] loss: 9.05\n",
      "[epoch 6] loss: 6.22\n",
      "[epoch 7] loss: 4.16\n",
      "[epoch 8] loss: 3.14\n",
      "[epoch 9] loss: 2.01\n",
      "[epoch 10] loss: 1.48\n",
      "[epoch 11] loss: 1.07\n",
      "[epoch 12] loss: 0.79\n",
      "[epoch 13] loss: 0.53\n",
      "[epoch 14] loss: 0.39\n",
      "[epoch 15] loss: 0.33\n",
      "[epoch 16] loss: 0.28\n",
      "[epoch 17] loss: 0.25\n",
      "[epoch 18] loss: 0.22\n",
      "[epoch 19] loss: 0.20\n",
      "[epoch 20] loss: 0.18\n",
      "[epoch 21] loss: 0.16\n",
      "[epoch 22] loss: 0.15\n",
      "[epoch 23] loss: 0.14\n",
      "[epoch 24] loss: 0.13\n",
      "[epoch 25] loss: 0.12\n",
      "[epoch 1] loss: 429.64\n",
      "[epoch 2] loss: 50.00\n",
      "[epoch 3] loss: 26.59\n",
      "[epoch 4] loss: 17.86\n",
      "[epoch 5] loss: 12.44\n",
      "[epoch 6] loss: 8.65\n",
      "[epoch 7] loss: 5.88\n",
      "[epoch 8] loss: 4.15\n",
      "[epoch 9] loss: 3.29\n",
      "[epoch 10] loss: 2.11\n",
      "[epoch 11] loss: 1.36\n",
      "[epoch 12] loss: 0.99\n",
      "[epoch 13] loss: 0.71\n",
      "[epoch 14] loss: 0.54\n",
      "[epoch 15] loss: 0.43\n",
      "[epoch 16] loss: 0.36\n",
      "[epoch 17] loss: 0.31\n",
      "[epoch 18] loss: 0.26\n",
      "[epoch 19] loss: 0.23\n",
      "[epoch 20] loss: 0.20\n",
      "[epoch 21] loss: 0.18\n",
      "[epoch 22] loss: 0.17\n",
      "[epoch 23] loss: 0.15\n",
      "[epoch 24] loss: 0.14\n",
      "[epoch 25] loss: 0.13\n",
      "[epoch 1] loss: 1132.92\n",
      "[epoch 2] loss: 74.75\n",
      "[epoch 3] loss: 41.21\n",
      "[epoch 4] loss: 28.90\n",
      "[epoch 5] loss: 22.13\n",
      "[epoch 6] loss: 18.10\n",
      "[epoch 7] loss: 14.93\n",
      "[epoch 8] loss: 12.36\n",
      "[epoch 9] loss: 10.57\n",
      "[epoch 10] loss: 8.91\n",
      "[epoch 11] loss: 7.31\n",
      "[epoch 12] loss: 6.24\n",
      "[epoch 13] loss: 5.38\n",
      "[epoch 14] loss: 4.17\n",
      "[epoch 15] loss: 3.35\n",
      "[epoch 16] loss: 2.71\n",
      "[epoch 17] loss: 2.06\n",
      "[epoch 18] loss: 1.64\n",
      "[epoch 19] loss: 1.25\n",
      "[epoch 20] loss: 0.95\n",
      "[epoch 21] loss: 0.73\n",
      "[epoch 22] loss: 0.58\n",
      "[epoch 23] loss: 0.49\n",
      "[epoch 24] loss: 0.40\n",
      "[epoch 25] loss: 0.36\n",
      "[epoch 1] loss: 518.27\n",
      "[epoch 2] loss: 64.37\n",
      "[epoch 3] loss: 36.06\n",
      "[epoch 4] loss: 27.80\n",
      "[epoch 5] loss: 23.55\n",
      "[epoch 6] loss: 18.89\n",
      "[epoch 7] loss: 14.93\n",
      "[epoch 8] loss: 14.11\n",
      "[epoch 9] loss: 9.97\n",
      "[epoch 10] loss: 7.91\n",
      "[epoch 11] loss: 8.67\n",
      "[epoch 12] loss: 6.46\n",
      "[epoch 13] loss: 4.97\n",
      "[epoch 14] loss: 5.54\n",
      "[epoch 15] loss: 4.90\n",
      "[epoch 16] loss: 3.32\n",
      "[epoch 17] loss: 2.16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 18] loss: 1.56\n",
      "[epoch 19] loss: 1.44\n",
      "[epoch 20] loss: 0.68\n",
      "[epoch 21] loss: 0.53\n",
      "[epoch 22] loss: 0.58\n",
      "[epoch 23] loss: 0.36\n",
      "[epoch 24] loss: 0.26\n",
      "[epoch 25] loss: 0.21\n",
      "[epoch 1] loss: 328.65\n",
      "[epoch 2] loss: 26.42\n",
      "[epoch 3] loss: 14.87\n",
      "[epoch 4] loss: 9.95\n",
      "[epoch 5] loss: 6.67\n",
      "[epoch 6] loss: 4.18\n",
      "[epoch 7] loss: 2.61\n",
      "[epoch 8] loss: 1.65\n",
      "[epoch 9] loss: 1.12\n",
      "[epoch 10] loss: 0.82\n",
      "[epoch 11] loss: 0.62\n",
      "[epoch 12] loss: 0.48\n",
      "[epoch 13] loss: 0.40\n",
      "[epoch 14] loss: 0.34\n",
      "[epoch 15] loss: 0.29\n",
      "[epoch 16] loss: 0.26\n",
      "[epoch 17] loss: 0.23\n",
      "[epoch 18] loss: 0.20\n",
      "[epoch 19] loss: 0.18\n",
      "[epoch 20] loss: 0.17\n",
      "[epoch 21] loss: 0.15\n",
      "[epoch 22] loss: 0.14\n",
      "[epoch 23] loss: 0.13\n",
      "[epoch 24] loss: 0.12\n",
      "[epoch 25] loss: 0.11\n",
      "[epoch 1] loss: 266.24\n",
      "[epoch 2] loss: 113.32\n",
      "[epoch 3] loss: 75.67\n",
      "[epoch 4] loss: 57.60\n",
      "[epoch 5] loss: 47.02\n",
      "[epoch 6] loss: 40.08\n",
      "[epoch 7] loss: 35.11\n",
      "[epoch 8] loss: 31.40\n",
      "[epoch 9] loss: 28.43\n",
      "[epoch 10] loss: 26.05\n",
      "[epoch 11] loss: 24.10\n",
      "[epoch 12] loss: 22.47\n",
      "[epoch 13] loss: 21.07\n",
      "[epoch 14] loss: 19.84\n",
      "[epoch 15] loss: 18.75\n",
      "[epoch 16] loss: 17.78\n",
      "[epoch 17] loss: 16.89\n",
      "[epoch 18] loss: 16.07\n",
      "[epoch 19] loss: 15.32\n",
      "[epoch 20] loss: 14.63\n",
      "[epoch 21] loss: 14.00\n",
      "[epoch 22] loss: 13.41\n",
      "[epoch 23] loss: 12.86\n",
      "[epoch 24] loss: 12.36\n",
      "[epoch 25] loss: 11.89\n",
      "[epoch 1] loss: 217.86\n",
      "[epoch 2] loss: 99.29\n",
      "[epoch 3] loss: 71.17\n",
      "[epoch 4] loss: 57.41\n",
      "[epoch 5] loss: 48.91\n",
      "[epoch 6] loss: 42.89\n",
      "[epoch 7] loss: 38.37\n",
      "[epoch 8] loss: 34.80\n",
      "[epoch 9] loss: 31.91\n",
      "[epoch 10] loss: 29.52\n",
      "[epoch 11] loss: 27.50\n",
      "[epoch 12] loss: 25.76\n",
      "[epoch 13] loss: 24.24\n",
      "[epoch 14] loss: 22.88\n",
      "[epoch 15] loss: 21.65\n",
      "[epoch 16] loss: 20.55\n",
      "[epoch 17] loss: 19.55\n",
      "[epoch 18] loss: 18.62\n",
      "[epoch 19] loss: 17.77\n",
      "[epoch 20] loss: 16.99\n",
      "[epoch 21] loss: 16.28\n",
      "[epoch 22] loss: 15.62\n",
      "[epoch 23] loss: 15.01\n",
      "[epoch 24] loss: 14.44\n",
      "[epoch 25] loss: 13.92\n",
      "[epoch 1] loss: 244.97\n",
      "[epoch 2] loss: 98.83\n",
      "[epoch 3] loss: 70.43\n",
      "[epoch 4] loss: 56.80\n",
      "[epoch 5] loss: 48.34\n",
      "[epoch 6] loss: 42.66\n",
      "[epoch 7] loss: 38.44\n",
      "[epoch 8] loss: 35.10\n",
      "[epoch 9] loss: 32.43\n",
      "[epoch 10] loss: 30.21\n",
      "[epoch 11] loss: 28.29\n",
      "[epoch 12] loss: 26.64\n",
      "[epoch 13] loss: 25.20\n",
      "[epoch 14] loss: 23.89\n",
      "[epoch 15] loss: 22.76\n",
      "[epoch 16] loss: 21.69\n",
      "[epoch 17] loss: 20.73\n",
      "[epoch 18] loss: 19.85\n",
      "[epoch 19] loss: 19.04\n",
      "[epoch 20] loss: 18.28\n",
      "[epoch 21] loss: 17.60\n",
      "[epoch 22] loss: 16.97\n",
      "[epoch 23] loss: 16.36\n",
      "[epoch 24] loss: 15.80\n",
      "[epoch 25] loss: 15.27\n",
      "[epoch 1] loss: 212.63\n",
      "[epoch 2] loss: 95.41\n",
      "[epoch 3] loss: 72.05\n",
      "[epoch 4] loss: 59.35\n",
      "[epoch 5] loss: 51.00\n",
      "[epoch 6] loss: 44.93\n",
      "[epoch 7] loss: 40.27\n",
      "[epoch 8] loss: 36.72\n",
      "[epoch 9] loss: 33.84\n",
      "[epoch 10] loss: 31.45\n",
      "[epoch 11] loss: 29.42\n",
      "[epoch 12] loss: 27.64\n",
      "[epoch 13] loss: 26.09\n",
      "[epoch 14] loss: 24.72\n",
      "[epoch 15] loss: 23.50\n",
      "[epoch 16] loss: 22.40\n",
      "[epoch 17] loss: 21.40\n",
      "[epoch 18] loss: 20.49\n",
      "[epoch 19] loss: 19.67\n",
      "[epoch 20] loss: 18.91\n",
      "[epoch 21] loss: 18.21\n",
      "[epoch 22] loss: 17.57\n",
      "[epoch 23] loss: 16.95\n",
      "[epoch 24] loss: 16.37\n",
      "[epoch 25] loss: 15.83\n",
      "[epoch 1] loss: 241.72\n",
      "[epoch 2] loss: 115.57\n",
      "[epoch 3] loss: 80.32\n",
      "[epoch 4] loss: 63.21\n",
      "[epoch 5] loss: 52.78\n",
      "[epoch 6] loss: 45.68\n",
      "[epoch 7] loss: 40.50\n",
      "[epoch 8] loss: 36.53\n",
      "[epoch 9] loss: 33.38\n",
      "[epoch 10] loss: 30.80\n",
      "[epoch 11] loss: 28.62\n",
      "[epoch 12] loss: 26.75\n",
      "[epoch 13] loss: 25.14\n",
      "[epoch 14] loss: 23.72\n",
      "[epoch 15] loss: 22.47\n",
      "[epoch 16] loss: 21.35\n",
      "[epoch 17] loss: 20.34\n",
      "[epoch 18] loss: 19.44\n",
      "[epoch 19] loss: 18.61\n",
      "[epoch 20] loss: 17.85\n",
      "[epoch 21] loss: 17.15\n",
      "[epoch 22] loss: 16.50\n",
      "[epoch 23] loss: 15.89\n",
      "[epoch 24] loss: 15.32\n",
      "[epoch 25] loss: 14.78\n",
      "[epoch 1] loss: 157.16\n",
      "[epoch 2] loss: 39.26\n",
      "[epoch 3] loss: 26.25\n",
      "[epoch 4] loss: 19.70\n",
      "[epoch 5] loss: 15.59\n",
      "[epoch 6] loss: 12.50\n",
      "[epoch 7] loss: 10.14\n",
      "[epoch 8] loss: 8.41\n",
      "[epoch 9] loss: 6.99\n",
      "[epoch 10] loss: 5.89\n",
      "[epoch 11] loss: 5.01\n",
      "[epoch 12] loss: 4.34\n",
      "[epoch 13] loss: 3.76\n",
      "[epoch 14] loss: 3.29\n",
      "[epoch 15] loss: 2.90\n",
      "[epoch 16] loss: 2.58\n",
      "[epoch 17] loss: 2.32\n",
      "[epoch 18] loss: 2.10\n",
      "[epoch 19] loss: 1.91\n",
      "[epoch 20] loss: 1.75\n",
      "[epoch 21] loss: 1.61\n",
      "[epoch 22] loss: 1.49\n",
      "[epoch 23] loss: 1.38\n",
      "[epoch 24] loss: 1.29\n",
      "[epoch 25] loss: 1.20\n",
      "[epoch 1] loss: 142.88\n",
      "[epoch 2] loss: 37.11\n",
      "[epoch 3] loss: 25.09\n",
      "[epoch 4] loss: 18.96\n",
      "[epoch 5] loss: 15.09\n",
      "[epoch 6] loss: 12.41\n",
      "[epoch 7] loss: 10.36\n",
      "[epoch 8] loss: 8.72\n",
      "[epoch 9] loss: 7.48\n",
      "[epoch 10] loss: 6.46\n",
      "[epoch 11] loss: 5.61\n",
      "[epoch 12] loss: 4.87\n",
      "[epoch 13] loss: 4.28\n",
      "[epoch 14] loss: 3.77\n",
      "[epoch 15] loss: 3.33\n",
      "[epoch 16] loss: 2.98\n",
      "[epoch 17] loss: 2.66\n",
      "[epoch 18] loss: 2.38\n",
      "[epoch 19] loss: 2.12\n",
      "[epoch 20] loss: 1.93\n",
      "[epoch 21] loss: 1.75\n",
      "[epoch 22] loss: 1.60\n",
      "[epoch 23] loss: 1.47\n",
      "[epoch 24] loss: 1.36\n",
      "[epoch 25] loss: 1.27\n",
      "[epoch 1] loss: 206.77\n",
      "[epoch 2] loss: 41.89\n",
      "[epoch 3] loss: 28.23\n",
      "[epoch 4] loss: 21.25\n",
      "[epoch 5] loss: 16.35\n",
      "[epoch 6] loss: 12.98\n",
      "[epoch 7] loss: 10.60\n",
      "[epoch 8] loss: 8.64\n",
      "[epoch 9] loss: 7.27\n",
      "[epoch 10] loss: 6.11\n",
      "[epoch 11] loss: 5.14\n",
      "[epoch 12] loss: 4.35\n",
      "[epoch 13] loss: 3.75\n",
      "[epoch 14] loss: 3.26\n",
      "[epoch 15] loss: 2.83\n",
      "[epoch 16] loss: 2.52\n",
      "[epoch 17] loss: 2.24\n",
      "[epoch 18] loss: 2.01\n",
      "[epoch 19] loss: 1.82\n",
      "[epoch 20] loss: 1.65\n",
      "[epoch 21] loss: 1.51\n",
      "[epoch 22] loss: 1.39\n",
      "[epoch 23] loss: 1.28\n",
      "[epoch 24] loss: 1.19\n",
      "[epoch 25] loss: 1.11\n",
      "[epoch 1] loss: 191.88\n",
      "[epoch 2] loss: 41.91\n",
      "[epoch 3] loss: 27.55\n",
      "[epoch 4] loss: 20.30\n",
      "[epoch 5] loss: 15.98\n",
      "[epoch 6] loss: 13.04\n",
      "[epoch 7] loss: 10.83\n",
      "[epoch 8] loss: 9.22\n",
      "[epoch 9] loss: 7.86\n",
      "[epoch 10] loss: 6.77\n",
      "[epoch 11] loss: 5.88\n",
      "[epoch 12] loss: 5.13\n",
      "[epoch 13] loss: 4.50\n",
      "[epoch 14] loss: 3.99\n",
      "[epoch 15] loss: 3.54\n",
      "[epoch 16] loss: 3.15\n",
      "[epoch 17] loss: 2.82\n",
      "[epoch 18] loss: 2.53\n",
      "[epoch 19] loss: 2.30\n",
      "[epoch 20] loss: 2.08\n",
      "[epoch 21] loss: 1.91\n",
      "[epoch 22] loss: 1.76\n",
      "[epoch 23] loss: 1.62\n",
      "[epoch 24] loss: 1.50\n",
      "[epoch 25] loss: 1.40\n",
      "[epoch 1] loss: 176.30\n",
      "[epoch 2] loss: 38.96\n",
      "[epoch 3] loss: 25.78\n",
      "[epoch 4] loss: 19.21\n",
      "[epoch 5] loss: 15.15\n",
      "[epoch 6] loss: 12.23\n",
      "[epoch 7] loss: 10.14\n",
      "[epoch 8] loss: 8.47\n",
      "[epoch 9] loss: 7.20\n",
      "[epoch 10] loss: 6.15\n",
      "[epoch 11] loss: 5.25\n",
      "[epoch 12] loss: 4.56\n",
      "[epoch 13] loss: 3.94\n",
      "[epoch 14] loss: 3.46\n",
      "[epoch 15] loss: 3.04\n",
      "[epoch 16] loss: 2.69\n",
      "[epoch 17] loss: 2.40\n",
      "[epoch 18] loss: 2.17\n",
      "[epoch 19] loss: 1.97\n",
      "[epoch 20] loss: 1.80\n",
      "[epoch 21] loss: 1.66\n",
      "[epoch 22] loss: 1.53\n",
      "[epoch 23] loss: 1.42\n",
      "[epoch 24] loss: 1.32\n",
      "[epoch 25] loss: 1.23\n",
      "[epoch 1] loss: 282.02\n",
      "[epoch 2] loss: 37.44\n",
      "[epoch 3] loss: 23.89\n",
      "[epoch 4] loss: 15.20\n",
      "[epoch 5] loss: 10.61\n",
      "[epoch 6] loss: 7.12\n",
      "[epoch 7] loss: 4.51\n",
      "[epoch 8] loss: 2.82\n",
      "[epoch 9] loss: 1.72\n",
      "[epoch 10] loss: 1.06\n",
      "[epoch 11] loss: 0.75\n",
      "[epoch 12] loss: 0.56\n",
      "[epoch 13] loss: 0.42\n",
      "[epoch 14] loss: 0.33\n",
      "[epoch 15] loss: 0.28\n",
      "[epoch 16] loss: 0.24\n",
      "[epoch 17] loss: 0.22\n",
      "[epoch 18] loss: 0.19\n",
      "[epoch 19] loss: 0.17\n",
      "[epoch 20] loss: 0.16\n",
      "[epoch 21] loss: 0.14\n",
      "[epoch 22] loss: 0.13\n",
      "[epoch 23] loss: 0.12\n",
      "[epoch 24] loss: 0.11\n",
      "[epoch 25] loss: 0.10\n",
      "[epoch 1] loss: 367.21\n",
      "[epoch 2] loss: 30.78\n",
      "[epoch 3] loss: 17.65\n",
      "[epoch 4] loss: 11.35\n",
      "[epoch 5] loss: 7.29\n",
      "[epoch 6] loss: 4.88\n",
      "[epoch 7] loss: 2.74\n",
      "[epoch 8] loss: 1.61\n",
      "[epoch 9] loss: 0.93\n",
      "[epoch 10] loss: 0.63\n",
      "[epoch 11] loss: 0.46\n",
      "[epoch 12] loss: 0.35\n",
      "[epoch 13] loss: 0.29\n",
      "[epoch 14] loss: 0.25\n",
      "[epoch 15] loss: 0.22\n",
      "[epoch 16] loss: 0.19\n",
      "[epoch 17] loss: 0.17\n",
      "[epoch 18] loss: 0.16\n",
      "[epoch 19] loss: 0.14\n",
      "[epoch 20] loss: 0.13\n",
      "[epoch 21] loss: 0.12\n",
      "[epoch 22] loss: 0.11\n",
      "[epoch 23] loss: 0.11\n",
      "[epoch 24] loss: 0.10\n",
      "[epoch 25] loss: 0.09\n",
      "[epoch 1] loss: 852.68\n",
      "[epoch 2] loss: 83.63\n",
      "[epoch 3] loss: 32.00\n",
      "[epoch 4] loss: 20.19\n",
      "[epoch 5] loss: 14.18\n",
      "[epoch 6] loss: 10.58\n",
      "[epoch 7] loss: 7.62\n",
      "[epoch 8] loss: 4.89\n",
      "[epoch 9] loss: 3.35\n",
      "[epoch 10] loss: 2.09\n",
      "[epoch 11] loss: 1.42\n",
      "[epoch 12] loss: 1.03\n",
      "[epoch 13] loss: 0.77\n",
      "[epoch 14] loss: 0.57\n",
      "[epoch 15] loss: 0.46\n",
      "[epoch 16] loss: 0.38\n",
      "[epoch 17] loss: 0.32\n",
      "[epoch 18] loss: 0.27\n",
      "[epoch 19] loss: 0.24\n",
      "[epoch 20] loss: 0.22\n",
      "[epoch 21] loss: 0.19\n",
      "[epoch 22] loss: 0.17\n",
      "[epoch 23] loss: 0.16\n",
      "[epoch 24] loss: 0.15\n",
      "[epoch 25] loss: 0.13\n",
      "[epoch 1] loss: 644.59\n",
      "[epoch 2] loss: 49.75\n",
      "[epoch 3] loss: 26.76\n",
      "[epoch 4] loss: 16.42\n",
      "[epoch 5] loss: 10.88\n",
      "[epoch 6] loss: 7.43\n",
      "[epoch 7] loss: 5.06\n",
      "[epoch 8] loss: 3.40\n",
      "[epoch 9] loss: 2.25\n",
      "[epoch 10] loss: 1.42\n",
      "[epoch 11] loss: 0.92\n",
      "[epoch 12] loss: 0.70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 13] loss: 0.53\n",
      "[epoch 14] loss: 0.42\n",
      "[epoch 15] loss: 0.35\n",
      "[epoch 16] loss: 0.31\n",
      "[epoch 17] loss: 0.27\n",
      "[epoch 18] loss: 0.24\n",
      "[epoch 19] loss: 0.21\n",
      "[epoch 20] loss: 0.19\n",
      "[epoch 21] loss: 0.17\n",
      "[epoch 22] loss: 0.16\n",
      "[epoch 23] loss: 0.15\n",
      "[epoch 24] loss: 0.14\n",
      "[epoch 25] loss: 0.13\n",
      "[epoch 1] loss: 378.64\n",
      "[epoch 2] loss: 25.99\n",
      "[epoch 3] loss: 15.03\n",
      "[epoch 4] loss: 9.11\n",
      "[epoch 5] loss: 5.76\n",
      "[epoch 6] loss: 3.79\n",
      "[epoch 7] loss: 2.32\n",
      "[epoch 8] loss: 1.61\n",
      "[epoch 9] loss: 1.20\n",
      "[epoch 10] loss: 0.84\n",
      "[epoch 11] loss: 0.60\n",
      "[epoch 12] loss: 0.45\n",
      "[epoch 13] loss: 0.36\n",
      "[epoch 14] loss: 0.30\n",
      "[epoch 15] loss: 0.26\n",
      "[epoch 16] loss: 0.23\n",
      "[epoch 17] loss: 0.20\n",
      "[epoch 18] loss: 0.18\n",
      "[epoch 19] loss: 0.16\n",
      "[epoch 20] loss: 0.15\n",
      "[epoch 21] loss: 0.14\n",
      "[epoch 22] loss: 0.13\n",
      "[epoch 23] loss: 0.12\n",
      "[epoch 24] loss: 0.11\n",
      "[epoch 25] loss: 0.10\n"
     ]
    }
   ],
   "source": [
    "nb_iter = 5\n",
    "nhs = [20, 50, 100, 200]\n",
    "lrs = [1e-4, 1e-3, 1e-2] #1e-1 too high\n",
    "\n",
    "train_error_storage = np.zeros([len(nhs), len(lrs)])\n",
    "test_error_storage = np.zeros([len(nhs), len(lrs)])\n",
    "\n",
    "for i in range(len(nhs)):\n",
    "    for j in range(len(lrs)):\n",
    "        train_error = []\n",
    "        test_error = []\n",
    "        \n",
    "        for k in range(nb_iter):\n",
    "            model = Net(nhs[i])\n",
    "            train_model(model, train_input, train_classes, criterion, lrs[j], nb_epochs)    \n",
    "            \n",
    "            \n",
    "            train_error.append(\n",
    "                compute_target_error(model, train_input, train_target) / nb_pairs * 100)\n",
    "            test_error.append(\n",
    "                compute_target_error(model, test_input, test_target) / nb_pairs * 100)\n",
    "\n",
    "    avg_train = sum(train_error) / nb_iter\n",
    "    avg_test = sum(test_error) / nb_iter\n",
    "        \n",
    "    train_error_storage[i,j] = avg_train\n",
    "    test_error_storage[i,j] = avg_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "fig = sns.heatmap(test_error_storage)\n",
    "#fig.set_yticks()\n",
    "fig.set_xlabel('Hidden layers')\n",
    "fig.set_ylabel('Learning rate')\n",
    "fig.set_title('Training error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.  ,  0.  , 29.82],\n",
       "       [ 0.  ,  0.  ,  4.44],\n",
       "       [ 0.  ,  0.  ,  3.9 ],\n",
       "       [ 0.  ,  0.  ,  3.42]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_error_storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVoAAAD8CAYAAAA2Y2wxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAD0RJREFUeJzt3XusZWdZx/Hv78xMaRmwRQukzFRbIkgQtA1DIRIJFNByCfUPTChSiCkeYgIUlXAJf1RMMHgDTbzEE1uF2JRwaYRAgzaGUlDobSzYMqAICNMCtREs1Yb2nP34x97jHOeyb2e9s/dZ8/1MVrrPWnu9+5md9jlPn/W+a6WqkCS1s7LoACSp70y0ktSYiVaSGjPRSlJjJlpJasxEK0mNmWglqTETrSQ1ZqKVpMZ2Nv+AU/a49Ewa44G7P73oEJbGrjMfn62O8dC9X50653TxedOwopWkxppXtJJ0Qg02Fh3BUUy0kvplY33RERzFRCupV6oGiw7hKCZaSf0yMNFKUltWtJLUmBfDJKkxK1pJaqucdSBJjXkxTJIas3UgSY15MUySGrOilaTGvBgmSY15MUyS2qqyRytJbdmjlaTGbB1IUmPbsaJN8iTgYmAPUMDdwEer6kDj2CRpdhsPdTpckh3ArcBdVfWSJOcC7wd+GNgPXFpVD44bY+wzw5K8ZTRggJuBW0avr0ny1q3/FSSpY4PB9Nt0Lgc2F5a/A7ynqp4AfBe4bNIAkyray4CfrKr/9ysiybuBO4F3HeukJKvAKkB2nM7Kyu5JcUhSNzpsHSTZC7wYeCfw60kCXAi8YvSW9wK/CfzZuHEmPQV3ADzuGPvPGh07pqpaq6p9VbXPJCvphOq2ov1D4M0cznc/Anyvqg6tijjIsK061qSK9o3A3yf5V+Cbo30/Cvw48LppopSkE2qGWQeb/+97ZK2q1kbHXgLcU1W3JXnOoVOOMUxN+pyxibaqPpHkicAFDLN2GGbwW2oZZwVLOunVDBfDRkl17TiHnwW8NMmLgFOBH2JY4Z6RZOeoqt3LcILAWBNnHdTwkZKfmzZwSVqojnq0VfU24G0Ao4r2TVX1S0k+CLyM4USBVwMfmTTWpB6tJG0v3c86ONJbGF4Y+wrDnu2Vk05wwYKkfmmwYKGqbgBuGL3+KsN26tRMtJL6xSW4ktTYdlyCK0nbyro3/paktqxoJakxe7SS1JgVrSQ1ZkUrSY1Z0UpSY846kKTGauLNtE44E62kfrFHK0mNmWglqTEvhklSYxvL90wCE620YIPvfG3RISyPMx+/9TFsHUhSYyZaSWrMHq0ktVUD59FKUlu2DiSpMWcdSFJjVrSS1JiJVpIa86YyktSYFa0kNeb0LklqzFkHktRW2TqQpMZsHUhSY97rQJIas6KVpMbWu7kYluRU4EbgYQxz5Yeq6ookVwP7gIeAm4HXVtVD48Za6SQiSVoWNZh+G+8HwIVV9dPAecBFSZ4JXA08CXgqcBrwmkkDWdFK6peOWgdVVcD9ox93jbaqqusOvSfJzcDeSWNZ0UrqlRoMpt4mSbIjye3APcD1VXXTpmO7gEuBT0wax0QrqV8GNfWWZDXJrZu21c1DVdVGVZ3HsGq9IMlTNh3+U+DGqvr0pJDmbh0k+eWq+st5z5ekJmZoHVTVGrA2xfu+l+QG4CLgjiRXAI8GXjvN52ylon3HFs6VpDY2Nqbfxkjy6CRnjF6fBjwf+FKS1wA/D1xSNd2k3bEVbZIvHO8Q8Ngx560CqwDZcTorK7uniUWStqzDZ4adBbw3yQ6GRekHqupjSdaBfwc+mwTg2qr6rXEDTWodPJZh5v7uEfsD/OPxTtpcju88Zc/yzR6W1F/dzTr4AnD+MfbP3HKddMLHgEdU1e1HHhj1KyRpuWy3m8pU1WVjjr2i+3AkaYtcgitJjZloJamt2thmrQNJ2nasaCWprQ6nd3XGRCupX0y0ktTY8rVoTbSS+qXWly/Tmmgl9cvy5VkTraR+8WKYJLVmRStJbVnRSlJrVrSS1FatLzqCo5loJfXKdM88OLFMtJL6xUQrSW1Z0UpSYyZaSUdZeey5iw6hV2ojiw7hKCZaSb1iRStJjdXAilaSmrKilaTGqqxoJakpK1pJamzgrANJasuLYZLUmIlWkhqr5bsdrYlWUr8sY0W7sugAJKlLVZl6GyfJ2Uk+meRAkjuTXH7E8TclqSRnTorJilZSr2x0N+tgHfiNqtqf5JHAbUmur6ovJjkbeAHwjWkGsqKV1CtdVbRV9a2q2j96/X3gALBndPg9wJuBqTrCVrSSeqVFjzbJOcD5wE1JXgrcVVWfT6b7LBOtpF6ZZdZBklVgddOutapaO+I9jwA+DLyRYTvh7cDPzRKTiVZSr8xS0Y6S6trxjifZxTDJXl1V1yZ5KnAucKia3QvsT3JBVX37eOOYaCX1ysagm0tPGWbSK4EDVfVugKr6Z+Axm97zdWBfVd07biwvhknqlarptwmeBVwKXJjk9tH2onlisqKV1CuDjm6TWFWfAcYOVlXnTDPWxIo2yZOSPG/UEN68/6JpPkCSTqSupnd1aWyiTfIG4CPA64E7kly86fBvtwxMkubRYeugM5NaB78CPK2q7h/NI/tQknOq6o8YU1JvnjKRHaezsrK7o3AlabyuWgddmpRod1TV/QBV9fUkz2GYbH+MMYl285SJnafsWcJ76Ujqq65mHXRpUkTfTnLeoR9GSfclwJnAU1sGJknzqBm2E2VSRfsqhish/k9VrQOvSvLnzaKSpDltu9ZBVR0cc+wfug9HkrbGp+BKUmNL+BBcE62kfqnxawwWwkQrqVfWbR1IUltWtJLUmD1aSWrMilaSGrOilaTGNqxoJamtBs9m3DITraReGVjRSlJby3i7QBOtpF7xYpgkNTaIrQNJampj0QEcg4lWUq8460CSGnPWgSQ15qwDSWrM1oEkNeb0LklqbMOKVpLasqKVpMZMtJLU2BI+MoyVRQcgSV0azLBNkuSqJPckueOI/a9P8uUkdyb53UnjWNFK6pWOl+D+FfDHwPsO7UjyXOBi4Keq6gdJHjNpEBOtpF7pch5tVd2Y5Jwjdv8q8K6q+sHoPfdMGsfWgaRemaV1kGQ1ya2bttUpPuKJwM8muSnJp5I8fdIJVrSSemWWWQdVtQaszfgRO4FHAc8Eng58IMnjq+q4q3+taCX1Ss2wzekgcG0N3cwwt5857gQTraReGWT6bU5/A1wIkOSJwCnAveNOsHUgqVe6nHWQ5BrgOcCZSQ4CVwBXAVeNpnw9CLx6XNsATLSSembQ4Y0Sq+qS4xx65SzjmGgl9YpLcCWpMW/8LUmNWdFKUmPrWb6admKiTXIBUFV1S5InAxcBX6qq65pHJ0kzWr40OyHRJrkCeCGwM8n1wDOAG4C3Jjm/qt7ZPkRJmt52bB28DDgPeBjwbWBvVd2X5PeAmwATraSl0uX0rq5MWhm2XlUbVfU/wL9V1X0AVfUAY35xbL5Rw2Dw3x2GK0njnYAluDOblGgfTPLw0eunHdqZ5HTGJNqqWquqfVW1b2VldwdhStJ0urzxd1cmtQ6evemei5vj2gW8ullUkjSnjSVsHYxNtIeS7DH238uEmyhI0iJsx4thkrSt1HaraCVpu7GilaTGlnF6l4lWUq8sX5o10UrqmfUlTLUmWkm94sUwSWrMi2GS1JgVrSQ1ZkUrSY1tjH8g7UKYaCX1ivNoJakxe7SS1Jg9WklqzNaBJDVm60CSGnPWgSQ1ZutAkhpbxothkx7OKEnbSs3wZ5Ikv5bkziR3JLkmyanzxGSildQrA2rqbZwke4A3APuq6inADuDl88Rk60BSr1S3F8N2AqcleQh4OHD3PINY0UrqlQ1q6m2cqroL+H3gG8C3gP+qqr+bJyYTraRemaV1kGQ1ya2bttVD4yR5FHAxcC7wOGB3klfOE5OtA0m9MkvroKrWgLXjHH4+8LWq+g+AJNcCPwP89awxmWgl9UqH82i/ATwzycOBB4DnAbfOM5CJVlKvdLUEt6puSvIhYD+wDvwTx69+xzLRSuqVLpfgVtUVwBVbHcdEK6lXXIIrSY2ZaCWpsY4XLHTCRCupV6xoJakxb/wtSY1t1PLdKNFEK6lX7NFKUmP2aCWpMXu0ktTYYAlbBzPfJjHJ+1oEIkld6PJRNl0ZW9Em+eiRu4DnJjkDoKpe2iowSZrHdpx1sBf4IvAXQDFMtPuAPxh30ujmuasA2XE6Kyu7tx6pJE1hO7YO9gG3AW9n+BiHG4AHqupTVfWp451UVWtVta+q9plkJZ1I2651UFUD4D1JPjj653cmnSNJi7SMFe1USbOqDgK/mOTFwH1tQ5Kk+W376V1V9XHg441ikaQt26iNRYdwFNsAknrFJbiS1JhLcCWpMStaSWps2846kKTtYtvPOpCkZbcdl+BK0rZij1aSGrNHK0mNWdFKUmPOo5WkxqxoJakxZx1IUmPLeDFs5meGSdIyq6qpt0mSXJTky0m+kuSt88ZkopXUK109YSHJDuBPgBcCTwYuSfLkeWIy0UrqlQ4r2guAr1TVV6vqQeD9wMXzxGSPVlKvdNij3QN8c9PPB4FnzDNQ80S7/uBdaf0Z00iyWlVri45jGfhdHOZ3cVhfvotZcs7mJ3aPrG36Do41zlxZ/GRqHaxOfstJw+/iML+Lw06672LzE7tH2+ZfNAeBszf9vBe4e57POZkSrSTN4hbgCUnOTXIK8HLgo/MMZI9Wko6hqtaTvA74W2AHcFVV3TnPWCdTot32vacO+V0c5ndxmN/FEarqOuC6rY6TZVwXLEl9Yo9WkhrrfaLtagldHyS5Ksk9Se5YdCyLlOTsJJ9MciDJnUkuX3RMi5Lk1CQ3J/n86Lt4x6Jj6qNetw5GS+j+BXgBw6katwCXVNUXFxrYgiR5NnA/8L6qesqi41mUJGcBZ1XV/iSPBG4DfuFk/PciSYDdVXV/kl3AZ4DLq+pzCw6tV/pe0Xa2hK4PqupG4D8XHceiVdW3qmr/6PX3gQMMVwGddGro/tGPu0Zbf6uvBel7oj3WErqT8j8oHVuSc4DzgZsWG8niJNmR5HbgHuD6qjppv4tW+p5oO1tCp/5J8gjgw8Abq+q+RcezKFW1UVXnMVz5dEGSk7at1ErfE21nS+jUL6N+5IeBq6vq2kXHswyq6nvADcBFCw6ld/qeaDtbQqf+GF0AuhI4UFXvXnQ8i5Tk0UnOGL0+DXg+8KXFRtU/vU60VbUOHFpCdwD4wLxL6PogyTXAZ4GfSHIwyWWLjmlBngVcClyY5PbR9qJFB7UgZwGfTPIFhoXJ9VX1sQXH1Du9nt4lScug1xWtJC0DE60kNWailaTGTLSS1JiJVpIaM9FKUmMmWklqzEQrSY39L6k3CE0RWLCWAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.heatmap(train_error_storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0. ,  0. ,  0. , 44.9],\n",
       "       [ 0. ,  0. ,  0. , 42.1],\n",
       "       [ 0. ,  0. ,  0. , 44.9],\n",
       "       [ 0. ,  0. ,  0. , 44.9],\n",
       "       [ 0. ,  0. ,  0. , 44.9]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_error_storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.  ,  0.  ,  0.  , 47.4 ],\n",
       "       [ 0.  ,  0.  ,  0.  , 44.31],\n",
       "       [ 0.  ,  0.  ,  0.  , 47.4 ],\n",
       "       [ 0.  ,  0.  ,  0.  , 47.4 ],\n",
       "       [ 0.  ,  0.  ,  0.  , 47.4 ]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_error_storage"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
